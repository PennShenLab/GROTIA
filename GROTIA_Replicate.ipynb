{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f405430f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f405430f",
        "outputId": "472d5380-6c45-4364-b077-b77a047e5273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/PythonOT/POT/archive/master.zip\n",
            "  Using cached https://github.com/PythonOT/POT/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from POT==0.9.7.dev0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from POT==0.9.7.dev0) (1.10.1)\n",
            "Building wheels for collected packages: POT\n",
            "  Building wheel for POT (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for POT: filename=pot-0.9.7.dev0-cp311-cp311-macosx_15_0_arm64.whl size=468699 sha256=520addbeb5395f39f8cd9c26b291f734565aead564f64b6609c99f856c5c47c1\n",
            "  Stored in directory: /private/var/folders/b7/md0dj4pn73bd0tyht9p6x0cw0000gn/T/pip-ephem-wheel-cache-ppt76xn8/wheels/fc/b3/69/deb9c12f26c4c311bb43fab28b37c7a1faa3c089b07eea1ceb\n",
            "Successfully built POT\n",
            "Installing collected packages: POT\n",
            "  Attempting uninstall: POT\n",
            "    Found existing installation: POT 0.9.6.post1\n",
            "    Uninstalling POT-0.9.6.post1:\n",
            "      Successfully uninstalled POT-0.9.6.post1\n",
            "^Cpt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
            "\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py\", line 40, in global_tempdir_manager\n",
            "    with ExitStack() as stack:\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 601, in __exit__\n",
            "    raise exc_details[1]\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
            "    if cb(*exc_details):\n",
            "       ^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py\", line 167, in __exit__\n",
            "    self.cleanup()\n",
            "  File \"/Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py\", line 210, in cleanup\n",
            "    rmtree(self._path, ignore_errors=False)\n",
            "  File \"/Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages/pip/_internal/utils/retry.py\", line 37, in retry_wrapped\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages/pip/_internal/utils/misc.py\", line 130, in rmtree\n",
            "    shutil.rmtree(dir, onerror=handler)  # type: ignore\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py\", line 752, in rmtree\n",
            "    _rmtree_safe_fd(fd, path, onerror)\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py\", line 672, in _rmtree_safe_fd\n",
            "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py\", line 672, in _rmtree_safe_fd\n",
            "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py\", line 672, in _rmtree_safe_fd\n",
            "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
            "  [Previous line repeated 3 more times]\n",
            "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py\", line 681, in _rmtree_safe_fd\n",
            "    os.rmdir(entry.name, dir_fd=topfd)\n",
            "KeyboardInterrupt\n",
            "Requirement already satisfied: pykeops in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (2.3)\n",
            "Requirement already satisfied: numpy in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pykeops) (1.26.4)\n",
            "Requirement already satisfied: pybind11 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pykeops) (3.0.1)\n",
            "Requirement already satisfied: keopscore==2.3 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pykeops) (2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: geomloss in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (0.2.6)\n",
            "Requirement already satisfied: numpy in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from geomloss) (1.26.4)\n",
            "Requirement already satisfied: torch in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from geomloss) (2.8.0)\n",
            "Requirement already satisfied: filelock in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from torch->geomloss) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from torch->geomloss) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from torch->geomloss) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from torch->geomloss) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from torch->geomloss) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from torch->geomloss) (2023.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from sympy>=1.13.3->torch->geomloss) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from jinja2->torch->geomloss) (3.0.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: muon in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (0.1.7)\n",
            "Requirement already satisfied: numpy in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (1.26.4)\n",
            "Requirement already satisfied: pandas in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (3.10.6)\n",
            "Requirement already satisfied: seaborn in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (0.13.2)\n",
            "Requirement already satisfied: h5py in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (3.14.0)\n",
            "Requirement already satisfied: anndata in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (0.11.4)\n",
            "Requirement already satisfied: scanpy in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (1.8.0)\n",
            "Requirement already satisfied: umap-learn in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (0.5.7)\n",
            "Requirement already satisfied: numba in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (0.62.1)\n",
            "Requirement already satisfied: protobuf in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (6.31.1)\n",
            "Requirement already satisfied: tqdm in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (4.67.1)\n",
            "Requirement already satisfied: mudata in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from muon) (0.3.2)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from anndata->muon) (1.12.0)\n",
            "Requirement already satisfied: natsort in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from anndata->muon) (8.4.0)\n",
            "Requirement already satisfied: packaging>=24.2 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from anndata->muon) (25.0)\n",
            "Requirement already satisfied: scipy>1.8 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from anndata->muon) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pandas->muon) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pandas->muon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pandas->muon) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->muon) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib->muon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib->muon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib->muon) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib->muon) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib->muon) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib->muon) (3.2.5)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from numba->muon) (0.45.1)\n",
            "Requirement already satisfied: joblib in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (1.5.3)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.7.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (3.5)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (0.5.13)\n",
            "Requirement already satisfied: session-info2 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (0.2.3)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (0.14.5)\n",
            "Requirement already satisfied: typing-extensions in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy->muon) (4.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scikit-learn->muon) (3.6.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: scanpy in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (1.11.4)\n",
            "Requirement already satisfied: anndata>=0.8 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.11.4)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (3.14.0)\n",
            "Requirement already satisfied: joblib in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (1.5.3)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (3.10.6)\n",
            "Requirement already satisfied: natsort in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (3.5)\n",
            "Requirement already satisfied: numba>=0.57.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.62.1)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (25.0)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (2.3.0)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.5.13)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (1.8.0)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (1.10.1)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.13.2)\n",
            "Requirement already satisfied: session-info2 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.2.3)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (4.15.0)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scanpy) (0.5.7)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from anndata>=0.8->scanpy) (1.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from numba>=0.57.1->scanpy) (0.45.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Collecting scikit-misc==0.2.0rc1\n",
            "  Using cached https://test-files.pythonhosted.org/packages/4d/6a/71db48ba81a5f36f4e58226baee2121526704202165793ea8d510c06e136/scikit_misc-0.2.0rc1.tar.gz (246 kB)\n",
            "  Installing build dependencies ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Looking in indexes: https://test.pypi.org/simple/\n",
            "  \u001b[31m   \u001b[0m Collecting meson-python>=0.9.0\n",
            "  \u001b[31m   \u001b[0m   Using cached https://test-files.pythonhosted.org/packages/c9/b6/9665154ee9926317a248e2b171ea21ac2b77788adea404566eec29b84f3b/meson_python-0.13.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "  \u001b[31m   \u001b[0m \u001b[31mERROR: Could not find a version that satisfies the requirement Cython>=0.29.32 (from versions: 0.23.4)\u001b[0m\u001b[31m\n",
            "  \u001b[31m   \u001b[0m \u001b[0m\u001b[31mERROR: No matching distribution found for Cython>=0.29.32\u001b[0m\u001b[31m\n",
            "  \u001b[31m   \u001b[0m \u001b[0m\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Requirement already satisfied: numpy==1.26.4 in /Users/aaaaaaaron/venvs/py311-vscode/lib/python3.11/site-packages (1.26.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U https://github.com/PythonOT/POT/archive/master.zip # with --user for user install (no root)\n",
        "!pip install pykeops\n",
        "!pip install geomloss\n",
        "!pip install muon\n",
        "!pip install scanpy\n",
        "!pip install -i https://test.pypi.org/simple/ \"scikit-misc==0.2.0rc1\"\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b0500785",
      "metadata": {
        "id": "b0500785"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib\n",
        "import os\n",
        "import importlib\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.preprocessing import KernelCenterer\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from geomloss import SamplesLoss\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import KernelPCA\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import dijkstra\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "import muon as mu\n",
        "import numpy as np\n",
        "import anndata as ad\n",
        "import scanpy as sc\n",
        "# import the main pieces\n",
        "\n",
        "import Grotia_utils_re\n",
        "importlib.reload(Grotia_utils_re)\n",
        "from Grotia_utils_re import (\n",
        "    AlignmentConfig,\n",
        "    GridConfig,\n",
        "    run_alignment,\n",
        "    run_alignment_grid,\n",
        "    compute_centered_rbf_kernel,build_knn_distance_matrix,\n",
        "    build_knn_distance_matrix\n",
        ")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def summarize_results(results):\n",
        "    \"\"\"\n",
        "    Convert the results dict from run_alignment_grid into a pandas DataFrame,\n",
        "    then return three ranked views: by accuracy, by final_loss, and by FOSCTTM.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        rows.append({\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "            \"final_loss\": res.get(\"final_loss\", np.nan),\n",
        "            \"accuracy\": metrics.get(\"accuracy\", np.nan),\n",
        "            \"foscttm\": metrics.get(\"foscttm\", np.nan),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Sortings\n",
        "    by_acc = df.sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
        "    by_loss = df.sort_values(\"final_loss\", ascending=True).reset_index(drop=True)\n",
        "    by_fos = df.sort_values(\"foscttm\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "    return df, by_acc, by_loss, by_fos\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iFuDBDbwES34",
      "metadata": {
        "id": "iFuDBDbwES34"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def summarize_results(results):\n",
        "    \"\"\"\n",
        "    Convert the results dict from run_alignment_grid into a pandas DataFrame,\n",
        "    then return three ranked views: by accuracy, by final_loss, and by FOSCTTM.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        rows.append({\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "            \"final_loss\": res.get(\"final_loss\", np.nan),\n",
        "            \"accuracy\": metrics.get(\"accuracy\", np.nan),\n",
        "            \"foscttm\": metrics.get(\"foscttm\", np.nan),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Sortings\n",
        "    by_acc = df.sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
        "    by_loss = df.sort_values(\"final_loss\", ascending=True).reset_index(drop=True)\n",
        "    by_fos = df.sort_values(\"foscttm\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "    return df, by_acc, by_loss, by_fos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1941ca5",
      "metadata": {},
      "source": [
        "# sc_gem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "owl6Zfxmp-48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owl6Zfxmp-48",
        "outputId": "644f154b-793d-46cd-a1e8-e826ccf8d01e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.071787 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.065578 | OT=0.008901 | Ortho=0.000103 | Graph=56.573907 | lr=2.50e-04 | Acc=0.5254\n",
            "[Iter  1000] total=0.055673 | OT=0.007042 | Ortho=0.000082 | Graph=48.549708 | lr=2.50e-04 | Acc=0.6610\n",
            "[Iter  1500] total=0.046282 | OT=0.005683 | Ortho=0.000062 | Graph=40.538329 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  2000] total=0.039110 | OT=0.004377 | Ortho=0.000047 | Graph=34.685260 | lr=2.50e-04 | Acc=0.6158\n",
            "[Iter  2500] total=0.033574 | OT=0.003517 | Ortho=0.000036 | Graph=30.021697 | lr=2.50e-04 | Acc=0.5537\n",
            "[Iter  3000] total=0.028719 | OT=0.002814 | Ortho=0.000028 | Graph=25.876562 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  3500] total=0.024470 | OT=0.002397 | Ortho=0.000022 | Graph=22.051200 | lr=2.50e-04 | Acc=0.5706\n",
            "[Iter  4000] total=0.020683 | OT=0.002088 | Ortho=0.000016 | Graph=18.579567 | lr=2.50e-04 | Acc=0.5593\n",
            "[Iter  4500] total=0.017352 | OT=0.001804 | Ortho=0.000013 | Graph=15.534917 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  5000] total=0.014775 | OT=0.001578 | Ortho=0.000009 | Graph=13.188403 | lr=2.50e-04 | Acc=0.6328\n",
            "[Iter  5500] total=0.012601 | OT=0.001299 | Ortho=0.000006 | Graph=11.294986 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  6000] total=0.010882 | OT=0.001157 | Ortho=0.000005 | Graph=9.720581 | lr=2.50e-04 | Acc=0.5198\n",
            "[Iter  6500] total=0.009478 | OT=0.000986 | Ortho=0.000004 | Graph=8.488966 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  7000] total=0.008278 | OT=0.000809 | Ortho=0.000002 | Graph=7.466478 | lr=2.50e-04 | Acc=0.5198\n",
            "[Iter  7500] total=0.007397 | OT=0.000717 | Ortho=0.000002 | Graph=6.677894 | lr=2.50e-04 | Acc=0.5311\n",
            "[Iter  8000] total=0.006708 | OT=0.000623 | Ortho=0.000001 | Graph=6.083506 | lr=2.50e-04 | Acc=0.5989\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084670 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.064818 | OT=0.012318 | Ortho=0.000130 | Graph=52.370689 | lr=5.00e-04 | Acc=0.6215\n",
            "[Iter  1000] total=0.049895 | OT=0.006782 | Ortho=0.000076 | Graph=43.036737 | lr=5.00e-04 | Acc=0.5480\n",
            "[Iter  1500] total=0.040184 | OT=0.004745 | Ortho=0.000049 | Graph=35.389663 | lr=5.00e-04 | Acc=0.5706\n",
            "[Iter  2000] total=0.032660 | OT=0.003470 | Ortho=0.000036 | Graph=29.154666 | lr=5.00e-04 | Acc=0.5932\n",
            "[Iter  2500] total=0.026458 | OT=0.002694 | Ortho=0.000026 | Graph=23.738345 | lr=5.00e-04 | Acc=0.5876\n",
            "[Iter  3000] total=0.021638 | OT=0.002205 | Ortho=0.000017 | Graph=19.415101 | lr=5.00e-04 | Acc=0.4915\n",
            "[Iter  3500] total=0.017712 | OT=0.001759 | Ortho=0.000030 | Graph=15.922993 | lr=5.00e-04 | Acc=0.5876\n",
            "[Iter  4000] total=0.014525 | OT=0.001467 | Ortho=0.000009 | Graph=13.048635 | lr=5.00e-04 | Acc=0.5254\n",
            "[Iter  4500] total=0.012050 | OT=0.001274 | Ortho=0.000006 | Graph=10.770272 | lr=5.00e-04 | Acc=0.5819\n",
            "[Iter  5000] total=0.010289 | OT=0.001143 | Ortho=0.000004 | Graph=9.141501 | lr=5.00e-04 | Acc=0.5932\n",
            "[Iter  5500] total=0.009076 | OT=0.001054 | Ortho=0.000003 | Graph=8.018527 | lr=5.00e-04 | Acc=0.5876\n",
            "[Iter  6000] total=0.007953 | OT=0.000858 | Ortho=0.000002 | Graph=7.093306 | lr=5.00e-04 | Acc=0.5876\n",
            "[Iter  6500] total=0.007112 | OT=0.000724 | Ortho=0.000002 | Graph=6.385901 | lr=5.00e-04 | Acc=0.4972\n",
            "[Iter  7000] total=0.006482 | OT=0.000633 | Ortho=0.000001 | Graph=5.847094 | lr=5.00e-04 | Acc=0.5085\n",
            "[Iter  7500] total=0.006080 | OT=0.000573 | Ortho=0.000001 | Graph=5.505336 | lr=2.50e-04 | Acc=0.5198\n",
            "[Iter  8000] total=0.005842 | OT=0.000552 | Ortho=0.000001 | Graph=5.289027 | lr=2.50e-04 | Acc=0.5593\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084764 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.064723 | OT=0.012413 | Ortho=0.000132 | Graph=52.178125 | lr=5.00e-04 | Acc=0.6158\n",
            "[Iter  1000] total=0.050365 | OT=0.007086 | Ortho=0.000079 | Graph=43.200139 | lr=5.00e-04 | Acc=0.5537\n",
            "[Iter  1500] total=0.040133 | OT=0.004797 | Ortho=0.000050 | Graph=35.285943 | lr=5.00e-04 | Acc=0.6045\n",
            "[Iter  2000] total=0.032428 | OT=0.003630 | Ortho=0.000034 | Graph=28.764013 | lr=5.00e-04 | Acc=0.6271\n",
            "[Iter  2500] total=0.026696 | OT=0.002820 | Ortho=0.000024 | Graph=23.851570 | lr=5.00e-04 | Acc=0.5593\n",
            "[Iter  3000] total=0.021891 | OT=0.002306 | Ortho=0.000019 | Graph=19.566717 | lr=5.00e-04 | Acc=0.5311\n",
            "[Iter  3500] total=0.018016 | OT=0.001895 | Ortho=0.000013 | Graph=16.108526 | lr=5.00e-04 | Acc=0.5537\n",
            "[Iter  4000] total=0.014612 | OT=0.001533 | Ortho=0.000008 | Graph=13.070946 | lr=5.00e-04 | Acc=0.5367\n",
            "[Iter  4500] total=0.012199 | OT=0.001301 | Ortho=0.000006 | Graph=10.893050 | lr=5.00e-04 | Acc=0.6271\n",
            "[Iter  5000] total=0.010432 | OT=0.001150 | Ortho=0.000004 | Graph=9.278686 | lr=5.00e-04 | Acc=0.5763\n",
            "[Iter  5500] total=0.009070 | OT=0.001024 | Ortho=0.000003 | Graph=8.043675 | lr=5.00e-04 | Acc=0.5141\n",
            "[Iter  6000] total=0.007954 | OT=0.000867 | Ortho=0.000002 | Graph=7.084549 | lr=5.00e-04 | Acc=0.5593\n",
            "Early stopping at iter=6394 (best@6384 total=0.007271).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.016578 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.015895 | OT=0.009774 | Ortho=0.000004 | Graph=61.168690 | lr=1.25e-04 | Acc=0.5028\n",
            "[Iter  1000] total=0.015192 | OT=0.009109 | Ortho=0.000003 | Graph=60.800763 | lr=1.25e-04 | Acc=0.5537\n",
            "[Iter  1500] total=0.014507 | OT=0.008491 | Ortho=0.000004 | Graph=60.122838 | lr=1.25e-04 | Acc=0.5876\n",
            "[Iter  2000] total=0.013895 | OT=0.007974 | Ortho=0.000004 | Graph=59.172591 | lr=1.25e-04 | Acc=0.5819\n",
            "[Iter  2500] total=0.013182 | OT=0.007403 | Ortho=0.000004 | Graph=57.746636 | lr=1.25e-04 | Acc=0.5819\n",
            "[Iter  3000] total=0.012247 | OT=0.006666 | Ortho=0.000004 | Graph=55.763220 | lr=1.25e-04 | Acc=0.6158\n",
            "[Iter  3500] total=0.011324 | OT=0.005946 | Ortho=0.000004 | Graph=53.742052 | lr=1.25e-04 | Acc=0.5424\n",
            "[Iter  4000] total=0.010368 | OT=0.005171 | Ortho=0.000003 | Graph=51.941769 | lr=1.25e-04 | Acc=0.5989\n",
            "[Iter  4500] total=0.009501 | OT=0.004480 | Ortho=0.000002 | Graph=50.181844 | lr=1.25e-04 | Acc=0.5989\n",
            "[Iter  5000] total=0.008758 | OT=0.003940 | Ortho=0.000002 | Graph=48.156762 | lr=1.25e-04 | Acc=0.5819\n",
            "[Iter  5500] total=0.008026 | OT=0.003392 | Ortho=0.000002 | Graph=46.320954 | lr=1.25e-04 | Acc=0.5763\n",
            "[Iter  6000] total=0.007389 | OT=0.002963 | Ortho=0.000001 | Graph=44.248695 | lr=1.25e-04 | Acc=0.6158\n",
            "[Iter  6500] total=0.006871 | OT=0.002641 | Ortho=0.000003 | Graph=42.272875 | lr=1.25e-04 | Acc=0.6215\n",
            "[Iter  7000] total=0.006480 | OT=0.002406 | Ortho=0.000001 | Graph=40.733632 | lr=1.25e-04 | Acc=0.6271\n",
            "[Iter  7500] total=0.006109 | OT=0.002164 | Ortho=0.000001 | Graph=39.439583 | lr=6.25e-05 | Acc=0.6328\n",
            "[Iter  8000] total=0.005963 | OT=0.002075 | Ortho=0.000001 | Graph=38.877059 | lr=6.25e-05 | Acc=0.6328\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029460 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.022276 | OT=0.016197 | Ortho=0.000031 | Graph=60.482689 | lr=2.50e-04 | Acc=0.6158\n",
            "[Iter  1000] total=0.018751 | OT=0.012856 | Ortho=0.000030 | Graph=58.659978 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  1500] total=0.015659 | OT=0.009976 | Ortho=0.000023 | Graph=56.600027 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  2000] total=0.012543 | OT=0.007080 | Ortho=0.000009 | Graph=54.546545 | lr=2.50e-04 | Acc=0.6554\n",
            "[Iter  2500] total=0.010801 | OT=0.005559 | Ortho=0.000005 | Graph=52.359910 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  3000] total=0.009593 | OT=0.004579 | Ortho=0.000004 | Graph=50.111040 | lr=2.50e-04 | Acc=0.5876\n",
            "[Iter  3500] total=0.008713 | OT=0.003900 | Ortho=0.000003 | Graph=48.098695 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  4000] total=0.008107 | OT=0.003464 | Ortho=0.000002 | Graph=46.413247 | lr=2.50e-04 | Acc=0.5989\n",
            "Early stopping at iter=4303 (best@4293 total=0.007699).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029554 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.022627 | OT=0.016540 | Ortho=0.000032 | Graph=60.555064 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  1000] total=0.018913 | OT=0.012999 | Ortho=0.000031 | Graph=58.830650 | lr=2.50e-04 | Acc=0.6215\n",
            "[Iter  1500] total=0.015906 | OT=0.010183 | Ortho=0.000020 | Graph=57.025104 | lr=2.50e-04 | Acc=0.6102\n",
            "[Iter  2000] total=0.012854 | OT=0.007324 | Ortho=0.000009 | Graph=55.209489 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  2500] total=0.011276 | OT=0.005941 | Ortho=0.000005 | Graph=53.306354 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  3000] total=0.010107 | OT=0.004973 | Ortho=0.000004 | Graph=51.300217 | lr=2.50e-04 | Acc=0.5763\n",
            "[Iter  3500] total=0.009048 | OT=0.004168 | Ortho=0.000003 | Graph=48.772551 | lr=2.50e-04 | Acc=0.5706\n",
            "[Iter  4000] total=0.008503 | OT=0.003783 | Ortho=0.000002 | Graph=47.179273 | lr=1.25e-04 | Acc=0.5650\n",
            "[Iter  4500] total=0.008109 | OT=0.003493 | Ortho=0.000002 | Graph=46.136265 | lr=1.25e-04 | Acc=0.5763\n",
            "[Iter  5000] total=0.007740 | OT=0.003242 | Ortho=0.000002 | Graph=44.969588 | lr=1.25e-04 | Acc=0.5876\n",
            "[Iter  5500] total=0.007350 | OT=0.002986 | Ortho=0.000004 | Graph=43.599140 | lr=1.25e-04 | Acc=0.5989\n",
            "[Iter  6000] total=0.006940 | OT=0.002721 | Ortho=0.000001 | Graph=42.174946 | lr=1.25e-04 | Acc=0.6045\n",
            "[Iter  6500] total=0.006637 | OT=0.002542 | Ortho=0.000001 | Graph=40.938098 | lr=1.25e-04 | Acc=0.6045\n",
            "[Iter  7000] total=0.006295 | OT=0.002342 | Ortho=0.000001 | Graph=39.516315 | lr=1.25e-04 | Acc=0.6102\n",
            "[Iter  7500] total=0.005985 | OT=0.002158 | Ortho=0.000001 | Graph=38.255973 | lr=1.25e-04 | Acc=0.6102\n",
            "[Iter  8000] total=0.005723 | OT=0.002014 | Ortho=0.000001 | Graph=37.078606 | lr=1.25e-04 | Acc=0.5876\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.011057 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.010748 | OT=0.010133 | Ortho=0.000002 | Graph=61.349338 | lr=3.13e-05 | Acc=0.4689\n",
            "[Iter  1000] total=0.010500 | OT=0.009885 | Ortho=0.000002 | Graph=61.353084 | lr=3.13e-05 | Acc=0.4746\n",
            "[Iter  1500] total=0.010212 | OT=0.009597 | Ortho=0.000001 | Graph=61.330915 | lr=3.13e-05 | Acc=0.5085\n",
            "[Iter  2000] total=0.009908 | OT=0.009294 | Ortho=0.000001 | Graph=61.267812 | lr=3.13e-05 | Acc=0.5367\n",
            "[Iter  2500] total=0.009609 | OT=0.008996 | Ortho=0.000001 | Graph=61.152310 | lr=3.13e-05 | Acc=0.5706\n",
            "[Iter  3000] total=0.009300 | OT=0.008689 | Ortho=0.000002 | Graph=60.973588 | lr=3.13e-05 | Acc=0.5989\n",
            "[Iter  3500] total=0.008977 | OT=0.008369 | Ortho=0.000002 | Graph=60.709667 | lr=3.13e-05 | Acc=0.6158\n",
            "[Iter  4000] total=0.008672 | OT=0.008067 | Ortho=0.000002 | Graph=60.367023 | lr=3.13e-05 | Acc=0.5989\n",
            "[Iter  4500] total=0.008367 | OT=0.007766 | Ortho=0.000002 | Graph=59.931098 | lr=3.13e-05 | Acc=0.5876\n",
            "[Iter  5000] total=0.008040 | OT=0.007444 | Ortho=0.000002 | Graph=59.374939 | lr=3.13e-05 | Acc=0.5763\n",
            "[Iter  5500] total=0.007632 | OT=0.007043 | Ortho=0.000002 | Graph=58.671243 | lr=3.13e-05 | Acc=0.5819\n",
            "[Iter  6000] total=0.007114 | OT=0.006535 | Ortho=0.000002 | Graph=57.702947 | lr=3.13e-05 | Acc=0.5763\n",
            "[Iter  6500] total=0.006572 | OT=0.006003 | Ortho=0.000002 | Graph=56.638583 | lr=3.13e-05 | Acc=0.5480\n",
            "[Iter  7000] total=0.005957 | OT=0.005398 | Ortho=0.000002 | Graph=55.726562 | lr=3.13e-05 | Acc=0.5876\n",
            "[Iter  7500] total=0.005349 | OT=0.004798 | Ortho=0.000001 | Graph=54.963008 | lr=3.13e-05 | Acc=0.5989\n",
            "[Iter  8000] total=0.004945 | OT=0.004400 | Ortho=0.000001 | Graph=54.365049 | lr=3.13e-05 | Acc=0.5876\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.023939 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.017043 | OT=0.016408 | Ortho=0.000027 | Graph=60.816335 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  1000] total=0.013715 | OT=0.013094 | Ortho=0.000027 | Graph=59.466664 | lr=2.50e-04 | Acc=0.6328\n",
            "[Iter  1500] total=0.010783 | OT=0.010185 | Ortho=0.000017 | Graph=58.048886 | lr=2.50e-04 | Acc=0.5819\n",
            "[Iter  2000] total=0.007864 | OT=0.007286 | Ortho=0.000006 | Graph=57.125297 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  2500] total=0.006341 | OT=0.005776 | Ortho=0.000003 | Graph=56.151614 | lr=2.50e-04 | Acc=0.5763\n",
            "[Iter  3000] total=0.005499 | OT=0.004944 | Ortho=0.000002 | Graph=55.281697 | lr=2.50e-04 | Acc=0.6102\n",
            "[Iter  3500] total=0.004885 | OT=0.004341 | Ortho=0.000002 | Graph=54.315382 | lr=2.50e-04 | Acc=0.5989\n",
            "Early stopping at iter=3575 (best@3565 total=0.004816).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.024033 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.017062 | OT=0.016425 | Ortho=0.000029 | Graph=60.793653 | lr=2.50e-04 | Acc=0.6158\n",
            "[Iter  1000] total=0.013751 | OT=0.013129 | Ortho=0.000028 | Graph=59.449531 | lr=2.50e-04 | Acc=0.6328\n",
            "[Iter  1500] total=0.010874 | OT=0.010276 | Ortho=0.000017 | Graph=58.073152 | lr=2.50e-04 | Acc=0.6102\n",
            "[Iter  2000] total=0.008008 | OT=0.007433 | Ortho=0.000006 | Graph=56.988550 | lr=2.50e-04 | Acc=0.5876\n",
            "[Iter  2500] total=0.006584 | OT=0.006022 | Ortho=0.000003 | Graph=55.820981 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  3000] total=0.005786 | OT=0.005236 | Ortho=0.000002 | Graph=54.787589 | lr=2.50e-04 | Acc=0.5989\n",
            "[Iter  3500] total=0.005096 | OT=0.004559 | Ortho=0.000002 | Graph=53.530782 | lr=2.50e-04 | Acc=0.5989\n",
            "Early stopping at iter=3826 (best@3816 total=0.004706).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010505 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.010192 | OT=0.010129 | Ortho=0.000002 | Graph=61.353048 | lr=3.13e-05 | Acc=0.4689\n",
            "[Iter  1000] total=0.009946 | OT=0.009883 | Ortho=0.000001 | Graph=61.362929 | lr=3.13e-05 | Acc=0.4746\n",
            "[Iter  1500] total=0.009663 | OT=0.009600 | Ortho=0.000001 | Graph=61.349874 | lr=3.13e-05 | Acc=0.5085\n",
            "[Iter  2000] total=0.009362 | OT=0.009299 | Ortho=0.000001 | Graph=61.298005 | lr=3.13e-05 | Acc=0.5480\n",
            "[Iter  2500] total=0.009066 | OT=0.009004 | Ortho=0.000001 | Graph=61.198470 | lr=3.13e-05 | Acc=0.5706\n",
            "[Iter  3000] total=0.008765 | OT=0.008702 | Ortho=0.000002 | Graph=61.049582 | lr=3.13e-05 | Acc=0.5989\n",
            "[Iter  3500] total=0.008459 | OT=0.008397 | Ortho=0.000002 | Graph=60.834090 | lr=3.13e-05 | Acc=0.6215\n",
            "[Iter  4000] total=0.008151 | OT=0.008089 | Ortho=0.000002 | Graph=60.530603 | lr=3.13e-05 | Acc=0.6158\n",
            "[Iter  4500] total=0.007849 | OT=0.007787 | Ortho=0.000002 | Graph=60.141506 | lr=3.13e-05 | Acc=0.5932\n",
            "[Iter  5000] total=0.007523 | OT=0.007461 | Ortho=0.000002 | Graph=59.653119 | lr=3.13e-05 | Acc=0.5763\n",
            "[Iter  5500] total=0.007135 | OT=0.007074 | Ortho=0.000002 | Graph=59.021144 | lr=3.13e-05 | Acc=0.5537\n",
            "[Iter  6000] total=0.006652 | OT=0.006592 | Ortho=0.000002 | Graph=58.154838 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  6500] total=0.006095 | OT=0.006036 | Ortho=0.000002 | Graph=57.066401 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  7000] total=0.005481 | OT=0.005424 | Ortho=0.000002 | Graph=56.133823 | lr=3.13e-05 | Acc=0.5876\n",
            "[Iter  7500] total=0.004898 | OT=0.004841 | Ortho=0.000001 | Graph=55.459807 | lr=3.13e-05 | Acc=0.5819\n",
            "[Iter  8000] total=0.004442 | OT=0.004386 | Ortho=0.000001 | Graph=55.002417 | lr=3.13e-05 | Acc=0.6102\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.023387 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016504 | OT=0.016417 | Ortho=0.000027 | Graph=60.844660 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  1000] total=0.013207 | OT=0.013121 | Ortho=0.000027 | Graph=59.539276 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  1500] total=0.010302 | OT=0.010226 | Ortho=0.000017 | Graph=58.175155 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  2000] total=0.007363 | OT=0.007300 | Ortho=0.000006 | Graph=57.316003 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  2500] total=0.005831 | OT=0.005771 | Ortho=0.000003 | Graph=56.415985 | lr=2.50e-04 | Acc=0.5706\n",
            "[Iter  3000] total=0.005019 | OT=0.004962 | Ortho=0.000002 | Graph=55.562835 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  3500] total=0.004431 | OT=0.004375 | Ortho=0.000001 | Graph=54.747343 | lr=2.50e-04 | Acc=0.5989\n",
            "[Iter  4000] total=0.003916 | OT=0.003861 | Ortho=0.000001 | Graph=53.638918 | lr=2.50e-04 | Acc=0.5819\n",
            "Early stopping at iter=4042 (best@4032 total=0.003889).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.023481 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016525 | OT=0.016436 | Ortho=0.000028 | Graph=60.820066 | lr=2.50e-04 | Acc=0.6102\n",
            "[Iter  1000] total=0.013233 | OT=0.013146 | Ortho=0.000028 | Graph=59.515619 | lr=2.50e-04 | Acc=0.6328\n",
            "[Iter  1500] total=0.010367 | OT=0.010292 | Ortho=0.000017 | Graph=58.185186 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  2000] total=0.007498 | OT=0.007436 | Ortho=0.000006 | Graph=57.233380 | lr=2.50e-04 | Acc=0.5876\n",
            "[Iter  2500] total=0.006017 | OT=0.005958 | Ortho=0.000003 | Graph=56.197255 | lr=2.50e-04 | Acc=0.6158\n",
            "[Iter  3000] total=0.005214 | OT=0.005156 | Ortho=0.000002 | Graph=55.307726 | lr=2.50e-04 | Acc=0.6215\n",
            "[Iter  3500] total=0.004568 | OT=0.004512 | Ortho=0.000001 | Graph=54.328452 | lr=2.50e-04 | Acc=0.6158\n",
            "Early stopping at iter=3880 (best@3870 total=0.004238).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010449 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.010137 | OT=0.010129 | Ortho=0.000002 | Graph=61.354244 | lr=3.13e-05 | Acc=0.4689\n",
            "[Iter  1000] total=0.009893 | OT=0.009885 | Ortho=0.000001 | Graph=61.364494 | lr=3.13e-05 | Acc=0.4746\n",
            "[Iter  1500] total=0.009612 | OT=0.009604 | Ortho=0.000001 | Graph=61.352470 | lr=3.13e-05 | Acc=0.5085\n",
            "[Iter  2000] total=0.009311 | OT=0.009303 | Ortho=0.000001 | Graph=61.301437 | lr=3.13e-05 | Acc=0.5367\n",
            "[Iter  2500] total=0.009015 | OT=0.009008 | Ortho=0.000001 | Graph=61.203502 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  3000] total=0.008713 | OT=0.008705 | Ortho=0.000002 | Graph=61.056523 | lr=3.13e-05 | Acc=0.5989\n",
            "[Iter  3500] total=0.008409 | OT=0.008401 | Ortho=0.000002 | Graph=60.844289 | lr=3.13e-05 | Acc=0.6215\n",
            "[Iter  4000] total=0.008101 | OT=0.008094 | Ortho=0.000002 | Graph=60.546257 | lr=3.13e-05 | Acc=0.6158\n",
            "[Iter  4500] total=0.007800 | OT=0.007792 | Ortho=0.000002 | Graph=60.162381 | lr=3.13e-05 | Acc=0.5932\n",
            "[Iter  5000] total=0.007477 | OT=0.007469 | Ortho=0.000002 | Graph=59.683188 | lr=3.13e-05 | Acc=0.5763\n",
            "[Iter  5500] total=0.007092 | OT=0.007084 | Ortho=0.000002 | Graph=59.064716 | lr=3.13e-05 | Acc=0.5593\n",
            "[Iter  6000] total=0.006614 | OT=0.006607 | Ortho=0.000002 | Graph=58.209287 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  6500] total=0.006060 | OT=0.006052 | Ortho=0.000002 | Graph=57.128427 | lr=3.13e-05 | Acc=0.5706\n",
            "[Iter  7000] total=0.005448 | OT=0.005440 | Ortho=0.000002 | Graph=56.188206 | lr=3.13e-05 | Acc=0.5876\n",
            "[Iter  7500] total=0.004868 | OT=0.004861 | Ortho=0.000001 | Graph=55.501402 | lr=3.13e-05 | Acc=0.5819\n",
            "[Iter  8000] total=0.004402 | OT=0.004396 | Ortho=0.000001 | Graph=55.075103 | lr=3.13e-05 | Acc=0.6102\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.023332 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016450 | OT=0.016417 | Ortho=0.000027 | Graph=60.847152 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  1000] total=0.013155 | OT=0.013122 | Ortho=0.000027 | Graph=59.545614 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  1500] total=0.010251 | OT=0.010228 | Ortho=0.000017 | Graph=58.186049 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  2000] total=0.007311 | OT=0.007299 | Ortho=0.000006 | Graph=57.331358 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  2500] total=0.005781 | OT=0.005773 | Ortho=0.000003 | Graph=56.440172 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  3000] total=0.004970 | OT=0.004963 | Ortho=0.000002 | Graph=55.585203 | lr=2.50e-04 | Acc=0.5989\n",
            "[Iter  3500] total=0.004388 | OT=0.004381 | Ortho=0.000001 | Graph=54.771461 | lr=2.50e-04 | Acc=0.6045\n",
            "Early stopping at iter=3943 (best@3933 total=0.003944).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.023426 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016471 | OT=0.016437 | Ortho=0.000028 | Graph=60.822496 | lr=2.50e-04 | Acc=0.6102\n",
            "[Iter  1000] total=0.013181 | OT=0.013147 | Ortho=0.000028 | Graph=59.521712 | lr=2.50e-04 | Acc=0.6328\n",
            "[Iter  1500] total=0.010315 | OT=0.010292 | Ortho=0.000017 | Graph=58.195439 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  2000] total=0.007447 | OT=0.007436 | Ortho=0.000006 | Graph=57.249778 | lr=2.50e-04 | Acc=0.5876\n",
            "[Iter  2500] total=0.005968 | OT=0.005959 | Ortho=0.000003 | Graph=56.220363 | lr=2.50e-04 | Acc=0.6215\n",
            "[Iter  3000] total=0.005165 | OT=0.005158 | Ortho=0.000002 | Graph=55.358705 | lr=2.50e-04 | Acc=0.6158\n",
            "[Iter  3500] total=0.004522 | OT=0.004515 | Ortho=0.000001 | Graph=54.368392 | lr=2.50e-04 | Acc=0.6215\n",
            "Early stopping at iter=3943 (best@3933 total=0.004145).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010444 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.010132 | OT=0.010129 | Ortho=0.000002 | Graph=61.354303 | lr=3.13e-05 | Acc=0.4689\n",
            "[Iter  1000] total=0.009887 | OT=0.009885 | Ortho=0.000001 | Graph=61.364616 | lr=3.13e-05 | Acc=0.4746\n",
            "[Iter  1500] total=0.009606 | OT=0.009604 | Ortho=0.000001 | Graph=61.352688 | lr=3.13e-05 | Acc=0.5085\n",
            "[Iter  2000] total=0.009305 | OT=0.009303 | Ortho=0.000001 | Graph=61.301779 | lr=3.13e-05 | Acc=0.5367\n",
            "[Iter  2500] total=0.009010 | OT=0.009008 | Ortho=0.000001 | Graph=61.204007 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  3000] total=0.008708 | OT=0.008706 | Ortho=0.000002 | Graph=61.057235 | lr=3.13e-05 | Acc=0.5989\n",
            "[Iter  3500] total=0.008403 | OT=0.008401 | Ortho=0.000002 | Graph=60.845267 | lr=3.13e-05 | Acc=0.6215\n",
            "[Iter  4000] total=0.008096 | OT=0.008094 | Ortho=0.000002 | Graph=60.547683 | lr=3.13e-05 | Acc=0.6158\n",
            "[Iter  4500] total=0.007795 | OT=0.007793 | Ortho=0.000002 | Graph=60.164223 | lr=3.13e-05 | Acc=0.5932\n",
            "[Iter  5000] total=0.007472 | OT=0.007469 | Ortho=0.000002 | Graph=59.685736 | lr=3.13e-05 | Acc=0.5763\n",
            "[Iter  5500] total=0.007086 | OT=0.007084 | Ortho=0.000002 | Graph=59.070029 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  6000] total=0.006610 | OT=0.006608 | Ortho=0.000002 | Graph=58.216804 | lr=3.13e-05 | Acc=0.5650\n",
            "[Iter  6500] total=0.006056 | OT=0.006054 | Ortho=0.000002 | Graph=57.136692 | lr=3.13e-05 | Acc=0.5706\n",
            "[Iter  7000] total=0.005444 | OT=0.005442 | Ortho=0.000002 | Graph=56.194427 | lr=3.13e-05 | Acc=0.5932\n",
            "[Iter  7500] total=0.004866 | OT=0.004864 | Ortho=0.000001 | Graph=55.507157 | lr=3.13e-05 | Acc=0.5819\n",
            "[Iter  8000] total=0.004397 | OT=0.004396 | Ortho=0.000001 | Graph=55.081061 | lr=3.13e-05 | Acc=0.6158\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.023327 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016444 | OT=0.016417 | Ortho=0.000027 | Graph=60.847402 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  1000] total=0.013150 | OT=0.013122 | Ortho=0.000027 | Graph=59.546247 | lr=2.50e-04 | Acc=0.6271\n",
            "[Iter  1500] total=0.010246 | OT=0.010229 | Ortho=0.000017 | Graph=58.187140 | lr=2.50e-04 | Acc=0.5932\n",
            "[Iter  2000] total=0.007306 | OT=0.007299 | Ortho=0.000006 | Graph=57.332890 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  2500] total=0.005776 | OT=0.005773 | Ortho=0.000003 | Graph=56.442558 | lr=2.50e-04 | Acc=0.5650\n",
            "[Iter  3000] total=0.004965 | OT=0.004963 | Ortho=0.000002 | Graph=55.587401 | lr=2.50e-04 | Acc=0.5989\n",
            "[Iter  3500] total=0.004384 | OT=0.004382 | Ortho=0.000001 | Graph=54.774910 | lr=2.50e-04 | Acc=0.6045\n",
            "Early stopping at iter=3722 (best@3712 total=0.004170).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.023421 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016466 | OT=0.016437 | Ortho=0.000028 | Graph=60.822739 | lr=2.50e-04 | Acc=0.6102\n",
            "[Iter  1000] total=0.013175 | OT=0.013147 | Ortho=0.000028 | Graph=59.522322 | lr=2.50e-04 | Acc=0.6328\n",
            "[Iter  1500] total=0.010310 | OT=0.010292 | Ortho=0.000017 | Graph=58.196449 | lr=2.50e-04 | Acc=0.6045\n",
            "[Iter  2000] total=0.007442 | OT=0.007436 | Ortho=0.000006 | Graph=57.251352 | lr=2.50e-04 | Acc=0.5876\n",
            "[Iter  2500] total=0.005963 | OT=0.005960 | Ortho=0.000003 | Graph=56.222561 | lr=2.50e-04 | Acc=0.6215\n",
            "[Iter  3000] total=0.005160 | OT=0.005157 | Ortho=0.000002 | Graph=55.361504 | lr=2.50e-04 | Acc=0.6158\n",
            "[Iter  3500] total=0.004517 | OT=0.004515 | Ortho=0.000001 | Graph=54.371022 | lr=2.50e-04 | Acc=0.6215\n",
            "[Iter  4000] total=0.004093 | OT=0.004092 | Ortho=0.000001 | Graph=53.387434 | lr=2.50e-04 | Acc=0.6215\n",
            "Early stopping at iter=4229 (best@4219 total=0.003924).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.071787 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.025321 | OT=0.002328 | Ortho=0.002236 | Graph=22.768625 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  1000] total=0.012683 | OT=0.001440 | Ortho=0.000608 | Graph=11.182431 | lr=1.00e-03 | Acc=0.5424\n",
            "[Iter  1500] total=0.008676 | OT=0.000909 | Ortho=0.000270 | Graph=7.740357 | lr=1.00e-03 | Acc=0.5028\n",
            "[Iter  2000] total=0.006815 | OT=0.000648 | Ortho=0.000154 | Graph=6.151174 | lr=1.00e-03 | Acc=0.4915\n",
            "Early stopping at iter=2466 (best@2456 total=0.005846).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084670 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.027565 | OT=0.002654 | Ortho=0.002619 | Graph=24.649397 | lr=1.00e-03 | Acc=0.5593\n",
            "[Iter  1000] total=0.013373 | OT=0.001348 | Ortho=0.000672 | Graph=11.958040 | lr=1.00e-03 | Acc=0.6045\n",
            "[Iter  1500] total=0.009374 | OT=0.000926 | Ortho=0.000304 | Graph=8.418246 | lr=1.00e-03 | Acc=0.4972\n",
            "[Iter  2000] total=0.007524 | OT=0.000698 | Ortho=0.000189 | Graph=6.806712 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  2500] total=0.006271 | OT=0.000589 | Ortho=0.000155 | Graph=5.666043 | lr=1.00e-03 | Acc=0.5537\n",
            "Early stopping at iter=2625 (best@2615 total=0.006018).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084764 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.028430 | OT=0.002889 | Ortho=0.002709 | Graph=25.270555 | lr=1.00e-03 | Acc=0.5424\n",
            "[Iter  1000] total=0.013530 | OT=0.001344 | Ortho=0.000705 | Graph=12.115571 | lr=1.00e-03 | Acc=0.5763\n",
            "[Iter  1500] total=0.009488 | OT=0.000958 | Ortho=0.000311 | Graph=8.498890 | lr=1.00e-03 | Acc=0.5254\n",
            "[Iter  2000] total=0.007638 | OT=0.000739 | Ortho=0.000192 | Graph=6.879719 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  2500] total=0.006389 | OT=0.000579 | Ortho=0.000141 | Graph=5.795739 | lr=1.00e-03 | Acc=0.5593\n",
            "Early stopping at iter=2823 (best@2813 total=0.005798).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.016578 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.011062 | OT=0.005728 | Ortho=0.000370 | Graph=52.972691 | lr=5.00e-04 | Acc=0.5763\n",
            "[Iter  1000] total=0.007443 | OT=0.002972 | Ortho=0.000171 | Graph=44.541175 | lr=5.00e-04 | Acc=0.6102\n",
            "[Iter  1500] total=0.005956 | OT=0.001996 | Ortho=0.000110 | Graph=39.491636 | lr=5.00e-04 | Acc=0.6045\n",
            "[Iter  2000] total=0.004993 | OT=0.001540 | Ortho=0.000081 | Graph=34.449953 | lr=5.00e-04 | Acc=0.5706\n",
            "[Iter  2500] total=0.004183 | OT=0.001271 | Ortho=0.000061 | Graph=29.059435 | lr=5.00e-04 | Acc=0.5537\n",
            "[Iter  3000] total=0.003338 | OT=0.000972 | Ortho=0.000041 | Graph=23.618135 | lr=5.00e-04 | Acc=0.5424\n",
            "[Iter  3500] total=0.002706 | OT=0.000756 | Ortho=0.000028 | Graph=19.476966 | lr=5.00e-04 | Acc=0.5819\n",
            "Early stopping at iter=3699 (best@3689 total=0.002521).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029460 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.009447 | OT=0.004424 | Ortho=0.000334 | Graph=49.895781 | lr=1.00e-03 | Acc=0.6045\n",
            "[Iter  1000] total=0.006514 | OT=0.002326 | Ortho=0.000132 | Graph=41.754097 | lr=1.00e-03 | Acc=0.6215\n",
            "[Iter  1500] total=0.005054 | OT=0.001519 | Ortho=0.000079 | Graph=35.263124 | lr=1.00e-03 | Acc=0.6497\n",
            "Early stopping at iter=1600 (best@1590 total=0.004858).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029554 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.009497 | OT=0.004413 | Ortho=0.000325 | Graph=50.519949 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  1000] total=0.006492 | OT=0.002325 | Ortho=0.000156 | Graph=41.510068 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  1500] total=0.004987 | OT=0.001476 | Ortho=0.000077 | Graph=35.031432 | lr=1.00e-03 | Acc=0.5254\n",
            "Early stopping at iter=1803 (best@1793 total=0.004381).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.011057 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.006742 | OT=0.006152 | Ortho=0.000196 | Graph=57.088677 | lr=5.00e-04 | Acc=0.5593\n",
            "[Iter  1000] total=0.004381 | OT=0.003855 | Ortho=0.000051 | Graph=52.114009 | lr=5.00e-04 | Acc=0.5932\n",
            "[Iter  1500] total=0.003415 | OT=0.002924 | Ortho=0.000037 | Graph=48.745470 | lr=5.00e-04 | Acc=0.6328\n",
            "[Iter  2000] total=0.002535 | OT=0.002091 | Ortho=0.000024 | Graph=44.188123 | lr=5.00e-04 | Acc=0.6102\n",
            "[Iter  2500] total=0.001956 | OT=0.001548 | Ortho=0.000014 | Graph=40.569553 | lr=5.00e-04 | Acc=0.6215\n",
            "Early stopping at iter=2803 (best@2793 total=0.001717).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.023939 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.005208 | OT=0.004665 | Ortho=0.000164 | Graph=52.691087 | lr=1.00e-03 | Acc=0.5537\n",
            "[Iter  1000] total=0.003121 | OT=0.002654 | Ortho=0.000045 | Graph=46.254567 | lr=1.00e-03 | Acc=0.5706\n",
            "Early stopping at iter=1372 (best@1362 total=0.002540).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.024033 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.005376 | OT=0.004813 | Ortho=0.000210 | Graph=54.255491 | lr=1.00e-03 | Acc=0.6215\n",
            "[Iter  1000] total=0.003733 | OT=0.003200 | Ortho=0.000351 | Graph=49.843753 | lr=1.00e-03 | Acc=0.6271\n",
            "Early stopping at iter=1410 (best@1400 total=0.002885).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010505 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004519 | OT=0.004458 | Ortho=0.000069 | Graph=54.767871 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  1000] total=0.003081 | OT=0.003009 | Ortho=0.000203 | Graph=50.747804 | lr=1.00e-03 | Acc=0.5763\n",
            "Early stopping at iter=1166 (best@1156 total=0.002761).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.023387 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004718 | OT=0.004651 | Ortho=0.000145 | Graph=52.847231 | lr=1.00e-03 | Acc=0.5876\n",
            "[Iter  1000] total=0.002849 | OT=0.002797 | Ortho=0.000050 | Graph=47.031542 | lr=1.00e-03 | Acc=0.5989\n",
            "Early stopping at iter=1445 (best@1435 total=0.002175).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.023481 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004919 | OT=0.004842 | Ortho=0.000212 | Graph=54.941178 | lr=1.00e-03 | Acc=0.6158\n",
            "[Iter  1000] total=0.003065 | OT=0.003008 | Ortho=0.000058 | Graph=50.648475 | lr=1.00e-03 | Acc=0.6045\n",
            "[Iter  1500] total=0.002132 | OT=0.002083 | Ortho=0.000022 | Graph=47.036888 | lr=1.00e-03 | Acc=0.5876\n",
            "Early stopping at iter=1647 (best@1637 total=0.001968).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010449 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004479 | OT=0.004466 | Ortho=0.000069 | Graph=54.823414 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  1000] total=0.003036 | OT=0.003028 | Ortho=0.000023 | Graph=51.036120 | lr=1.00e-03 | Acc=0.5763\n",
            "Early stopping at iter=1231 (best@1221 total=0.002598).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.023332 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004676 | OT=0.004655 | Ortho=0.000149 | Graph=52.882005 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  1000] total=0.002831 | OT=0.002821 | Ortho=0.000051 | Graph=47.258152 | lr=1.00e-03 | Acc=0.5819\n",
            "Early stopping at iter=1467 (best@1457 total=0.002192).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.023426 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004874 | OT=0.004848 | Ortho=0.000211 | Graph=54.968129 | lr=1.00e-03 | Acc=0.6158\n",
            "[Iter  1000] total=0.003019 | OT=0.003008 | Ortho=0.000058 | Graph=50.697328 | lr=1.00e-03 | Acc=0.6045\n",
            "Early stopping at iter=1476 (best@1466 total=0.002139).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010444 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004474 | OT=0.004466 | Ortho=0.000069 | Graph=54.827994 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  1000] total=0.003033 | OT=0.003030 | Ortho=0.000023 | Graph=51.007791 | lr=1.00e-03 | Acc=0.5763\n",
            "Early stopping at iter=1246 (best@1236 total=0.002567).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.023327 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004674 | OT=0.004659 | Ortho=0.000149 | Graph=52.895335 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  1000] total=0.002840 | OT=0.002835 | Ortho=0.000048 | Graph=47.297313 | lr=1.00e-03 | Acc=0.5819\n",
            "Early stopping at iter=1476 (best@1466 total=0.002140).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.023421 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004871 | OT=0.004849 | Ortho=0.000211 | Graph=54.972489 | lr=1.00e-03 | Acc=0.6158\n",
            "[Iter  1000] total=0.003017 | OT=0.003010 | Ortho=0.000059 | Graph=50.703677 | lr=1.00e-03 | Acc=0.6045\n",
            "[Iter  1500] total=0.002106 | OT=0.002103 | Ortho=0.000021 | Graph=46.920230 | lr=1.00e-03 | Acc=0.5593\n",
            "Early stopping at iter=1540 (best@1530 total=0.002062).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.071787 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.016612 | OT=0.001568 | Ortho=0.121751 | Graph=13.826549 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  1000] total=0.008769 | OT=0.000853 | Ortho=0.027056 | Graph=7.645696 | lr=1.00e-03 | Acc=0.4972\n",
            "[Iter  1500] total=0.006621 | OT=0.000628 | Ortho=0.014464 | Graph=5.847812 | lr=1.00e-03 | Acc=0.4859\n",
            "[Iter  2000] total=0.005475 | OT=0.000480 | Ortho=0.009422 | Graph=4.900978 | lr=1.00e-03 | Acc=0.4350\n",
            "Early stopping at iter=2389 (best@2379 total=0.004954).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084670 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.019573 | OT=0.001837 | Ortho=0.155117 | Graph=16.185060 | lr=1.00e-03 | Acc=0.6045\n",
            "[Iter  1000] total=0.010481 | OT=0.000998 | Ortho=0.043591 | Graph=9.047056 | lr=1.00e-03 | Acc=0.4859\n",
            "[Iter  1500] total=0.007560 | OT=0.000706 | Ortho=0.019840 | Graph=6.656398 | lr=1.00e-03 | Acc=0.4350\n",
            "Early stopping at iter=1922 (best@1912 total=0.006347).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084764 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.020052 | OT=0.001854 | Ortho=0.165045 | Graph=16.547190 | lr=1.00e-03 | Acc=0.6441\n",
            "[Iter  1000] total=0.010551 | OT=0.001047 | Ortho=0.042463 | Graph=9.079344 | lr=1.00e-03 | Acc=0.5367\n",
            "[Iter  1500] total=0.007577 | OT=0.000717 | Ortho=0.020233 | Graph=6.657622 | lr=1.00e-03 | Acc=0.4124\n",
            "[Iter  2000] total=0.006162 | OT=0.000557 | Ortho=0.012344 | Graph=5.481240 | lr=5.00e-04 | Acc=0.4689\n",
            "[Iter  2500] total=0.005675 | OT=0.000524 | Ortho=0.010301 | Graph=5.048023 | lr=5.00e-04 | Acc=0.4237\n",
            "[Iter  3000] total=0.005220 | OT=0.000466 | Ortho=0.008595 | Graph=4.667992 | lr=5.00e-04 | Acc=0.3955\n",
            "Early stopping at iter=3457 (best@3447 total=0.004842).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.016578 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.005515 | OT=0.001835 | Ortho=0.008762 | Graph=35.926662 | lr=1.00e-03 | Acc=0.6328\n",
            "[Iter  1000] total=0.003499 | OT=0.000970 | Ortho=0.004158 | Graph=24.874308 | lr=1.00e-03 | Acc=0.6271\n",
            "[Iter  1500] total=0.002625 | OT=0.000706 | Ortho=0.002381 | Graph=18.949749 | lr=1.00e-03 | Acc=0.6328\n",
            "Early stopping at iter=1550 (best@1540 total=0.002588).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029460 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.006974 | OT=0.002534 | Ortho=0.014515 | Graph=42.948319 | lr=1.00e-03 | Acc=0.5932\n",
            "[Iter  1000] total=0.004718 | OT=0.001341 | Ortho=0.007623 | Graph=33.006493 | lr=1.00e-03 | Acc=0.5876\n",
            "Early stopping at iter=1492 (best@1482 total=0.003377).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029554 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.007106 | OT=0.002611 | Ortho=0.016867 | Graph=43.259372 | lr=1.00e-03 | Acc=0.6045\n",
            "[Iter  1000] total=0.004951 | OT=0.001350 | Ortho=0.007235 | Graph=35.279443 | lr=1.00e-03 | Acc=0.5706\n",
            "[Iter  1500] total=0.003772 | OT=0.001013 | Ortho=0.004637 | Graph=27.127196 | lr=1.00e-03 | Acc=0.5593\n",
            "[Iter  2000] total=0.002840 | OT=0.000822 | Ortho=0.003082 | Graph=19.869143 | lr=1.00e-03 | Acc=0.5650\n",
            "[Iter  2500] total=0.002283 | OT=0.000635 | Ortho=0.001985 | Graph=16.281554 | lr=5.00e-04 | Acc=0.6045\n",
            "[Iter  3000] total=0.002023 | OT=0.000555 | Ortho=0.001475 | Graph=14.529927 | lr=5.00e-04 | Acc=0.6045\n",
            "[Iter  3500] total=0.001766 | OT=0.000455 | Ortho=0.001117 | Graph=13.001830 | lr=5.00e-04 | Acc=0.6441\n",
            "Early stopping at iter=3713 (best@3703 total=0.001679).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.011057 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.002641 | OT=0.002151 | Ortho=0.002736 | Graph=46.249676 | lr=1.00e-03 | Acc=0.6158\n",
            "[Iter  1000] total=0.001767 | OT=0.001353 | Ortho=0.001085 | Graph=40.372608 | lr=1.00e-03 | Acc=0.5706\n",
            "Early stopping at iter=1054 (best@1044 total=0.001720).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.023939 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003253 | OT=0.002718 | Ortho=0.005184 | Graph=48.325594 | lr=1.00e-03 | Acc=0.5932\n",
            "[Iter  1000] total=0.002087 | OT=0.001638 | Ortho=0.001724 | Graph=43.221666 | lr=1.00e-03 | Acc=0.5706\n",
            "[Iter  1500] total=0.001567 | OT=0.001167 | Ortho=0.001078 | Graph=38.891989 | lr=1.00e-03 | Acc=0.5763\n",
            "Early stopping at iter=1556 (best@1546 total=0.001522).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.024033 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003453 | OT=0.002902 | Ortho=0.006105 | Graph=48.961609 | lr=1.00e-03 | Acc=0.5932\n",
            "[Iter  1000] total=0.002093 | OT=0.001640 | Ortho=0.002149 | Graph=43.106488 | lr=1.00e-03 | Acc=0.5593\n",
            "[Iter  1500] total=0.001571 | OT=0.001169 | Ortho=0.000944 | Graph=39.306668 | lr=1.00e-03 | Acc=0.5537\n",
            "Early stopping at iter=1524 (best@1514 total=0.001554).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010505 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.002274 | OT=0.002210 | Ortho=0.001722 | Graph=47.105850 | lr=1.00e-03 | Acc=0.5876\n",
            "Early stopping at iter=834 (best@824 total=0.001651).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.023387 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003063 | OT=0.002967 | Ortho=0.004595 | Graph=49.385601 | lr=1.00e-03 | Acc=0.5819\n",
            "Early stopping at iter=791 (best@781 total=0.002240).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.023481 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003054 | OT=0.002951 | Ortho=0.005382 | Graph=49.511606 | lr=1.00e-03 | Acc=0.5932\n",
            "[Iter  1000] total=0.001727 | OT=0.001663 | Ortho=0.001994 | Graph=43.984106 | lr=1.00e-03 | Acc=0.5593\n",
            "Early stopping at iter=1474 (best@1464 total=0.001261).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010449 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.002186 | OT=0.002162 | Ortho=0.001954 | Graph=48.088451 | lr=1.00e-03 | Acc=0.5706\n",
            "Early stopping at iter=876 (best@866 total=0.001530).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.023332 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003024 | OT=0.002974 | Ortho=0.004541 | Graph=49.438457 | lr=1.00e-03 | Acc=0.5876\n",
            "Early stopping at iter=791 (best@781 total=0.002204).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.023426 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003013 | OT=0.002955 | Ortho=0.005310 | Graph=49.545092 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  1000] total=0.001682 | OT=0.001659 | Ortho=0.001918 | Graph=44.049645 | lr=1.00e-03 | Acc=0.5593\n",
            "[Iter  1500] total=0.001201 | OT=0.001189 | Ortho=0.000835 | Graph=40.511038 | lr=1.00e-03 | Acc=0.5593\n",
            "Early stopping at iter=1566 (best@1556 total=0.001155).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010444 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.002180 | OT=0.002161 | Ortho=0.001847 | Graph=48.107395 | lr=1.00e-03 | Acc=0.5819\n",
            "Early stopping at iter=817 (best@807 total=0.001593).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.023327 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003021 | OT=0.002975 | Ortho=0.004538 | Graph=49.443762 | lr=1.00e-03 | Acc=0.5876\n",
            "Early stopping at iter=795 (best@785 total=0.002194).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.023421 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003009 | OT=0.002955 | Ortho=0.005303 | Graph=49.547234 | lr=1.00e-03 | Acc=0.5819\n",
            "[Iter  1000] total=0.001683 | OT=0.001664 | Ortho=0.001944 | Graph=44.057843 | lr=1.00e-03 | Acc=0.5593\n",
            "Early stopping at iter=1075 (best@1065 total=0.001591).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.071787 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.009634 | OT=0.000010 | Ortho=9.284351 | Graph=0.339470 | lr=1.00e-03 | Acc=0.2034\n",
            "[Iter  1000] total=0.007312 | OT=0.000153 | Ortho=4.853859 | Graph=2.305232 | lr=1.00e-03 | Acc=0.2881\n",
            "[Iter  1500] total=0.005554 | OT=0.000202 | Ortho=2.309594 | Graph=3.041670 | lr=1.00e-03 | Acc=0.3390\n",
            "[Iter  2000] total=0.004481 | OT=0.000215 | Ortho=0.988904 | Graph=3.277628 | lr=1.00e-03 | Acc=0.2994\n",
            "[Iter  2500] total=0.003936 | OT=0.000192 | Ortho=0.671323 | Graph=3.072287 | lr=1.00e-03 | Acc=0.3164\n",
            "[Iter  3000] total=0.003552 | OT=0.000165 | Ortho=0.515496 | Graph=2.870927 | lr=1.00e-03 | Acc=0.2881\n",
            "[Iter  3500] total=0.003344 | OT=0.000144 | Ortho=0.443522 | Graph=2.756109 | lr=5.00e-04 | Acc=0.3785\n",
            "[Iter  4000] total=0.003188 | OT=0.000132 | Ortho=0.396547 | Graph=2.660095 | lr=5.00e-04 | Acc=0.3333\n",
            "[Iter  4500] total=0.003022 | OT=0.000120 | Ortho=0.350993 | Graph=2.550845 | lr=5.00e-04 | Acc=0.3390\n",
            "[Iter  5000] total=0.002918 | OT=0.000115 | Ortho=0.324614 | Graph=2.478496 | lr=2.50e-04 | Acc=0.3503\n",
            "[Iter  5500] total=0.002828 | OT=0.000111 | Ortho=0.303512 | Graph=2.414243 | lr=2.50e-04 | Acc=0.3616\n",
            "[Iter  6000] total=0.002729 | OT=0.000105 | Ortho=0.281430 | Graph=2.342253 | lr=2.50e-04 | Acc=0.3842\n",
            "[Iter  6500] total=0.002635 | OT=0.000100 | Ortho=0.259905 | Graph=2.274309 | lr=2.50e-04 | Acc=0.4181\n",
            "[Iter  7000] total=0.002544 | OT=0.000093 | Ortho=0.240435 | Graph=2.210225 | lr=2.50e-04 | Acc=0.4633\n",
            "[Iter  7500] total=0.002465 | OT=0.000087 | Ortho=0.221611 | Graph=2.156166 | lr=2.50e-04 | Acc=0.4915\n",
            "[Iter  8000] total=0.002399 | OT=0.000082 | Ortho=0.206591 | Graph=2.110187 | lr=2.50e-04 | Acc=0.4802\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084670 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.009850 | OT=0.000003 | Ortho=9.713071 | Graph=0.134027 | lr=1.00e-03 | Acc=0.2373\n",
            "[Iter  1000] total=0.008814 | OT=0.000060 | Ortho=7.718637 | Graph=1.035329 | lr=1.00e-03 | Acc=0.2486\n",
            "[Iter  1500] total=0.006512 | OT=0.000201 | Ortho=3.599173 | Graph=2.711018 | lr=1.00e-03 | Acc=0.2768\n",
            "[Iter  2000] total=0.005126 | OT=0.000245 | Ortho=1.677224 | Graph=3.203835 | lr=1.00e-03 | Acc=0.2938\n",
            "[Iter  2500] total=0.004291 | OT=0.000246 | Ortho=0.839082 | Graph=3.206360 | lr=1.00e-03 | Acc=0.2655\n",
            "[Iter  3000] total=0.003843 | OT=0.000216 | Ortho=0.601590 | Graph=3.024553 | lr=1.00e-03 | Acc=0.2373\n",
            "[Iter  3500] total=0.003504 | OT=0.000188 | Ortho=0.485195 | Graph=2.830247 | lr=1.00e-03 | Acc=0.2881\n",
            "[Iter  4000] total=0.003241 | OT=0.000168 | Ortho=0.400945 | Graph=2.671428 | lr=1.00e-03 | Acc=0.2429\n",
            "[Iter  4500] total=0.003121 | OT=0.000152 | Ortho=0.367754 | Graph=2.601186 | lr=5.00e-04 | Acc=0.2599\n",
            "[Iter  5000] total=0.003001 | OT=0.000141 | Ortho=0.335273 | Graph=2.524730 | lr=5.00e-04 | Acc=0.2203\n",
            "[Iter  5500] total=0.002881 | OT=0.000135 | Ortho=0.304017 | Graph=2.441591 | lr=5.00e-04 | Acc=0.2034\n",
            "[Iter  6000] total=0.002794 | OT=0.000127 | Ortho=0.282764 | Graph=2.384579 | lr=2.50e-04 | Acc=0.2203\n",
            "[Iter  6500] total=0.002728 | OT=0.000122 | Ortho=0.267803 | Graph=2.337787 | lr=2.50e-04 | Acc=0.2542\n",
            "[Iter  7000] total=0.002652 | OT=0.000117 | Ortho=0.250717 | Graph=2.284883 | lr=2.50e-04 | Acc=0.2203\n",
            "[Iter  7500] total=0.002576 | OT=0.000113 | Ortho=0.234273 | Graph=2.228625 | lr=2.50e-04 | Acc=0.2090\n",
            "[Iter  8000] total=0.002504 | OT=0.000109 | Ortho=0.220353 | Graph=2.174258 | lr=2.50e-04 | Acc=0.2147\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084764 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.009864 | OT=0.000002 | Ortho=9.738918 | Graph=0.122584 | lr=1.00e-03 | Acc=0.2768\n",
            "[Iter  1000] total=0.008980 | OT=0.000052 | Ortho=8.024015 | Graph=0.903466 | lr=1.00e-03 | Acc=0.2712\n",
            "[Iter  1500] total=0.006633 | OT=0.000195 | Ortho=3.747588 | Graph=2.690427 | lr=1.00e-03 | Acc=0.2316\n",
            "[Iter  2000] total=0.005127 | OT=0.000225 | Ortho=1.695190 | Graph=3.206744 | lr=1.00e-03 | Acc=0.3051\n",
            "[Iter  2500] total=0.004268 | OT=0.000224 | Ortho=0.848093 | Graph=3.196359 | lr=1.00e-03 | Acc=0.2938\n",
            "[Iter  3000] total=0.003825 | OT=0.000199 | Ortho=0.594852 | Graph=3.030640 | lr=1.00e-03 | Acc=0.3164\n",
            "[Iter  3500] total=0.003495 | OT=0.000173 | Ortho=0.478914 | Graph=2.843032 | lr=1.00e-03 | Acc=0.2881\n",
            "Early stopping at iter=3832 (best@3822 total=0.003329).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.016578 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004975 | OT=0.001022 | Ortho=1.651237 | Graph=23.015676 | lr=1.00e-03 | Acc=0.4237\n",
            "[Iter  1000] total=0.003162 | OT=0.000787 | Ortho=0.406420 | Graph=19.687197 | lr=1.00e-03 | Acc=0.4746\n",
            "[Iter  1500] total=0.002393 | OT=0.000596 | Ortho=0.218671 | Graph=15.777855 | lr=1.00e-03 | Acc=0.4859\n",
            "Early stopping at iter=1763 (best@1753 total=0.002132).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029460 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.006466 | OT=0.001024 | Ortho=3.036743 | Graph=24.054662 | lr=1.00e-03 | Acc=0.4294\n",
            "[Iter  1000] total=0.004478 | OT=0.001105 | Ortho=0.976514 | Graph=23.963881 | lr=1.00e-03 | Acc=0.5367\n",
            "[Iter  1500] total=0.003217 | OT=0.000767 | Ortho=0.432915 | Graph=20.168899 | lr=1.00e-03 | Acc=0.5537\n",
            "[Iter  2000] total=0.002596 | OT=0.000618 | Ortho=0.272992 | Graph=17.047025 | lr=1.00e-03 | Acc=0.5254\n",
            "Early stopping at iter=2206 (best@2196 total=0.002401).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029554 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.006430 | OT=0.000925 | Ortho=3.055389 | Graph=24.496951 | lr=1.00e-03 | Acc=0.4746\n",
            "[Iter  1000] total=0.004771 | OT=0.000970 | Ortho=1.565519 | Graph=22.350364 | lr=1.00e-03 | Acc=0.4859\n",
            "[Iter  1500] total=0.003096 | OT=0.000782 | Ortho=0.399616 | Graph=19.142679 | lr=1.00e-03 | Acc=0.4520\n",
            "Early stopping at iter=1690 (best@1680 total=0.002733).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.011057 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.002098 | OT=0.001532 | Ortho=0.153937 | Graph=41.234076 | lr=1.00e-03 | Acc=0.6328\n",
            "Early stopping at iter=809 (best@799 total=0.001652).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.023939 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004015 | OT=0.001454 | Ortho=2.186507 | Graph=37.411494 | lr=1.00e-03 | Acc=0.4576\n",
            "[Iter  1000] total=0.002123 | OT=0.001488 | Ortho=0.245193 | Graph=38.980586 | lr=1.00e-03 | Acc=0.4633\n",
            "[Iter  1500] total=0.001521 | OT=0.001053 | Ortho=0.102583 | Graph=36.545535 | lr=1.00e-03 | Acc=0.4689\n",
            "Early stopping at iter=1523 (best@1513 total=0.001502).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.024033 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.004102 | OT=0.001558 | Ortho=2.168983 | Graph=37.513760 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter  1000] total=0.002331 | OT=0.001679 | Ortho=0.249234 | Graph=40.337206 | lr=1.00e-03 | Acc=0.5480\n",
            "Early stopping at iter=1376 (best@1366 total=0.001802).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010505 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.001760 | OT=0.001636 | Ortho=0.080890 | Graph=42.882642 | lr=1.00e-03 | Acc=0.6271\n",
            "Early stopping at iter=970 (best@960 total=0.001255).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.023387 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003781 | OT=0.001638 | Ortho=2.103362 | Graph=39.115332 | lr=1.00e-03 | Acc=0.4972\n",
            "[Iter  1000] total=0.001940 | OT=0.001698 | Ortho=0.200297 | Graph=41.014384 | lr=1.00e-03 | Acc=0.4972\n",
            "Early stopping at iter=1172 (best@1162 total=0.001717).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.023481 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003820 | OT=0.001709 | Ortho=2.071480 | Graph=39.600991 | lr=1.00e-03 | Acc=0.5198\n",
            "[Iter  1000] total=0.001917 | OT=0.001703 | Ortho=0.171386 | Graph=42.618673 | lr=1.00e-03 | Acc=0.5085\n",
            "Early stopping at iter=1447 (best@1437 total=0.001359).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010449 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.001746 | OT=0.001650 | Ortho=0.092255 | Graph=42.340425 | lr=1.00e-03 | Acc=0.6271\n",
            "Early stopping at iter=985 (best@975 total=0.001198).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.023332 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003763 | OT=0.001655 | Ortho=2.104688 | Graph=39.414230 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter  1000] total=0.001960 | OT=0.001762 | Ortho=0.193851 | Graph=41.984952 | lr=1.00e-03 | Acc=0.4859\n",
            "Early stopping at iter=1440 (best@1430 total=0.001427).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.023426 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003805 | OT=0.001751 | Ortho=2.050300 | Graph=40.204613 | lr=1.00e-03 | Acc=0.4802\n",
            "[Iter  1000] total=0.001842 | OT=0.001671 | Ortho=0.166731 | Graph=42.313505 | lr=1.00e-03 | Acc=0.5198\n",
            "[Iter  1500] total=0.001259 | OT=0.001197 | Ortho=0.058574 | Graph=40.444818 | lr=1.00e-03 | Acc=0.5593\n",
            "Early stopping at iter=1521 (best@1511 total=0.001253).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010444 | OT=0.010443 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.001736 | OT=0.001636 | Ortho=0.099539 | Graph=42.131989 | lr=1.00e-03 | Acc=0.6045\n",
            "Early stopping at iter=909 (best@899 total=0.001323).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.023327 | OT=0.023326 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003760 | OT=0.001655 | Ortho=2.104500 | Graph=39.416776 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter  1000] total=0.001958 | OT=0.001764 | Ortho=0.193459 | Graph=41.984632 | lr=1.00e-03 | Acc=0.4689\n",
            "Early stopping at iter=1236 (best@1226 total=0.001612).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.023421 | OT=0.023420 | Ortho=0.000000 | Graph=61.343770 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter   500] total=0.003766 | OT=0.001657 | Ortho=2.108869 | Graph=39.124934 | lr=1.00e-03 | Acc=0.4689\n",
            "[Iter  1000] total=0.001857 | OT=0.001642 | Ortho=0.214294 | Graph=42.034220 | lr=1.00e-03 | Acc=0.5028\n",
            "Early stopping at iter=1459 (best@1449 total=0.001279).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "    # use_rkhs_weights=False,     # True => geodesics sum RKHS distances; False => hop counts\n",
        "    # normalize=True,\n",
        "X =np.genfromtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/Cheow_expression.csv\", delimiter=\",\")\n",
        "X_normalized = normalize(X, norm='l2')\n",
        "y=np.genfromtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/Cheow_methylation.csv\", delimiter=\",\")\n",
        "y_normalized = normalize(y, norm='l2')\n",
        "\n",
        "cellTypes_X=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/scGEM_typeExpression.txt\")\n",
        "cellTypes_y=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/scGEM_typeMethylation.txt\")\n",
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    X_normalized\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "  y_normalized\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[5],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=8000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "     X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "    labels_X=cellTypes_X,\n",
        "    labels_Y=cellTypes_y,\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_n4pg-0KqFbf",
      "metadata": {
        "id": "_n4pg-0KqFbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        0.001  1.000000e-07    0.1    0.001198  0.672316  0.210332\n",
            "1   5  5        1.000  1.000000e-04    0.1    0.005963  0.632768  0.209694\n",
            "2   5  5        0.100  1.000000e-04    1.0    0.004858  0.632768  0.210508\n",
            "3   5  5        0.100  1.000000e-05    5.0    0.002885  0.627119  0.202113\n",
            "4   5  5        0.001  1.000000e-06    0.1    0.001255  0.627119  0.209071\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        0.010  1.000000e-03    0.1    0.004954  0.435028  0.257573\n",
            "68  5  5        0.010  1.000000e-03    1.0    0.006347  0.423729  0.251540\n",
            "69  5  5        0.010  1.000000e-03    5.0    0.004842  0.361582  0.249529\n",
            "70  5  5        0.001  1.000000e-03    5.0    0.003329  0.310734  0.424335\n",
            "71  5  5        0.001  1.000000e-03    1.0    0.002504  0.214689  0.433368\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        0.010  1.000000e-07    5.0    0.001155  0.564972  0.212966\n",
            "1   5  5        0.001  1.000000e-07    0.1    0.001198  0.672316  0.210332\n",
            "2   5  5        0.001  1.000000e-07    5.0    0.001253  0.542373  0.265585\n",
            "3   5  5        0.001  1.000000e-06    0.1    0.001255  0.627119  0.209071\n",
            "4   5  5        0.010  1.000000e-06    5.0    0.001261  0.559322  0.212327\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        0.100  1.000000e-03    1.0    0.006018  0.525424  0.242986\n",
            "68  5  5        0.010  1.000000e-03    1.0    0.006347  0.423729  0.251540\n",
            "69  5  5        1.000  1.000000e-03    0.1    0.006708  0.598870  0.251572\n",
            "70  5  5        1.000  1.000000e-03    5.0    0.007271  0.502825  0.254397\n",
            "71  5  5        1.000  1.000000e-04    1.0    0.007699  0.598870  0.197277\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        1.000  1.000000e-05    1.0    0.004816  0.587571  0.193335\n",
            "1   5  5        1.000  1.000000e-06    1.0    0.003889  0.581921  0.194405\n",
            "2   5  5        1.000  1.000000e-08    1.0    0.004170  0.581921  0.194867\n",
            "3   5  5        1.000  1.000000e-07    1.0    0.003944  0.570621  0.195155\n",
            "4   5  5        1.000  1.000000e-04    5.0    0.005723  0.587571  0.196559\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        0.001  1.000000e-06    5.0    0.001359  0.485876  0.271490\n",
            "68  5  5        0.001  1.000000e-04    0.1    0.002132  0.446328  0.298733\n",
            "69  5  5        0.001  1.000000e-03    0.1    0.002399  0.480226  0.397555\n",
            "70  5  5        0.001  1.000000e-03    5.0    0.003329  0.310734  0.424335\n",
            "71  5  5        0.001  1.000000e-03    1.0    0.002504  0.214689  0.433368\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UtHr5rDTwUHp",
      "metadata": {
        "id": "UtHr5rDTwUHp"
      },
      "source": [
        "# **Unbalance** Cell Type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ha6SYjIXqCaV",
      "metadata": {
        "id": "Ha6SYjIXqCaV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ef8fe1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "48ef8fe1",
        "outputId": "e63a7851-1964-45ea-d3be-67e0fc6917dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ATAC] Keeping 207180/207202 peaks (removed 22 all-zero peaks).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. RNA: (131, 4516) | ATAC: (205, 207180)\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# !pip install scanpy anndata muon --quiet\n",
        "\n",
        "import scanpy as sc\n",
        "import muon as mu\n",
        "import warnings\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "import muon as mu\n",
        "\n",
        "path = \"/Users/aaaaaaaron/Downloads/data_repro 2/cell_lines_2.h5mu.gz\"   # or .h5mz\n",
        "\n",
        "# Try reading directly with muon (it can handle .h5mu and .h5mz)\n",
        "mdata= mu.read_h5mu(path)\n",
        "\n",
        "# mdata = mu.read(PATH)  # <- uncomment if you haven't loaded it yet\n",
        "\n",
        "# ---------------- RNA ----------------\n",
        "# 1) Preserve raw RNA counts in a layer\n",
        "mdata.mod[\"rna\"].layers[\"counts\"] = mdata.mod[\"rna\"].X.copy()\n",
        "\n",
        "# 2) Log-normalize RNA counts\n",
        "sc.pp.normalize_total(mdata.mod[\"rna\"], target_sum=1e4)\n",
        "sc.pp.log1p(mdata.mod[\"rna\"])\n",
        "\n",
        "# 3) HVGs from both raw and normalized, then take the union\n",
        "raw_hvg = sc.pp.highly_variable_genes(\n",
        "    mdata.mod[\"rna\"], layer=\"counts\", n_top_genes=3000, subset=False,\n",
        "    inplace=False, flavor=\"seurat_v3\"\n",
        ")[\"highly_variable\"].values\n",
        "\n",
        "norm_hvg = sc.pp.highly_variable_genes(\n",
        "    mdata.mod[\"rna\"], n_top_genes=3000, subset=False, inplace=False\n",
        ")[\"highly_variable\"].values\n",
        "\n",
        "hvg_union = np.logical_or(raw_hvg, norm_hvg)  # <-- fixed\n",
        "mdata.mod[\"rna\"] = mdata.mod[\"rna\"][:, hvg_union].copy()\n",
        "\n",
        "# 4) PCA on RNA (selected genes)\n",
        "sc.tl.pca(mdata.mod[\"rna\"], n_comps=50, zero_center=None)\n",
        "\n",
        "# ---------------- ATAC ----------------\n",
        "# 5) Remove peaks that are zero across all cells to avoid TF–IDF / 0\n",
        "atac = mdata.mod[\"atac\"]\n",
        "nonempty = np.ravel(atac.X.sum(axis=0)) > 0\n",
        "kept, total = int(nonempty.sum()), int(nonempty.size)\n",
        "print(f\"[ATAC] Keeping {kept}/{total} peaks (removed {total-kept} all-zero peaks).\")\n",
        "atac = atac[:, nonempty].copy()\n",
        "mdata.mod[\"atac\"] = atac\n",
        "\n",
        "# 6) TF–IDF (log TF and log IDF), then PCA\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"divide by zero encountered in divide\")\n",
        "    mu.atac.pp.tfidf(mdata.mod[\"atac\"], log_tf=True, log_idf=True)\n",
        "\n",
        "sc.tl.pca(mdata.mod[\"atac\"], n_comps=50, zero_center=None)\n",
        "\n",
        "# ---------------- UMAPs ----------------\n",
        "# 7) Neighbors + UMAP for each modality\n",
        "sc.pp.neighbors(mdata.mod[\"rna\"],  n_neighbors=15, n_pcs=50, metric=\"euclidean\")\n",
        "sc.tl.umap(mdata.mod[\"rna\"])\n",
        "\n",
        "sc.pp.neighbors(mdata.mod[\"atac\"], n_neighbors=15, n_pcs=50, metric=\"euclidean\")\n",
        "sc.tl.umap(mdata.mod[\"atac\"])\n",
        "\n",
        "# 8) Plot UMAPs (color by celltype if present)\n",
        "color_key_rna  = \"celltype\" if \"celltype\" in mdata.mod[\"rna\"].obs.columns  else None\n",
        "color_key_atac = \"celltype\" if \"celltype\" in mdata.mod[\"atac\"].obs.columns else None\n",
        "\n",
        "sc.pl.umap(mdata.mod[\"rna\"],  color=color_key_rna,  title=\"RNA (UMAP)\",  frameon=False)\n",
        "sc.pl.umap(mdata.mod[\"atac\"], color=color_key_atac, title=\"ATAC (UMAP)\", frameon=False)\n",
        "\n",
        "print(\"Done. RNA:\", mdata['rna'].shape, \"| ATAC:\", mdata['atac'].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T7N_1mZnjASa",
      "metadata": {
        "id": "T7N_1mZnjASa"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "res_x = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"rna\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"atac\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef04902",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DD2lzpkpYxDW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD2lzpkpYxDW",
        "outputId": "03546f62-b162-4b1f-eaee-7e3a992c533e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.136030 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.061942 | OT=0.014499 | Ortho=0.000070 | Graph=47.373314 | lr=5.00e-04 | Acc=0.8702\n",
            "[Iter  1000] total=0.046124 | OT=0.012862 | Ortho=0.000031 | Graph=33.230731 | lr=5.00e-04 | Acc=0.9466\n",
            "[Iter  1500] total=0.039356 | OT=0.009510 | Ortho=0.000023 | Graph=29.823490 | lr=5.00e-04 | Acc=0.7481\n",
            "[Iter  2000] total=0.035487 | OT=0.008290 | Ortho=0.000024 | Graph=27.172752 | lr=5.00e-04 | Acc=0.7328\n",
            "[Iter  2500] total=0.030570 | OT=0.006182 | Ortho=0.000016 | Graph=24.371737 | lr=5.00e-04 | Acc=0.7557\n",
            "[Iter  3000] total=0.026659 | OT=0.004737 | Ortho=0.000012 | Graph=21.909716 | lr=5.00e-04 | Acc=0.7099\n",
            "[Iter  3500] total=0.023824 | OT=0.004037 | Ortho=0.000010 | Graph=19.776294 | lr=5.00e-04 | Acc=0.7176\n",
            "Early stopping at iter=3906 (best@3896 total=0.021983).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.188955 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.069231 | OT=0.025174 | Ortho=0.000169 | Graph=43.887810 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  1000] total=0.040847 | OT=0.011155 | Ortho=0.000037 | Graph=29.654805 | lr=1.00e-03 | Acc=0.9313\n",
            "[Iter  1500] total=0.031305 | OT=0.006321 | Ortho=0.000019 | Graph=24.964367 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2000] total=0.026575 | OT=0.004577 | Ortho=0.000013 | Graph=21.984812 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2500] total=0.023353 | OT=0.003628 | Ortho=0.000009 | Graph=19.715735 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  3000] total=0.021325 | OT=0.003090 | Ortho=0.000008 | Graph=18.226847 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  3500] total=0.019386 | OT=0.002538 | Ortho=0.000007 | Graph=16.841152 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  4000] total=0.017601 | OT=0.002198 | Ortho=0.000006 | Graph=15.396222 | lr=1.00e-03 | Acc=0.9084\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.190976 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.069144 | OT=0.025990 | Ortho=0.000172 | Graph=42.982468 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  1000] total=0.039861 | OT=0.011313 | Ortho=0.000035 | Graph=28.513339 | lr=1.00e-03 | Acc=0.9313\n",
            "[Iter  1500] total=0.030269 | OT=0.006103 | Ortho=0.000018 | Graph=24.148492 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  2000] total=0.025984 | OT=0.004600 | Ortho=0.000012 | Graph=21.372961 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  2500] total=0.023367 | OT=0.003828 | Ortho=0.000009 | Graph=19.529334 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3000] total=0.021385 | OT=0.003278 | Ortho=0.000008 | Graph=18.099232 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3500] total=0.019709 | OT=0.002881 | Ortho=0.000007 | Graph=16.820968 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  4000] total=0.017907 | OT=0.002512 | Ortho=0.000006 | Graph=15.389822 | lr=1.00e-03 | Acc=0.8931\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.028962 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=141 (best@141 total=0.028863).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.081887 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.059277 | OT=0.047685 | Ortho=0.000213 | Graph=113.791558 | lr=5.00e-04 | Acc=0.7328\n",
            "[Iter  1000] total=0.026537 | OT=0.017200 | Ortho=0.000033 | Graph=93.046321 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  1500] total=0.016874 | OT=0.011044 | Ortho=0.000013 | Graph=58.165861 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.012360 | OT=0.007548 | Ortho=0.000006 | Graph=48.061830 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.010084 | OT=0.005884 | Ortho=0.000004 | Graph=41.963388 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3000] total=0.008422 | OT=0.004619 | Ortho=0.000003 | Graph=37.997780 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3500] total=0.007260 | OT=0.003780 | Ortho=0.000002 | Graph=34.785852 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=3565 (best@3555 total=0.007160).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.083908 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.060597 | OT=0.048897 | Ortho=0.000228 | Graph=114.722126 | lr=5.00e-04 | Acc=0.7252\n",
            "[Iter  1000] total=0.027542 | OT=0.017759 | Ortho=0.000035 | Graph=97.490814 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1500] total=0.018954 | OT=0.012313 | Ortho=0.000017 | Graph=66.240883 | lr=5.00e-04 | Acc=0.7863\n",
            "[Iter  2000] total=0.013693 | OT=0.008386 | Ortho=0.000007 | Graph=52.992544 | lr=5.00e-04 | Acc=0.7786\n",
            "[Iter  2500] total=0.010922 | OT=0.006302 | Ortho=0.000004 | Graph=46.155751 | lr=5.00e-04 | Acc=0.7863\n",
            "[Iter  3000] total=0.009263 | OT=0.004991 | Ortho=0.000003 | Graph=42.680397 | lr=5.00e-04 | Acc=0.7863\n",
            "[Iter  3500] total=0.007913 | OT=0.004091 | Ortho=0.000002 | Graph=38.197662 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  4000] total=0.006630 | OT=0.003252 | Ortho=0.000002 | Graph=33.767402 | lr=5.00e-04 | Acc=0.8092\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018255 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=143 (best@143 total=0.018195).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.071180 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.049863 | OT=0.048506 | Ortho=0.000190 | Graph=116.687927 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.018679 | OT=0.017566 | Ortho=0.000018 | Graph=109.488381 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.012784 | OT=0.011787 | Ortho=0.000009 | Graph=98.870569 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  2000] total=0.009042 | OT=0.008166 | Ortho=0.000004 | Graph=87.269846 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.006937 | OT=0.006146 | Ortho=0.000004 | Graph=78.602958 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=2775 (best@2765 total=0.006168).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.073201 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.057546 | OT=0.056136 | Ortho=0.000229 | Graph=118.147739 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.040514 | OT=0.039213 | Ortho=0.000162 | Graph=113.915855 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.019695 | OT=0.018577 | Ortho=0.000023 | Graph=109.632300 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.015515 | OT=0.014468 | Ortho=0.000014 | Graph=103.403144 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011864 | OT=0.010913 | Ortho=0.000007 | Graph=94.403469 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  3000] total=0.009238 | OT=0.008373 | Ortho=0.000005 | Graph=85.980543 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3500] total=0.007359 | OT=0.006572 | Ortho=0.000004 | Graph=78.321685 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.006074 | OT=0.005346 | Ortho=0.000003 | Graph=72.511190 | lr=2.50e-04 | Acc=0.8244\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017185 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=162 (best@162 total=0.017149).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070109 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.048910 | OT=0.048604 | Ortho=0.000189 | Graph=116.900718 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.017768 | OT=0.017642 | Ortho=0.000016 | Graph=110.392488 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011942 | OT=0.011833 | Ortho=0.000008 | Graph=101.342133 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.008270 | OT=0.008175 | Ortho=0.000004 | Graph=91.176320 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.006365 | OT=0.006279 | Ortho=0.000003 | Graph=83.544475 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=2574 (best@2564 total=0.006171).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072131 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.056511 | OT=0.056166 | Ortho=0.000228 | Graph=118.258000 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.039816 | OT=0.039539 | Ortho=0.000163 | Graph=114.343635 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.018708 | OT=0.018576 | Ortho=0.000022 | Graph=110.333783 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.014598 | OT=0.014480 | Ortho=0.000013 | Graph=105.263155 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011172 | OT=0.011067 | Ortho=0.000007 | Graph=98.103077 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.008829 | OT=0.008732 | Ortho=0.000005 | Graph=91.350122 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.006937 | OT=0.006849 | Ortho=0.000004 | Graph=84.420398 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.005682 | OT=0.005600 | Ortho=0.000003 | Graph=79.220688 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017078 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=146 (best@146 total=0.017046).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070002 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.048810 | OT=0.048609 | Ortho=0.000189 | Graph=116.918619 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.017671 | OT=0.017644 | Ortho=0.000016 | Graph=110.475937 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011857 | OT=0.011840 | Ortho=0.000008 | Graph=101.577499 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.008202 | OT=0.008188 | Ortho=0.000004 | Graph=91.571547 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.006305 | OT=0.006293 | Ortho=0.000003 | Graph=84.007654 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2920 (best@2910 total=0.005209).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072024 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.056407 | OT=0.056167 | Ortho=0.000227 | Graph=118.267367 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.039730 | OT=0.039556 | Ortho=0.000163 | Graph=114.378340 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.018611 | OT=0.018579 | Ortho=0.000022 | Graph=110.410905 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.014506 | OT=0.014483 | Ortho=0.000013 | Graph=105.414924 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011087 | OT=0.011071 | Ortho=0.000007 | Graph=98.128716 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.008759 | OT=0.008745 | Ortho=0.000005 | Graph=91.574228 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.006887 | OT=0.006875 | Ortho=0.000004 | Graph=84.777999 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.005636 | OT=0.005625 | Ortho=0.000003 | Graph=79.676887 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=146 (best@146 total=0.017035).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069992 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.048800 | OT=0.048609 | Ortho=0.000189 | Graph=116.920406 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.017661 | OT=0.017644 | Ortho=0.000016 | Graph=110.484272 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011849 | OT=0.011840 | Ortho=0.000008 | Graph=101.600807 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.008195 | OT=0.008190 | Ortho=0.000004 | Graph=91.610661 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.006298 | OT=0.006294 | Ortho=0.000003 | Graph=84.047940 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.005439 | OT=0.005436 | Ortho=0.000002 | Graph=80.773728 | lr=2.50e-04 | Acc=0.8168\n",
            "[Iter  3500] total=0.004778 | OT=0.004776 | Ortho=0.000002 | Graph=78.376952 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  4000] total=0.004208 | OT=0.004206 | Ortho=0.000002 | Graph=76.148449 | lr=2.50e-04 | Acc=0.8168\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.056396 | OT=0.056168 | Ortho=0.000227 | Graph=118.268302 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.039721 | OT=0.039557 | Ortho=0.000163 | Graph=114.381802 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.018602 | OT=0.018579 | Ortho=0.000022 | Graph=110.418599 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.014497 | OT=0.014484 | Ortho=0.000013 | Graph=105.430992 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011079 | OT=0.011071 | Ortho=0.000007 | Graph=98.151923 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.008753 | OT=0.008747 | Ortho=0.000005 | Graph=91.609497 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.006882 | OT=0.006877 | Ortho=0.000004 | Graph=84.821094 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.005631 | OT=0.005627 | Ortho=0.000003 | Graph=79.723165 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.136030 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.032482 | OT=0.007482 | Ortho=0.001730 | Graph=24.826642 | lr=1.00e-03 | Acc=0.8550\n",
            "[Iter  1000] total=0.020610 | OT=0.003609 | Ortho=0.000753 | Graph=16.926122 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.015311 | OT=0.002431 | Ortho=0.000462 | Graph=12.834038 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  2000] total=0.011905 | OT=0.001952 | Ortho=0.000306 | Graph=9.921843 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  2500] total=0.009724 | OT=0.001840 | Ortho=0.000219 | Graph=7.862023 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  3000] total=0.008083 | OT=0.001532 | Ortho=0.000152 | Graph=6.535428 | lr=1.00e-03 | Acc=0.7252\n",
            "[Iter  3500] total=0.007204 | OT=0.001332 | Ortho=0.000111 | Graph=5.861289 | lr=5.00e-04 | Acc=0.6183\n",
            "[Iter  4000] total=0.006737 | OT=0.001208 | Ortho=0.000092 | Graph=5.519532 | lr=5.00e-04 | Acc=0.5573\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.188955 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.045869 | OT=0.014424 | Ortho=0.006182 | Graph=30.826358 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.028237 | OT=0.005773 | Ortho=0.001459 | Graph=22.317682 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  1500] total=0.023480 | OT=0.004377 | Ortho=0.000932 | Graph=19.010744 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2000] total=0.020340 | OT=0.003484 | Ortho=0.000720 | Graph=16.783905 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.017416 | OT=0.002699 | Ortho=0.000577 | Graph=14.659685 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.014815 | OT=0.002347 | Ortho=0.000457 | Graph=12.422450 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  3500] total=0.012340 | OT=0.002013 | Ortho=0.000334 | Graph=10.294492 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  4000] total=0.010494 | OT=0.001742 | Ortho=0.000246 | Graph=8.727036 | lr=5.00e-04 | Acc=0.8397\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.190976 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.030961 | OT=0.006989 | Ortho=0.001920 | Graph=23.780147 | lr=1.00e-03 | Acc=0.8473\n",
            "[Iter  1000] total=0.023192 | OT=0.004477 | Ortho=0.000908 | Graph=18.624476 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1500] total=0.018956 | OT=0.003122 | Ortho=0.000651 | Graph=15.769750 | lr=1.00e-03 | Acc=0.8473\n",
            "[Iter  2000] total=0.016108 | OT=0.002474 | Ortho=0.000503 | Graph=13.583637 | lr=1.00e-03 | Acc=0.8473\n",
            "[Iter  2500] total=0.013294 | OT=0.001995 | Ortho=0.000378 | Graph=11.261483 | lr=1.00e-03 | Acc=0.8473\n",
            "[Iter  3000] total=0.010990 | OT=0.001625 | Ortho=0.000272 | Graph=9.337332 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  3500] total=0.008980 | OT=0.001335 | Ortho=0.000193 | Graph=7.625912 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  4000] total=0.007393 | OT=0.001153 | Ortho=0.000124 | Graph=6.227621 | lr=1.00e-03 | Acc=0.8397\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.028962 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.016672 | OT=0.011775 | Ortho=0.000209 | Graph=48.758055 | lr=5.00e-04 | Acc=0.9618\n",
            "[Iter  1000] total=0.012481 | OT=0.008723 | Ortho=0.000108 | Graph=37.466103 | lr=5.00e-04 | Acc=0.9924\n",
            "[Iter  1500] total=0.008579 | OT=0.005558 | Ortho=0.000072 | Graph=30.141904 | lr=5.00e-04 | Acc=0.9924\n",
            "[Iter  2000] total=0.006851 | OT=0.004133 | Ortho=0.000033 | Graph=27.150793 | lr=5.00e-04 | Acc=0.9924\n",
            "[Iter  2500] total=0.005749 | OT=0.003281 | Ortho=0.000025 | Graph=24.655906 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  3000] total=0.004975 | OT=0.002699 | Ortho=0.000020 | Graph=22.732480 | lr=5.00e-04 | Acc=0.9542\n",
            "[Iter  3500] total=0.004178 | OT=0.002070 | Ortho=0.000017 | Graph=21.061421 | lr=5.00e-04 | Acc=0.9313\n",
            "[Iter  4000] total=0.003469 | OT=0.001500 | Ortho=0.000018 | Graph=19.666314 | lr=5.00e-04 | Acc=0.9160\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.081887 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.012674 | OT=0.007993 | Ortho=0.000577 | Graph=46.235996 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.007418 | OT=0.003818 | Ortho=0.000201 | Graph=35.802375 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1500] total=0.005184 | OT=0.002427 | Ortho=0.000068 | Graph=27.503788 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.004306 | OT=0.001888 | Ortho=0.000156 | Graph=24.017382 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=2004 (best@1994 total=0.004288).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.083908 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.020225 | OT=0.013322 | Ortho=0.001854 | Graph=67.180525 | lr=5.00e-04 | Acc=0.7634\n",
            "[Iter  1000] total=0.011083 | OT=0.006639 | Ortho=0.000422 | Graph=44.017453 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  1500] total=0.008075 | OT=0.004302 | Ortho=0.000221 | Graph=37.499746 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2000] total=0.006286 | OT=0.003172 | Ortho=0.000107 | Graph=31.036279 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2500] total=0.005165 | OT=0.002440 | Ortho=0.000052 | Graph=27.199284 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  3000] total=0.004518 | OT=0.002039 | Ortho=0.000034 | Graph=24.756404 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  3500] total=0.004105 | OT=0.001842 | Ortho=0.000023 | Graph=22.612166 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  4000] total=0.003783 | OT=0.001670 | Ortho=0.000022 | Graph=21.099476 | lr=5.00e-04 | Acc=0.8015\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018255 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.013874 | OT=0.012654 | Ortho=0.000408 | Graph=117.962715 | lr=5.00e-04 | Acc=0.6565\n",
            "[Iter  1000] total=0.011482 | OT=0.010427 | Ortho=0.000042 | Graph=105.054282 | lr=5.00e-04 | Acc=0.5420\n",
            "[Iter  1500] total=0.009431 | OT=0.008634 | Ortho=0.000035 | Graph=79.377446 | lr=5.00e-04 | Acc=0.0458\n",
            "[Iter  2000] total=0.004624 | OT=0.004098 | Ortho=0.000019 | Graph=52.473374 | lr=5.00e-04 | Acc=0.0458\n",
            "[Iter  2500] total=0.003194 | OT=0.002750 | Ortho=0.000007 | Graph=44.406537 | lr=5.00e-04 | Acc=0.0840\n",
            "[Iter  3000] total=0.002736 | OT=0.002326 | Ortho=0.000005 | Graph=40.936085 | lr=2.50e-04 | Acc=0.0840\n",
            "[Iter  3500] total=0.002524 | OT=0.002125 | Ortho=0.000005 | Graph=39.920523 | lr=2.50e-04 | Acc=0.0687\n",
            "[Iter  4000] total=0.002219 | OT=0.001832 | Ortho=0.000004 | Graph=38.700554 | lr=2.50e-04 | Acc=0.0687\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.071180 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008454 | OT=0.007646 | Ortho=0.000339 | Graph=77.473522 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004863 | OT=0.004193 | Ortho=0.000129 | Graph=65.730327 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.003706 | OT=0.003098 | Ortho=0.000062 | Graph=60.262693 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=1604 (best@1594 total=0.003541).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.073201 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008704 | OT=0.007912 | Ortho=0.000378 | Graph=75.351884 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.004653 | OT=0.004000 | Ortho=0.000114 | Graph=64.175321 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.003497 | OT=0.002895 | Ortho=0.000053 | Graph=59.751475 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1709 (best@1699 total=0.003217).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017185 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008802 | OT=0.008659 | Ortho=0.000265 | Graph=116.105648 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.006058 | OT=0.005943 | Ortho=0.000060 | Graph=109.331248 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1500] total=0.004590 | OT=0.004496 | Ortho=0.000034 | Graph=90.244007 | lr=5.00e-04 | Acc=0.8702\n",
            "[Iter  2000] total=0.003669 | OT=0.003595 | Ortho=0.000013 | Graph=72.805946 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.003094 | OT=0.003028 | Ortho=0.000009 | Graph=64.946442 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  3000] total=0.002733 | OT=0.002673 | Ortho=0.000006 | Graph=59.151200 | lr=5.00e-04 | Acc=0.8626\n",
            "Early stopping at iter=3205 (best@3195 total=0.002618).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070109 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.007855 | OT=0.007741 | Ortho=0.000323 | Graph=81.108871 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004255 | OT=0.004172 | Ortho=0.000126 | Graph=70.812741 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.003140 | OT=0.003068 | Ortho=0.000057 | Graph=66.008492 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002595 | OT=0.002528 | Ortho=0.000066 | Graph=60.422291 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2150 (best@2140 total=0.002422).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072131 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008229 | OT=0.008112 | Ortho=0.000364 | Graph=79.688645 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004286 | OT=0.004206 | Ortho=0.000110 | Graph=68.825897 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.003147 | OT=0.003075 | Ortho=0.000065 | Graph=65.491250 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1530 (best@1520 total=0.003084).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017078 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.013525 | OT=0.013432 | Ortho=0.000805 | Graph=116.527309 | lr=2.50e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.007936 | OT=0.007900 | Ortho=0.000248 | Graph=115.229017 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  1500] total=0.006069 | OT=0.006052 | Ortho=0.000058 | Graph=108.823900 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.005014 | OT=0.005001 | Ortho=0.000041 | Graph=93.959080 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.004191 | OT=0.004181 | Ortho=0.000023 | Graph=78.254155 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.003698 | OT=0.003689 | Ortho=0.000019 | Graph=67.767158 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  3500] total=0.003182 | OT=0.003175 | Ortho=0.000012 | Graph=60.510957 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  4000] total=0.002716 | OT=0.002710 | Ortho=0.000005 | Graph=55.864043 | lr=2.50e-04 | Acc=0.8397\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070002 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.007791 | OT=0.007751 | Ortho=0.000323 | Graph=81.490688 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004202 | OT=0.004182 | Ortho=0.000126 | Graph=71.256837 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002939 | OT=0.002927 | Ortho=0.000058 | Graph=66.833952 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002337 | OT=0.002328 | Ortho=0.000028 | Graph=62.325173 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2172 (best@2162 total=0.002182).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072024 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008175 | OT=0.008131 | Ortho=0.000366 | Graph=80.170361 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004219 | OT=0.004201 | Ortho=0.000111 | Graph=69.312450 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1500] total=0.003165 | OT=0.003124 | Ortho=0.000346 | Graph=66.025865 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1516 (best@1506 total=0.003030).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.013514 | OT=0.013432 | Ortho=0.000802 | Graph=116.524166 | lr=2.50e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.007926 | OT=0.007900 | Ortho=0.000248 | Graph=115.238346 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  1500] total=0.006059 | OT=0.006053 | Ortho=0.000057 | Graph=108.872777 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.005005 | OT=0.005000 | Ortho=0.000041 | Graph=94.081529 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.004184 | OT=0.004180 | Ortho=0.000023 | Graph=78.402576 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.003695 | OT=0.003693 | Ortho=0.000019 | Graph=67.967402 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  3500] total=0.003177 | OT=0.003176 | Ortho=0.000011 | Graph=60.201175 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  4000] total=0.002719 | OT=0.002718 | Ortho=0.000005 | Graph=55.310113 | lr=2.50e-04 | Acc=0.8397\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069992 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.007785 | OT=0.007752 | Ortho=0.000322 | Graph=81.528795 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004196 | OT=0.004183 | Ortho=0.000126 | Graph=71.300918 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002934 | OT=0.002928 | Ortho=0.000058 | Graph=66.882857 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002332 | OT=0.002328 | Ortho=0.000028 | Graph=62.393237 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2482 (best@2472 total=0.001971).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008171 | OT=0.008134 | Ortho=0.000366 | Graph=80.219492 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004214 | OT=0.004202 | Ortho=0.000111 | Graph=69.358388 | lr=1.00e-03 | Acc=0.8397\n",
            "Early stopping at iter=1441 (best@1431 total=0.003114).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.136030 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.023443 | OT=0.004556 | Ortho=0.140536 | Graph=17.481706 | lr=1.00e-03 | Acc=0.0305\n",
            "[Iter  1000] total=0.015698 | OT=0.002820 | Ortho=0.053001 | Graph=12.348710 | lr=1.00e-03 | Acc=0.0382\n",
            "[Iter  1500] total=0.011713 | OT=0.002042 | Ortho=0.034040 | Graph=9.330637 | lr=1.00e-03 | Acc=0.0382\n",
            "[Iter  2000] total=0.008385 | OT=0.001419 | Ortho=0.017028 | Graph=6.795648 | lr=1.00e-03 | Acc=0.0382\n",
            "Early stopping at iter=2480 (best@2470 total=0.006963).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.188955 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.028184 | OT=0.005148 | Ortho=0.201897 | Graph=21.017309 | lr=1.00e-03 | Acc=0.0458\n",
            "[Iter  1000] total=0.019262 | OT=0.003068 | Ortho=0.074862 | Graph=15.445706 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  1500] total=0.015277 | OT=0.002360 | Ortho=0.050179 | Graph=12.415356 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  2000] total=0.012489 | OT=0.002093 | Ortho=0.034682 | Graph=10.049318 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  2500] total=0.010267 | OT=0.001712 | Ortho=0.024915 | Graph=8.305171 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  3000] total=0.008754 | OT=0.001525 | Ortho=0.018731 | Graph=7.041996 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  3500] total=0.007472 | OT=0.001330 | Ortho=0.014354 | Graph=5.998272 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  4000] total=0.006370 | OT=0.001115 | Ortho=0.008864 | Graph=5.166148 | lr=1.00e-03 | Acc=0.0687\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.190976 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.028532 | OT=0.005062 | Ortho=0.204388 | Graph=21.426296 | lr=1.00e-03 | Acc=0.0382\n",
            "[Iter  1000] total=0.019999 | OT=0.003157 | Ortho=0.083291 | Graph=16.009608 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  1500] total=0.015443 | OT=0.002353 | Ortho=0.053434 | Graph=12.555380 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  2000] total=0.012229 | OT=0.001961 | Ortho=0.034266 | Graph=9.925018 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  2500] total=0.010029 | OT=0.001575 | Ortho=0.023909 | Graph=8.214707 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  3000] total=0.008491 | OT=0.001360 | Ortho=0.017518 | Graph=6.956309 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  3500] total=0.007388 | OT=0.001201 | Ortho=0.013420 | Graph=6.053594 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  4000] total=0.006377 | OT=0.001010 | Ortho=0.009405 | Graph=5.273350 | lr=1.00e-03 | Acc=0.0611\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.028962 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008659 | OT=0.005810 | Ortho=0.005988 | Graph=27.893543 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.005198 | OT=0.002936 | Ortho=0.001964 | Graph=22.420731 | lr=1.00e-03 | Acc=0.9160\n",
            "Early stopping at iter=1411 (best@1401 total=0.003730).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.081887 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.009338 | OT=0.005028 | Ortho=0.031843 | Graph=39.915962 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.005657 | OT=0.002689 | Ortho=0.009913 | Graph=28.693908 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.004304 | OT=0.001856 | Ortho=0.004003 | Graph=24.077882 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.003599 | OT=0.001431 | Ortho=0.002488 | Graph=21.436386 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2500] total=0.003231 | OT=0.001213 | Ortho=0.001864 | Graph=19.991619 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3000] total=0.003043 | OT=0.001109 | Ortho=0.001579 | Graph=19.191288 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3500] total=0.002856 | OT=0.001006 | Ortho=0.001327 | Graph=18.363581 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  4000] total=0.002688 | OT=0.000919 | Ortho=0.001144 | Graph=17.581820 | lr=5.00e-04 | Acc=0.8092\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.083908 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.009306 | OT=0.004950 | Ortho=0.034824 | Graph=40.070283 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.005713 | OT=0.002725 | Ortho=0.010127 | Graph=28.864318 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1500] total=0.004332 | OT=0.001863 | Ortho=0.003635 | Graph=24.332644 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  2000] total=0.003617 | OT=0.001470 | Ortho=0.002439 | Graph=21.226498 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=2348 (best@2338 total=0.003297).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018255 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008543 | OT=0.007859 | Ortho=0.002561 | Graph=65.793428 | lr=1.00e-03 | Acc=0.1832\n",
            "[Iter  1000] total=0.002656 | OT=0.002275 | Ortho=0.000405 | Graph=37.651330 | lr=1.00e-03 | Acc=0.0611\n",
            "Early stopping at iter=1260 (best@1250 total=0.002255).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.071180 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006316 | OT=0.005410 | Ortho=0.022866 | Graph=67.775989 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.003516 | OT=0.002887 | Ortho=0.006956 | Graph=56.019438 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=1303 (best@1293 total=0.002951).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.073201 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006709 | OT=0.005752 | Ortho=0.026010 | Graph=69.738356 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1000] total=0.003834 | OT=0.003192 | Ortho=0.008462 | Graph=55.677938 | lr=1.00e-03 | Acc=0.8473\n",
            "[Iter  1500] total=0.002827 | OT=0.002353 | Ortho=0.003931 | Graph=43.426531 | lr=1.00e-03 | Acc=0.8397\n",
            "Early stopping at iter=1825 (best@1815 total=0.002178).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017185 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006556 | OT=0.006453 | Ortho=0.001648 | Graph=86.154843 | lr=1.00e-03 | Acc=0.9695\n",
            "[Iter  1000] total=0.004320 | OT=0.004243 | Ortho=0.000391 | Graph=73.162517 | lr=1.00e-03 | Acc=0.9542\n",
            "Early stopping at iter=1266 (best@1256 total=0.004020).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070109 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005880 | OT=0.005581 | Ortho=0.022545 | Graph=72.788826 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003104 | OT=0.002975 | Ortho=0.006604 | Graph=62.831067 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1490 (best@1480 total=0.002248).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072131 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006116 | OT=0.005747 | Ortho=0.029429 | Graph=75.040910 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.003407 | OT=0.003271 | Ortho=0.007608 | Graph=59.978076 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1093 (best@1083 total=0.003225).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017078 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006608 | OT=0.006592 | Ortho=0.000743 | Graph=89.444928 | lr=1.00e-03 | Acc=0.9618\n",
            "[Iter  1000] total=0.004605 | OT=0.004592 | Ortho=0.000555 | Graph=75.049714 | lr=1.00e-03 | Acc=0.9389\n",
            "Early stopping at iter=1258 (best@1248 total=0.004144).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070002 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005834 | OT=0.005601 | Ortho=0.022560 | Graph=73.334459 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003055 | OT=0.002983 | Ortho=0.006571 | Graph=63.387625 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1308 (best@1298 total=0.002445).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072024 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006104 | OT=0.005794 | Ortho=0.030268 | Graph=76.319566 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003358 | OT=0.003277 | Ortho=0.007574 | Graph=60.717781 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1102 (best@1092 total=0.003142).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006587 | OT=0.006579 | Ortho=0.000742 | Graph=89.559476 | lr=1.00e-03 | Acc=0.9618\n",
            "[Iter  1000] total=0.004588 | OT=0.004583 | Ortho=0.000420 | Graph=75.229548 | lr=1.00e-03 | Acc=0.9389\n",
            "Early stopping at iter=1311 (best@1301 total=0.004099).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069992 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005829 | OT=0.005602 | Ortho=0.022560 | Graph=73.388794 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003051 | OT=0.002985 | Ortho=0.006566 | Graph=63.450373 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.002197 | OT=0.002168 | Ortho=0.002899 | Graph=58.306309 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1800 (best@1790 total=0.001861).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006105 | OT=0.005802 | Ortho=0.030289 | Graph=76.419911 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003352 | OT=0.003276 | Ortho=0.007571 | Graph=60.807671 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=1101 (best@1091 total=0.003153).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.136030 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.014083 | OT=0.000460 | Ortho=10.750324 | Graph=2.873172 | lr=1.00e-03 | Acc=0.5038\n",
            "[Iter  1000] total=0.011704 | OT=0.000585 | Ortho=7.185821 | Graph=3.933069 | lr=1.00e-03 | Acc=0.5115\n",
            "[Iter  1500] total=0.009838 | OT=0.000741 | Ortho=5.022741 | Graph=4.073630 | lr=1.00e-03 | Acc=0.5038\n",
            "[Iter  2000] total=0.008219 | OT=0.000794 | Ortho=3.598691 | Graph=3.826125 | lr=1.00e-03 | Acc=0.5038\n",
            "[Iter  2500] total=0.007033 | OT=0.000751 | Ortho=2.381524 | Graph=3.901002 | lr=1.00e-03 | Acc=0.5267\n",
            "[Iter  3000] total=0.006181 | OT=0.000678 | Ortho=1.493538 | Graph=4.009549 | lr=1.00e-03 | Acc=0.5649\n",
            "[Iter  3500] total=0.005440 | OT=0.000609 | Ortho=0.959286 | Graph=3.871670 | lr=1.00e-03 | Acc=0.5878\n",
            "[Iter  4000] total=0.004886 | OT=0.000549 | Ortho=0.645896 | Graph=3.691891 | lr=1.00e-03 | Acc=0.5420\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.188955 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.014795 | OT=0.000460 | Ortho=11.532557 | Graph=2.802121 | lr=1.00e-03 | Acc=0.8473\n",
            "[Iter  1000] total=0.013022 | OT=0.000490 | Ortho=8.966650 | Graph=3.564715 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1500] total=0.011420 | OT=0.000556 | Ortho=6.997836 | Graph=3.866665 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.010064 | OT=0.000632 | Ortho=5.425025 | Graph=4.006852 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2040 (best@2030 total=0.010001).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.190976 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.014953 | OT=0.000531 | Ortho=11.526285 | Graph=2.895268 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.013245 | OT=0.000573 | Ortho=9.044251 | Graph=3.627708 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.011422 | OT=0.000581 | Ortho=6.858294 | Graph=3.982636 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.010081 | OT=0.000684 | Ortho=5.287993 | Graph=4.108886 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2500] total=0.008910 | OT=0.000662 | Ortho=4.064831 | Graph=4.182602 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3000] total=0.008039 | OT=0.000704 | Ortho=3.071940 | Graph=4.263574 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3500] total=0.007069 | OT=0.000767 | Ortho=1.915502 | Graph=4.386476 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  4000] total=0.006132 | OT=0.000726 | Ortho=1.281762 | Graph=4.123759 | lr=1.00e-03 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.028962 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006497 | OT=0.002161 | Ortho=1.939479 | Graph=23.965243 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003983 | OT=0.001554 | Ortho=0.225008 | Graph=22.046606 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1414 (best@1404 total=0.003272).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.081887 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008595 | OT=0.001737 | Ortho=4.687640 | Graph=21.711022 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.006359 | OT=0.001741 | Ortho=2.496790 | Graph=21.216828 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.004342 | OT=0.001664 | Ortho=0.535315 | Graph=21.421426 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  2000] total=0.003637 | OT=0.001352 | Ortho=0.296613 | Graph=19.886165 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=2361 (best@2351 total=0.003298).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.083908 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008731 | OT=0.001816 | Ortho=4.772332 | Graph=21.422745 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.006521 | OT=0.001816 | Ortho=2.600816 | Graph=21.040436 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.004368 | OT=0.001730 | Ortho=0.544545 | Graph=20.941290 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.003762 | OT=0.001435 | Ortho=0.296051 | Graph=20.314186 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2500] total=0.003496 | OT=0.001306 | Ortho=0.229661 | Graph=19.607041 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.003305 | OT=0.001218 | Ortho=0.190091 | Graph=18.969424 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3500] total=0.003104 | OT=0.001125 | Ortho=0.159547 | Graph=18.195355 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=3611 (best@3601 total=0.003060).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018255 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003827 | OT=0.003173 | Ortho=0.149671 | Graph=50.365172 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.002932 | OT=0.002480 | Ortho=0.051384 | Graph=40.069348 | lr=1.00e-03 | Acc=0.8855\n",
            "[Iter  1500] total=0.002701 | OT=0.002295 | Ortho=0.042531 | Graph=36.343110 | lr=5.00e-04 | Acc=0.8855\n",
            "[Iter  2000] total=0.002442 | OT=0.002052 | Ortho=0.057270 | Graph=33.241342 | lr=5.00e-04 | Acc=0.8779\n",
            "[Iter  2500] total=0.001963 | OT=0.001627 | Ortho=0.030165 | Graph=30.507490 | lr=5.00e-04 | Acc=0.8855\n",
            "Early stopping at iter=2972 (best@2962 total=0.001741).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.071180 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006048 | OT=0.002368 | Ortho=3.205146 | Graph=47.500443 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.003938 | OT=0.002195 | Ortho=1.226356 | Graph=51.642055 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002686 | OT=0.001842 | Ortho=0.334164 | Graph=51.043862 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  2000] total=0.002062 | OT=0.001449 | Ortho=0.142222 | Graph=47.124999 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=2214 (best@2204 total=0.001884).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.073201 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006175 | OT=0.002288 | Ortho=3.425743 | Graph=46.074348 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.004579 | OT=0.002330 | Ortho=1.723737 | Graph=52.497350 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.003193 | OT=0.002286 | Ortho=0.368978 | Graph=53.720735 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1976 (best@1966 total=0.002448).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017185 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003717 | OT=0.003513 | Ortho=0.126423 | Graph=78.153418 | lr=1.00e-03 | Acc=0.9313\n",
            "[Iter  1000] total=0.002886 | OT=0.002780 | Ortho=0.040552 | Graph=64.686501 | lr=1.00e-03 | Acc=0.9313\n",
            "Early stopping at iter=1010 (best@1000 total=0.002886).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070109 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005439 | OT=0.002437 | Ortho=2.947148 | Graph=54.954234 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.003727 | OT=0.002202 | Ortho=1.467059 | Graph=58.113356 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.002298 | OT=0.001985 | Ortho=0.254410 | Graph=58.738919 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  2000] total=0.001730 | OT=0.001561 | Ortho=0.112603 | Graph=56.297184 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=2119 (best@2109 total=0.001646).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072131 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005631 | OT=0.002520 | Ortho=3.056004 | Graph=54.622653 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.003828 | OT=0.002444 | Ortho=1.325058 | Graph=58.915532 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002549 | OT=0.002125 | Ortho=0.364202 | Graph=60.007696 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1517 (best@1507 total=0.002506).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017078 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003529 | OT=0.003301 | Ortho=0.220202 | Graph=79.021146 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.002154 | OT=0.002106 | Ortho=0.041521 | Graph=70.550498 | lr=1.00e-03 | Acc=0.9618\n",
            "[Iter  1500] total=0.001828 | OT=0.001794 | Ortho=0.027624 | Graph=66.433834 | lr=5.00e-04 | Acc=0.9542\n",
            "[Iter  2000] total=0.001690 | OT=0.001664 | Ortho=0.019120 | Graph=63.737080 | lr=5.00e-04 | Acc=0.9695\n",
            "[Iter  2500] total=0.001550 | OT=0.001531 | Ortho=0.013101 | Graph=61.417839 | lr=5.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=2550 (best@2540 total=0.001536).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070002 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005439 | OT=0.002497 | Ortho=2.936353 | Graph=55.808712 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.003551 | OT=0.002220 | Ortho=1.325539 | Graph=58.386455 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.002072 | OT=0.001848 | Ortho=0.217882 | Graph=58.338324 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  2000] total=0.001686 | OT=0.001562 | Ortho=0.118299 | Graph=55.563901 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=2037 (best@2027 total=0.001669).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072024 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005700 | OT=0.002574 | Ortho=3.120080 | Graph=53.275636 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.003858 | OT=0.002765 | Ortho=1.087151 | Graph=60.467395 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002548 | OT=0.002200 | Ortho=0.341192 | Graph=60.966106 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1705 (best@1695 total=0.002201).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003540 | OT=0.003292 | Ortho=0.247718 | Graph=77.770893 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.002153 | OT=0.002111 | Ortho=0.041654 | Graph=70.852035 | lr=1.00e-03 | Acc=0.9618\n",
            "Early stopping at iter=1124 (best@1114 total=0.002048).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069992 | OT=0.069991 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005435 | OT=0.002499 | Ortho=2.935057 | Graph=55.870570 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.003545 | OT=0.002220 | Ortho=1.324533 | Graph=58.468761 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.002066 | OT=0.001848 | Ortho=0.217555 | Graph=58.412749 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1908 (best@1898 total=0.001735).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=118.964130 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005696 | OT=0.002576 | Ortho=3.119317 | Graph=53.329732 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.003857 | OT=0.002769 | Ortho=1.087726 | Graph=60.518803 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002540 | OT=0.002199 | Ortho=0.340186 | Graph=61.023853 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1693 (best@1683 total=0.002216).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n",
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.100  1.000000e-04    0.1    0.003469  0.954198  0.350009\n",
            "1   8  5        0.001  1.000000e-07    0.1    0.001536  0.954198  0.318775\n",
            "2   8  5        0.010  1.000000e-04    0.1    0.003730  0.950382  0.436396\n",
            "3   8  5        0.001  1.000000e-08    0.1    0.002048  0.938931  0.321718\n",
            "4   8  5        0.001  1.000000e-06    0.1    0.002886  0.935115  0.307441\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.010  1.000000e-05    0.1    0.002255  0.076336  0.670357\n",
            "68  8  5        0.100  1.000000e-05    0.1    0.002219  0.076336  0.648447\n",
            "69  8  5        0.010  1.000000e-03    1.0    0.006370  0.045802  0.701970\n",
            "70  8  5        0.010  1.000000e-03    5.0    0.006377  0.038168  0.692937\n",
            "71  8  5        0.010  1.000000e-03    0.1    0.006963  0.038168  0.706223\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-07    0.1    0.001536  0.954198  0.318775\n",
            "1   8  5        0.001  1.000000e-06    1.0    0.001646  0.755725  0.405804\n",
            "2   8  5        0.001  1.000000e-07    1.0    0.001669  0.759542  0.388060\n",
            "3   8  5        0.001  1.000000e-08    1.0    0.001735  0.763359  0.386458\n",
            "4   8  5        0.001  1.000000e-05    0.1    0.001741  0.900763  0.345551\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        1.000  1.000000e-03    1.0    0.017601  0.912214  0.358779\n",
            "68  8  5        1.000  1.000000e-03    5.0    0.017907  0.889313  0.364344\n",
            "69  8  5        1.000  1.000000e-05    0.1    0.018195  0.816794  0.328681\n",
            "70  8  5        1.000  1.000000e-03    0.1    0.021983  0.698473  0.462444\n",
            "71  8  5        1.000  1.000000e-04    0.1    0.028863  0.828244  0.324631\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-06    0.1    0.002886  0.935115  0.307441\n",
            "1   8  5        0.001  1.000000e-07    0.1    0.001536  0.954198  0.318775\n",
            "2   8  5        0.001  1.000000e-08    0.1    0.002048  0.938931  0.321718\n",
            "3   8  5        1.000  1.000000e-04    0.1    0.028863  0.828244  0.324631\n",
            "4   8  5        1.000  1.000000e-08    0.1    0.017035  0.824427  0.325389\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-05    0.1    0.002219  0.076336  0.648447\n",
            "68  8  5        0.010  1.000000e-05    0.1    0.002255  0.076336  0.670357\n",
            "69  8  5        0.010  1.000000e-03    5.0    0.006377  0.038168  0.692937\n",
            "70  8  5        0.010  1.000000e-03    1.0    0.006370  0.045802  0.701970\n",
            "71  8  5        0.010  1.000000e-03    0.1    0.006963  0.038168  0.706223\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"rna\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"atac\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "       labels_X=mdata['rna'].obs['celltype'],\n",
        "    labels_Y=mdata['atac'].obs['celltype'],\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "60551c56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.114633 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.104197 | OT=0.016293 | Ortho=0.000801 | Graph=87.103664 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  1000] total=0.052138 | OT=0.013632 | Ortho=0.000045 | Graph=38.460198 | lr=2.50e-04 | Acc=0.8855\n",
            "[Iter  1500] total=0.044841 | OT=0.012522 | Ortho=0.000032 | Graph=32.286352 | lr=2.50e-04 | Acc=0.8931\n",
            "[Iter  2000] total=0.038856 | OT=0.012531 | Ortho=0.000021 | Graph=26.303371 | lr=2.50e-04 | Acc=0.8931\n",
            "[Iter  2500] total=0.033086 | OT=0.009317 | Ortho=0.000017 | Graph=23.751933 | lr=2.50e-04 | Acc=0.8931\n",
            "[Iter  3000] total=0.029017 | OT=0.007954 | Ortho=0.000012 | Graph=21.050953 | lr=2.50e-04 | Acc=0.9237\n",
            "[Iter  3500] total=0.026371 | OT=0.007146 | Ortho=0.000010 | Graph=19.214397 | lr=2.50e-04 | Acc=0.9313\n",
            "[Iter  4000] total=0.023942 | OT=0.006165 | Ortho=0.000009 | Graph=17.768246 | lr=2.50e-04 | Acc=0.9160\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.167557 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.060908 | OT=0.024153 | Ortho=0.000162 | Graph=36.593319 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  1000] total=0.036437 | OT=0.011698 | Ortho=0.000032 | Graph=24.707937 | lr=1.00e-03 | Acc=0.9237\n",
            "[Iter  1500] total=0.027386 | OT=0.007139 | Ortho=0.000016 | Graph=20.231667 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2000] total=0.022692 | OT=0.004990 | Ortho=0.000009 | Graph=17.693020 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2500] total=0.020079 | OT=0.003914 | Ortho=0.000007 | Graph=16.158132 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  3000] total=0.018252 | OT=0.003291 | Ortho=0.000006 | Graph=14.954874 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3500] total=0.016663 | OT=0.002758 | Ortho=0.000005 | Graph=13.900350 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  4000] total=0.015534 | OT=0.002455 | Ortho=0.000004 | Graph=13.074279 | lr=5.00e-04 | Acc=0.9008\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.169579 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.063573 | OT=0.026716 | Ortho=0.000173 | Graph=36.683458 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  1000] total=0.035806 | OT=0.011691 | Ortho=0.000030 | Graph=24.084966 | lr=1.00e-03 | Acc=0.9160\n",
            "[Iter  1500] total=0.027525 | OT=0.007387 | Ortho=0.000015 | Graph=20.123195 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2000] total=0.022592 | OT=0.005148 | Ortho=0.000009 | Graph=17.435281 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2500] total=0.019848 | OT=0.004093 | Ortho=0.000007 | Graph=15.747567 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  3000] total=0.017942 | OT=0.003375 | Ortho=0.000006 | Graph=14.561059 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  3500] total=0.016775 | OT=0.003016 | Ortho=0.000005 | Graph=13.753886 | lr=5.00e-04 | Acc=0.9008\n",
            "[Iter  4000] total=0.015928 | OT=0.002759 | Ortho=0.000004 | Graph=13.165231 | lr=5.00e-04 | Acc=0.8931\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.026822 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=136 (best@136 total=0.026725).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.079747 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.057839 | OT=0.048196 | Ortho=0.000205 | Graph=94.376289 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.025898 | OT=0.017578 | Ortho=0.000031 | Graph=82.895379 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  1500] total=0.017301 | OT=0.011571 | Ortho=0.000015 | Graph=57.143417 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.011908 | OT=0.007475 | Ortho=0.000005 | Graph=44.275229 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2500] total=0.009620 | OT=0.005695 | Ortho=0.000004 | Graph=39.219454 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  3000] total=0.008326 | OT=0.004672 | Ortho=0.000003 | Graph=36.508851 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=3331 (best@3321 total=0.007648).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.081768 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.058244 | OT=0.048596 | Ortho=0.000219 | Graph=94.284874 | lr=5.00e-04 | Acc=0.7252\n",
            "[Iter  1000] total=0.026251 | OT=0.017935 | Ortho=0.000033 | Graph=82.833483 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1500] total=0.018128 | OT=0.012346 | Ortho=0.000017 | Graph=57.656969 | lr=5.00e-04 | Acc=0.7863\n",
            "[Iter  2000] total=0.012904 | OT=0.008361 | Ortho=0.000007 | Graph=45.355299 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2500] total=0.010126 | OT=0.006229 | Ortho=0.000004 | Graph=38.929395 | lr=5.00e-04 | Acc=0.7863\n",
            "[Iter  3000] total=0.008558 | OT=0.004963 | Ortho=0.000003 | Graph=35.914305 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  3500] total=0.007338 | OT=0.004164 | Ortho=0.000002 | Graph=31.711213 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  4000] total=0.006185 | OT=0.003446 | Ortho=0.000002 | Graph=27.371949 | lr=5.00e-04 | Acc=0.8092\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018041 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=146 (best@146 total=0.017981).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.070966 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.049667 | OT=0.048520 | Ortho=0.000190 | Graph=95.710743 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.018501 | OT=0.017580 | Ortho=0.000018 | Graph=90.325788 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.012618 | OT=0.011797 | Ortho=0.000008 | Graph=81.315576 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  2000] total=0.008907 | OT=0.008186 | Ortho=0.000004 | Graph=71.704181 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.006818 | OT=0.006171 | Ortho=0.000003 | Graph=64.474370 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3000] total=0.005491 | OT=0.004887 | Ortho=0.000002 | Graph=60.121140 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=3066 (best@3056 total=0.005375).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.072987 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.057345 | OT=0.056148 | Ortho=0.000228 | Graph=96.885752 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.040397 | OT=0.039298 | Ortho=0.000162 | Graph=93.733100 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.019561 | OT=0.018633 | Ortho=0.000022 | Graph=90.576176 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.015367 | OT=0.014500 | Ortho=0.000014 | Graph=85.315244 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011733 | OT=0.010947 | Ortho=0.000007 | Graph=77.871206 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.009132 | OT=0.008419 | Ortho=0.000005 | Graph=70.795725 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3500] total=0.007248 | OT=0.006600 | Ortho=0.000004 | Graph=64.383319 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005958 | OT=0.005361 | Ortho=0.000003 | Graph=59.446594 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017163 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=155 (best@155 total=0.017128).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070088 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.048890 | OT=0.048605 | Ortho=0.000189 | Graph=95.852099 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.017749 | OT=0.017642 | Ortho=0.000016 | Graph=90.938441 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011925 | OT=0.011834 | Ortho=0.000008 | Graph=83.032801 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.008256 | OT=0.008177 | Ortho=0.000004 | Graph=74.447732 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.006352 | OT=0.006281 | Ortho=0.000003 | Graph=67.968840 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=2835 (best@2825 total=0.005458).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072109 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.056491 | OT=0.056166 | Ortho=0.000228 | Graph=96.960933 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.039801 | OT=0.039545 | Ortho=0.000163 | Graph=94.014870 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.018689 | OT=0.018577 | Ortho=0.000022 | Graph=90.992148 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.014580 | OT=0.014481 | Ortho=0.000013 | Graph=86.496347 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011156 | OT=0.011069 | Ortho=0.000007 | Graph=80.413227 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.008815 | OT=0.008736 | Ortho=0.000005 | Graph=74.691006 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.006925 | OT=0.006852 | Ortho=0.000004 | Graph=68.889191 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.005671 | OT=0.005603 | Ortho=0.000003 | Graph=64.521331 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017075 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=146 (best@146 total=0.017044).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070000 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.048808 | OT=0.048609 | Ortho=0.000189 | Graph=95.863826 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.017669 | OT=0.017644 | Ortho=0.000016 | Graph=90.993823 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011856 | OT=0.011840 | Ortho=0.000008 | Graph=83.199547 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.008200 | OT=0.008189 | Ortho=0.000004 | Graph=74.727163 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.006303 | OT=0.006293 | Ortho=0.000003 | Graph=68.298189 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2618 (best@2608 total=0.005980).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072022 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.056405 | OT=0.056167 | Ortho=0.000227 | Graph=96.967172 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.039728 | OT=0.039556 | Ortho=0.000163 | Graph=94.037107 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.018609 | OT=0.018579 | Ortho=0.000022 | Graph=91.044316 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.014505 | OT=0.014483 | Ortho=0.000013 | Graph=86.603695 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011086 | OT=0.011071 | Ortho=0.000007 | Graph=80.415389 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.008758 | OT=0.008746 | Ortho=0.000005 | Graph=74.842018 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.006886 | OT=0.006875 | Ortho=0.000004 | Graph=69.142404 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.005635 | OT=0.005625 | Ortho=0.000003 | Graph=64.849929 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=146 (best@146 total=0.017035).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069991 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.048800 | OT=0.048609 | Ortho=0.000189 | Graph=95.864997 | lr=5.00e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.017661 | OT=0.017644 | Ortho=0.000016 | Graph=90.999332 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011849 | OT=0.011840 | Ortho=0.000008 | Graph=83.216094 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.008194 | OT=0.008190 | Ortho=0.000004 | Graph=74.754892 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.006297 | OT=0.006294 | Ortho=0.000003 | Graph=68.326482 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2583 (best@2573 total=0.006078).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.056396 | OT=0.056168 | Ortho=0.000227 | Graph=96.967795 | lr=2.50e-04 | Acc=0.7176\n",
            "[Iter  1000] total=0.039721 | OT=0.039557 | Ortho=0.000163 | Graph=94.039326 | lr=2.50e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.018601 | OT=0.018579 | Ortho=0.000022 | Graph=91.049521 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.014497 | OT=0.014484 | Ortho=0.000013 | Graph=86.615019 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.011079 | OT=0.011071 | Ortho=0.000007 | Graph=80.431419 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.008752 | OT=0.008747 | Ortho=0.000005 | Graph=74.866795 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.006881 | OT=0.006877 | Ortho=0.000004 | Graph=69.173083 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.005631 | OT=0.005628 | Ortho=0.000003 | Graph=64.885588 | lr=2.50e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.114633 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.026642 | OT=0.007040 | Ortho=0.001096 | Graph=19.492143 | lr=1.00e-03 | Acc=0.8779\n",
            "[Iter  1000] total=0.018005 | OT=0.003878 | Ortho=0.000548 | Graph=14.071801 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.013417 | OT=0.002646 | Ortho=0.000382 | Graph=10.732767 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.010774 | OT=0.002088 | Ortho=0.000227 | Graph=8.662595 | lr=1.00e-03 | Acc=0.8626\n",
            "[Iter  2500] total=0.009244 | OT=0.001849 | Ortho=0.000175 | Graph=7.377893 | lr=1.00e-03 | Acc=0.8626\n",
            "[Iter  3000] total=0.008554 | OT=0.001762 | Ortho=0.000153 | Graph=6.777498 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.007806 | OT=0.001667 | Ortho=0.000127 | Graph=6.126204 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  4000] total=0.006958 | OT=0.001462 | Ortho=0.000112 | Graph=5.484047 | lr=5.00e-04 | Acc=0.8626\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.167557 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.040606 | OT=0.013966 | Ortho=0.005278 | Graph=26.112016 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1000] total=0.024047 | OT=0.005587 | Ortho=0.001144 | Graph=18.345374 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.019795 | OT=0.003936 | Ortho=0.000680 | Graph=15.790938 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.017235 | OT=0.003149 | Ortho=0.000514 | Graph=14.034671 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.015198 | OT=0.002670 | Ortho=0.000434 | Graph=12.485221 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3000] total=0.013156 | OT=0.002248 | Ortho=0.000359 | Graph=10.872117 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3500] total=0.011123 | OT=0.001849 | Ortho=0.000278 | Graph=9.246823 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  4000] total=0.009481 | OT=0.001569 | Ortho=0.000203 | Graph=7.891619 | lr=5.00e-04 | Acc=0.8244\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.169579 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.041312 | OT=0.014264 | Ortho=0.004865 | Graph=26.561251 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  1000] total=0.024256 | OT=0.005821 | Ortho=0.001133 | Graph=18.322432 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.019955 | OT=0.004378 | Ortho=0.000694 | Graph=15.507466 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.016919 | OT=0.003301 | Ortho=0.000517 | Graph=13.566371 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.014667 | OT=0.002649 | Ortho=0.000401 | Graph=11.977589 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.012735 | OT=0.002153 | Ortho=0.000327 | Graph=10.549809 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  3500] total=0.011172 | OT=0.001920 | Ortho=0.000266 | Graph=9.224531 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  4000] total=0.009729 | OT=0.001681 | Ortho=0.000210 | Graph=8.026183 | lr=5.00e-04 | Acc=0.8321\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.026822 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.016241 | OT=0.011781 | Ortho=0.000195 | Graph=44.396990 | lr=5.00e-04 | Acc=0.9618\n",
            "[Iter  1000] total=0.011770 | OT=0.008572 | Ortho=0.000096 | Graph=31.885868 | lr=5.00e-04 | Acc=0.9924\n",
            "[Iter  1500] total=0.008270 | OT=0.005654 | Ortho=0.000046 | Graph=26.113979 | lr=5.00e-04 | Acc=1.0000\n",
            "[Iter  2000] total=0.006901 | OT=0.004664 | Ortho=0.000031 | Graph=22.334227 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  2500] total=0.005963 | OT=0.003902 | Ortho=0.000020 | Graph=20.590250 | lr=5.00e-04 | Acc=0.9771\n",
            "[Iter  3000] total=0.005464 | OT=0.003530 | Ortho=0.000016 | Graph=19.328936 | lr=5.00e-04 | Acc=0.9771\n",
            "[Iter  3500] total=0.004358 | OT=0.002566 | Ortho=0.000018 | Graph=17.903711 | lr=5.00e-04 | Acc=0.9389\n",
            "[Iter  4000] total=0.003658 | OT=0.001994 | Ortho=0.000011 | Graph=16.635270 | lr=5.00e-04 | Acc=0.9237\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.079747 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.019417 | OT=0.013317 | Ortho=0.001900 | Graph=59.105838 | lr=5.00e-04 | Acc=0.7786\n",
            "[Iter  1000] total=0.009482 | OT=0.005951 | Ortho=0.000353 | Graph=34.949574 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  1500] total=0.006626 | OT=0.003808 | Ortho=0.000175 | Graph=28.008845 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2000] total=0.005181 | OT=0.002808 | Ortho=0.000084 | Graph=23.647831 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.004313 | OT=0.002225 | Ortho=0.000044 | Graph=20.834577 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  3000] total=0.003693 | OT=0.001777 | Ortho=0.000027 | Graph=19.129751 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  3500] total=0.003284 | OT=0.001498 | Ortho=0.000020 | Graph=17.841078 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  4000] total=0.002966 | OT=0.001293 | Ortho=0.000014 | Graph=16.717676 | lr=5.00e-04 | Acc=0.8092\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.081768 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.019493 | OT=0.013318 | Ortho=0.001891 | Graph=59.863295 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  1000] total=0.010380 | OT=0.006626 | Ortho=0.000406 | Graph=37.131996 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  1500] total=0.007264 | OT=0.004277 | Ortho=0.000201 | Graph=29.663289 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2000] total=0.005565 | OT=0.003091 | Ortho=0.000099 | Graph=24.648259 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  2500] total=0.004687 | OT=0.002522 | Ortho=0.000048 | Graph=21.606513 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3000] total=0.004123 | OT=0.002161 | Ortho=0.000029 | Graph=19.590151 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  3500] total=0.003649 | OT=0.001872 | Ortho=0.000020 | Graph=17.754363 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  4000] total=0.003349 | OT=0.001671 | Ortho=0.000022 | Graph=16.755423 | lr=5.00e-04 | Acc=0.8092\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018041 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.013669 | OT=0.012659 | Ortho=0.000407 | Graph=96.938363 | lr=5.00e-04 | Acc=0.6565\n",
            "[Iter  1000] total=0.011361 | OT=0.010472 | Ortho=0.000044 | Graph=88.545283 | lr=5.00e-04 | Acc=0.6031\n",
            "[Iter  1500] total=0.009378 | OT=0.008675 | Ortho=0.000027 | Graph=70.066904 | lr=5.00e-04 | Acc=0.1069\n",
            "[Iter  2000] total=0.005883 | OT=0.005421 | Ortho=0.000086 | Graph=45.273627 | lr=5.00e-04 | Acc=0.0076\n",
            "[Iter  2500] total=0.003018 | OT=0.002649 | Ortho=0.000010 | Graph=36.774578 | lr=5.00e-04 | Acc=0.0992\n",
            "[Iter  3000] total=0.002388 | OT=0.002056 | Ortho=0.000005 | Graph=33.109547 | lr=5.00e-04 | Acc=0.1221\n",
            "[Iter  3500] total=0.002080 | OT=0.001771 | Ortho=0.000003 | Graph=30.879070 | lr=5.00e-04 | Acc=0.1145\n",
            "Early stopping at iter=3681 (best@3671 total=0.001995).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.070966 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008335 | OT=0.007667 | Ortho=0.000336 | Graph=63.417390 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004758 | OT=0.004207 | Ortho=0.000127 | Graph=53.780822 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.003614 | OT=0.003113 | Ortho=0.000067 | Graph=49.370593 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=1631 (best@1621 total=0.003414).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.072987 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008661 | OT=0.008004 | Ortho=0.000379 | Graph=61.840727 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.004640 | OT=0.004106 | Ortho=0.000116 | Graph=52.167069 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1463 (best@1453 total=0.003639).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017163 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008768 | OT=0.008646 | Ortho=0.000264 | Graph=95.714544 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.006003 | OT=0.005908 | Ortho=0.000063 | Graph=88.667545 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1500] total=0.004573 | OT=0.004499 | Ortho=0.000031 | Graph=70.242163 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.003674 | OT=0.003615 | Ortho=0.000013 | Graph=57.697251 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2500] total=0.003136 | OT=0.003083 | Ortho=0.000009 | Graph=51.949098 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  3000] total=0.002802 | OT=0.002753 | Ortho=0.000003 | Graph=48.063535 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.002712 | OT=0.002665 | Ortho=0.000002 | Graph=47.101241 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.002629 | OT=0.002583 | Ortho=0.000002 | Graph=46.332031 | lr=2.50e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070088 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.007841 | OT=0.007743 | Ortho=0.000323 | Graph=66.001715 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004245 | OT=0.004175 | Ortho=0.000126 | Graph=57.535070 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.003141 | OT=0.003080 | Ortho=0.000072 | Graph=53.940229 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002558 | OT=0.002506 | Ortho=0.000027 | Graph=49.465006 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2248 (best@2238 total=0.002339).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072109 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008269 | OT=0.008167 | Ortho=0.000368 | Graph=64.963721 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004292 | OT=0.004225 | Ortho=0.000112 | Graph=55.978797 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1500] total=0.003136 | OT=0.003073 | Ortho=0.000106 | Graph=53.234287 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1652 (best@1642 total=0.002898).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017075 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.013522 | OT=0.013433 | Ortho=0.000802 | Graph=95.673523 | lr=2.50e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.007934 | OT=0.007900 | Ortho=0.000248 | Graph=94.878909 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  1500] total=0.006067 | OT=0.006052 | Ortho=0.000058 | Graph=89.109647 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.005011 | OT=0.004999 | Ortho=0.000041 | Graph=76.302931 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.004188 | OT=0.004180 | Ortho=0.000023 | Graph=62.878396 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.003699 | OT=0.003691 | Ortho=0.000019 | Graph=54.263971 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  3500] total=0.003179 | OT=0.003173 | Ortho=0.000011 | Graph=48.353712 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  4000] total=0.002722 | OT=0.002716 | Ortho=0.000005 | Graph=44.745374 | lr=2.50e-04 | Acc=0.8397\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070000 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.007790 | OT=0.007751 | Ortho=0.000323 | Graph=66.275572 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004200 | OT=0.004182 | Ortho=0.000126 | Graph=57.859817 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002938 | OT=0.002927 | Ortho=0.000058 | Graph=54.555567 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002345 | OT=0.002336 | Ortho=0.000037 | Graph=51.180920 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2355 (best@2345 total=0.002056).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072022 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008176 | OT=0.008133 | Ortho=0.000366 | Graph=65.174240 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004219 | OT=0.004202 | Ortho=0.000111 | Graph=56.269085 | lr=1.00e-03 | Acc=0.8397\n",
            "Early stopping at iter=1397 (best@1387 total=0.003187).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.013513 | OT=0.013432 | Ortho=0.000802 | Graph=95.675411 | lr=2.50e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.007926 | OT=0.007900 | Ortho=0.000248 | Graph=94.887496 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  1500] total=0.006059 | OT=0.006053 | Ortho=0.000057 | Graph=89.150191 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.005005 | OT=0.005000 | Ortho=0.000041 | Graph=76.414046 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.004183 | OT=0.004180 | Ortho=0.000023 | Graph=63.004831 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.003695 | OT=0.003693 | Ortho=0.000019 | Graph=54.386544 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  3500] total=0.003177 | OT=0.003176 | Ortho=0.000011 | Graph=48.469117 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  4000] total=0.002719 | OT=0.002718 | Ortho=0.000005 | Graph=44.813035 | lr=2.50e-04 | Acc=0.8397\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069991 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.007785 | OT=0.007752 | Ortho=0.000322 | Graph=66.302934 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004196 | OT=0.004183 | Ortho=0.000126 | Graph=57.891727 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002934 | OT=0.002928 | Ortho=0.000058 | Graph=54.590231 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002333 | OT=0.002329 | Ortho=0.000028 | Graph=51.225180 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2295 (best@2285 total=0.002091).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008171 | OT=0.008134 | Ortho=0.000366 | Graph=65.204222 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004214 | OT=0.004203 | Ortho=0.000111 | Graph=56.299754 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1500] total=0.003060 | OT=0.003053 | Ortho=0.000061 | Graph=53.657402 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1926 (best@1916 total=0.002564).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.114633 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.020247 | OT=0.004525 | Ortho=0.085002 | Graph=14.871495 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  1000] total=0.013898 | OT=0.002571 | Ortho=0.039517 | Graph=10.931864 | lr=1.00e-03 | Acc=0.0840\n",
            "[Iter  1500] total=0.010678 | OT=0.001993 | Ortho=0.024744 | Graph=8.437501 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  2000] total=0.008016 | OT=0.001561 | Ortho=0.014385 | Graph=6.311615 | lr=1.00e-03 | Acc=0.0992\n",
            "[Iter  2500] total=0.006269 | OT=0.001179 | Ortho=0.008074 | Graph=5.009118 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  3000] total=0.005467 | OT=0.000997 | Ortho=0.005761 | Graph=4.413061 | lr=1.00e-03 | Acc=0.0992\n",
            "Early stopping at iter=3254 (best@3244 total=0.005234).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.167557 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.024167 | OT=0.004753 | Ortho=0.130919 | Graph=18.104288 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  1000] total=0.016997 | OT=0.003071 | Ortho=0.055872 | Graph=13.366646 | lr=1.00e-03 | Acc=0.1221\n",
            "[Iter  1500] total=0.013681 | OT=0.002356 | Ortho=0.039480 | Graph=10.930495 | lr=1.00e-03 | Acc=0.1221\n",
            "[Iter  2000] total=0.010996 | OT=0.001984 | Ortho=0.026427 | Graph=8.748281 | lr=1.00e-03 | Acc=0.1069\n",
            "[Iter  2500] total=0.009102 | OT=0.001739 | Ortho=0.018116 | Graph=7.182117 | lr=1.00e-03 | Acc=0.0992\n",
            "[Iter  3000] total=0.007658 | OT=0.001436 | Ortho=0.013735 | Graph=6.085470 | lr=1.00e-03 | Acc=0.1069\n",
            "[Iter  3500] total=0.006464 | OT=0.001198 | Ortho=0.009792 | Graph=5.168719 | lr=1.00e-03 | Acc=0.1145\n",
            "[Iter  4000] total=0.005638 | OT=0.001067 | Ortho=0.007163 | Graph=4.499438 | lr=1.00e-03 | Acc=0.1145\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.169579 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.024796 | OT=0.005100 | Ortho=0.135985 | Graph=18.335567 | lr=1.00e-03 | Acc=0.0611\n",
            "[Iter  1000] total=0.017468 | OT=0.002929 | Ortho=0.059782 | Graph=13.941092 | lr=1.00e-03 | Acc=0.1069\n",
            "[Iter  1500] total=0.014024 | OT=0.002449 | Ortho=0.041238 | Graph=11.162963 | lr=1.00e-03 | Acc=0.1221\n",
            "[Iter  2000] total=0.010977 | OT=0.001927 | Ortho=0.027671 | Graph=8.773705 | lr=1.00e-03 | Acc=0.1145\n",
            "[Iter  2500] total=0.008969 | OT=0.001591 | Ortho=0.018248 | Graph=7.195114 | lr=1.00e-03 | Acc=0.1221\n",
            "[Iter  3000] total=0.007638 | OT=0.001412 | Ortho=0.013406 | Graph=6.091166 | lr=1.00e-03 | Acc=0.1145\n",
            "[Iter  3500] total=0.006489 | OT=0.001175 | Ortho=0.009712 | Graph=5.216892 | lr=1.00e-03 | Acc=0.1145\n",
            "[Iter  4000] total=0.005807 | OT=0.001062 | Ortho=0.007163 | Graph=4.673028 | lr=1.00e-03 | Acc=0.1069\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.026822 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008249 | OT=0.005829 | Ortho=0.003056 | Graph=23.894698 | lr=1.00e-03 | Acc=1.0000\n",
            "[Iter  1000] total=0.006233 | OT=0.004344 | Ortho=0.001665 | Graph=18.716103 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1500] total=0.003978 | OT=0.002285 | Ortho=0.001556 | Graph=16.777188 | lr=1.00e-03 | Acc=0.9389\n",
            "[Iter  2000] total=0.002754 | OT=0.001192 | Ortho=0.000871 | Graph=15.538533 | lr=1.00e-03 | Acc=0.9618\n",
            "Early stopping at iter=2384 (best@2374 total=0.002528).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.079747 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008442 | OT=0.004936 | Ortho=0.029576 | Graph=32.098873 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.005084 | OT=0.002682 | Ortho=0.008590 | Graph=23.163904 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.003709 | OT=0.001752 | Ortho=0.003138 | Graph=19.260113 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.003054 | OT=0.001315 | Ortho=0.001830 | Graph=17.205707 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=2188 (best@2178 total=0.002916).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.081768 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008456 | OT=0.004813 | Ortho=0.030566 | Graph=33.367779 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.005216 | OT=0.002794 | Ortho=0.009894 | Graph=23.233723 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.003883 | OT=0.001881 | Ortho=0.003560 | Graph=19.670994 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.003225 | OT=0.001449 | Ortho=0.001889 | Graph=17.562615 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2500] total=0.002966 | OT=0.001288 | Ortho=0.001437 | Graph=16.636943 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.002807 | OT=0.001198 | Ortho=0.001195 | Graph=15.975628 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3500] total=0.002647 | OT=0.001112 | Ortho=0.000982 | Graph=15.254623 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=3576 (best@3566 total=0.002625).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018041 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008587 | OT=0.007960 | Ortho=0.002642 | Graph=60.026670 | lr=1.00e-03 | Acc=0.2366\n",
            "[Iter  1000] total=0.002451 | OT=0.002122 | Ortho=0.000394 | Graph=32.568466 | lr=1.00e-03 | Acc=0.0458\n",
            "Early stopping at iter=1354 (best@1344 total=0.002044).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.070966 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=392 (best@382 total=0.008131).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.072987 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006535 | OT=0.005704 | Ortho=0.026178 | Graph=56.917902 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.003786 | OT=0.003246 | Ortho=0.008272 | Graph=45.770353 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002855 | OT=0.002439 | Ortho=0.004001 | Graph=37.677197 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1594 (best@1584 total=0.002616).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017163 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006613 | OT=0.006525 | Ortho=0.001696 | Graph=70.832882 | lr=1.00e-03 | Acc=0.9695\n",
            "[Iter  1000] total=0.004427 | OT=0.004363 | Ortho=0.000403 | Graph=60.558276 | lr=1.00e-03 | Acc=0.9466\n",
            "[Iter  1500] total=0.003577 | OT=0.003514 | Ortho=0.000630 | Graph=56.673179 | lr=1.00e-03 | Acc=0.9542\n",
            "Early stopping at iter=1666 (best@1656 total=0.003405).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070088 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005870 | OT=0.005585 | Ortho=0.022545 | Graph=59.463075 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003096 | OT=0.002978 | Ortho=0.006600 | Graph=51.593876 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.002228 | OT=0.002151 | Ortho=0.002949 | Graph=47.520792 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1914 (best@1904 total=0.001805).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072109 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006108 | OT=0.005751 | Ortho=0.029509 | Graph=61.366481 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.003398 | OT=0.003273 | Ortho=0.007601 | Graph=49.011133 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1096 (best@1086 total=0.003221).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017075 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006604 | OT=0.006590 | Ortho=0.000704 | Graph=72.888605 | lr=1.00e-03 | Acc=0.9618\n",
            "[Iter  1000] total=0.004598 | OT=0.004587 | Ortho=0.000520 | Graph=60.684274 | lr=1.00e-03 | Acc=0.9389\n",
            "Early stopping at iter=1213 (best@1203 total=0.004191).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070000 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005833 | OT=0.005601 | Ortho=0.022560 | Graph=59.849569 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003054 | OT=0.002983 | Ortho=0.006571 | Graph=52.008679 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.002193 | OT=0.002159 | Ortho=0.002898 | Graph=48.221419 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1760 (best@1750 total=0.001915).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072022 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006104 | OT=0.005795 | Ortho=0.030274 | Graph=62.301120 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003357 | OT=0.003276 | Ortho=0.007572 | Graph=49.572461 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1100 (best@1090 total=0.003147).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006587 | OT=0.006578 | Ortho=0.000738 | Graph=73.017139 | lr=1.00e-03 | Acc=0.9618\n",
            "[Iter  1000] total=0.004589 | OT=0.004584 | Ortho=0.000421 | Graph=60.915037 | lr=1.00e-03 | Acc=0.9389\n",
            "Early stopping at iter=1350 (best@1340 total=0.004065).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069991 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005829 | OT=0.005602 | Ortho=0.022560 | Graph=59.888056 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003051 | OT=0.002985 | Ortho=0.006566 | Graph=52.055497 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1403 (best@1393 total=0.002332).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006105 | OT=0.005802 | Ortho=0.030289 | Graph=62.374309 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.003351 | OT=0.003275 | Ortho=0.007569 | Graph=49.640671 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=1107 (best@1097 total=0.003145).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.114633 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.012991 | OT=0.000758 | Ortho=8.803975 | Graph=3.428829 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1000] total=0.010545 | OT=0.000734 | Ortho=5.657071 | Graph=4.154176 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.008792 | OT=0.000764 | Ortho=3.772941 | Graph=4.254452 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.007442 | OT=0.000779 | Ortho=2.313767 | Graph=4.348608 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2500] total=0.006205 | OT=0.000739 | Ortho=1.404892 | Graph=4.060996 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3000] total=0.005247 | OT=0.000721 | Ortho=0.856696 | Graph=3.669022 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=3084 (best@3074 total=0.005138).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.167557 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.014056 | OT=0.000688 | Ortho=10.034368 | Graph=3.333480 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.012168 | OT=0.000760 | Ortho=7.556173 | Graph=3.851472 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1500] total=0.010503 | OT=0.000846 | Ortho=5.428862 | Graph=4.227704 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.009205 | OT=0.000817 | Ortho=4.067290 | Graph=4.320832 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2500] total=0.007908 | OT=0.000783 | Ortho=3.020448 | Graph=4.104722 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3000] total=0.006599 | OT=0.000839 | Ortho=1.589015 | Graph=4.171252 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  3500] total=0.005799 | OT=0.000827 | Ortho=1.101408 | Graph=3.871238 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=3568 (best@3558 total=0.005710).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.169579 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.014196 | OT=0.000750 | Ortho=10.111064 | Graph=3.335427 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.012400 | OT=0.000715 | Ortho=7.808400 | Graph=3.877270 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.010683 | OT=0.000759 | Ortho=5.447707 | Graph=4.476367 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.009412 | OT=0.000780 | Ortho=4.195508 | Graph=4.436318 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2500] total=0.008091 | OT=0.000739 | Ortho=3.177691 | Graph=4.174227 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3000] total=0.006723 | OT=0.000770 | Ortho=1.731121 | Graph=4.221576 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3500] total=0.005822 | OT=0.000747 | Ortho=1.133121 | Graph=3.941225 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=3561 (best@3551 total=0.005742).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.026822 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005239 | OT=0.002266 | Ortho=1.014981 | Graph=19.585632 | lr=1.00e-03 | Acc=0.8626\n",
            "[Iter  1000] total=0.003907 | OT=0.001835 | Ortho=0.188243 | Graph=18.836175 | lr=1.00e-03 | Acc=0.8550\n",
            "[Iter  1500] total=0.003599 | OT=0.001698 | Ortho=0.144557 | Graph=17.569793 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.003377 | OT=0.001603 | Ortho=0.120271 | Graph=16.543178 | lr=5.00e-04 | Acc=0.8473\n",
            "Early stopping at iter=2468 (best@2458 total=0.003094).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.079747 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008265 | OT=0.001966 | Ortho=4.508466 | Graph=17.910227 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.006183 | OT=0.002052 | Ortho=2.372920 | Graph=17.582894 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.004113 | OT=0.002004 | Ortho=0.386218 | Graph=17.236346 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  2000] total=0.003444 | OT=0.001650 | Ortho=0.201277 | Graph=15.929768 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=2153 (best@2143 total=0.003317).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.081768 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.008378 | OT=0.001992 | Ortho=4.588285 | Graph=17.977876 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.006364 | OT=0.002068 | Ortho=2.507544 | Graph=17.881881 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.004311 | OT=0.002080 | Ortho=0.481503 | Graph=17.493342 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.003622 | OT=0.001769 | Ortho=0.237764 | Graph=16.153752 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2286 (best@2276 total=0.003344).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018041 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003827 | OT=0.003257 | Ortho=0.130854 | Graph=43.980972 | lr=1.00e-03 | Acc=0.8550\n",
            "[Iter  1000] total=0.002995 | OT=0.002600 | Ortho=0.044030 | Graph=35.085954 | lr=1.00e-03 | Acc=0.8931\n",
            "Early stopping at iter=1142 (best@1132 total=0.002896).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.070966 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005914 | OT=0.002340 | Ortho=3.179912 | Graph=39.335819 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.003927 | OT=0.002327 | Ortho=1.160733 | Graph=43.998404 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.002646 | OT=0.001873 | Ortho=0.334282 | Graph=43.875511 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1910 (best@1900 total=0.002115).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.072987 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.006205 | OT=0.002370 | Ortho=3.472128 | Graph=36.306186 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.004076 | OT=0.002539 | Ortho=1.120607 | Graph=41.644811 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.002960 | OT=0.002223 | Ortho=0.314811 | Graph=42.256042 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.002341 | OT=0.001790 | Ortho=0.165665 | Graph=38.526704 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=2009 (best@1999 total=0.002326).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017163 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003711 | OT=0.003523 | Ortho=0.123274 | Graph=64.749129 | lr=1.00e-03 | Acc=0.9237\n",
            "[Iter  1000] total=0.002872 | OT=0.002778 | Ortho=0.040136 | Graph=54.723032 | lr=1.00e-03 | Acc=0.9084\n",
            "Early stopping at iter=1272 (best@1262 total=0.002505).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070088 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005428 | OT=0.002438 | Ortho=2.943873 | Graph=45.267817 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.003702 | OT=0.002209 | Ortho=1.445204 | Graph=47.977921 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.002273 | OT=0.001969 | Ortho=0.255353 | Graph=48.506567 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1701 (best@1691 total=0.002015).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072109 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005602 | OT=0.002512 | Ortho=3.045379 | Graph=44.416243 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.003845 | OT=0.002459 | Ortho=1.337066 | Graph=48.458080 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1444 (best@1434 total=0.002606).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017075 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003514 | OT=0.003279 | Ortho=0.228380 | Graph=63.547311 | lr=1.00e-03 | Acc=1.0000\n",
            "[Iter  1000] total=0.002153 | OT=0.002106 | Ortho=0.041408 | Graph=57.977437 | lr=1.00e-03 | Acc=0.9618\n",
            "Early stopping at iter=1051 (best@1041 total=0.002117).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070000 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005438 | OT=0.002497 | Ortho=2.936183 | Graph=45.610428 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.003550 | OT=0.002220 | Ortho=1.325236 | Graph=47.910955 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.002069 | OT=0.001847 | Ortho=0.217726 | Graph=47.889778 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1771 (best@1761 total=0.001826).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072022 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005699 | OT=0.002575 | Ortho=3.120098 | Graph=43.189495 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.003846 | OT=0.002753 | Ortho=1.087859 | Graph=49.468792 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002546 | OT=0.002201 | Ortho=0.340291 | Graph=49.945127 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1666 (best@1656 total=0.002270).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.003541 | OT=0.003292 | Ortho=0.248178 | Graph=63.359266 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.002157 | OT=0.002114 | Ortho=0.041753 | Graph=58.160231 | lr=1.00e-03 | Acc=0.9618\n",
            "Early stopping at iter=1407 (best@1397 total=0.001833).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069991 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005435 | OT=0.002499 | Ortho=2.935031 | Graph=45.657284 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.003545 | OT=0.002220 | Ortho=1.324350 | Graph=47.950081 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.002069 | OT=0.001851 | Ortho=0.217775 | Graph=47.939779 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1732 (best@1722 total=0.001852).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.005696 | OT=0.002576 | Ortho=3.119309 | Graph=43.232406 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.003857 | OT=0.002769 | Ortho=1.087744 | Graph=49.492794 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.002539 | OT=0.002199 | Ortho=0.340350 | Graph=50.034912 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1845 (best@1835 total=0.002039).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n",
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.010  1.000000e-04    0.1    0.002528  0.969466  0.392605\n",
            "1   8  5        0.100  1.000000e-04    0.1    0.003658  0.958015  0.364985\n",
            "2   8  5        0.001  1.000000e-07    0.1    0.002117  0.942748  0.322009\n",
            "3   8  5        0.001  1.000000e-08    0.1    0.001833  0.942748  0.321164\n",
            "4   8  5        0.001  1.000000e-06    0.1    0.002505  0.923664  0.325913\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-05    0.1    0.001995  0.087786  0.648680\n",
            "68  8  5        0.010  1.000000e-05    0.1    0.002044  0.083969  0.658761\n",
            "69  8  5        0.010  1.000000e-03    1.0    0.005637  0.072519  0.689121\n",
            "70  8  5        0.010  1.000000e-03    5.0    0.005807  0.061069  0.693899\n",
            "71  8  5        0.010  1.000000e-03    0.1    0.005234  0.057252  0.707826\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.010  1.000000e-06    1.0    0.001805  0.729008  0.377455\n",
            "1   8  5        0.001  1.000000e-07    1.0    0.001826  0.767176  0.386283\n",
            "2   8  5        0.001  1.000000e-08    0.1    0.001833  0.942748  0.321164\n",
            "3   8  5        0.001  1.000000e-08    1.0    0.001852  0.767176  0.386516\n",
            "4   8  5        0.010  1.000000e-07    1.0    0.001915  0.729008  0.375881\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        1.000  1.000000e-07    0.1    0.017044  0.824427  0.325389\n",
            "68  8  5        1.000  1.000000e-06    0.1    0.017128  0.824427  0.325418\n",
            "69  8  5        1.000  1.000000e-05    0.1    0.017981  0.816794  0.328594\n",
            "70  8  5        1.000  1.000000e-03    0.1    0.023942  0.797710  0.415069\n",
            "71  8  5        1.000  1.000000e-04    0.1    0.026725  0.828244  0.325156\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-05    0.1    0.002896  0.900763  0.320436\n",
            "1   8  5        0.001  1.000000e-08    0.1    0.001833  0.942748  0.321164\n",
            "2   8  5        0.001  1.000000e-07    0.1    0.002117  0.942748  0.322009\n",
            "3   8  5        1.000  1.000000e-04    0.1    0.026725  0.828244  0.325156\n",
            "4   8  5        1.000  1.000000e-07    0.1    0.017044  0.824427  0.325389\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-05    0.1    0.001995  0.087786  0.648680\n",
            "68  8  5        0.010  1.000000e-05    0.1    0.002044  0.083969  0.658761\n",
            "69  8  5        0.010  1.000000e-03    1.0    0.005637  0.072519  0.689121\n",
            "70  8  5        0.010  1.000000e-03    5.0    0.005807  0.061069  0.693899\n",
            "71  8  5        0.010  1.000000e-03    0.1    0.005234  0.057252  0.707826\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"rna\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"atac\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['Ori_Feature'],\n",
        "    Y_features= res_y['Ori_Feature'],\n",
        "       labels_X=mdata['rna'].obs['celltype'],\n",
        "    labels_Y=mdata['atac'].obs['celltype'],\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "741e8e91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.103656 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.042944 | OT=0.012956 | Ortho=0.000042 | Graph=29.946619 | lr=5.00e-04 | Acc=0.8702\n",
            "[Iter  1000] total=0.031228 | OT=0.010549 | Ortho=0.000025 | Graph=20.653707 | lr=5.00e-04 | Acc=0.8855\n",
            "[Iter  1500] total=0.021970 | OT=0.007326 | Ortho=0.000013 | Graph=14.630840 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.016888 | OT=0.005161 | Ortho=0.000013 | Graph=11.714298 | lr=5.00e-04 | Acc=0.9084\n",
            "[Iter  2500] total=0.014237 | OT=0.003966 | Ortho=0.000005 | Graph=10.264861 | lr=5.00e-04 | Acc=0.9084\n",
            "[Iter  3000] total=0.012156 | OT=0.003017 | Ortho=0.000004 | Graph=9.133807 | lr=5.00e-04 | Acc=0.9008\n",
            "[Iter  3500] total=0.010664 | OT=0.002492 | Ortho=0.000003 | Graph=8.169020 | lr=5.00e-04 | Acc=0.8473\n",
            "Early stopping at iter=3712 (best@3702 total=0.010201).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144772 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.035506 | OT=0.011272 | Ortho=0.000052 | Graph=24.182474 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  1000] total=0.022247 | OT=0.006733 | Ortho=0.000022 | Graph=15.492101 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  1500] total=0.016280 | OT=0.004447 | Ortho=0.000008 | Graph=11.825476 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  2000] total=0.013839 | OT=0.003319 | Ortho=0.000005 | Graph=10.514842 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  2500] total=0.011995 | OT=0.002492 | Ortho=0.000004 | Graph=9.499106 | lr=1.00e-03 | Acc=0.8779\n",
            "[Iter  3000] total=0.010644 | OT=0.001986 | Ortho=0.000019 | Graph=8.638586 | lr=1.00e-03 | Acc=0.8702\n",
            "[Iter  3500] total=0.009361 | OT=0.001600 | Ortho=0.000003 | Graph=7.758628 | lr=1.00e-03 | Acc=0.8702\n",
            "[Iter  4000] total=0.008772 | OT=0.001432 | Ortho=0.000002 | Graph=7.337522 | lr=5.00e-04 | Acc=0.8702\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.146412 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.065293 | OT=0.031617 | Ortho=0.000283 | Graph=33.393026 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1000] total=0.031584 | OT=0.009848 | Ortho=0.000036 | Graph=21.700267 | lr=5.00e-04 | Acc=0.9084\n",
            "[Iter  1500] total=0.022628 | OT=0.006817 | Ortho=0.000022 | Graph=15.788436 | lr=5.00e-04 | Acc=0.9008\n",
            "[Iter  2000] total=0.017765 | OT=0.005061 | Ortho=0.000011 | Graph=12.692814 | lr=5.00e-04 | Acc=0.8855\n",
            "[Iter  2500] total=0.014908 | OT=0.003664 | Ortho=0.000007 | Graph=11.237160 | lr=5.00e-04 | Acc=0.8779\n",
            "[Iter  3000] total=0.013261 | OT=0.003004 | Ortho=0.000005 | Graph=10.251393 | lr=5.00e-04 | Acc=0.8779\n",
            "[Iter  3500] total=0.011884 | OT=0.002539 | Ortho=0.000004 | Graph=9.340812 | lr=5.00e-04 | Acc=0.8779\n",
            "[Iter  4000] total=0.010476 | OT=0.002029 | Ortho=0.000003 | Graph=8.443260 | lr=5.00e-04 | Acc=0.8779\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.025219 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.024740 | OT=0.016079 | Ortho=0.000010 | Graph=86.503680 | lr=2.50e-04 | Acc=0.7710\n",
            "[Iter  1000] total=0.023046 | OT=0.014535 | Ortho=0.000012 | Graph=84.983516 | lr=2.50e-04 | Acc=0.8015\n",
            "[Iter  1500] total=0.019848 | OT=0.012013 | Ortho=0.000017 | Graph=78.180795 | lr=2.50e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.013455 | OT=0.006651 | Ortho=0.000011 | Graph=67.939725 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  2500] total=0.009943 | OT=0.005735 | Ortho=0.000009 | Graph=41.992726 | lr=2.50e-04 | Acc=0.8397\n",
            "[Iter  3000] total=0.007506 | OT=0.004514 | Ortho=0.000003 | Graph=29.885795 | lr=2.50e-04 | Acc=0.8779\n",
            "[Iter  3500] total=0.006542 | OT=0.003946 | Ortho=0.000001 | Graph=25.945993 | lr=2.50e-04 | Acc=0.8779\n",
            "[Iter  4000] total=0.005891 | OT=0.003463 | Ortho=0.000001 | Graph=24.270996 | lr=2.50e-04 | Acc=0.8779\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.066335 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.058368).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.067975 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.059963).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017376 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=141 (best@141 total=0.017327).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058492 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.050606).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060131 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.052120).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016591 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.016378 | OT=0.016289 | Ortho=0.000002 | Graph=87.085953 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  1000] total=0.015947 | OT=0.015858 | Ortho=0.000002 | Graph=86.986942 | lr=1.25e-04 | Acc=0.7710\n",
            "[Iter  1500] total=0.014540 | OT=0.014445 | Ortho=0.000009 | Graph=86.726522 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  2000] total=0.013539 | OT=0.013444 | Ortho=0.000009 | Graph=86.039127 | lr=1.25e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.012331 | OT=0.012237 | Ortho=0.000009 | Graph=84.396229 | lr=1.25e-04 | Acc=0.8321\n",
            "[Iter  3000] total=0.008757 | OT=0.008666 | Ortho=0.000008 | Graph=83.540206 | lr=1.25e-04 | Acc=0.8626\n",
            "[Iter  3500] total=0.006551 | OT=0.006464 | Ortho=0.000004 | Graph=83.450095 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005730 | OT=0.005645 | Ortho=0.000003 | Graph=81.883340 | lr=1.25e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057707 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.049825).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059347 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.051332).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016513 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.016302 | OT=0.016292 | Ortho=0.000002 | Graph=87.100676 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  1000] total=0.015880 | OT=0.015869 | Ortho=0.000002 | Graph=86.992767 | lr=1.25e-04 | Acc=0.7710\n",
            "[Iter  1500] total=0.014486 | OT=0.014469 | Ortho=0.000008 | Graph=86.702631 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  2000] total=0.013355 | OT=0.013338 | Ortho=0.000009 | Graph=85.879517 | lr=1.25e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.012026 | OT=0.012008 | Ortho=0.000009 | Graph=84.121123 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.007845 | OT=0.007832 | Ortho=0.000005 | Graph=83.916183 | lr=1.25e-04 | Acc=0.8626\n",
            "[Iter  3500] total=0.006405 | OT=0.006393 | Ortho=0.000004 | Graph=83.672103 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005605 | OT=0.005594 | Ortho=0.000003 | Graph=82.165404 | lr=1.25e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057629 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.049747).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059269 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.051254).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.016295 | OT=0.016292 | Ortho=0.000002 | Graph=87.100952 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  1000] total=0.015872 | OT=0.015869 | Ortho=0.000002 | Graph=86.993276 | lr=1.25e-04 | Acc=0.7710\n",
            "[Iter  1500] total=0.014478 | OT=0.014469 | Ortho=0.000008 | Graph=86.703526 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  2000] total=0.013347 | OT=0.013338 | Ortho=0.000009 | Graph=85.881071 | lr=1.25e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.012018 | OT=0.012008 | Ortho=0.000009 | Graph=84.123658 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.007836 | OT=0.007830 | Ortho=0.000005 | Graph=83.920988 | lr=1.25e-04 | Acc=0.8626\n",
            "[Iter  3500] total=0.006398 | OT=0.006393 | Ortho=0.000004 | Graph=83.678973 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005598 | OT=0.005594 | Ortho=0.000003 | Graph=82.178083 | lr=1.25e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.049740).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.051246).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.103656 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.014932 | OT=0.003687 | Ortho=0.000642 | Graph=11.180695 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.009627 | OT=0.002086 | Ortho=0.000266 | Graph=7.514435 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.007248 | OT=0.001456 | Ortho=0.000173 | Graph=5.774927 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  2000] total=0.006161 | OT=0.001248 | Ortho=0.000138 | Graph=4.899044 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2500] total=0.005005 | OT=0.000910 | Ortho=0.000111 | Graph=4.083312 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=2802 (best@2792 total=0.004550).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144772 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.024899 | OT=0.007664 | Ortho=0.003432 | Graph=16.891981 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  1000] total=0.013788 | OT=0.003227 | Ortho=0.000575 | Graph=10.503348 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1500] total=0.011514 | OT=0.002522 | Ortho=0.000378 | Graph=8.954043 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.010076 | OT=0.002001 | Ortho=0.000302 | Graph=8.044735 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  2500] total=0.009005 | OT=0.001700 | Ortho=0.000251 | Graph=7.280262 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.007893 | OT=0.001456 | Ortho=0.000201 | Graph=6.416874 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  3500] total=0.006856 | OT=0.001238 | Ortho=0.000154 | Graph=5.602678 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005997 | OT=0.001066 | Ortho=0.000120 | Graph=4.918287 | lr=5.00e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.146412 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.026407 | OT=0.008315 | Ortho=0.003360 | Graph=17.755425 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  1000] total=0.014027 | OT=0.003210 | Ortho=0.000588 | Graph=10.758429 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.011760 | OT=0.002504 | Ortho=0.000387 | Graph=9.216424 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.010370 | OT=0.002071 | Ortho=0.000313 | Graph=8.267618 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.009262 | OT=0.001733 | Ortho=0.000262 | Graph=7.502320 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3000] total=0.008156 | OT=0.001456 | Ortho=0.000224 | Graph=6.678317 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3500] total=0.006979 | OT=0.001179 | Ortho=0.000168 | Graph=5.783322 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  4000] total=0.005880 | OT=0.000933 | Ortho=0.000125 | Graph=4.934616 | lr=5.00e-04 | Acc=0.8244\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.025219 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.009765 | OT=0.007375 | Ortho=0.000128 | Graph=23.765833 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.005544 | OT=0.003832 | Ortho=0.000025 | Graph=17.101965 | lr=1.00e-03 | Acc=1.0000\n",
            "[Iter  1500] total=0.004386 | OT=0.002911 | Ortho=0.000036 | Graph=14.714798 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  2000] total=0.003737 | OT=0.002382 | Ortho=0.000012 | Graph=13.534591 | lr=1.00e-03 | Acc=0.9924\n",
            "Early stopping at iter=2498 (best@2488 total=0.003078).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.066335 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007330 | OT=0.003869 | Ortho=0.000306 | Graph=34.308553 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.003850 | OT=0.001854 | Ortho=0.000078 | Graph=19.877299 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1500] total=0.002646 | OT=0.001082 | Ortho=0.000027 | Graph=15.616695 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002263 | OT=0.000838 | Ortho=0.000017 | Graph=14.230364 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2500] total=0.002028 | OT=0.000711 | Ortho=0.000014 | Graph=13.161512 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=2918 (best@2908 total=0.001869).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.067975 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.011157 | OT=0.006242 | Ortho=0.000774 | Graph=48.376958 | lr=5.00e-04 | Acc=0.7939\n",
            "[Iter  1000] total=0.005794 | OT=0.002960 | Ortho=0.000191 | Graph=28.155058 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1500] total=0.004092 | OT=0.002014 | Ortho=0.000082 | Graph=20.695819 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  2000] total=0.003173 | OT=0.001404 | Ortho=0.000039 | Graph=17.652408 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  2500] total=0.002706 | OT=0.001130 | Ortho=0.000023 | Graph=15.735220 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3000] total=0.002430 | OT=0.000970 | Ortho=0.000016 | Graph=14.575828 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3500] total=0.002192 | OT=0.000841 | Ortho=0.000013 | Graph=13.497135 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  4000] total=0.001982 | OT=0.000732 | Ortho=0.000011 | Graph=12.492117 | lr=5.00e-04 | Acc=0.8168\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017376 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.012211 | OT=0.011322 | Ortho=0.000476 | Graph=84.143119 | lr=5.00e-04 | Acc=0.6412\n",
            "[Iter  1000] total=0.008249 | OT=0.007678 | Ortho=0.000052 | Graph=56.600161 | lr=5.00e-04 | Acc=0.0687\n",
            "[Iter  1500] total=0.005201 | OT=0.004830 | Ortho=0.000064 | Graph=36.471024 | lr=5.00e-04 | Acc=0.0153\n",
            "[Iter  2000] total=0.002356 | OT=0.002034 | Ortho=0.000011 | Graph=32.132236 | lr=5.00e-04 | Acc=0.1221\n",
            "[Iter  2500] total=0.001861 | OT=0.001572 | Ortho=0.000004 | Graph=28.843711 | lr=5.00e-04 | Acc=0.1450\n",
            "[Iter  3000] total=0.001643 | OT=0.001391 | Ortho=0.000002 | Graph=25.226273 | lr=5.00e-04 | Acc=0.1679\n",
            "Early stopping at iter=3439 (best@3429 total=0.001383).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058492 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004035 | OT=0.003431 | Ortho=0.000131 | Graph=59.100298 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.002145 | OT=0.001632 | Ortho=0.000037 | Graph=50.915074 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.001544 | OT=0.001076 | Ortho=0.000012 | Graph=46.715649 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=1650 (best@1640 total=0.001443).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060131 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007556 | OT=0.006739 | Ortho=0.000613 | Graph=75.542398 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  1000] total=0.003204 | OT=0.002647 | Ortho=0.000090 | Graph=54.874669 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  1500] total=0.002297 | OT=0.001791 | Ortho=0.000043 | Graph=50.180392 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2000] total=0.001863 | OT=0.001386 | Ortho=0.000021 | Graph=47.575815 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.001554 | OT=0.001106 | Ortho=0.000017 | Graph=44.634212 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.001321 | OT=0.000914 | Ortho=0.000005 | Graph=40.616714 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=3088 (best@3078 total=0.001292).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016591 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006055 | OT=0.005936 | Ortho=0.000344 | Graph=84.039334 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.003584 | OT=0.003509 | Ortho=0.000045 | Graph=70.727058 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  1500] total=0.002777 | OT=0.002711 | Ortho=0.000029 | Graph=63.044168 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2000] total=0.002289 | OT=0.002230 | Ortho=0.000015 | Graph=56.831502 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  2500] total=0.001891 | OT=0.001843 | Ortho=0.000008 | Graph=47.689639 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  3000] total=0.001603 | OT=0.001566 | Ortho=0.000004 | Graph=36.958326 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  3500] total=0.001174 | OT=0.001143 | Ortho=0.000002 | Graph=30.464785 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=3776 (best@3766 total=0.001095).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057707 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003601 | OT=0.003526 | Ortho=0.000126 | Graph=61.851919 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001744 | OT=0.001686 | Ortho=0.000034 | Graph=54.519081 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001160 | OT=0.001108 | Ortho=0.000011 | Graph=51.073945 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1806 (best@1796 total=0.000979).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059347 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006924 | OT=0.006788 | Ortho=0.000592 | Graph=76.909192 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.002882 | OT=0.002815 | Ortho=0.000081 | Graph=58.668392 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1500] total=0.001929 | OT=0.001871 | Ortho=0.000037 | Graph=54.081533 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.001546 | OT=0.001492 | Ortho=0.000019 | Graph=52.167302 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.001233 | OT=0.001182 | Ortho=0.000009 | Graph=49.894320 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2864 (best@2854 total=0.001098).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016513 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006027 | OT=0.005984 | Ortho=0.000340 | Graph=84.087833 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.003552 | OT=0.003541 | Ortho=0.000044 | Graph=71.446768 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.002744 | OT=0.002735 | Ortho=0.000030 | Graph=63.605610 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.002275 | OT=0.002268 | Ortho=0.000015 | Graph=57.732949 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.001903 | OT=0.001894 | Ortho=0.000037 | Graph=49.410232 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=2766 (best@2756 total=0.001743).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057629 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003650 | OT=0.003629 | Ortho=0.000143 | Graph=63.598449 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001696 | OT=0.001686 | Ortho=0.000044 | Graph=55.108645 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001148 | OT=0.001142 | Ortho=0.000012 | Graph=52.294439 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1630 (best@1620 total=0.001067).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059269 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006864 | OT=0.006797 | Ortho=0.000590 | Graph=77.044178 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.002838 | OT=0.002824 | Ortho=0.000080 | Graph=58.985155 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1500] total=0.001885 | OT=0.001876 | Ortho=0.000036 | Graph=54.392407 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.001507 | OT=0.001500 | Ortho=0.000019 | Graph=52.548698 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.001213 | OT=0.001207 | Ortho=0.000010 | Graph=50.606507 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2632 (best@2622 total=0.001163).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006019 | OT=0.005984 | Ortho=0.000340 | Graph=84.096090 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.003547 | OT=0.003542 | Ortho=0.000044 | Graph=71.512444 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.002739 | OT=0.002736 | Ortho=0.000030 | Graph=63.686386 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.002271 | OT=0.002269 | Ortho=0.000015 | Graph=57.837004 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.001899 | OT=0.001896 | Ortho=0.000026 | Graph=49.436490 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=2852 (best@2842 total=0.001693).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003645 | OT=0.003630 | Ortho=0.000143 | Graph=63.623799 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001689 | OT=0.001684 | Ortho=0.000044 | Graph=55.151580 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001144 | OT=0.001142 | Ortho=0.000014 | Graph=52.346521 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1625 (best@1615 total=0.001067).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006858 | OT=0.006798 | Ortho=0.000590 | Graph=77.057273 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.002834 | OT=0.002825 | Ortho=0.000080 | Graph=59.015669 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1500] total=0.001881 | OT=0.001877 | Ortho=0.000036 | Graph=54.422854 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.001502 | OT=0.001500 | Ortho=0.000019 | Graph=52.581864 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.001209 | OT=0.001208 | Ortho=0.000010 | Graph=50.648259 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2632 (best@2622 total=0.001157).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.103656 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.011809 | OT=0.002473 | Ortho=0.048555 | Graph=8.850286 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  1000] total=0.008385 | OT=0.001413 | Ortho=0.025264 | Graph=6.719421 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  1500] total=0.006556 | OT=0.001059 | Ortho=0.015569 | Graph=5.341062 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  2000] total=0.005283 | OT=0.000860 | Ortho=0.010020 | Graph=4.322882 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  2500] total=0.004316 | OT=0.000748 | Ortho=0.006422 | Graph=3.503672 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  3000] total=0.003523 | OT=0.000629 | Ortho=0.004138 | Graph=2.852672 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  3500] total=0.003007 | OT=0.000550 | Ortho=0.002878 | Graph=2.428337 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  4000] total=0.002675 | OT=0.000478 | Ortho=0.002185 | Graph=2.175032 | lr=1.00e-03 | Acc=0.0534\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144772 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.013972 | OT=0.002789 | Ortho=0.069425 | Graph=10.488579 | lr=1.00e-03 | Acc=0.0840\n",
            "[Iter  1000] total=0.010530 | OT=0.001834 | Ortho=0.036352 | Graph=8.331838 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  1500] total=0.008599 | OT=0.001433 | Ortho=0.024800 | Graph=6.918112 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  2000] total=0.007037 | OT=0.001123 | Ortho=0.016723 | Graph=5.747009 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  2500] total=0.005845 | OT=0.000900 | Ortho=0.012001 | Graph=4.824855 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  3000] total=0.005005 | OT=0.000777 | Ortho=0.009155 | Graph=4.136251 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  3500] total=0.004259 | OT=0.000703 | Ortho=0.006570 | Graph=3.490608 | lr=1.00e-03 | Acc=0.0916\n",
            "Early stopping at iter=3647 (best@3637 total=0.004108).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.146412 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.014351 | OT=0.003004 | Ortho=0.074834 | Graph=10.597999 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  1000] total=0.010654 | OT=0.001817 | Ortho=0.037538 | Graph=8.460712 | lr=1.00e-03 | Acc=0.0992\n",
            "[Iter  1500] total=0.008696 | OT=0.001397 | Ortho=0.025456 | Graph=7.044340 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  2000] total=0.006940 | OT=0.001041 | Ortho=0.016081 | Graph=5.739079 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  2500] total=0.005791 | OT=0.000903 | Ortho=0.011498 | Graph=4.773428 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  3000] total=0.004790 | OT=0.000698 | Ortho=0.008222 | Graph=4.009045 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  3500] total=0.004014 | OT=0.000581 | Ortho=0.005765 | Graph=3.375130 | lr=1.00e-03 | Acc=0.0916\n",
            "[Iter  4000] total=0.003503 | OT=0.000521 | Ortho=0.004259 | Graph=2.940049 | lr=1.00e-03 | Acc=0.0916\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.025219 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.005582 | OT=0.003999 | Ortho=0.002632 | Graph=15.568574 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.003534 | OT=0.002273 | Ortho=0.001165 | Graph=12.487073 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1500] total=0.002586 | OT=0.001518 | Ortho=0.000788 | Graph=10.600551 | lr=1.00e-03 | Acc=0.9847\n",
            "Early stopping at iter=1563 (best@1553 total=0.002551).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.066335 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006316 | OT=0.002952 | Ortho=0.022501 | Graph=31.392163 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.003509 | OT=0.001680 | Ortho=0.003860 | Graph=17.897980 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002671 | OT=0.001133 | Ortho=0.001853 | Graph=15.195420 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.002222 | OT=0.000866 | Ortho=0.001403 | Graph=13.412378 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  2500] total=0.001865 | OT=0.000670 | Ortho=0.000929 | Graph=11.859349 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=2576 (best@2566 total=0.001835).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.067975 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006475 | OT=0.003019 | Ortho=0.025399 | Graph=32.025593 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.003750 | OT=0.001863 | Ortho=0.004730 | Graph=18.394244 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002897 | OT=0.001341 | Ortho=0.001758 | Graph=15.389610 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1816 (best@1806 total=0.002616).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017376 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006023 | OT=0.005560 | Ortho=0.003742 | Graph=42.498003 | lr=1.00e-03 | Acc=0.4504\n",
            "[Iter  1000] total=0.001311 | OT=0.001079 | Ortho=0.000247 | Graph=22.989402 | lr=1.00e-03 | Acc=0.0382\n",
            "Early stopping at iter=1292 (best@1282 total=0.000992).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058492 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003629 | OT=0.002917 | Ortho=0.010480 | Graph=60.701468 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.002018 | OT=0.001531 | Ortho=0.002066 | Graph=46.705611 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1272 (best@1262 total=0.001689).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060131 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003728 | OT=0.002993 | Ortho=0.011389 | Graph=62.117787 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002152 | OT=0.001639 | Ortho=0.001786 | Graph=49.522360 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.001623 | OT=0.001202 | Ortho=0.000696 | Graph=41.406967 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  2000] total=0.001315 | OT=0.000973 | Ortho=0.000403 | Graph=33.824340 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=2160 (best@2150 total=0.001243).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016591 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006337 | OT=0.006252 | Ortho=0.002175 | Graph=63.791709 | lr=1.00e-03 | Acc=0.4504\n",
            "[Iter  1000] total=0.002229 | OT=0.002187 | Ortho=0.000237 | Graph=38.957389 | lr=1.00e-03 | Acc=0.2061\n",
            "[Iter  1500] total=0.001747 | OT=0.001709 | Ortho=0.000115 | Graph=36.744455 | lr=1.00e-03 | Acc=0.2672\n",
            "Early stopping at iter=1529 (best@1519 total=0.001735).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057707 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003178 | OT=0.003015 | Ortho=0.009912 | Graph=63.944524 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.001713 | OT=0.001642 | Ortho=0.001773 | Graph=52.650767 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001195 | OT=0.001144 | Ortho=0.000485 | Graph=45.889059 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  2000] total=0.000967 | OT=0.000924 | Ortho=0.000250 | Graph=41.191271 | lr=1.00e-03 | Acc=0.7710\n",
            "Early stopping at iter=2305 (best@2295 total=0.000882).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059347 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003265 | OT=0.003094 | Ortho=0.010484 | Graph=65.736268 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001815 | OT=0.001743 | Ortho=0.001569 | Graph=55.704127 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001404 | OT=0.001347 | Ortho=0.000553 | Graph=50.869242 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  2000] total=0.001196 | OT=0.001145 | Ortho=0.000288 | Graph=48.156463 | lr=5.00e-04 | Acc=0.7786\n",
            "[Iter  2500] total=0.001100 | OT=0.001052 | Ortho=0.000198 | Graph=46.227431 | lr=5.00e-04 | Acc=0.7786\n",
            "[Iter  3000] total=0.001018 | OT=0.000972 | Ortho=0.000144 | Graph=44.190848 | lr=5.00e-04 | Acc=0.7863\n",
            "Early stopping at iter=3258 (best@3248 total=0.000969).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016513 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006266 | OT=0.006238 | Ortho=0.002101 | Graph=64.768087 | lr=1.00e-03 | Acc=0.5115\n",
            "[Iter  1000] total=0.002312 | OT=0.002305 | Ortho=0.000252 | Graph=39.475919 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  1500] total=0.001707 | OT=0.001703 | Ortho=0.000091 | Graph=35.218755 | lr=1.00e-03 | Acc=0.0611\n",
            "Early stopping at iter=1674 (best@1664 total=0.001619).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057629 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003129 | OT=0.003023 | Ortho=0.009867 | Graph=64.291512 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.001676 | OT=0.001653 | Ortho=0.001778 | Graph=53.209700 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001161 | OT=0.001152 | Ortho=0.000482 | Graph=46.775785 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  2000] total=0.000948 | OT=0.000942 | Ortho=0.000221 | Graph=42.421977 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  2500] total=0.000849 | OT=0.000844 | Ortho=0.000140 | Graph=40.502450 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  3000] total=0.000787 | OT=0.000782 | Ortho=0.000110 | Graph=39.169489 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  3500] total=0.000744 | OT=0.000739 | Ortho=0.000094 | Graph=38.207525 | lr=5.00e-04 | Acc=0.7710\n",
            "Early stopping at iter=3523 (best@3513 total=0.000737).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059269 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003216 | OT=0.003105 | Ortho=0.010403 | Graph=66.071932 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001776 | OT=0.001756 | Ortho=0.001517 | Graph=56.207889 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001351 | OT=0.001340 | Ortho=0.000520 | Graph=51.546711 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1823 (best@1813 total=0.001175).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006261 | OT=0.006240 | Ortho=0.002099 | Graph=64.852721 | lr=1.00e-03 | Acc=0.5191\n",
            "[Iter  1000] total=0.002306 | OT=0.002304 | Ortho=0.000237 | Graph=39.472468 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  1500] total=0.001752 | OT=0.001749 | Ortho=0.000217 | Graph=35.918644 | lr=1.00e-03 | Acc=0.0687\n",
            "Early stopping at iter=1766 (best@1756 total=0.001600).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003124 | OT=0.003025 | Ortho=0.009868 | Graph=64.331469 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.001672 | OT=0.001654 | Ortho=0.001777 | Graph=53.264609 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1131 (best@1121 total=0.001504).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003211 | OT=0.003107 | Ortho=0.010391 | Graph=66.105497 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001769 | OT=0.001752 | Ortho=0.001547 | Graph=56.264118 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1495 (best@1485 total=0.001346).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.103656 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.008172 | OT=0.000228 | Ortho=6.416207 | Graph=1.527789 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.006919 | OT=0.000299 | Ortho=4.307984 | Graph=2.311924 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1500] total=0.006033 | OT=0.000274 | Ortho=3.071999 | Graph=2.687002 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2000] total=0.005144 | OT=0.000324 | Ortho=2.146703 | Graph=2.673464 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2500] total=0.004022 | OT=0.000347 | Ortho=0.873720 | Graph=2.800519 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  3000] total=0.003401 | OT=0.000361 | Ortho=0.549924 | Graph=2.489704 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  3500] total=0.002884 | OT=0.000339 | Ortho=0.361298 | Graph=2.184647 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=3863 (best@3853 total=0.002594).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144772 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.008450 | OT=0.000189 | Ortho=6.819059 | Graph=1.442175 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.007601 | OT=0.000226 | Ortho=5.636682 | Graph=1.737794 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1500] total=0.006844 | OT=0.000354 | Ortho=4.125160 | Graph=2.364091 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2000] total=0.005985 | OT=0.000406 | Ortho=3.058865 | Graph=2.520960 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2500] total=0.005059 | OT=0.000464 | Ortho=2.055282 | Graph=2.539808 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3000] total=0.004160 | OT=0.000488 | Ortho=0.944568 | Graph=2.727593 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  3500] total=0.003647 | OT=0.000453 | Ortho=0.689845 | Graph=2.503696 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  4000] total=0.003251 | OT=0.000418 | Ortho=0.525117 | Graph=2.307878 | lr=1.00e-03 | Acc=0.8244\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.146412 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.008526 | OT=0.000179 | Ortho=6.898760 | Graph=1.447899 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.007641 | OT=0.000219 | Ortho=5.713229 | Graph=1.708461 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1500] total=0.006805 | OT=0.000357 | Ortho=4.067491 | Graph=2.380977 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2000] total=0.006054 | OT=0.000423 | Ortho=3.092423 | Graph=2.538420 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2500] total=0.005226 | OT=0.000443 | Ortho=2.279137 | Graph=2.503018 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  3000] total=0.004274 | OT=0.000488 | Ortho=1.093982 | Graph=2.691928 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  3500] total=0.003746 | OT=0.000464 | Ortho=0.725670 | Graph=2.556714 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=3986 (best@3976 total=0.003312).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.025219 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003473 | OT=0.000816 | Ortho=1.262465 | Graph=13.944878 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001968 | OT=0.000546 | Ortho=0.163675 | Graph=12.582058 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001577 | OT=0.000397 | Ortho=0.096459 | Graph=10.834375 | lr=1.00e-03 | Acc=0.7634\n",
            "Early stopping at iter=1540 (best@1530 total=0.001558).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.066335 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.005614 | OT=0.000607 | Ortho=3.973160 | Graph=10.337129 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.004026 | OT=0.000847 | Ortho=2.083223 | Graph=10.961309 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.002222 | OT=0.000781 | Ortho=0.316013 | Graph=11.258929 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.001770 | OT=0.000583 | Ortho=0.137977 | Graph=10.487144 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.001630 | OT=0.000518 | Ortho=0.100086 | Graph=10.118114 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.001527 | OT=0.000482 | Ortho=0.076438 | Graph=9.676274 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=3468 (best@3458 total=0.001414).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.067975 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.005668 | OT=0.000585 | Ortho=4.025903 | Graph=10.566968 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.004267 | OT=0.000847 | Ortho=2.317352 | Graph=11.025509 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1500] total=0.002368 | OT=0.000833 | Ortho=0.316917 | Graph=12.177751 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  2000] total=0.001959 | OT=0.000699 | Ortho=0.148603 | Graph=11.110901 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2500] total=0.001793 | OT=0.000637 | Ortho=0.104967 | Graph=10.513584 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  3000] total=0.001682 | OT=0.000599 | Ortho=0.076739 | Graph=10.056916 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3500] total=0.001589 | OT=0.000570 | Ortho=0.061926 | Graph=9.572187 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=3588 (best@3578 total=0.001575).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017376 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.002254 | OT=0.001660 | Ortho=0.150951 | Graph=44.266512 | lr=1.00e-03 | Acc=0.8626\n",
            "[Iter  1000] total=0.001268 | OT=0.000909 | Ortho=0.044334 | Graph=31.439429 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1500] total=0.001031 | OT=0.000723 | Ortho=0.025416 | Graph=28.185177 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  2000] total=0.000869 | OT=0.000582 | Ortho=0.027110 | Graph=25.990678 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=2486 (best@2476 total=0.000785).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058492 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004091 | OT=0.001309 | Ortho=2.322902 | Graph=45.855185 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1000] total=0.002742 | OT=0.001435 | Ortho=0.841202 | Graph=46.515318 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1500] total=0.001808 | OT=0.001170 | Ortho=0.196246 | Graph=44.094633 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  2000] total=0.001389 | OT=0.000908 | Ortho=0.080275 | Graph=40.148373 | lr=1.00e-03 | Acc=0.7634\n",
            "Early stopping at iter=2177 (best@2167 total=0.001312).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060131 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004192 | OT=0.001406 | Ortho=2.311070 | Graph=47.448130 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1000] total=0.002715 | OT=0.001296 | Ortho=0.970353 | Graph=44.867131 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1500] total=0.001728 | OT=0.001081 | Ortho=0.214633 | Graph=43.311342 | lr=1.00e-03 | Acc=0.7634\n",
            "Early stopping at iter=1608 (best@1598 total=0.001610).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016591 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.001677 | OT=0.001447 | Ortho=0.172675 | Graph=56.923687 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1000] total=0.001020 | OT=0.000951 | Ortho=0.018044 | Graph=50.710565 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1147 (best@1137 total=0.000978).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057707 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003724 | OT=0.001453 | Ortho=2.216581 | Graph=54.053103 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002233 | OT=0.001360 | Ortho=0.819762 | Graph=52.687520 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.001325 | OT=0.001127 | Ortho=0.146288 | Graph=51.703225 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1921 (best@1911 total=0.000981).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059347 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003861 | OT=0.001578 | Ortho=2.228027 | Graph=54.244035 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.002383 | OT=0.001412 | Ortho=0.917452 | Graph=52.738276 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.001444 | OT=0.001214 | Ortho=0.177411 | Graph=52.588964 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1984 (best@1974 total=0.001071).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016513 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.001658 | OT=0.001491 | Ortho=0.160475 | Graph=60.356316 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=902 (best@892 total=0.001080).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057629 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003708 | OT=0.001491 | Ortho=2.212146 | Graph=55.051185 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002196 | OT=0.001361 | Ortho=0.829917 | Graph=53.298199 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.001243 | OT=0.001105 | Ortho=0.132838 | Graph=52.637901 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1933 (best@1923 total=0.000965).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059269 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003815 | OT=0.001591 | Ortho=2.217979 | Graph=55.089610 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  1000] total=0.002332 | OT=0.001413 | Ortho=0.914202 | Graph=53.511334 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001421 | OT=0.001216 | Ortho=0.198974 | Graph=52.959612 | lr=1.00e-03 | Acc=0.7557\n",
            "Early stopping at iter=1941 (best@1931 total=0.001001).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.001648 | OT=0.001483 | Ortho=0.164074 | Graph=60.196563 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1000] total=0.001032 | OT=0.001017 | Ortho=0.014371 | Graph=56.321513 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1500] total=0.000874 | OT=0.000865 | Ortho=0.009065 | Graph=54.817016 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  2000] total=0.000789 | OT=0.000784 | Ortho=0.004818 | Graph=54.608153 | lr=5.00e-04 | Acc=0.8244\n",
            "Early stopping at iter=2153 (best@2143 total=0.000773).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003705 | OT=0.001493 | Ortho=2.211609 | Graph=55.092906 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002189 | OT=0.001358 | Ortho=0.830242 | Graph=53.361861 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.001240 | OT=0.001106 | Ortho=0.132880 | Graph=52.720550 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1944 (best@1934 total=0.000955).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=87.151703 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003811 | OT=0.001593 | Ortho=2.217253 | Graph=55.174035 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  1000] total=0.002328 | OT=0.001413 | Ortho=0.913709 | Graph=53.595806 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001411 | OT=0.001211 | Ortho=0.199243 | Graph=53.051746 | lr=1.00e-03 | Acc=0.7557\n",
            "Early stopping at iter=1758 (best@1748 total=0.001129).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n",
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        0.010  1.000000e-04    0.1    0.002551  0.980916  0.315862\n",
            "1   5  5        0.100  1.000000e-04    0.1    0.003078  0.977099  0.311200\n",
            "2   5  5        1.000  1.000000e-04    0.1    0.005891  0.908397  0.303304\n",
            "3   5  5        0.001  1.000000e-03    5.0    0.003312  0.904580  0.364285\n",
            "4   5  5        0.001  1.000000e-03    0.1    0.002594  0.900763  0.353068\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        0.010  1.000000e-05    0.1    0.000992  0.064885  0.654915\n",
            "68  5  5        0.010  1.000000e-07    0.1    0.001619  0.061069  0.675135\n",
            "69  5  5        0.010  1.000000e-08    0.1    0.001600  0.057252  0.675398\n",
            "70  5  5        0.010  1.000000e-03    1.0    0.004108  0.053435  0.704941\n",
            "71  5  5        0.010  1.000000e-03    0.1    0.002674  0.038168  0.704708\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        0.010  1.000000e-07    1.0    0.000737  0.767176  0.361313\n",
            "1   5  5        0.001  1.000000e-08    0.1    0.000773  0.832061  0.350300\n",
            "2   5  5        0.001  1.000000e-05    0.1    0.000785  0.843511  0.373492\n",
            "3   5  5        0.010  1.000000e-06    1.0    0.000882  0.770992  0.360614\n",
            "4   5  5        0.001  1.000000e-08    1.0    0.000955  0.770992  0.366762\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        1.000  1.000000e-07    5.0    0.051254  0.530534  0.381155\n",
            "68  5  5        1.000  1.000000e-06    5.0    0.051332  0.530534  0.381126\n",
            "69  5  5        1.000  1.000000e-05    5.0    0.052120  0.530534  0.380922\n",
            "70  5  5        1.000  1.000000e-04    1.0    0.058368  0.522901  0.384710\n",
            "71  5  5        1.000  1.000000e-04    5.0    0.059963  0.534351  0.379902\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5         1.00  1.000000e-04    0.1    0.005891  0.908397  0.303304\n",
            "1   5  5         0.10  1.000000e-04    0.1    0.003078  0.977099  0.311200\n",
            "2   5  5         0.01  1.000000e-04    0.1    0.002551  0.980916  0.315862\n",
            "3   5  5         0.10  1.000000e-08    0.1    0.001693  0.839695  0.326962\n",
            "4   5  5         0.10  1.000000e-07    0.1    0.001743  0.839695  0.327545\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5         0.01  1.000000e-08    0.1    0.001600  0.057252  0.675398\n",
            "68  5  5         0.10  1.000000e-05    0.1    0.001383  0.103053  0.691859\n",
            "69  5  5         0.01  1.000000e-03    5.0    0.003503  0.064885  0.694715\n",
            "70  5  5         0.01  1.000000e-03    0.1    0.002674  0.038168  0.704708\n",
            "71  5  5         0.01  1.000000e-03    1.0    0.004108  0.053435  0.704941\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"rna\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"atac\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[5],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['Ori_Feature'],\n",
        "    Y_features= res_y['Ori_Feature'],\n",
        "       labels_X=mdata['rna'].obs['celltype'],\n",
        "    labels_Y=mdata['atac'].obs['celltype'],\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d177231c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.121988 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.047333 | OT=0.012861 | Ortho=0.000060 | Graph=34.411757 | lr=5.00e-04 | Acc=0.8855\n",
            "[Iter  1000] total=0.030409 | OT=0.010460 | Ortho=0.000022 | Graph=19.927722 | lr=5.00e-04 | Acc=0.8779\n",
            "[Iter  1500] total=0.024244 | OT=0.007238 | Ortho=0.000013 | Graph=16.992302 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.021527 | OT=0.006442 | Ortho=0.000011 | Graph=15.074067 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.018724 | OT=0.005312 | Ortho=0.000010 | Graph=13.402551 | lr=5.00e-04 | Acc=0.7863\n",
            "[Iter  3000] total=0.014764 | OT=0.002873 | Ortho=0.000007 | Graph=11.884001 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.012873 | OT=0.002280 | Ortho=0.000005 | Graph=10.586986 | lr=5.00e-04 | Acc=0.8626\n",
            "Early stopping at iter=3868 (best@3858 total=0.011889).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.163104 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.042433 | OT=0.012547 | Ortho=0.000087 | Graph=29.799245 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  1000] total=0.024175 | OT=0.006725 | Ortho=0.000024 | Graph=17.426400 | lr=1.00e-03 | Acc=0.9771\n",
            "[Iter  1500] total=0.018381 | OT=0.004011 | Ortho=0.000010 | Graph=14.359112 | lr=1.00e-03 | Acc=0.9084\n",
            "[Iter  2000] total=0.015949 | OT=0.003129 | Ortho=0.000007 | Graph=12.812401 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  2500] total=0.014225 | OT=0.002530 | Ortho=0.000006 | Graph=11.688923 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3000] total=0.012522 | OT=0.001886 | Ortho=0.000005 | Graph=10.631260 | lr=1.00e-03 | Acc=0.8779\n",
            "[Iter  3500] total=0.011199 | OT=0.001505 | Ortho=0.000004 | Graph=9.689593 | lr=1.00e-03 | Acc=0.8779\n",
            "[Iter  4000] total=0.010135 | OT=0.001265 | Ortho=0.000005 | Graph=8.864975 | lr=1.00e-03 | Acc=0.8626\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.164744 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.064569 | OT=0.030940 | Ortho=0.000286 | Graph=33.342544 | lr=5.00e-04 | Acc=0.8321\n",
            "[Iter  1000] total=0.035814 | OT=0.009585 | Ortho=0.000054 | Graph=26.174996 | lr=5.00e-04 | Acc=0.9084\n",
            "[Iter  1500] total=0.024899 | OT=0.006888 | Ortho=0.000028 | Graph=17.982775 | lr=5.00e-04 | Acc=0.9466\n",
            "[Iter  2000] total=0.019617 | OT=0.004497 | Ortho=0.000013 | Graph=15.107548 | lr=5.00e-04 | Acc=0.9160\n",
            "[Iter  2500] total=0.016986 | OT=0.003444 | Ortho=0.000009 | Graph=13.533711 | lr=5.00e-04 | Acc=0.9008\n",
            "[Iter  3000] total=0.015439 | OT=0.002977 | Ortho=0.000007 | Graph=12.455026 | lr=5.00e-04 | Acc=0.9008\n",
            "[Iter  3500] total=0.013938 | OT=0.002405 | Ortho=0.000006 | Graph=11.527753 | lr=5.00e-04 | Acc=0.9008\n",
            "[Iter  4000] total=0.012884 | OT=0.002114 | Ortho=0.000005 | Graph=10.764831 | lr=5.00e-04 | Acc=0.9008\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.027053 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.026365 | OT=0.015893 | Ortho=0.000017 | Graph=104.546259 | lr=2.50e-04 | Acc=0.8244\n",
            "[Iter  1000] total=0.022357 | OT=0.012123 | Ortho=0.000026 | Graph=102.075250 | lr=2.50e-04 | Acc=0.9084\n",
            "[Iter  1500] total=0.019657 | OT=0.010982 | Ortho=0.000023 | Graph=86.519578 | lr=2.50e-04 | Acc=0.9313\n",
            "[Iter  2000] total=0.015424 | OT=0.010699 | Ortho=0.000003 | Graph=47.219597 | lr=2.50e-04 | Acc=0.9237\n",
            "[Iter  2500] total=0.013605 | OT=0.010003 | Ortho=0.000002 | Graph=35.999519 | lr=2.50e-04 | Acc=0.9618\n",
            "[Iter  3000] total=0.012092 | OT=0.008953 | Ortho=0.000001 | Graph=31.369944 | lr=2.50e-04 | Acc=0.9695\n",
            "[Iter  3500] total=0.010485 | OT=0.007768 | Ortho=0.000001 | Graph=27.156803 | lr=2.50e-04 | Acc=0.9924\n",
            "[Iter  4000] total=0.008767 | OT=0.006154 | Ortho=0.000001 | Graph=26.122914 | lr=2.50e-04 | Acc=0.9924\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.068169 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.053222 | OT=0.042614 | Ortho=0.000221 | Graph=103.876391 | lr=2.50e-04 | Acc=0.7328\n",
            "[Iter  1000] total=0.034648 | OT=0.024774 | Ortho=0.000185 | Graph=96.887312 | lr=2.50e-04 | Acc=0.7710\n",
            "[Iter  1500] total=0.017618 | OT=0.009335 | Ortho=0.000024 | Graph=82.582172 | lr=2.50e-04 | Acc=0.8473\n",
            "[Iter  2000] total=0.013814 | OT=0.007558 | Ortho=0.000010 | Graph=62.454012 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.011145 | OT=0.006025 | Ortho=0.000007 | Graph=51.129227 | lr=2.50e-04 | Acc=0.8092\n",
            "[Iter  3000] total=0.008897 | OT=0.004564 | Ortho=0.000004 | Graph=43.294695 | lr=2.50e-04 | Acc=0.8092\n",
            "[Iter  3500] total=0.006698 | OT=0.003459 | Ortho=0.000002 | Graph=32.366276 | lr=2.50e-04 | Acc=0.8321\n",
            "[Iter  4000] total=0.005486 | OT=0.002673 | Ortho=0.000001 | Graph=28.111511 | lr=2.50e-04 | Acc=0.8244\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.069808 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.057137 | OT=0.046437 | Ortho=0.000237 | Graph=104.626096 | lr=1.25e-04 | Acc=0.7328\n",
            "[Iter  1000] total=0.051205 | OT=0.040713 | Ortho=0.000228 | Graph=102.638643 | lr=1.25e-04 | Acc=0.7405\n",
            "[Iter  1500] total=0.038238 | OT=0.028313 | Ortho=0.000200 | Graph=97.245551 | lr=1.25e-04 | Acc=0.7634\n",
            "[Iter  2000] total=0.020654 | OT=0.011715 | Ortho=0.000039 | Graph=88.993723 | lr=1.25e-04 | Acc=0.8321\n",
            "[Iter  2500] total=0.016287 | OT=0.008631 | Ortho=0.000020 | Graph=76.363602 | lr=1.25e-04 | Acc=0.8397\n",
            "[Iter  3000] total=0.013432 | OT=0.007260 | Ortho=0.000010 | Graph=61.619470 | lr=1.25e-04 | Acc=0.8168\n",
            "[Iter  3500] total=0.011396 | OT=0.005966 | Ortho=0.000007 | Graph=54.228606 | lr=1.25e-04 | Acc=0.8015\n",
            "[Iter  4000] total=0.009338 | OT=0.004753 | Ortho=0.000005 | Graph=45.794382 | lr=1.25e-04 | Acc=0.8015\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017559 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=139 (best@139 total=0.017507).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058675 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.050785).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060315 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.052303).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016610 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=148 (best@148 total=0.016563).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057726 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.049843).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059365 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.051350).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016515 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.016304 | OT=0.016292 | Ortho=0.000002 | Graph=105.406744 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  1000] total=0.015882 | OT=0.015869 | Ortho=0.000002 | Graph=105.274638 | lr=1.25e-04 | Acc=0.7710\n",
            "[Iter  1500] total=0.014488 | OT=0.014469 | Ortho=0.000008 | Graph=104.945654 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  2000] total=0.013357 | OT=0.013338 | Ortho=0.000009 | Graph=103.996180 | lr=1.25e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.012029 | OT=0.012009 | Ortho=0.000009 | Graph=101.876048 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.007849 | OT=0.007834 | Ortho=0.000005 | Graph=101.000086 | lr=1.25e-04 | Acc=0.8626\n",
            "[Iter  3500] total=0.006407 | OT=0.006393 | Ortho=0.000004 | Graph=100.718280 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005607 | OT=0.005594 | Ortho=0.000003 | Graph=98.871778 | lr=1.25e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057631 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.049748).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059270 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.051256).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.016295 | OT=0.016292 | Ortho=0.000002 | Graph=105.407151 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  1000] total=0.015872 | OT=0.015869 | Ortho=0.000002 | Graph=105.275377 | lr=1.25e-04 | Acc=0.7710\n",
            "[Iter  1500] total=0.014478 | OT=0.014469 | Ortho=0.000008 | Graph=104.946929 | lr=1.25e-04 | Acc=0.7939\n",
            "[Iter  2000] total=0.013347 | OT=0.013338 | Ortho=0.000009 | Graph=103.998232 | lr=1.25e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.012018 | OT=0.012008 | Ortho=0.000009 | Graph=101.878740 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  3000] total=0.007836 | OT=0.007830 | Ortho=0.000005 | Graph=101.008135 | lr=1.25e-04 | Acc=0.8626\n",
            "[Iter  3500] total=0.006398 | OT=0.006393 | Ortho=0.000004 | Graph=100.728250 | lr=1.25e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.005598 | OT=0.005594 | Ortho=0.000003 | Graph=98.889538 | lr=1.25e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@58 total=0.049740).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=100 (best@30 total=0.051246).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.121988 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.018951 | OT=0.005009 | Ortho=0.001051 | Graph=13.837478 | lr=1.00e-03 | Acc=0.8626\n",
            "[Iter  1000] total=0.011099 | OT=0.001991 | Ortho=0.000387 | Graph=9.069470 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1500] total=0.008862 | OT=0.001633 | Ortho=0.000256 | Graph=7.203384 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.007296 | OT=0.001313 | Ortho=0.000193 | Graph=5.963564 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  2500] total=0.005933 | OT=0.001062 | Ortho=0.000159 | Graph=4.854965 | lr=1.00e-03 | Acc=0.7176\n",
            "Early stopping at iter=2974 (best@2964 total=0.005047).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.163104 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.028762 | OT=0.007574 | Ortho=0.004440 | Graph=20.744066 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.016629 | OT=0.003338 | Ortho=0.000843 | Graph=13.207142 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  1500] total=0.013726 | OT=0.002325 | Ortho=0.000536 | Graph=11.346966 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2000] total=0.012253 | OT=0.002022 | Ortho=0.000434 | Graph=10.187830 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.011104 | OT=0.001849 | Ortho=0.000369 | Graph=9.217501 | lr=5.00e-04 | Acc=0.8702\n",
            "[Iter  3000] total=0.009822 | OT=0.001585 | Ortho=0.000305 | Graph=8.206676 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  3500] total=0.008484 | OT=0.001362 | Ortho=0.000250 | Graph=7.096317 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  4000] total=0.007005 | OT=0.001068 | Ortho=0.000181 | Graph=5.919420 | lr=5.00e-04 | Acc=0.8702\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.164744 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.030303 | OT=0.008441 | Ortho=0.004698 | Graph=21.392013 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.017070 | OT=0.003554 | Ortho=0.000862 | Graph=13.430040 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.014095 | OT=0.002574 | Ortho=0.000536 | Graph=11.467321 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.012633 | OT=0.002246 | Ortho=0.000454 | Graph=10.341342 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.011117 | OT=0.001874 | Ortho=0.000372 | Graph=9.205773 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  3000] total=0.009866 | OT=0.001607 | Ortho=0.000311 | Graph=8.228264 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  3500] total=0.008457 | OT=0.001272 | Ortho=0.000247 | Graph=7.160178 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  4000] total=0.007041 | OT=0.001046 | Ortho=0.000180 | Graph=5.977182 | lr=5.00e-04 | Acc=0.8473\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.027053 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.010097 | OT=0.007438 | Ortho=0.000116 | Graph=26.473044 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.006225 | OT=0.004197 | Ortho=0.000041 | Graph=20.241429 | lr=1.00e-03 | Acc=1.0000\n",
            "[Iter  1500] total=0.005041 | OT=0.003338 | Ortho=0.000023 | Graph=17.004519 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  2000] total=0.004005 | OT=0.002556 | Ortho=0.000026 | Graph=14.464090 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  2500] total=0.003445 | OT=0.002143 | Ortho=0.000066 | Graph=12.958124 | lr=1.00e-03 | Acc=0.9924\n",
            "Early stopping at iter=2966 (best@2956 total=0.002951).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.068169 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007382 | OT=0.003943 | Ortho=0.000301 | Graph=34.091680 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.003987 | OT=0.001745 | Ortho=0.000067 | Graph=22.357062 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1500] total=0.003106 | OT=0.001165 | Ortho=0.000031 | Graph=19.381863 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.002637 | OT=0.000913 | Ortho=0.000021 | Graph=17.212927 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=2439 (best@2429 total=0.002365).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.069808 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007392 | OT=0.003814 | Ortho=0.000294 | Graph=35.487276 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  1000] total=0.004047 | OT=0.001762 | Ortho=0.000071 | Graph=22.774807 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.003000 | OT=0.001092 | Ortho=0.000031 | Graph=19.051670 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2000] total=0.002581 | OT=0.000880 | Ortho=0.000021 | Graph=16.992375 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  2500] total=0.002268 | OT=0.000717 | Ortho=0.000013 | Graph=15.493146 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.002106 | OT=0.000628 | Ortho=0.000011 | Graph=14.763119 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  3500] total=0.001965 | OT=0.000565 | Ortho=0.000010 | Graph=13.996198 | lr=5.00e-04 | Acc=0.8015\n",
            "[Iter  4000] total=0.001834 | OT=0.000515 | Ortho=0.000009 | Graph=13.183576 | lr=5.00e-04 | Acc=0.8168\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017559 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.012332 | OT=0.011264 | Ortho=0.000486 | Graph=101.957830 | lr=5.00e-04 | Acc=0.6412\n",
            "[Iter  1000] total=0.008420 | OT=0.007682 | Ortho=0.000041 | Graph=73.377124 | lr=5.00e-04 | Acc=0.4198\n",
            "[Iter  1500] total=0.007015 | OT=0.006457 | Ortho=0.000029 | Graph=55.505288 | lr=5.00e-04 | Acc=0.0229\n",
            "[Iter  2000] total=0.003001 | OT=0.002649 | Ortho=0.000013 | Graph=35.128456 | lr=5.00e-04 | Acc=0.0840\n",
            "[Iter  2500] total=0.002063 | OT=0.001719 | Ortho=0.000008 | Graph=34.370739 | lr=5.00e-04 | Acc=0.0305\n",
            "[Iter  3000] total=0.001520 | OT=0.001199 | Ortho=0.000004 | Graph=32.031754 | lr=5.00e-04 | Acc=0.0458\n",
            "[Iter  3500] total=0.001262 | OT=0.000974 | Ortho=0.000002 | Graph=28.788251 | lr=5.00e-04 | Acc=0.0687\n",
            "Early stopping at iter=3747 (best@3737 total=0.001179).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058675 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004140 | OT=0.003413 | Ortho=0.000132 | Graph=71.362272 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.002240 | OT=0.001625 | Ortho=0.000039 | Graph=61.205261 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1500] total=0.001631 | OT=0.001071 | Ortho=0.000015 | Graph=55.802713 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=1705 (best@1695 total=0.001499).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060315 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007695 | OT=0.006725 | Ortho=0.000616 | Graph=90.810695 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  1000] total=0.003299 | OT=0.002631 | Ortho=0.000092 | Graph=65.845723 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  1500] total=0.002385 | OT=0.001781 | Ortho=0.000044 | Graph=59.945457 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2000] total=0.001946 | OT=0.001377 | Ortho=0.000022 | Graph=56.660369 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.001632 | OT=0.001100 | Ortho=0.000011 | Graph=53.059678 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3000] total=0.001398 | OT=0.000917 | Ortho=0.000006 | Graph=48.019028 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  3500] total=0.001246 | OT=0.000817 | Ortho=0.000003 | Graph=42.845674 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=3790 (best@3780 total=0.001167).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016610 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.011735 | OT=0.011583 | Ortho=0.000488 | Graph=103.373758 | lr=5.00e-04 | Acc=0.6412\n",
            "[Iter  1000] total=0.008652 | OT=0.008552 | Ortho=0.000024 | Graph=97.282096 | lr=5.00e-04 | Acc=0.5649\n",
            "[Iter  1500] total=0.006799 | OT=0.006712 | Ortho=0.000024 | Graph=84.691558 | lr=5.00e-04 | Acc=0.5191\n",
            "[Iter  2000] total=0.001975 | OT=0.001922 | Ortho=0.000017 | Graph=51.610301 | lr=5.00e-04 | Acc=0.0458\n",
            "[Iter  2500] total=0.001371 | OT=0.001327 | Ortho=0.000003 | Graph=44.122581 | lr=5.00e-04 | Acc=0.0611\n",
            "[Iter  3000] total=0.001148 | OT=0.001107 | Ortho=0.000002 | Graph=41.018828 | lr=5.00e-04 | Acc=0.0534\n",
            "[Iter  3500] total=0.001013 | OT=0.000974 | Ortho=0.000001 | Graph=38.445364 | lr=5.00e-04 | Acc=0.0458\n",
            "Early stopping at iter=3514 (best@3504 total=0.001012).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057726 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003606 | OT=0.003518 | Ortho=0.000127 | Graph=75.145787 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001754 | OT=0.001684 | Ortho=0.000034 | Graph=66.171143 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001170 | OT=0.001107 | Ortho=0.000010 | Graph=61.880247 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1886 (best@1876 total=0.000956).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059365 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006937 | OT=0.006785 | Ortho=0.000593 | Graph=92.804416 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.002811 | OT=0.002732 | Ortho=0.000085 | Graph=69.885853 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1500] total=0.001864 | OT=0.001795 | Ortho=0.000041 | Graph=64.243940 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.001479 | OT=0.001415 | Ortho=0.000020 | Graph=61.886073 | lr=5.00e-04 | Acc=0.8168\n",
            "[Iter  2500] total=0.001211 | OT=0.001151 | Ortho=0.000010 | Graph=59.411540 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2831 (best@2821 total=0.001095).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016515 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006028 | OT=0.005984 | Ortho=0.000340 | Graph=101.229825 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.003554 | OT=0.003541 | Ortho=0.000044 | Graph=86.526461 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.002746 | OT=0.002735 | Ortho=0.000030 | Graph=77.635995 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.002276 | OT=0.002268 | Ortho=0.000015 | Graph=70.986280 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.001901 | OT=0.001893 | Ortho=0.000015 | Graph=61.163129 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=2721 (best@2711 total=0.001770).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057631 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003651 | OT=0.003629 | Ortho=0.000143 | Graph=77.299638 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001697 | OT=0.001686 | Ortho=0.000044 | Graph=66.948703 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001149 | OT=0.001141 | Ortho=0.000013 | Graph=63.505008 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1637 (best@1627 total=0.001065).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059270 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006865 | OT=0.006797 | Ortho=0.000590 | Graph=93.002703 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.002839 | OT=0.002824 | Ortho=0.000080 | Graph=71.404238 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1500] total=0.001886 | OT=0.001876 | Ortho=0.000036 | Graph=65.568493 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.001508 | OT=0.001499 | Ortho=0.000019 | Graph=63.231670 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.001214 | OT=0.001207 | Ortho=0.000010 | Graph=60.837595 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2619 (best@2609 total=0.001165).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006019 | OT=0.005984 | Ortho=0.000340 | Graph=101.241553 | lr=5.00e-04 | Acc=0.8473\n",
            "[Iter  1000] total=0.003547 | OT=0.003542 | Ortho=0.000044 | Graph=86.616450 | lr=5.00e-04 | Acc=0.8397\n",
            "[Iter  1500] total=0.002740 | OT=0.002736 | Ortho=0.000030 | Graph=77.742959 | lr=5.00e-04 | Acc=0.8550\n",
            "[Iter  2000] total=0.002271 | OT=0.002269 | Ortho=0.000015 | Graph=71.130780 | lr=5.00e-04 | Acc=0.8626\n",
            "[Iter  2500] total=0.001896 | OT=0.001894 | Ortho=0.000010 | Graph=61.351463 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=2733 (best@2723 total=0.001759).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003645 | OT=0.003630 | Ortho=0.000143 | Graph=77.335423 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001689 | OT=0.001684 | Ortho=0.000044 | Graph=67.010632 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001145 | OT=0.001143 | Ortho=0.000013 | Graph=63.553108 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1619 (best@1609 total=0.001070).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006858 | OT=0.006798 | Ortho=0.000590 | Graph=93.021587 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1000] total=0.002834 | OT=0.002825 | Ortho=0.000080 | Graph=71.447798 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  1500] total=0.001881 | OT=0.001877 | Ortho=0.000036 | Graph=65.611731 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2000] total=0.001503 | OT=0.001500 | Ortho=0.000019 | Graph=63.277744 | lr=5.00e-04 | Acc=0.8092\n",
            "[Iter  2500] total=0.001209 | OT=0.001208 | Ortho=0.000010 | Graph=60.896849 | lr=5.00e-04 | Acc=0.8168\n",
            "Early stopping at iter=2651 (best@2641 total=0.001150).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.121988 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.014581 | OT=0.002748 | Ortho=0.078146 | Graph=11.051610 | lr=1.00e-03 | Acc=0.0382\n",
            "[Iter  1000] total=0.010241 | OT=0.001721 | Ortho=0.036210 | Graph=8.158375 | lr=1.00e-03 | Acc=0.0382\n",
            "[Iter  1500] total=0.008004 | OT=0.001378 | Ortho=0.022618 | Graph=6.399711 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  2000] total=0.006398 | OT=0.001049 | Ortho=0.015422 | Graph=5.194933 | lr=1.00e-03 | Acc=0.0458\n",
            "[Iter  2500] total=0.005246 | OT=0.000863 | Ortho=0.010110 | Graph=4.281812 | lr=1.00e-03 | Acc=0.0458\n",
            "[Iter  3000] total=0.004386 | OT=0.000666 | Ortho=0.006501 | Graph=3.654682 | lr=1.00e-03 | Acc=0.0458\n",
            "[Iter  3500] total=0.003794 | OT=0.000528 | Ortho=0.004774 | Graph=3.218446 | lr=1.00e-03 | Acc=0.0382\n",
            "Early stopping at iter=3961 (best@3951 total=0.003434).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.163104 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.017147 | OT=0.002942 | Ortho=0.113543 | Graph=13.068748 | lr=1.00e-03 | Acc=0.0534\n",
            "[Iter  1000] total=0.012250 | OT=0.001757 | Ortho=0.050293 | Graph=9.989183 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  1500] total=0.009873 | OT=0.001434 | Ortho=0.033423 | Graph=8.104752 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  2000] total=0.008209 | OT=0.001167 | Ortho=0.022723 | Graph=6.815268 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  2500] total=0.007092 | OT=0.000999 | Ortho=0.017444 | Graph=5.918397 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  3000] total=0.005975 | OT=0.000904 | Ortho=0.012948 | Graph=4.940747 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  3500] total=0.004951 | OT=0.000757 | Ortho=0.008917 | Graph=4.104536 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  4000] total=0.004025 | OT=0.000582 | Ortho=0.005771 | Graph=3.385440 | lr=1.00e-03 | Acc=0.0687\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.164744 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.017101 | OT=0.003010 | Ortho=0.109656 | Graph=12.994469 | lr=1.00e-03 | Acc=0.0611\n",
            "[Iter  1000] total=0.012603 | OT=0.001982 | Ortho=0.051525 | Graph=10.106197 | lr=1.00e-03 | Acc=0.0840\n",
            "[Iter  1500] total=0.010078 | OT=0.001526 | Ortho=0.034434 | Graph=8.207418 | lr=1.00e-03 | Acc=0.0840\n",
            "[Iter  2000] total=0.008261 | OT=0.001213 | Ortho=0.024060 | Graph=6.807660 | lr=1.00e-03 | Acc=0.0687\n",
            "[Iter  2500] total=0.006928 | OT=0.000953 | Ortho=0.016995 | Graph=5.805057 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  3000] total=0.005859 | OT=0.000824 | Ortho=0.012728 | Graph=4.907730 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  3500] total=0.004919 | OT=0.000676 | Ortho=0.009296 | Graph=4.149846 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  4000] total=0.004119 | OT=0.000579 | Ortho=0.006064 | Graph=3.478998 | lr=1.00e-03 | Acc=0.0687\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.027053 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.005598 | OT=0.003717 | Ortho=0.003540 | Graph=18.459608 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1000] total=0.003758 | OT=0.002291 | Ortho=0.001548 | Graph=14.514819 | lr=1.00e-03 | Acc=0.9924\n",
            "[Iter  1500] total=0.002932 | OT=0.001688 | Ortho=0.001041 | Graph=12.333770 | lr=1.00e-03 | Acc=0.9771\n",
            "Early stopping at iter=1727 (best@1717 total=0.002588).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.068169 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007022 | OT=0.003072 | Ortho=0.025951 | Graph=36.902180 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004262 | OT=0.001840 | Ortho=0.005531 | Graph=23.672898 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.003185 | OT=0.001275 | Ortho=0.002639 | Graph=18.841318 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.002497 | OT=0.000901 | Ortho=0.001568 | Graph=15.804131 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=2249 (best@2239 total=0.002305).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.069808 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.007115 | OT=0.003311 | Ortho=0.023728 | Graph=35.664882 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.003611 | OT=0.001485 | Ortho=0.003774 | Graph=20.885017 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002656 | OT=0.000902 | Ortho=0.002202 | Graph=17.315960 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  2000] total=0.002173 | OT=0.000706 | Ortho=0.001547 | Graph=14.512424 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=2415 (best@2405 total=0.001900).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017559 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003038 | OT=0.002679 | Ortho=0.002311 | Graph=33.631272 | lr=1.00e-03 | Acc=0.1069\n",
            "[Iter  1000] total=0.001252 | OT=0.000959 | Ortho=0.000385 | Graph=29.001241 | lr=1.00e-03 | Acc=0.0687\n",
            "Early stopping at iter=1320 (best@1310 total=0.001034).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058675 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003736 | OT=0.002897 | Ortho=0.010658 | Graph=73.235666 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1000] total=0.002100 | OT=0.001514 | Ortho=0.002096 | Graph=56.558358 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001540 | OT=0.001081 | Ortho=0.000561 | Graph=45.327487 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  2000] total=0.001178 | OT=0.000822 | Ortho=0.000278 | Graph=35.317096 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=2288 (best@2278 total=0.001049).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060315 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003839 | OT=0.002977 | Ortho=0.011607 | Graph=74.549390 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002213 | OT=0.001602 | Ortho=0.001942 | Graph=59.153640 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1500] total=0.001695 | OT=0.001192 | Ortho=0.000773 | Graph=49.518306 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1957 (best@1947 total=0.001395).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016610 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006328 | OT=0.006230 | Ortho=0.002159 | Graph=76.962521 | lr=1.00e-03 | Acc=0.4580\n",
            "[Iter  1000] total=0.002119 | OT=0.002066 | Ortho=0.000360 | Graph=48.946127 | lr=1.00e-03 | Acc=0.2214\n",
            "Early stopping at iter=1434 (best@1424 total=0.001653).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057726 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003190 | OT=0.003013 | Ortho=0.009930 | Graph=77.735326 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.001722 | OT=0.001640 | Ortho=0.001782 | Graph=64.176719 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001208 | OT=0.001147 | Ortho=0.000481 | Graph=55.959331 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  2000] total=0.000980 | OT=0.000927 | Ortho=0.000252 | Graph=50.260571 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  2500] total=0.000874 | OT=0.000825 | Ortho=0.000138 | Graph=47.449253 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  3000] total=0.000816 | OT=0.000770 | Ortho=0.000109 | Graph=45.683507 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  3500] total=0.000771 | OT=0.000725 | Ortho=0.000086 | Graph=44.249121 | lr=5.00e-04 | Acc=0.7710\n",
            "Early stopping at iter=3642 (best@3632 total=0.000758).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059365 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003276 | OT=0.003091 | Ortho=0.010498 | Graph=79.565911 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001829 | OT=0.001746 | Ortho=0.001555 | Graph=67.385145 | lr=1.00e-03 | Acc=0.7939\n",
            "[Iter  1500] total=0.001389 | OT=0.001322 | Ortho=0.000576 | Graph=61.459418 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1878 (best@1868 total=0.001215).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016515 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006267 | OT=0.006238 | Ortho=0.002100 | Graph=78.607980 | lr=1.00e-03 | Acc=0.5115\n",
            "[Iter  1000] total=0.002312 | OT=0.002304 | Ortho=0.000237 | Graph=47.760892 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  1500] total=0.001709 | OT=0.001704 | Ortho=0.000092 | Graph=43.021908 | lr=1.00e-03 | Acc=0.0687\n",
            "Early stopping at iter=1615 (best@1605 total=0.001648).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057631 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003130 | OT=0.003023 | Ortho=0.009869 | Graph=78.217075 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.001677 | OT=0.001653 | Ortho=0.001780 | Graph=64.920142 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001163 | OT=0.001152 | Ortho=0.000487 | Graph=57.108529 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  2000] total=0.001008 | OT=0.001000 | Ortho=0.000268 | Graph=53.596230 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  2500] total=0.000903 | OT=0.000896 | Ortho=0.000167 | Graph=50.876963 | lr=5.00e-04 | Acc=0.7710\n",
            "[Iter  3000] total=0.000815 | OT=0.000809 | Ortho=0.000123 | Graph=48.564008 | lr=5.00e-04 | Acc=0.7710\n",
            "Early stopping at iter=3059 (best@3049 total=0.000808).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059270 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003217 | OT=0.003105 | Ortho=0.010407 | Graph=80.039786 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001777 | OT=0.001755 | Ortho=0.001523 | Graph=67.973229 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1500] total=0.001351 | OT=0.001339 | Ortho=0.000527 | Graph=62.240361 | lr=1.00e-03 | Acc=0.7863\n",
            "Early stopping at iter=1642 (best@1632 total=0.001278).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.006261 | OT=0.006240 | Ortho=0.002099 | Graph=78.737793 | lr=1.00e-03 | Acc=0.5191\n",
            "[Iter  1000] total=0.002306 | OT=0.002304 | Ortho=0.000248 | Graph=47.758531 | lr=1.00e-03 | Acc=0.0763\n",
            "[Iter  1500] total=0.001738 | OT=0.001737 | Ortho=0.000089 | Graph=43.819470 | lr=1.00e-03 | Acc=0.0687\n",
            "Early stopping at iter=1536 (best@1526 total=0.001723).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003124 | OT=0.003025 | Ortho=0.009868 | Graph=78.271631 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1000] total=0.001673 | OT=0.001654 | Ortho=0.001779 | Graph=64.992918 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001159 | OT=0.001154 | Ortho=0.000482 | Graph=57.235996 | lr=1.00e-03 | Acc=0.7710\n",
            "Early stopping at iter=1526 (best@1516 total=0.001151).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003211 | OT=0.003107 | Ortho=0.010391 | Graph=80.087228 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001770 | OT=0.001754 | Ortho=0.001535 | Graph=68.044145 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1428 (best@1418 total=0.001383).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.121988 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.008555 | OT=0.000188 | Ortho=6.888042 | Graph=1.478962 | lr=1.00e-03 | Acc=0.6031\n",
            "[Iter  1000] total=0.007460 | OT=0.000256 | Ortho=5.326565 | Graph=1.876881 | lr=1.00e-03 | Acc=0.6794\n",
            "[Iter  1500] total=0.006221 | OT=0.000350 | Ortho=3.584344 | Graph=2.286439 | lr=1.00e-03 | Acc=0.5191\n",
            "[Iter  2000] total=0.005302 | OT=0.000371 | Ortho=2.558493 | Graph=2.373220 | lr=1.00e-03 | Acc=0.5191\n",
            "[Iter  2500] total=0.004469 | OT=0.000389 | Ortho=1.342281 | Graph=2.737744 | lr=1.00e-03 | Acc=0.5496\n",
            "[Iter  3000] total=0.003878 | OT=0.000402 | Ortho=0.811510 | Graph=2.664417 | lr=1.00e-03 | Acc=0.6260\n",
            "Early stopping at iter=3344 (best@3334 total=0.003518).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.163104 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.009121 | OT=0.000172 | Ortho=7.672149 | Graph=1.276952 | lr=1.00e-03 | Acc=0.8397\n",
            "[Iter  1000] total=0.008240 | OT=0.000225 | Ortho=6.303535 | Graph=1.711635 | lr=1.00e-03 | Acc=0.8550\n",
            "[Iter  1500] total=0.007418 | OT=0.000226 | Ortho=5.234897 | Graph=1.957486 | lr=1.00e-03 | Acc=0.8702\n",
            "[Iter  2000] total=0.006638 | OT=0.000296 | Ortho=3.937333 | Graph=2.404499 | lr=1.00e-03 | Acc=0.8855\n",
            "[Iter  2500] total=0.005983 | OT=0.000287 | Ortho=3.187937 | Graph=2.508623 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3000] total=0.005110 | OT=0.000334 | Ortho=2.108733 | Graph=2.667180 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3500] total=0.004182 | OT=0.000372 | Ortho=1.026207 | Graph=2.783721 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  4000] total=0.003747 | OT=0.000348 | Ortho=0.711310 | Graph=2.687068 | lr=5.00e-04 | Acc=0.9008\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.164744 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.009093 | OT=0.000156 | Ortho=7.691674 | Graph=1.244964 | lr=1.00e-03 | Acc=0.8550\n",
            "[Iter  1000] total=0.008233 | OT=0.000210 | Ortho=6.433525 | Graph=1.588736 | lr=1.00e-03 | Acc=0.8550\n",
            "[Iter  1500] total=0.007522 | OT=0.000193 | Ortho=5.604857 | Graph=1.724676 | lr=1.00e-03 | Acc=0.8702\n",
            "[Iter  2000] total=0.006611 | OT=0.000275 | Ortho=4.051629 | Graph=2.284414 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  2500] total=0.005917 | OT=0.000306 | Ortho=3.031510 | Graph=2.579838 | lr=1.00e-03 | Acc=0.8931\n",
            "[Iter  3000] total=0.005016 | OT=0.000351 | Ortho=1.721981 | Graph=2.942390 | lr=1.00e-03 | Acc=0.9008\n",
            "[Iter  3500] total=0.004255 | OT=0.000328 | Ortho=1.105196 | Graph=2.822048 | lr=1.00e-03 | Acc=0.9008\n",
            "Early stopping at iter=3592 (best@3582 total=0.004142).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.027053 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004590 | OT=0.001186 | Ortho=2.024707 | Graph=13.786366 | lr=1.00e-03 | Acc=0.5344\n",
            "[Iter  1000] total=0.002255 | OT=0.000713 | Ortho=0.156561 | Graph=13.856884 | lr=1.00e-03 | Acc=0.5649\n",
            "[Iter  1500] total=0.001832 | OT=0.000471 | Ortho=0.103149 | Graph=12.581988 | lr=1.00e-03 | Acc=0.5267\n",
            "Early stopping at iter=1790 (best@1780 total=0.001705).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.068169 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.005931 | OT=0.000560 | Ortho=4.117817 | Graph=12.525456 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004302 | OT=0.000749 | Ortho=2.237579 | Graph=13.153283 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.002483 | OT=0.000736 | Ortho=0.322959 | Graph=14.236559 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1691 (best@1681 total=0.002231).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.069808 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.005943 | OT=0.000558 | Ortho=4.144873 | Graph=12.401379 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.004460 | OT=0.000736 | Ortho=2.427588 | Graph=12.966636 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1500] total=0.002581 | OT=0.000765 | Ortho=0.400985 | Graph=14.145374 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter  2000] total=0.001971 | OT=0.000522 | Ortho=0.155047 | Graph=12.936019 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=2181 (best@2171 total=0.001877).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.017559 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.002363 | OT=0.001632 | Ortho=0.196715 | Graph=53.414009 | lr=1.00e-03 | Acc=0.8626\n",
            "[Iter  1000] total=0.001282 | OT=0.000846 | Ortho=0.059544 | Graph=37.702170 | lr=1.00e-03 | Acc=0.8550\n",
            "Early stopping at iter=1007 (best@997 total=0.001277).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.058675 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004170 | OT=0.001282 | Ortho=2.342167 | Graph=54.578604 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1000] total=0.002802 | OT=0.001405 | Ortho=0.850864 | Graph=54.637775 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1500] total=0.001862 | OT=0.001144 | Ortho=0.201917 | Graph=51.598674 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  2000] total=0.001451 | OT=0.000899 | Ortho=0.086858 | Graph=46.509886 | lr=1.00e-03 | Acc=0.7634\n",
            "Early stopping at iter=2115 (best@2105 total=0.001393).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.060315 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.004262 | OT=0.001371 | Ortho=2.328822 | Graph=56.239539 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1000] total=0.002750 | OT=0.001225 | Ortho=0.997342 | Graph=52.725270 | lr=1.00e-03 | Acc=0.7557\n",
            "[Iter  1500] total=0.001736 | OT=0.001030 | Ortho=0.207540 | Graph=49.917563 | lr=1.00e-03 | Acc=0.7634\n",
            "Early stopping at iter=1852 (best@1842 total=0.001460).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.016610 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.001696 | OT=0.001439 | Ortho=0.188772 | Graph=67.650056 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=988 (best@978 total=0.001049).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.057726 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003733 | OT=0.001449 | Ortho=2.218208 | Graph=65.544648 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002253 | OT=0.001370 | Ortho=0.819306 | Graph=63.648818 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1500] total=0.001368 | OT=0.001148 | Ortho=0.158703 | Graph=61.771434 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1873 (best@1863 total=0.001020).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.059365 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003868 | OT=0.001573 | Ortho=2.228936 | Graph=65.555086 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  1000] total=0.002390 | OT=0.001408 | Ortho=0.918444 | Graph=63.172812 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.001461 | OT=0.001222 | Ortho=0.176373 | Graph=62.935248 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1883 (best@1873 total=0.001119).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.016515 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.001660 | OT=0.001492 | Ortho=0.160423 | Graph=73.493542 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=883 (best@873 total=0.001090).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.057631 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003709 | OT=0.001490 | Ortho=2.212247 | Graph=66.623823 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002188 | OT=0.001350 | Ortho=0.832216 | Graph=63.822012 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.001243 | OT=0.001104 | Ortho=0.132689 | Graph=63.111543 | lr=1.00e-03 | Acc=0.7786\n",
            "Early stopping at iter=1942 (best@1932 total=0.000959).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.059270 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003816 | OT=0.001591 | Ortho=2.218101 | Graph=66.723694 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  1000] total=0.002333 | OT=0.001412 | Ortho=0.914251 | Graph=64.302072 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001419 | OT=0.001214 | Ortho=0.199253 | Graph=63.536391 | lr=1.00e-03 | Acc=0.7557\n",
            "Early stopping at iter=1952 (best@1942 total=0.000993).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.016505 | OT=0.016504 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.001647 | OT=0.001482 | Ortho=0.164080 | Graph=73.199732 | lr=1.00e-03 | Acc=0.8244\n",
            "Early stopping at iter=982 (best@972 total=0.001028).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.057621 | OT=0.057620 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003705 | OT=0.001493 | Ortho=2.211618 | Graph=66.681736 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.002188 | OT=0.001357 | Ortho=0.830287 | Graph=64.017793 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1500] total=0.001240 | OT=0.001107 | Ortho=0.132905 | Graph=63.236630 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  2000] total=0.000937 | OT=0.000889 | Ortho=0.047581 | Graph=61.589517 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  2500] total=0.000867 | OT=0.000829 | Ortho=0.037103 | Graph=60.771597 | lr=5.00e-04 | Acc=0.7786\n",
            "[Iter  3000] total=0.000809 | OT=0.000777 | Ortho=0.030904 | Graph=59.934522 | lr=5.00e-04 | Acc=0.7786\n",
            "Early stopping at iter=3486 (best@3476 total=0.000745).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.059261 | OT=0.059260 | Ortho=0.000000 | Graph=105.483970 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter   500] total=0.003811 | OT=0.001593 | Ortho=2.217265 | Graph=66.840204 | lr=1.00e-03 | Acc=0.7634\n",
            "[Iter  1000] total=0.002328 | OT=0.001413 | Ortho=0.913713 | Graph=64.419770 | lr=1.00e-03 | Acc=0.7786\n",
            "[Iter  1500] total=0.001412 | OT=0.001212 | Ortho=0.199068 | Graph=63.678558 | lr=1.00e-03 | Acc=0.7557\n",
            "Early stopping at iter=1963 (best@1953 total=0.000985).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n",
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        0.100  1.000000e-04    0.1    0.002951  0.984733  0.322067\n",
            "1   5  5        1.000  1.000000e-04    0.1    0.008767  0.973282  0.317668\n",
            "2   5  5        0.010  1.000000e-04    0.1    0.002588  0.969466  0.336985\n",
            "3   5  5        0.001  1.000000e-03    1.0    0.003747  0.950382  0.346192\n",
            "4   5  5        0.001  1.000000e-03    5.0    0.004142  0.950382  0.336373\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        0.100  1.000000e-06    0.1    0.001012  0.061069  0.658615\n",
            "68  5  5        0.010  1.000000e-07    0.1    0.001648  0.057252  0.675223\n",
            "69  5  5        0.010  1.000000e-03    1.0    0.004025  0.049618  0.700658\n",
            "70  5  5        0.010  1.000000e-03    5.0    0.004119  0.049618  0.697250\n",
            "71  5  5        0.010  1.000000e-03    0.1    0.003434  0.026718  0.700658\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5        0.001  1.000000e-08    1.0    0.000745  0.767176  0.363003\n",
            "1   5  5        0.010  1.000000e-06    1.0    0.000758  0.770992  0.360906\n",
            "2   5  5        0.010  1.000000e-07    1.0    0.000808  0.770992  0.361109\n",
            "3   5  5        0.100  1.000000e-06    1.0    0.000956  0.790076  0.367782\n",
            "4   5  5        0.001  1.000000e-07    1.0    0.000959  0.770992  0.366616\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5        1.000  1.000000e-05    1.0    0.050785  0.522901  0.385176\n",
            "68  5  5        1.000  1.000000e-08    5.0    0.051246  0.530534  0.381155\n",
            "69  5  5        1.000  1.000000e-07    5.0    0.051256  0.530534  0.381155\n",
            "70  5  5        1.000  1.000000e-06    5.0    0.051350  0.530534  0.381126\n",
            "71  5  5        1.000  1.000000e-05    5.0    0.052303  0.530534  0.380922\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   5  5         1.00  1.000000e-04    0.1    0.008767  0.973282  0.317668\n",
            "1   5  5         0.10  1.000000e-04    0.1    0.002951  0.984733  0.322067\n",
            "2   5  5         0.10  1.000000e-07    0.1    0.001770  0.839695  0.327487\n",
            "3   5  5         0.10  1.000000e-08    0.1    0.001759  0.839695  0.327749\n",
            "4   5  5         1.00  1.000000e-06    0.1    0.016563  0.824427  0.334683\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  5  5         0.01  1.000000e-05    0.1    0.001034  0.080153  0.677088\n",
            "68  5  5         0.10  1.000000e-05    0.1    0.001179  0.072519  0.681866\n",
            "69  5  5         0.01  1.000000e-03    5.0    0.004119  0.049618  0.697250\n",
            "70  5  5         0.01  1.000000e-03    1.0    0.004025  0.049618  0.700658\n",
            "71  5  5         0.01  1.000000e-03    0.1    0.003434  0.026718  0.700658\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"rna\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"atac\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[5],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "       labels_X=mdata['rna'].obs['celltype'],\n",
        "    labels_Y=mdata['atac'].obs['celltype'],\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f20b855f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.114633 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001823 | OT=0.000022 | Ortho=15.162039 | Graph=0.284461 | lr=1.00e-03 | Acc=0.8015\n",
            "[Iter  1000] total=0.001650 | OT=0.000004 | Ortho=15.529957 | Graph=0.093502 | lr=5.00e-04 | Acc=0.8244\n",
            "[Iter  1500] total=0.001616 | OT=0.000001 | Ortho=15.629987 | Graph=0.051527 | lr=5.00e-04 | Acc=0.8397\n",
            "Early stopping at iter=1868 (best@1868 total=0.001607).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.167557 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.002029 | OT=0.000037 | Ortho=14.874419 | Graph=0.504485 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.001674 | OT=0.000005 | Ortho=15.536303 | Graph=0.115452 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=1106 (best@1096 total=0.001654).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.169579 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.002097 | OT=0.000052 | Ortho=14.770426 | Graph=0.567209 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.001682 | OT=0.000006 | Ortho=15.540468 | Graph=0.122192 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=1202 (best@1192 total=0.001643).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.026822 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001720 | OT=0.000188 | Ortho=13.179656 | Graph=2.142456 | lr=1.00e-03 | Acc=0.8168\n",
            "Early stopping at iter=681 (best@671 total=0.001583).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.079747 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001996 | OT=0.000427 | Ortho=11.146548 | Graph=4.536366 | lr=1.00e-03 | Acc=0.7863\n",
            "[Iter  1000] total=0.001719 | OT=0.000212 | Ortho=12.341738 | Graph=2.725085 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1022 (best@1012 total=0.001716).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.081768 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.002016 | OT=0.000440 | Ortho=11.088256 | Graph=4.667366 | lr=1.00e-03 | Acc=0.7710\n",
            "[Iter  1000] total=0.001724 | OT=0.000218 | Ortho=12.298291 | Graph=2.761288 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=1296 (best@1286 total=0.001669).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.018041 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001626 | OT=0.000726 | Ortho=7.968930 | Graph=10.270093 | lr=1.00e-03 | Acc=0.8321\n",
            "[Iter  1000] total=0.001385 | OT=0.000536 | Ortho=7.393969 | Graph=10.889100 | lr=5.00e-04 | Acc=0.8092\n",
            "Early stopping at iter=1427 (best@1417 total=0.001295).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.070966 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001806 | OT=0.000821 | Ortho=8.548145 | Graph=12.972230 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.001502 | OT=0.000556 | Ortho=8.199463 | Graph=12.628701 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=1031 (best@1021 total=0.001494).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.072987 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001718 | OT=0.000745 | Ortho=8.281478 | Graph=14.502844 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=995 (best@985 total=0.001473).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.017163 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001543 | OT=0.000776 | Ortho=7.489233 | Graph=18.445535 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=543 (best@533 total=0.001521).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.070088 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001646 | OT=0.000733 | Ortho=8.930998 | Graph=20.430353 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=814 (best@804 total=0.001409).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.072109 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001618 | OT=0.000780 | Ortho=8.188347 | Graph=18.559186 | lr=1.00e-03 | Acc=0.8092\n",
            "Early stopping at iter=718 (best@708 total=0.001436).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.017075 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001555 | OT=0.000820 | Ortho=7.333063 | Graph=21.853706 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=645 (best@635 total=0.001467).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.070000 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001636 | OT=0.000746 | Ortho=8.876422 | Graph=21.402305 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=914 (best@904 total=0.001357).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.072022 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001675 | OT=0.000785 | Ortho=8.881883 | Graph=25.677939 | lr=1.00e-03 | Acc=0.8092\n",
            "[Iter  1000] total=0.001413 | OT=0.000622 | Ortho=7.881795 | Graph=25.744134 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1061 (best@1051 total=0.001399).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.017067 | OT=0.017066 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001571 | OT=0.000846 | Ortho=7.249018 | Graph=19.285843 | lr=1.00e-03 | Acc=0.8321\n",
            "Early stopping at iter=614 (best@604 total=0.001497).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.069991 | OT=0.069991 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001635 | OT=0.000748 | Ortho=8.871645 | Graph=21.502019 | lr=1.00e-03 | Acc=0.7939\n",
            "Early stopping at iter=922 (best@912 total=0.001354).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.0001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.072013 | OT=0.072012 | Ortho=0.000000 | Graph=97.566953 | lr=1.00e-03 | Acc=0.8244\n",
            "[Iter   500] total=0.001673 | OT=0.000785 | Ortho=8.879867 | Graph=25.801613 | lr=1.00e-03 | Acc=0.8168\n",
            "[Iter  1000] total=0.001411 | OT=0.000624 | Ortho=7.869981 | Graph=25.991799 | lr=1.00e-03 | Acc=0.8015\n",
            "Early stopping at iter=1223 (best@1213 total=0.001371).\n",
            "\n",
            "Grid search complete. Saved 18 runs to alignment_tuning_results.pkl\n",
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5       0.0001  1.000000e-03    0.1    0.001607  0.866412  0.388031\n",
            "1   8  5       0.0001  1.000000e-03    1.0    0.001654  0.858779  0.362829\n",
            "2   8  5       0.0001  1.000000e-03    5.0    0.001643  0.858779  0.354146\n",
            "3   8  5       0.0001  1.000000e-04    0.1    0.001583  0.851145  0.371773\n",
            "4   8  5       0.0001  1.000000e-06    0.1    0.001521  0.832061  0.373317\n",
            "5   8  5       0.0001  1.000000e-08    0.1    0.001497  0.812977  0.371365\n",
            "6   8  5       0.0001  1.000000e-05    5.0    0.001473  0.809160  0.371132\n",
            "7   8  5       0.0001  1.000000e-05    0.1    0.001295  0.805344  0.361313\n",
            "8   8  5       0.0001  1.000000e-07    0.1    0.001467  0.805344  0.380689\n",
            "9   8  5       0.0001  1.000000e-08    5.0    0.001371  0.793893  0.357380\n",
            "10  8  5       0.0001  1.000000e-07    5.0    0.001399  0.790076  0.355486\n",
            "11  8  5       0.0001  1.000000e-07    1.0    0.001357  0.782443  0.364081\n",
            "12  8  5       0.0001  1.000000e-08    1.0    0.001354  0.782443  0.363877\n",
            "13  8  5       0.0001  1.000000e-06    1.0    0.001409  0.778626  0.365189\n",
            "14  8  5       0.0001  1.000000e-06    5.0    0.001436  0.774809  0.356419\n",
            "15  8  5       0.0001  1.000000e-05    1.0    0.001494  0.763359  0.367490\n",
            "16  8  5       0.0001  1.000000e-04    1.0    0.001716  0.744275  0.416875\n",
            "17  8  5       0.0001  1.000000e-04    5.0    0.001669  0.725191  0.419352\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5       0.0001  1.000000e-05    0.1    0.001295  0.805344  0.361313\n",
            "1   8  5       0.0001  1.000000e-08    1.0    0.001354  0.782443  0.363877\n",
            "2   8  5       0.0001  1.000000e-07    1.0    0.001357  0.782443  0.364081\n",
            "3   8  5       0.0001  1.000000e-08    5.0    0.001371  0.793893  0.357380\n",
            "4   8  5       0.0001  1.000000e-07    5.0    0.001399  0.790076  0.355486\n",
            "5   8  5       0.0001  1.000000e-06    1.0    0.001409  0.778626  0.365189\n",
            "6   8  5       0.0001  1.000000e-06    5.0    0.001436  0.774809  0.356419\n",
            "7   8  5       0.0001  1.000000e-07    0.1    0.001467  0.805344  0.380689\n",
            "8   8  5       0.0001  1.000000e-05    5.0    0.001473  0.809160  0.371132\n",
            "9   8  5       0.0001  1.000000e-05    1.0    0.001494  0.763359  0.367490\n",
            "10  8  5       0.0001  1.000000e-08    0.1    0.001497  0.812977  0.371365\n",
            "11  8  5       0.0001  1.000000e-06    0.1    0.001521  0.832061  0.373317\n",
            "12  8  5       0.0001  1.000000e-04    0.1    0.001583  0.851145  0.371773\n",
            "13  8  5       0.0001  1.000000e-03    0.1    0.001607  0.866412  0.388031\n",
            "14  8  5       0.0001  1.000000e-03    5.0    0.001643  0.858779  0.354146\n",
            "15  8  5       0.0001  1.000000e-03    1.0    0.001654  0.858779  0.362829\n",
            "16  8  5       0.0001  1.000000e-04    5.0    0.001669  0.725191  0.419352\n",
            "17  8  5       0.0001  1.000000e-04    1.0    0.001716  0.744275  0.416875\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5       0.0001  1.000000e-03    5.0    0.001643  0.858779  0.354146\n",
            "1   8  5       0.0001  1.000000e-07    5.0    0.001399  0.790076  0.355486\n",
            "2   8  5       0.0001  1.000000e-06    5.0    0.001436  0.774809  0.356419\n",
            "3   8  5       0.0001  1.000000e-08    5.0    0.001371  0.793893  0.357380\n",
            "4   8  5       0.0001  1.000000e-05    0.1    0.001295  0.805344  0.361313\n",
            "5   8  5       0.0001  1.000000e-03    1.0    0.001654  0.858779  0.362829\n",
            "6   8  5       0.0001  1.000000e-08    1.0    0.001354  0.782443  0.363877\n",
            "7   8  5       0.0001  1.000000e-07    1.0    0.001357  0.782443  0.364081\n",
            "8   8  5       0.0001  1.000000e-06    1.0    0.001409  0.778626  0.365189\n",
            "9   8  5       0.0001  1.000000e-05    1.0    0.001494  0.763359  0.367490\n",
            "10  8  5       0.0001  1.000000e-05    5.0    0.001473  0.809160  0.371132\n",
            "11  8  5       0.0001  1.000000e-08    0.1    0.001497  0.812977  0.371365\n",
            "12  8  5       0.0001  1.000000e-04    0.1    0.001583  0.851145  0.371773\n",
            "13  8  5       0.0001  1.000000e-06    0.1    0.001521  0.832061  0.373317\n",
            "14  8  5       0.0001  1.000000e-07    0.1    0.001467  0.805344  0.380689\n",
            "15  8  5       0.0001  1.000000e-03    0.1    0.001607  0.866412  0.388031\n",
            "16  8  5       0.0001  1.000000e-04    1.0    0.001716  0.744275  0.416875\n",
            "17  8  5       0.0001  1.000000e-04    5.0    0.001669  0.725191  0.419352\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"rna\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "    mdata.mod[\"atac\"].obsm[\"X_pca\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1e-4],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['Ori_Feature'],\n",
        "    Y_features= res_y['Ori_Feature'],\n",
        "       labels_X=mdata['rna'].obs['celltype'],\n",
        "    labels_Y=mdata['atac'].obs['celltype'],\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b206533",
      "metadata": {},
      "source": [
        "# snare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "HuAeA7GIYjp5",
      "metadata": {
        "id": "HuAeA7GIYjp5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "X = np.load(\"/Users/aaaaaaaron/Desktop/GROTIA/SNAREseq_rna_feat.npy\")\n",
        "y = np.load(\"/Users/aaaaaaaron/Desktop/GROTIA/SNAREseq_atac_feat.npy\")\n",
        "cellTypes_X = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/SNAREseq_rna_types.txt\", dtype=str)\n",
        "cellTypes_y = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/SNAREseq_atac_types.txt\", dtype=str)\n",
        "\n",
        "X_normalized = normalize(X, norm='l2')\n",
        "y_normalized = normalize(y, norm='l2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "73GTkAjMY4nE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73GTkAjMY4nE",
        "outputId": "05ff04c8-6117-4673-c73a-aed4d6fb2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.125115 | OT=0.010549 | Ortho=0.000247 | Graph=114.318960 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  1000] total=0.124432 | OT=0.010422 | Ortho=0.000246 | Graph=113.764147 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1500] total=0.123333 | OT=0.010355 | Ortho=0.000244 | Graph=112.734409 | lr=6.25e-05 | Acc=0.9895\n",
            "[Iter  2000] total=0.121299 | OT=0.010295 | Ortho=0.000240 | Graph=110.765045 | lr=6.25e-05 | Acc=0.9904\n",
            "[Iter  2500] total=0.117042 | OT=0.010174 | Ortho=0.000232 | Graph=106.636060 | lr=6.25e-05 | Acc=0.9895\n",
            "[Iter  3000] total=0.107838 | OT=0.009861 | Ortho=0.000212 | Graph=97.765204 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  3500] total=0.095063 | OT=0.009289 | Ortho=0.000175 | Graph=85.598514 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  4000] total=0.083298 | OT=0.008709 | Ortho=0.000147 | Graph=74.441872 | lr=6.25e-05 | Acc=0.9828\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.140262 | OT=0.025805 | Ortho=0.000326 | Graph=114.131066 | lr=1.25e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.138759 | OT=0.025303 | Ortho=0.000322 | Graph=113.134014 | lr=1.25e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.135617 | OT=0.024463 | Ortho=0.000315 | Graph=110.839198 | lr=1.25e-04 | Acc=0.9847\n",
            "[Iter  2000] total=0.127952 | OT=0.022710 | Ortho=0.000297 | Graph=104.944376 | lr=1.25e-04 | Acc=0.9847\n",
            "[Iter  2500] total=0.110491 | OT=0.018742 | Ortho=0.000248 | Graph=91.500889 | lr=1.25e-04 | Acc=0.9838\n",
            "[Iter  3000] total=0.093057 | OT=0.014702 | Ortho=0.000192 | Graph=78.163516 | lr=1.25e-04 | Acc=0.9809\n",
            "[Iter  3500] total=0.077866 | OT=0.011869 | Ortho=0.000154 | Graph=65.842904 | lr=1.25e-04 | Acc=0.9780\n",
            "Early stopping at iter=3838 (best@3828 total=0.066658).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.140651 | OT=0.026206 | Ortho=0.000329 | Graph=114.116681 | lr=1.25e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.139092 | OT=0.025673 | Ortho=0.000325 | Graph=113.093891 | lr=1.25e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.135875 | OT=0.024806 | Ortho=0.000318 | Graph=110.751525 | lr=1.25e-04 | Acc=0.9847\n",
            "[Iter  2000] total=0.127918 | OT=0.022919 | Ortho=0.000301 | Graph=104.698923 | lr=1.25e-04 | Acc=0.9828\n",
            "[Iter  2500] total=0.109462 | OT=0.018603 | Ortho=0.000245 | Graph=90.613958 | lr=1.25e-04 | Acc=0.9847\n",
            "[Iter  3000] total=0.093361 | OT=0.014893 | Ortho=0.000192 | Graph=78.276240 | lr=1.25e-04 | Acc=0.9809\n",
            "[Iter  3500] total=0.079107 | OT=0.012105 | Ortho=0.000165 | Graph=66.836738 | lr=1.25e-04 | Acc=0.9799\n",
            "[Iter  4000] total=0.063480 | OT=0.009041 | Ortho=0.000112 | Graph=54.327163 | lr=1.25e-04 | Acc=0.9847\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=100 (best@1 total=0.022963).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.037328 | OT=0.025801 | Ortho=0.000033 | Graph=114.940654 | lr=1.25e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.036854 | OT=0.025334 | Ortho=0.000033 | Graph=114.867699 | lr=1.25e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.036176 | OT=0.024676 | Ortho=0.000033 | Graph=114.670010 | lr=1.25e-04 | Acc=0.9866\n",
            "[Iter  2000] total=0.035284 | OT=0.023831 | Ortho=0.000032 | Graph=114.202174 | lr=1.25e-04 | Acc=0.9828\n",
            "[Iter  2500] total=0.033996 | OT=0.022651 | Ortho=0.000031 | Graph=113.145158 | lr=1.25e-04 | Acc=0.9828\n",
            "Early stopping at iter=2931 (best@2921 total=0.032394).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.037945 | OT=0.026415 | Ortho=0.000034 | Graph=114.959948 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.037631 | OT=0.026102 | Ortho=0.000035 | Graph=114.938941 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.037292 | OT=0.025768 | Ortho=0.000035 | Graph=114.888280 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2000] total=0.036837 | OT=0.025325 | Ortho=0.000035 | Graph=114.774803 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2500] total=0.036232 | OT=0.024744 | Ortho=0.000034 | Graph=114.535518 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3000] total=0.035433 | OT=0.023994 | Ortho=0.000033 | Graph=114.060352 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.034259 | OT=0.022916 | Ortho=0.000032 | Graph=113.104156 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  4000] total=0.032328 | OT=0.021177 | Ortho=0.000029 | Graph=111.224914 | lr=6.25e-05 | Acc=0.9857\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=100 (best@1 total=0.012604).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.027161 | OT=0.025987 | Ortho=0.000024 | Graph=114.997933 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.026888 | OT=0.025713 | Ortho=0.000024 | Graph=115.002673 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.026582 | OT=0.025408 | Ortho=0.000025 | Graph=114.994513 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.026189 | OT=0.025014 | Ortho=0.000025 | Graph=114.956010 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.025651 | OT=0.024479 | Ortho=0.000024 | Graph=114.845989 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.024994 | OT=0.023825 | Ortho=0.000023 | Graph=114.603311 | lr=6.25e-05 | Acc=0.9838\n",
            "[Iter  3500] total=0.024147 | OT=0.022984 | Ortho=0.000022 | Graph=114.115220 | lr=6.25e-05 | Acc=0.9838\n",
            "[Iter  4000] total=0.022950 | OT=0.021798 | Ortho=0.000020 | Graph=113.176381 | lr=6.25e-05 | Acc=0.9838\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.027566 | OT=0.026391 | Ortho=0.000025 | Graph=115.012764 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.027256 | OT=0.026080 | Ortho=0.000026 | Graph=115.015641 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.026930 | OT=0.025753 | Ortho=0.000026 | Graph=115.003438 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.026498 | OT=0.025322 | Ortho=0.000026 | Graph=114.954452 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.025912 | OT=0.024738 | Ortho=0.000025 | Graph=114.816594 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.025186 | OT=0.024016 | Ortho=0.000025 | Graph=114.516981 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.024247 | OT=0.023084 | Ortho=0.000024 | Graph=113.936616 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  4000] total=0.022839 | OT=0.021689 | Ortho=0.000022 | Graph=112.833036 | lr=6.25e-05 | Acc=0.9847\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=100 (best@1 total=0.011568).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.026122 | OT=0.025984 | Ortho=0.000023 | Graph=114.997427 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.025853 | OT=0.025714 | Ortho=0.000024 | Graph=115.003971 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.025551 | OT=0.025412 | Ortho=0.000024 | Graph=114.999442 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.025163 | OT=0.025024 | Ortho=0.000024 | Graph=114.966576 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.024633 | OT=0.024494 | Ortho=0.000023 | Graph=114.866632 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.023991 | OT=0.023854 | Ortho=0.000023 | Graph=114.641157 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.023161 | OT=0.023025 | Ortho=0.000022 | Graph=114.184626 | lr=6.25e-05 | Acc=0.9838\n",
            "[Iter  4000] total=0.021989 | OT=0.021856 | Ortho=0.000020 | Graph=113.307100 | lr=6.25e-05 | Acc=0.9838\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.026534 | OT=0.026394 | Ortho=0.000025 | Graph=115.018218 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.026225 | OT=0.026084 | Ortho=0.000025 | Graph=115.022847 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.025900 | OT=0.025760 | Ortho=0.000026 | Graph=115.013162 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.025468 | OT=0.025328 | Ortho=0.000026 | Graph=114.967398 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.024882 | OT=0.024742 | Ortho=0.000025 | Graph=114.833550 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.024154 | OT=0.024015 | Ortho=0.000024 | Graph=114.537875 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.023213 | OT=0.023076 | Ortho=0.000023 | Graph=113.961351 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  4000] total=0.021825 | OT=0.021691 | Ortho=0.000021 | Graph=112.893233 | lr=6.25e-05 | Acc=0.9847\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=100 (best@1 total=0.011464).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.026023 | OT=0.025988 | Ortho=0.000023 | Graph=114.999068 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.025754 | OT=0.025719 | Ortho=0.000024 | Graph=115.006347 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.025453 | OT=0.025418 | Ortho=0.000024 | Graph=115.003202 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.025067 | OT=0.025032 | Ortho=0.000024 | Graph=114.972822 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.024540 | OT=0.024505 | Ortho=0.000023 | Graph=114.877240 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.023903 | OT=0.023869 | Ortho=0.000023 | Graph=114.659005 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.023078 | OT=0.023045 | Ortho=0.000022 | Graph=114.215349 | lr=6.25e-05 | Acc=0.9838\n",
            "[Iter  4000] total=0.021919 | OT=0.021888 | Ortho=0.000020 | Graph=113.362497 | lr=6.25e-05 | Acc=0.9838\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.026430 | OT=0.026394 | Ortho=0.000025 | Graph=115.019725 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.026121 | OT=0.026084 | Ortho=0.000025 | Graph=115.024597 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.025797 | OT=0.025760 | Ortho=0.000025 | Graph=115.015246 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.025365 | OT=0.025328 | Ortho=0.000026 | Graph=114.969955 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.024779 | OT=0.024743 | Ortho=0.000025 | Graph=114.836881 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.024052 | OT=0.024017 | Ortho=0.000024 | Graph=114.542609 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.023113 | OT=0.023078 | Ortho=0.000023 | Graph=113.968927 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  4000] total=0.021729 | OT=0.021696 | Ortho=0.000021 | Graph=112.907191 | lr=6.25e-05 | Acc=0.9847\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=100 (best@1 total=0.011454).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.026012 | OT=0.025988 | Ortho=0.000023 | Graph=114.999107 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.025744 | OT=0.025719 | Ortho=0.000024 | Graph=115.006408 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.025443 | OT=0.025418 | Ortho=0.000024 | Graph=115.003293 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.025057 | OT=0.025032 | Ortho=0.000024 | Graph=114.972954 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.024530 | OT=0.024505 | Ortho=0.000023 | Graph=114.877423 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.023892 | OT=0.023869 | Ortho=0.000023 | Graph=114.659259 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.023068 | OT=0.023045 | Ortho=0.000022 | Graph=114.215726 | lr=6.25e-05 | Acc=0.9838\n",
            "[Iter  4000] total=0.021909 | OT=0.021888 | Ortho=0.000020 | Graph=113.363085 | lr=6.25e-05 | Acc=0.9838\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.026420 | OT=0.026394 | Ortho=0.000025 | Graph=115.019790 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.026111 | OT=0.026084 | Ortho=0.000025 | Graph=115.024690 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.025786 | OT=0.025760 | Ortho=0.000025 | Graph=115.015381 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2000] total=0.025354 | OT=0.025328 | Ortho=0.000026 | Graph=114.970152 | lr=6.25e-05 | Acc=0.9866\n",
            "[Iter  2500] total=0.024769 | OT=0.024743 | Ortho=0.000025 | Graph=114.837172 | lr=6.25e-05 | Acc=0.9857\n",
            "[Iter  3000] total=0.024042 | OT=0.024017 | Ortho=0.000024 | Graph=114.543049 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.023102 | OT=0.023078 | Ortho=0.000023 | Graph=113.969620 | lr=6.25e-05 | Acc=0.9847\n",
            "[Iter  4000] total=0.021719 | OT=0.021697 | Ortho=0.000021 | Graph=112.908786 | lr=6.25e-05 | Acc=0.9847\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.067581 | OT=0.007674 | Ortho=0.010975 | Graph=58.809072 | lr=5.00e-04 | Acc=0.9780\n",
            "[Iter  1000] total=0.032296 | OT=0.004320 | Ortho=0.003448 | Graph=27.630966 | lr=5.00e-04 | Acc=0.9857\n",
            "[Iter  1500] total=0.022934 | OT=0.003467 | Ortho=0.001156 | Graph=19.351316 | lr=5.00e-04 | Acc=0.9389\n",
            "[Iter  2000] total=0.017629 | OT=0.001934 | Ortho=0.000572 | Graph=15.637529 | lr=5.00e-04 | Acc=0.9417\n",
            "Early stopping at iter=2259 (best@2249 total=0.016701).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.084083 | OT=0.013174 | Ortho=0.017438 | Graph=69.165057 | lr=5.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.037832 | OT=0.005344 | Ortho=0.004147 | Graph=32.073450 | lr=5.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.024047 | OT=0.003302 | Ortho=0.001380 | Graph=20.606626 | lr=5.00e-04 | Acc=0.9494\n",
            "[Iter  2000] total=0.019966 | OT=0.002587 | Ortho=0.000739 | Graph=17.304931 | lr=5.00e-04 | Acc=0.9293\n",
            "[Iter  2500] total=0.017954 | OT=0.002061 | Ortho=0.000595 | Graph=15.833798 | lr=5.00e-04 | Acc=0.9226\n",
            "Early stopping at iter=2761 (best@2751 total=0.017028).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.082168 | OT=0.012628 | Ortho=0.016818 | Graph=67.857483 | lr=5.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.037524 | OT=0.005216 | Ortho=0.004237 | Graph=31.884186 | lr=5.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.024610 | OT=0.003378 | Ortho=0.001415 | Graph=21.089956 | lr=5.00e-04 | Acc=0.9436\n",
            "[Iter  2000] total=0.019382 | OT=0.002211 | Ortho=0.000705 | Graph=17.100300 | lr=5.00e-04 | Acc=0.9322\n",
            "[Iter  2500] total=0.017614 | OT=0.001868 | Ortho=0.000556 | Graph=15.689680 | lr=5.00e-04 | Acc=0.9293\n",
            "Early stopping at iter=2786 (best@2776 total=0.016762).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.021714 | OT=0.010242 | Ortho=0.000586 | Graph=114.130671 | lr=1.25e-04 | Acc=0.9885\n",
            "[Iter  1000] total=0.021403 | OT=0.010012 | Ortho=0.000594 | Graph=113.311672 | lr=1.25e-04 | Acc=0.9866\n",
            "[Iter  1500] total=0.020757 | OT=0.009590 | Ortho=0.000599 | Graph=111.074067 | lr=1.25e-04 | Acc=0.9857\n",
            "[Iter  2000] total=0.019103 | OT=0.008610 | Ortho=0.000511 | Graph=104.421870 | lr=1.25e-04 | Acc=0.9876\n",
            "[Iter  2500] total=0.016903 | OT=0.007431 | Ortho=0.000400 | Graph=94.322799 | lr=1.25e-04 | Acc=0.9866\n",
            "[Iter  3000] total=0.014458 | OT=0.006254 | Ortho=0.000348 | Graph=81.699733 | lr=1.25e-04 | Acc=0.9847\n",
            "[Iter  3500] total=0.012207 | OT=0.005116 | Ortho=0.000294 | Graph=70.612903 | lr=1.25e-04 | Acc=0.9857\n",
            "[Iter  4000] total=0.010055 | OT=0.004073 | Ortho=0.000265 | Graph=59.552250 | lr=1.25e-04 | Acc=0.9838\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.034098 | OT=0.022553 | Ortho=0.002789 | Graph=112.655869 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.025173 | OT=0.014886 | Ortho=0.001576 | Graph=101.299695 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.017120 | OT=0.008860 | Ortho=0.000843 | Graph=81.762949 | lr=2.50e-04 | Acc=0.9828\n",
            "[Iter  2000] total=0.013068 | OT=0.006126 | Ortho=0.000418 | Graph=69.007231 | lr=2.50e-04 | Acc=0.9876\n",
            "Early stopping at iter=2186 (best@2176 total=0.012173).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.034701 | OT=0.023112 | Ortho=0.002939 | Graph=112.949785 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.026121 | OT=0.015632 | Ortho=0.001787 | Graph=103.102725 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.018419 | OT=0.009786 | Ortho=0.000924 | Graph=85.407768 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  2000] total=0.013891 | OT=0.006572 | Ortho=0.000507 | Graph=72.679289 | lr=2.50e-04 | Acc=0.9838\n",
            "Early stopping at iter=2176 (best@2166 total=0.012899).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.011491 | OT=0.010321 | Ortho=0.000213 | Graph=114.819175 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1000] total=0.011396 | OT=0.010227 | Ortho=0.000216 | Graph=114.779270 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.011263 | OT=0.010094 | Ortho=0.000222 | Graph=114.682910 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2000] total=0.011081 | OT=0.009914 | Ortho=0.000227 | Graph=114.439955 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  2500] total=0.010795 | OT=0.009634 | Ortho=0.000216 | Graph=113.854558 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  3000] total=0.010334 | OT=0.009195 | Ortho=0.000145 | Graph=112.501047 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  3500] total=0.009652 | OT=0.008546 | Ortho=0.000096 | Graph=109.595497 | lr=6.25e-05 | Acc=0.9895\n",
            "[Iter  4000] total=0.008853 | OT=0.007793 | Ortho=0.000077 | Graph=105.144084 | lr=6.25e-05 | Acc=0.9866\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.024311 | OT=0.022978 | Ortho=0.001952 | Graph=113.845247 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.017725 | OT=0.016533 | Ortho=0.001144 | Graph=107.737630 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.011928 | OT=0.010937 | Ortho=0.000414 | Graph=94.946564 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  2000] total=0.008277 | OT=0.007435 | Ortho=0.000191 | Graph=82.301530 | lr=2.50e-04 | Acc=0.9809\n",
            "Early stopping at iter=2154 (best@2144 total=0.007513).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.024514 | OT=0.023173 | Ortho=0.002036 | Graph=113.738769 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.017349 | OT=0.016152 | Ortho=0.001241 | Graph=107.210908 | lr=2.50e-04 | Acc=0.9857\n",
            "[Iter  1500] total=0.011689 | OT=0.010702 | Ortho=0.000384 | Graph=94.857227 | lr=2.50e-04 | Acc=0.9828\n",
            "[Iter  2000] total=0.008618 | OT=0.007757 | Ortho=0.000208 | Graph=84.059434 | lr=2.50e-04 | Acc=0.9819\n",
            "Early stopping at iter=2249 (best@2239 total=0.007458).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.010456 | OT=0.010322 | Ortho=0.000197 | Graph=114.879629 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1000] total=0.010362 | OT=0.010227 | Ortho=0.000199 | Graph=114.858869 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1500] total=0.010230 | OT=0.010095 | Ortho=0.000207 | Graph=114.792044 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2000] total=0.010053 | OT=0.009918 | Ortho=0.000211 | Graph=114.596999 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2500] total=0.009781 | OT=0.009647 | Ortho=0.000201 | Graph=114.102131 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  3000] total=0.009355 | OT=0.009229 | Ortho=0.000133 | Graph=112.951653 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  3500] total=0.008733 | OT=0.008615 | Ortho=0.000080 | Graph=110.460166 | lr=6.25e-05 | Acc=0.9895\n",
            "[Iter  4000] total=0.007999 | OT=0.007886 | Ortho=0.000062 | Graph=106.471300 | lr=6.25e-05 | Acc=0.9876\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023360 | OT=0.023056 | Ortho=0.001905 | Graph=113.983807 | lr=2.50e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.017161 | OT=0.016937 | Ortho=0.001145 | Graph=108.671902 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.011637 | OT=0.011498 | Ortho=0.000420 | Graph=96.792832 | lr=2.50e-04 | Acc=0.9819\n",
            "[Iter  2000] total=0.007942 | OT=0.007839 | Ortho=0.000190 | Graph=84.247546 | lr=2.50e-04 | Acc=0.9780\n",
            "Early stopping at iter=2304 (best@2294 total=0.006574).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023529 | OT=0.023217 | Ortho=0.001984 | Graph=113.836277 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.016602 | OT=0.016373 | Ortho=0.001212 | Graph=107.632993 | lr=2.50e-04 | Acc=0.9866\n",
            "[Iter  1500] total=0.011076 | OT=0.010942 | Ortho=0.000384 | Graph=95.565855 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  2000] total=0.008150 | OT=0.008042 | Ortho=0.000234 | Graph=85.237241 | lr=2.50e-04 | Acc=0.9828\n",
            "Early stopping at iter=2124 (best@2114 total=0.007523).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.010353 | OT=0.010322 | Ortho=0.000196 | Graph=114.885222 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1000] total=0.010258 | OT=0.010227 | Ortho=0.000197 | Graph=114.866229 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1500] total=0.010127 | OT=0.010095 | Ortho=0.000206 | Graph=114.801396 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2000] total=0.009950 | OT=0.009917 | Ortho=0.000211 | Graph=114.609357 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2500] total=0.009678 | OT=0.009647 | Ortho=0.000200 | Graph=114.117142 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  3000] total=0.009252 | OT=0.009227 | Ortho=0.000131 | Graph=112.968116 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  3500] total=0.008631 | OT=0.008612 | Ortho=0.000079 | Graph=110.482019 | lr=6.25e-05 | Acc=0.9895\n",
            "[Iter  4000] total=0.007900 | OT=0.007884 | Ortho=0.000061 | Graph=106.532448 | lr=6.25e-05 | Acc=0.9876\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023251 | OT=0.023050 | Ortho=0.001893 | Graph=113.981919 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.017028 | OT=0.016902 | Ortho=0.001145 | Graph=108.627601 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.011445 | OT=0.011393 | Ortho=0.000421 | Graph=96.748910 | lr=2.50e-04 | Acc=0.9819\n",
            "[Iter  2000] total=0.007835 | OT=0.007808 | Ortho=0.000179 | Graph=84.220460 | lr=2.50e-04 | Acc=0.9799\n",
            "Early stopping at iter=2254 (best@2244 total=0.006658).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023439 | OT=0.023230 | Ortho=0.001978 | Graph=113.852004 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.016549 | OT=0.016417 | Ortho=0.001209 | Graph=107.719547 | lr=2.50e-04 | Acc=0.9866\n",
            "[Iter  1500] total=0.011027 | OT=0.010980 | Ortho=0.000382 | Graph=95.739117 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  2000] total=0.008089 | OT=0.008058 | Ortho=0.000231 | Graph=85.376172 | lr=2.50e-04 | Acc=0.9828\n",
            "Early stopping at iter=2303 (best@2293 total=0.006627).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.010342 | OT=0.010322 | Ortho=0.000196 | Graph=114.885601 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1000] total=0.010248 | OT=0.010227 | Ortho=0.000197 | Graph=114.866705 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  1500] total=0.010116 | OT=0.010094 | Ortho=0.000206 | Graph=114.801826 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2000] total=0.009939 | OT=0.009917 | Ortho=0.000211 | Graph=114.609489 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  2500] total=0.009667 | OT=0.009646 | Ortho=0.000200 | Graph=114.116060 | lr=6.25e-05 | Acc=0.9885\n",
            "[Iter  3000] total=0.009240 | OT=0.009226 | Ortho=0.000131 | Graph=112.963549 | lr=6.25e-05 | Acc=0.9876\n",
            "[Iter  3500] total=0.008619 | OT=0.008610 | Ortho=0.000078 | Graph=110.472217 | lr=6.25e-05 | Acc=0.9895\n",
            "[Iter  4000] total=0.007888 | OT=0.007881 | Ortho=0.000060 | Graph=106.523169 | lr=6.25e-05 | Acc=0.9876\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023240 | OT=0.023050 | Ortho=0.001893 | Graph=113.982514 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.017017 | OT=0.016902 | Ortho=0.001145 | Graph=108.628220 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.011436 | OT=0.011392 | Ortho=0.000421 | Graph=96.751699 | lr=2.50e-04 | Acc=0.9819\n",
            "[Iter  2000] total=0.007829 | OT=0.007811 | Ortho=0.000177 | Graph=84.234224 | lr=2.50e-04 | Acc=0.9799\n",
            "Early stopping at iter=2275 (best@2265 total=0.006579).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023429 | OT=0.023230 | Ortho=0.001978 | Graph=113.852946 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.016537 | OT=0.016416 | Ortho=0.001206 | Graph=107.722560 | lr=2.50e-04 | Acc=0.9866\n",
            "[Iter  1500] total=0.011020 | OT=0.010981 | Ortho=0.000382 | Graph=95.748210 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  2000] total=0.008085 | OT=0.008064 | Ortho=0.000199 | Graph=85.386461 | lr=2.50e-04 | Acc=0.9828\n",
            "Early stopping at iter=2291 (best@2281 total=0.006677).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=409 (best@399 total=0.019131).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.025053 | OT=0.002882 | Ortho=0.184688 | Graph=20.324788 | lr=1.00e-03 | Acc=0.3047\n",
            "Early stopping at iter=681 (best@671 total=0.019587).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.023789 | OT=0.002847 | Ortho=0.165913 | Graph=19.282626 | lr=1.00e-03 | Acc=0.3190\n",
            "Early stopping at iter=687 (best@677 total=0.019389).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.012984 | OT=0.005426 | Ortho=0.033045 | Graph=72.279261 | lr=5.00e-04 | Acc=0.9790\n",
            "Early stopping at iter=894 (best@884 total=0.007060).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.020315 | OT=0.010694 | Ortho=0.106774 | Graph=85.533529 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.010727 | OT=0.004597 | Ortho=0.031874 | Graph=58.120707 | lr=5.00e-04 | Acc=0.9809\n",
            "[Iter  1500] total=0.006505 | OT=0.002792 | Ortho=0.010822 | Graph=36.046900 | lr=5.00e-04 | Acc=0.9761\n",
            "Early stopping at iter=1843 (best@1833 total=0.005417).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.020397 | OT=0.010690 | Ortho=0.117089 | Graph=85.361103 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.010906 | OT=0.004847 | Ortho=0.031829 | Graph=57.410696 | lr=5.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.006560 | OT=0.002734 | Ortho=0.011120 | Graph=37.146620 | lr=5.00e-04 | Acc=0.9799\n",
            "Early stopping at iter=1598 (best@1588 total=0.006167).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.009749 | OT=0.008541 | Ortho=0.012131 | Graph=108.725654 | lr=2.50e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.006593 | OT=0.005657 | Ortho=0.006461 | Graph=87.176244 | lr=2.50e-04 | Acc=0.9838\n",
            "Early stopping at iter=1348 (best@1338 total=0.004920).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.013151 | OT=0.011633 | Ortho=0.057789 | Graph=94.025441 | lr=5.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.006208 | OT=0.005406 | Ortho=0.009554 | Graph=70.636207 | lr=5.00e-04 | Acc=0.9828\n",
            "Early stopping at iter=1361 (best@1351 total=0.004533).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.015027 | OT=0.013307 | Ortho=0.074939 | Graph=97.083522 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.006565 | OT=0.005728 | Ortho=0.013071 | Graph=70.653638 | lr=5.00e-04 | Acc=0.9857\n",
            "[Iter  1500] total=0.004474 | OT=0.003841 | Ortho=0.004642 | Graph=58.620939 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  2000] total=0.003894 | OT=0.003321 | Ortho=0.003424 | Graph=53.852846 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  2500] total=0.003252 | OT=0.002743 | Ortho=0.002293 | Graph=48.682369 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  3000] total=0.002762 | OT=0.002311 | Ortho=0.001708 | Graph=43.476746 | lr=2.50e-04 | Acc=0.9866\n",
            "Early stopping at iter=3144 (best@3134 total=0.002660).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008849 | OT=0.008633 | Ortho=0.010606 | Graph=109.891277 | lr=2.50e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.006101 | OT=0.005962 | Ortho=0.004714 | Graph=92.093358 | lr=2.50e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.004000 | OT=0.003895 | Ortho=0.003112 | Graph=73.688591 | lr=2.50e-04 | Acc=0.9828\n",
            "Early stopping at iter=1848 (best@1838 total=0.003131).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.012031 | OT=0.011444 | Ortho=0.049283 | Graph=93.778879 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.005613 | OT=0.005452 | Ortho=0.008980 | Graph=72.170445 | lr=5.00e-04 | Acc=0.9828\n",
            "Early stopping at iter=1207 (best@1197 total=0.004596).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.014249 | OT=0.013439 | Ortho=0.071190 | Graph=98.096956 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.006042 | OT=0.005852 | Ortho=0.011803 | Graph=72.263456 | lr=5.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=1397 (best@1387 total=0.004275).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008758 | OT=0.008642 | Ortho=0.010457 | Graph=110.003106 | lr=2.50e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.006047 | OT=0.005992 | Ortho=0.004577 | Graph=92.573527 | lr=2.50e-04 | Acc=0.9847\n",
            "Early stopping at iter=1461 (best@1451 total=0.004122).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.011892 | OT=0.011409 | Ortho=0.047336 | Graph=93.696294 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.005504 | OT=0.005414 | Ortho=0.008283 | Graph=72.381616 | lr=5.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=1211 (best@1201 total=0.004539).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.014213 | OT=0.013482 | Ortho=0.072032 | Graph=98.192029 | lr=5.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.005887 | OT=0.005772 | Ortho=0.010804 | Graph=71.828001 | lr=5.00e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.004037 | OT=0.003991 | Ortho=0.003928 | Graph=62.299222 | lr=5.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=1561 (best@1551 total=0.003919).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008750 | OT=0.008644 | Ortho=0.010447 | Graph=110.019333 | lr=2.50e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.006043 | OT=0.005996 | Ortho=0.004637 | Graph=92.813865 | lr=2.50e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.003953 | OT=0.003921 | Ortho=0.003181 | Graph=75.074121 | lr=2.50e-04 | Acc=0.9857\n",
            "Early stopping at iter=1580 (best@1570 total=0.003754).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.011884 | OT=0.011410 | Ortho=0.047299 | Graph=93.702348 | lr=5.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.005503 | OT=0.005418 | Ortho=0.008385 | Graph=72.354910 | lr=5.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=1338 (best@1328 total=0.004120).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.014205 | OT=0.013484 | Ortho=0.071996 | Graph=98.200339 | lr=5.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.005880 | OT=0.005771 | Ortho=0.010798 | Graph=71.829116 | lr=5.00e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.004030 | OT=0.003991 | Ortho=0.003888 | Graph=62.253420 | lr=5.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=1559 (best@1549 total=0.003915).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=187 (best@177 total=0.015893).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=469 (best@459 total=0.015210).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=463 (best@453 total=0.015369).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "Early stopping at iter=234 (best@224 total=0.012243).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.012248 | OT=0.001420 | Ortho=8.109005 | Graph=27.188694 | lr=1.00e-03 | Acc=0.7545\n",
            "Early stopping at iter=890 (best@880 total=0.008508).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.010952 | OT=0.001561 | Ortho=6.839930 | Graph=25.510695 | lr=1.00e-03 | Acc=0.9675\n",
            "Early stopping at iter=715 (best@705 total=0.009049).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.005923 | OT=0.004696 | Ortho=0.546063 | Graph=68.149858 | lr=5.00e-04 | Acc=0.1929\n",
            "Early stopping at iter=665 (best@655 total=0.004890).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008918 | OT=0.002884 | Ortho=5.525171 | Graph=50.904115 | lr=1.00e-03 | Acc=0.9675\n",
            "Early stopping at iter=934 (best@924 total=0.004448).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.009156 | OT=0.002878 | Ortho=5.778193 | Graph=49.934522 | lr=1.00e-03 | Acc=0.9723\n",
            "Early stopping at iter=965 (best@955 total=0.004424).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.005293 | OT=0.004421 | Ortho=0.799547 | Graph=72.595344 | lr=5.00e-04 | Acc=0.7650\n",
            "Early stopping at iter=594 (best@584 total=0.004801).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008402 | OT=0.002987 | Ortho=5.361737 | Graph=53.226078 | lr=1.00e-03 | Acc=0.9656\n",
            "Early stopping at iter=939 (best@929 total=0.003986).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008827 | OT=0.003101 | Ortho=5.673774 | Graph=52.820797 | lr=1.00e-03 | Acc=0.9733\n",
            "Early stopping at iter=957 (best@947 total=0.004306).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.005155 | OT=0.004516 | Ortho=0.631100 | Graph=76.720209 | lr=5.00e-04 | Acc=0.8090\n",
            "Early stopping at iter=598 (best@588 total=0.004625).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008361 | OT=0.003002 | Ortho=5.353714 | Graph=53.494129 | lr=1.00e-03 | Acc=0.9666\n",
            "Early stopping at iter=942 (best@932 total=0.003940).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008794 | OT=0.003147 | Ortho=5.641657 | Graph=53.294813 | lr=1.00e-03 | Acc=0.9752\n",
            "Early stopping at iter=951 (best@941 total=0.004181).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.005175 | OT=0.004514 | Ortho=0.660197 | Graph=76.793411 | lr=5.00e-04 | Acc=0.7994\n",
            "Early stopping at iter=581 (best@571 total=0.004719).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008356 | OT=0.003003 | Ortho=5.353031 | Graph=53.517801 | lr=1.00e-03 | Acc=0.9666\n",
            "Early stopping at iter=942 (best@932 total=0.003935).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-03 | Acc=0.9819\n",
            "[Iter   500] total=0.008802 | OT=0.003154 | Ortho=5.648045 | Graph=53.187552 | lr=1.00e-03 | Acc=0.9733\n",
            "[Iter  1000] total=0.003912 | OT=0.003246 | Ortho=0.665436 | Graph=54.024536 | lr=5.00e-04 | Acc=0.9752\n",
            "[Iter  1500] total=0.003137 | OT=0.002835 | Ortho=0.302363 | Graph=50.803048 | lr=5.00e-04 | Acc=0.9761\n",
            "[Iter  2000] total=0.002598 | OT=0.002399 | Ortho=0.198127 | Graph=46.469830 | lr=5.00e-04 | Acc=0.9761\n",
            "Early stopping at iter=2059 (best@2049 total=0.002545).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    X_normalized\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "  y_normalized\n",
        ")\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "    labels_X=cellTypes_X,\n",
        "    labels_Y=cellTypes_y,\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "yfaZL4XUY6gz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfaZL4XUY6gz",
        "outputId": "a81d4013-3a99-46cc-dd31-b5ec9f0e89a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.100  1.000000e-06    0.1    0.008065  0.987584  0.154345\n",
            "1   8  5        0.100  1.000000e-07    0.1    0.007908  0.987584  0.154355\n",
            "2   8  5        0.100  1.000000e-08    0.1    0.007889  0.987584  0.154375\n",
            "3   8  5        0.100  1.000000e-05    0.1    0.009481  0.986628  0.153955\n",
            "4   8  5        1.000  1.000000e-04    5.0    0.038942  0.986628  0.150779\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.010  1.000000e-03    5.0    0.028324  0.279847  0.512446\n",
            "68  8  5        0.010  1.000000e-03    1.0    0.027261  0.270296  0.513803\n",
            "69  8  5        0.001  1.000000e-05    0.1    0.005138  0.208214  0.545526\n",
            "70  8  5        0.001  1.000000e-03    5.0    0.015964  0.190067  0.594196\n",
            "71  8  5        0.001  1.000000e-03    1.0    0.015957  0.167144  0.574220\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5         0.01  1.000000e-05    1.0    0.002891  0.975167  0.153613\n",
            "1   8  5         0.01  1.000000e-06    0.1    0.003425  0.978032  0.159026\n",
            "2   8  5         0.01  1.000000e-07    0.1    0.003634  0.978032  0.158314\n",
            "3   8  5         0.01  1.000000e-08    0.1    0.003872  0.985673  0.157494\n",
            "4   8  5         0.01  1.000000e-08    5.0    0.003913  0.979943  0.153205\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5         1.00  1.000000e-04    5.0    0.038942  0.986628  0.150779\n",
            "68  8  5         1.00  1.000000e-04    1.0    0.039291  0.984718  0.151351\n",
            "69  8  5         1.00  1.000000e-03    1.0    0.070598  0.986628  0.147299\n",
            "70  8  5         1.00  1.000000e-03    5.0    0.070833  0.985673  0.147570\n",
            "71  8  5         1.00  1.000000e-03    0.1    0.107640  0.976122  0.146796\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo  lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.100     0.00010    1.0    0.020101  0.983763  0.146385\n",
            "1   8  5        1.000     0.00100    0.1    0.107640  0.976122  0.146796\n",
            "2   8  5        1.000     0.00100    1.0    0.070598  0.986628  0.147299\n",
            "3   8  5        1.000     0.00100    5.0    0.070833  0.985673  0.147570\n",
            "4   8  5        0.100     0.00010    0.1    0.009989  0.983763  0.149825\n",
            ".. .. ..          ...         ...    ...         ...       ...       ...\n",
            "67  8  5        0.010     0.00100    5.0    0.028324  0.279847  0.512446\n",
            "68  8  5        0.010     0.00100    1.0    0.027261  0.270296  0.513803\n",
            "69  8  5        0.001     0.00001    0.1    0.005138  0.208214  0.545526\n",
            "70  8  5        0.001     0.00100    1.0    0.015957  0.167144  0.574220\n",
            "71  8  5        0.001     0.00100    5.0    0.015964  0.190067  0.594196\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "niX3E1q5wbuh",
      "metadata": {
        "id": "niX3E1q5wbuh"
      },
      "source": [
        "# Simulation-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "RtcV00jVyKHR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "RtcV00jVyKHR",
        "outputId": "0f3b8ca2-af35-402e-da38-992eda6be395"
      },
      "outputs": [],
      "source": [
        "X = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s1_mapped1.txt\")\n",
        "y = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001//s1_mapped2.txt\")\n",
        "def zscore_normalization(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    normalized_data = (data - mean) / std\n",
        "    return normalized_data\n",
        "cellTypes_X=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001//s1_label1.txt\")\n",
        "cellTypes_y=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001//s1_label2.txt\")\n",
        "\n",
        "X_normalized = zscore_normalization(X)\n",
        "y_normalized = zscore_normalization(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6vmftYzAwdaX",
      "metadata": {
        "id": "6vmftYzAwdaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.038825 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=153 (best@153 total=0.038704).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.054617 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=140 (best@140 total=0.054481).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.055051 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=144 (best@144 total=0.054914).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.013512 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.013424 | OT=0.010602 | Ortho=0.000010 | Graph=28.115824 | lr=7.81e-06 | Acc=0.9633\n",
            "Early stopping at iter=894 (best@894 total=0.013371).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029304 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=150 (best@150 total=0.029203).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029738 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=148 (best@148 total=0.029636).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.010981 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=100 (best@1 total=0.010981).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.026772 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=165 (best@165 total=0.026676).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.027206 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=170 (best@170 total=0.027108).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010727 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=100 (best@1 total=0.010727).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.026519 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=164 (best@164 total=0.026424).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.026953 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=157 (best@157 total=0.026857).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010702 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=100 (best@1 total=0.010702).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.026494 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=169 (best@169 total=0.026398).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.026928 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=163 (best@163 total=0.026832).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010700 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=100 (best@1 total=0.010700).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.026491 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=169 (best@169 total=0.026395).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.026925 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=163 (best@163 total=0.026829).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.038825 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.036521 | OT=0.009345 | Ortho=0.002150 | Graph=26.961399 | lr=5.00e-04 | Acc=0.9567\n",
            "[Iter  1000] total=0.032727 | OT=0.008821 | Ortho=0.001974 | Graph=23.708909 | lr=5.00e-04 | Acc=0.9400\n",
            "[Iter  1500] total=0.022313 | OT=0.007001 | Ortho=0.001364 | Graph=15.176399 | lr=5.00e-04 | Acc=0.9600\n",
            "[Iter  2000] total=0.014785 | OT=0.003200 | Ortho=0.000555 | Graph=11.529432 | lr=5.00e-04 | Acc=0.9467\n",
            "[Iter  2500] total=0.011520 | OT=0.001856 | Ortho=0.000332 | Graph=9.630171 | lr=5.00e-04 | Acc=0.9533\n",
            "[Iter  3000] total=0.009115 | OT=0.001078 | Ortho=0.000218 | Graph=8.015203 | lr=5.00e-04 | Acc=0.9467\n",
            "[Iter  3500] total=0.007703 | OT=0.000845 | Ortho=0.000141 | Graph=6.844061 | lr=5.00e-04 | Acc=0.9500\n",
            "Early stopping at iter=3888 (best@3878 total=0.006856).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.054617 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.046024 | OT=0.018430 | Ortho=0.005100 | Graph=27.084631 | lr=5.00e-04 | Acc=0.9633\n",
            "[Iter  1000] total=0.028449 | OT=0.002927 | Ortho=0.002056 | Graph=25.316826 | lr=5.00e-04 | Acc=0.9767\n",
            "[Iter  1500] total=0.022648 | OT=0.002410 | Ortho=0.001830 | Graph=20.055655 | lr=5.00e-04 | Acc=0.9767\n",
            "[Iter  2000] total=0.014951 | OT=0.001599 | Ortho=0.000678 | Graph=13.284052 | lr=5.00e-04 | Acc=0.9667\n",
            "[Iter  2500] total=0.011683 | OT=0.001177 | Ortho=0.000386 | Graph=10.467531 | lr=5.00e-04 | Acc=0.9533\n",
            "[Iter  3000] total=0.010022 | OT=0.000970 | Ortho=0.000251 | Graph=9.026472 | lr=5.00e-04 | Acc=0.9600\n",
            "[Iter  3500] total=0.008426 | OT=0.000818 | Ortho=0.000177 | Graph=7.590764 | lr=5.00e-04 | Acc=0.9567\n",
            "[Iter  4000] total=0.007329 | OT=0.000701 | Ortho=0.000130 | Graph=6.615451 | lr=2.50e-04 | Acc=0.9600\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.055051 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.046366 | OT=0.018718 | Ortho=0.005251 | Graph=27.122855 | lr=5.00e-04 | Acc=0.9633\n",
            "[Iter  1000] total=0.028658 | OT=0.002919 | Ortho=0.002469 | Graph=25.492419 | lr=5.00e-04 | Acc=0.9767\n",
            "[Iter  1500] total=0.023093 | OT=0.002409 | Ortho=0.001850 | Graph=20.499052 | lr=5.00e-04 | Acc=0.9700\n",
            "[Iter  2000] total=0.015031 | OT=0.001622 | Ortho=0.000722 | Graph=13.336519 | lr=5.00e-04 | Acc=0.9633\n",
            "[Iter  2500] total=0.011547 | OT=0.001186 | Ortho=0.000394 | Graph=10.322289 | lr=5.00e-04 | Acc=0.9600\n",
            "[Iter  3000] total=0.009706 | OT=0.000965 | Ortho=0.000235 | Graph=8.717948 | lr=5.00e-04 | Acc=0.9533\n",
            "[Iter  3500] total=0.008206 | OT=0.000810 | Ortho=0.000163 | Graph=7.379806 | lr=5.00e-04 | Acc=0.9667\n",
            "Early stopping at iter=3786 (best@3776 total=0.007575).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.013512 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.012390 | OT=0.009571 | Ortho=0.000144 | Graph=28.042160 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1000] total=0.012068 | OT=0.009255 | Ortho=0.000132 | Graph=27.995841 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1500] total=0.011729 | OT=0.008926 | Ortho=0.000123 | Graph=27.902161 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2000] total=0.011103 | OT=0.008315 | Ortho=0.000138 | Graph=27.742429 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2500] total=0.007648 | OT=0.004886 | Ortho=0.000201 | Graph=27.420630 | lr=2.50e-04 | Acc=0.9633\n",
            "Early stopping at iter=2846 (best@2836 total=0.005023).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029304 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=105 (best@95 total=0.028815).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029738 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=105 (best@95 total=0.029224).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.010981 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.009892 | OT=0.009602 | Ortho=0.000098 | Graph=28.096617 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1000] total=0.009591 | OT=0.009301 | Ortho=0.000089 | Graph=28.108590 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1500] total=0.009254 | OT=0.008965 | Ortho=0.000081 | Graph=28.108188 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2000] total=0.008710 | OT=0.008420 | Ortho=0.000090 | Graph=28.051562 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2500] total=0.005937 | OT=0.005646 | Ortho=0.000119 | Graph=27.837491 | lr=2.50e-04 | Acc=0.9667\n",
            "[Iter  3000] total=0.002495 | OT=0.002215 | Ortho=0.000031 | Graph=27.738780 | lr=2.50e-04 | Acc=0.9667\n",
            "Early stopping at iter=3054 (best@3044 total=0.002473).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.026772 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=105 (best@95 total=0.026302).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.027206 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=108 (best@98 total=0.026710).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010727 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.009642 | OT=0.009605 | Ortho=0.000095 | Graph=28.100678 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1000] total=0.009349 | OT=0.009313 | Ortho=0.000086 | Graph=28.116212 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1500] total=0.009014 | OT=0.008978 | Ortho=0.000079 | Graph=28.121968 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2000] total=0.008495 | OT=0.008459 | Ortho=0.000085 | Graph=28.074891 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2500] total=0.006002 | OT=0.005963 | Ortho=0.000116 | Graph=27.879704 | lr=2.50e-04 | Acc=0.9633\n",
            "Early stopping at iter=2960 (best@2950 total=0.002322).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.026519 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=105 (best@95 total=0.026051).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.026953 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=108 (best@98 total=0.026460).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010702 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.009618 | OT=0.009605 | Ortho=0.000095 | Graph=28.100794 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1000] total=0.009325 | OT=0.009313 | Ortho=0.000086 | Graph=28.116642 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1500] total=0.008989 | OT=0.008978 | Ortho=0.000079 | Graph=28.123221 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2000] total=0.008471 | OT=0.008460 | Ortho=0.000085 | Graph=28.077645 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2500] total=0.005984 | OT=0.005970 | Ortho=0.000116 | Graph=27.883574 | lr=2.50e-04 | Acc=0.9633\n",
            "[Iter  3000] total=0.002253 | OT=0.002247 | Ortho=0.000030 | Graph=27.790640 | lr=2.50e-04 | Acc=0.9633\n",
            "Early stopping at iter=3056 (best@3046 total=0.002225).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.026494 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=105 (best@95 total=0.026025).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.026928 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=108 (best@98 total=0.026435).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010700 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.009615 | OT=0.009606 | Ortho=0.000095 | Graph=28.100845 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1000] total=0.009323 | OT=0.009314 | Ortho=0.000086 | Graph=28.116711 | lr=2.50e-04 | Acc=0.9567\n",
            "[Iter  1500] total=0.008987 | OT=0.008979 | Ortho=0.000079 | Graph=28.123360 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2000] total=0.008471 | OT=0.008463 | Ortho=0.000085 | Graph=28.078033 | lr=2.50e-04 | Acc=0.9600\n",
            "[Iter  2500] total=0.006004 | OT=0.005992 | Ortho=0.000116 | Graph=27.885181 | lr=2.50e-04 | Acc=0.9633\n",
            "Early stopping at iter=2988 (best@2978 total=0.002272).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.026491 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=105 (best@95 total=0.026023).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.026925 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=108 (best@98 total=0.026433).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.038825 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.016161 | OT=0.004013 | Ortho=0.069579 | Graph=11.451755 | lr=1.00e-03 | Acc=0.9667\n",
            "[Iter  1000] total=0.009771 | OT=0.001333 | Ortho=0.022308 | Graph=8.214819 | lr=1.00e-03 | Acc=0.9500\n",
            "[Iter  1500] total=0.007949 | OT=0.000931 | Ortho=0.014247 | Graph=6.875513 | lr=5.00e-04 | Acc=0.9500\n",
            "[Iter  2000] total=0.006889 | OT=0.000773 | Ortho=0.011119 | Graph=6.004907 | lr=5.00e-04 | Acc=0.9433\n",
            "[Iter  2500] total=0.005913 | OT=0.000654 | Ortho=0.008393 | Graph=5.175110 | lr=5.00e-04 | Acc=0.9433\n",
            "Early stopping at iter=2681 (best@2671 total=0.005634).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.054617 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.023672 | OT=0.002257 | Ortho=0.187558 | Graph=19.539663 | lr=1.00e-03 | Acc=0.9700\n",
            "[Iter  1000] total=0.011687 | OT=0.001175 | Ortho=0.032335 | Graph=10.188650 | lr=5.00e-04 | Acc=0.9567\n",
            "[Iter  1500] total=0.009864 | OT=0.000953 | Ortho=0.024424 | Graph=8.666700 | lr=5.00e-04 | Acc=0.9633\n",
            "[Iter  2000] total=0.008196 | OT=0.000786 | Ortho=0.015911 | Graph=7.251285 | lr=5.00e-04 | Acc=0.9500\n",
            "Early stopping at iter=2333 (best@2323 total=0.007362).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.055051 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.024478 | OT=0.002336 | Ortho=0.188976 | Graph=20.251529 | lr=1.00e-03 | Acc=0.9700\n",
            "[Iter  1000] total=0.011380 | OT=0.001190 | Ortho=0.030542 | Graph=9.883927 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=1380 (best@1370 total=0.009111).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.013512 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.005017 | OT=0.002253 | Ortho=0.005809 | Graph=27.062153 | lr=1.00e-03 | Acc=0.9700\n",
            "Early stopping at iter=508 (best@498 total=0.005015).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029304 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.005637 | OT=0.002833 | Ortho=0.009055 | Graph=27.134221 | lr=1.00e-03 | Acc=0.9767\n",
            "[Iter  1000] total=0.005476 | OT=0.002705 | Ortho=0.009372 | Graph=26.770928 | lr=5.00e-04 | Acc=0.9767\n",
            "[Iter  1500] total=0.005346 | OT=0.002604 | Ortho=0.008947 | Graph=26.529280 | lr=5.00e-04 | Acc=0.9667\n",
            "Early stopping at iter=1874 (best@1864 total=0.004972).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029738 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.005680 | OT=0.002872 | Ortho=0.009204 | Graph=27.163550 | lr=5.00e-04 | Acc=0.9733\n",
            "[Iter  1000] total=0.005488 | OT=0.002713 | Ortho=0.009293 | Graph=26.822184 | lr=5.00e-04 | Acc=0.9767\n",
            "Early stopping at iter=1311 (best@1301 total=0.005428).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.010981 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002571 | OT=0.002271 | Ortho=0.002359 | Graph=27.625488 | lr=1.00e-03 | Acc=0.9700\n",
            "Early stopping at iter=526 (best@516 total=0.002528).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.026772 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.003208 | OT=0.002883 | Ortho=0.004943 | Graph=27.591905 | lr=1.00e-03 | Acc=0.9733\n",
            "Early stopping at iter=787 (best@777 total=0.003071).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.027206 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=476 (best@466 total=0.003250).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010727 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002328 | OT=0.002277 | Ortho=0.002317 | Graph=27.672439 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=529 (best@519 total=0.002277).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.026519 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002961 | OT=0.002886 | Ortho=0.004700 | Graph=27.635710 | lr=1.00e-03 | Acc=0.9733\n",
            "[Iter  1000] total=0.002820 | OT=0.002744 | Ortho=0.004803 | Graph=27.383323 | lr=5.00e-04 | Acc=0.9767\n",
            "[Iter  1500] total=0.002747 | OT=0.002672 | Ortho=0.004820 | Graph=27.206633 | lr=5.00e-04 | Acc=0.9733\n",
            "Early stopping at iter=1911 (best@1901 total=0.002512).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.026953 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002980 | OT=0.002904 | Ortho=0.004773 | Graph=27.630568 | lr=1.00e-03 | Acc=0.9733\n",
            "Early stopping at iter=538 (best@528 total=0.002962).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010702 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002300 | OT=0.002276 | Ortho=0.002145 | Graph=27.679979 | lr=1.00e-03 | Acc=0.9633\n",
            "Early stopping at iter=533 (best@523 total=0.002241).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.026494 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002936 | OT=0.002886 | Ortho=0.004677 | Graph=27.640230 | lr=1.00e-03 | Acc=0.9733\n",
            "Early stopping at iter=538 (best@528 total=0.002917).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.026928 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002955 | OT=0.002905 | Ortho=0.004750 | Graph=27.634545 | lr=1.00e-03 | Acc=0.9700\n",
            "Early stopping at iter=547 (best@537 total=0.002932).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010700 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002296 | OT=0.002273 | Ortho=0.002232 | Graph=27.680106 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=530 (best@520 total=0.002244).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.026491 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002933 | OT=0.002886 | Ortho=0.004674 | Graph=27.640664 | lr=1.00e-03 | Acc=0.9733\n",
            "Early stopping at iter=538 (best@528 total=0.002915).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.026925 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002952 | OT=0.002905 | Ortho=0.004747 | Graph=27.634978 | lr=1.00e-03 | Acc=0.9700\n",
            "[Iter  1000] total=0.002803 | OT=0.002756 | Ortho=0.004727 | Graph=27.386315 | lr=5.00e-04 | Acc=0.9767\n",
            "[Iter  1500] total=0.002727 | OT=0.002680 | Ortho=0.004700 | Graph=27.108809 | lr=5.00e-04 | Acc=0.9733\n",
            "[Iter  2000] total=0.002582 | OT=0.002540 | Ortho=0.004180 | Graph=27.098110 | lr=2.50e-04 | Acc=0.9733\n",
            "[Iter  2500] total=0.002418 | OT=0.002376 | Ortho=0.004104 | Graph=26.686401 | lr=2.50e-04 | Acc=0.9733\n",
            "[Iter  3000] total=0.002273 | OT=0.002246 | Ortho=0.002652 | Graph=26.214933 | lr=2.50e-04 | Acc=0.9700\n",
            "Early stopping at iter=3340 (best@3330 total=0.002171).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.038825 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=371 (best@361 total=0.012837).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.054617 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.013073 | OT=0.000467 | Ortho=9.038288 | Graph=3.567825 | lr=1.00e-03 | Acc=0.3000\n",
            "[Iter  1000] total=0.012174 | OT=0.000396 | Ortho=8.520059 | Graph=3.257739 | lr=1.00e-03 | Acc=0.2933\n",
            "[Iter  1500] total=0.009192 | OT=0.000562 | Ortho=4.640804 | Graph=3.989663 | lr=1.00e-03 | Acc=0.2733\n",
            "[Iter  2000] total=0.006574 | OT=0.000593 | Ortho=1.515628 | Graph=4.465254 | lr=1.00e-03 | Acc=0.2867\n",
            "Early stopping at iter=2492 (best@2482 total=0.005410).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.055051 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.013027 | OT=0.000445 | Ortho=9.058669 | Graph=3.523224 | lr=1.00e-03 | Acc=0.3167\n",
            "[Iter  1000] total=0.011949 | OT=0.000418 | Ortho=8.175104 | Graph=3.356238 | lr=1.00e-03 | Acc=0.3000\n",
            "[Iter  1500] total=0.008861 | OT=0.000605 | Ortho=4.015392 | Graph=4.240113 | lr=1.00e-03 | Acc=0.2833\n",
            "[Iter  2000] total=0.006571 | OT=0.000610 | Ortho=1.484204 | Graph=4.477104 | lr=1.00e-03 | Acc=0.2833\n",
            "Early stopping at iter=2214 (best@2204 total=0.006031).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.013512 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=278 (best@268 total=0.006137).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.029304 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.006524 | OT=0.001943 | Ortho=2.628488 | Graph=19.530602 | lr=1.00e-03 | Acc=0.9767\n",
            "Early stopping at iter=620 (best@610 total=0.006285).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.029738 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.006760 | OT=0.001869 | Ortho=3.027658 | Graph=18.639902 | lr=1.00e-03 | Acc=0.9700\n",
            "Early stopping at iter=852 (best@842 total=0.004877).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.010981 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002260 | OT=0.001910 | Ortho=0.091776 | Graph=25.810889 | lr=1.00e-03 | Acc=0.9633\n",
            "Early stopping at iter=529 (best@519 total=0.002249).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.026772 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004653 | OT=0.002265 | Ortho=2.160054 | Graph=22.765005 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=508 (best@498 total=0.004652).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.027206 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004575 | OT=0.002244 | Ortho=2.106338 | Graph=22.432717 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=841 (best@831 total=0.002877).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.010727 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.002028 | OT=0.001927 | Ortho=0.074156 | Graph=26.140877 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=514 (best@504 total=0.002027).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.026519 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004447 | OT=0.002300 | Ortho=2.124114 | Graph=23.128175 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=504 (best@494 total=0.004444).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.026953 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004380 | OT=0.002284 | Ortho=2.073164 | Graph=22.830457 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=851 (best@841 total=0.002674).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.010702 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=468 (best@458 total=0.002053).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.026494 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004431 | OT=0.002303 | Ortho=2.126238 | Graph=23.148106 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=504 (best@494 total=0.004429).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.026928 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004347 | OT=0.002290 | Ortho=2.054335 | Graph=22.905790 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=846 (best@836 total=0.002653).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.010700 | OT=0.010699 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "Early stopping at iter=484 (best@474 total=0.002025).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.026491 | OT=0.026491 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004430 | OT=0.002303 | Ortho=2.126254 | Graph=23.148656 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=504 (best@494 total=0.004427).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.026925 | OT=0.026925 | Ortho=0.000000 | Graph=28.126072 | lr=1.00e-03 | Acc=0.9567\n",
            "[Iter   500] total=0.004345 | OT=0.002292 | Ortho=2.052776 | Graph=22.912406 | lr=1.00e-03 | Acc=0.9667\n",
            "Early stopping at iter=845 (best@835 total=0.002650).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    X_normalized\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "  y_normalized\n",
        ")\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "    labels_X=cellTypes_X,\n",
        "    labels_Y=cellTypes_y,\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fcR56hK38Esd",
      "metadata": {
        "id": "fcR56hK38Esd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-08    5.0    0.002650  0.976667  0.070433\n",
            "1   8  5        0.001  1.000000e-05    5.0    0.002877  0.976667  0.070406\n",
            "2   8  5        0.010  1.000000e-05    1.0    0.003071  0.976667  0.070156\n",
            "3   8  5        0.010  1.000000e-06    1.0    0.002512  0.976667  0.069750\n",
            "4   8  5        0.010  1.000000e-06    5.0    0.002962  0.976667  0.070217\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.010  1.000000e-03    0.1    0.005634  0.946667  0.097078\n",
            "68  8  5        0.010  1.000000e-03    1.0    0.007362  0.943333  0.091094\n",
            "69  8  5        0.001  1.000000e-03    1.0    0.005410  0.300000  0.330533\n",
            "70  8  5        0.001  1.000000e-03    5.0    0.006031  0.286667  0.343967\n",
            "71  8  5        0.001  1.000000e-03    0.1    0.012837  0.253333  0.337472\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-08    0.1    0.002025  0.966667  0.069711\n",
            "1   8  5        0.001  1.000000e-06    0.1    0.002027  0.966667  0.069911\n",
            "2   8  5        0.001  1.000000e-07    0.1    0.002053  0.966667  0.069750\n",
            "3   8  5        0.010  1.000000e-08    5.0    0.002171  0.963333  0.068878\n",
            "4   8  5        0.100  1.000000e-07    0.1    0.002225  0.963333  0.070522\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-04    5.0    0.029224  0.963333  0.079950\n",
            "68  8  5        1.000  1.000000e-04    5.0    0.029636  0.960000  0.080533\n",
            "69  8  5        1.000  1.000000e-03    0.1    0.038704  0.960000  0.080522\n",
            "70  8  5        1.000  1.000000e-03    1.0    0.054481  0.960000  0.080600\n",
            "71  8  5        1.000  1.000000e-03    5.0    0.054914  0.960000  0.080550\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.010  1.000000e-08    5.0    0.002171  0.963333  0.068878\n",
            "1   8  5        0.010  1.000000e-04    1.0    0.004972  0.966667  0.069378\n",
            "2   8  5        0.001  1.000000e-04    0.1    0.006137  0.966667  0.069656\n",
            "3   8  5        0.001  1.000000e-08    0.1    0.002025  0.966667  0.069711\n",
            "4   8  5        0.010  1.000000e-06    1.0    0.002512  0.976667  0.069750\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-03    0.1    0.006856  0.960000  0.094261\n",
            "68  8  5        0.010  1.000000e-03    0.1    0.005634  0.946667  0.097078\n",
            "69  8  5        0.001  1.000000e-03    1.0    0.005410  0.300000  0.330533\n",
            "70  8  5        0.001  1.000000e-03    0.1    0.012837  0.253333  0.337472\n",
            "71  8  5        0.001  1.000000e-03    5.0    0.006031  0.286667  0.343967\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def summarize_results(results):\n",
        "    \"\"\"\n",
        "    Convert the results dict from run_alignment_grid into a pandas DataFrame,\n",
        "    then return three ranked views: by accuracy, by final_loss, and by FOSCTTM.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        rows.append({\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "            \"final_loss\": res.get(\"final_loss\", np.nan),\n",
        "            \"accuracy\": metrics.get(\"accuracy\", np.nan),\n",
        "            \"foscttm\": metrics.get(\"foscttm\", np.nan),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Sortings\n",
        "    by_acc = df.sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
        "    by_loss = df.sort_values(\"final_loss\", ascending=True).reset_index(drop=True)\n",
        "    by_fos = df.sort_values(\"foscttm\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "    return df, by_acc, by_loss, by_fos\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GUVX4eqS8Umz",
      "metadata": {
        "id": "GUVX4eqS8Umz"
      },
      "source": [
        "# sim-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "FHtR1TBz8QH5",
      "metadata": {
        "id": "FHtR1TBz8QH5"
      },
      "outputs": [],
      "source": [
        "X = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s2_mapped1.txt\")\n",
        "y = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s2_mapped2.txt\")\n",
        "X_normalized = zscore_normalization(X)\n",
        "y_normalized = zscore_normalization(y)\n",
        "cellTypes_X=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s2_label1.txt\", dtype=str)\n",
        "cellTypes_y=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s2_label2.txt\", dtype=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "YiaXuYOZ8Wuw",
      "metadata": {
        "id": "YiaXuYOZ8Wuw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.043733 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.042859 | OT=0.001943 | Ortho=0.000034 | Graph=40.881642 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.042476 | OT=0.001859 | Ortho=0.000034 | Graph=40.582949 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.041888 | OT=0.001782 | Ortho=0.000033 | Graph=40.073043 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.040977 | OT=0.001718 | Ortho=0.000032 | Graph=39.227133 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.039525 | OT=0.001665 | Ortho=0.000031 | Graph=37.828838 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  3000] total=0.037312 | OT=0.001603 | Ortho=0.000028 | Graph=35.680507 | lr=1.25e-04 | Acc=0.9933\n",
            "[Iter  3500] total=0.034681 | OT=0.001508 | Ortho=0.000036 | Graph=33.137752 | lr=1.25e-04 | Acc=0.9933\n",
            "[Iter  4000] total=0.032448 | OT=0.001399 | Ortho=0.000023 | Graph=31.026096 | lr=1.25e-04 | Acc=0.9933\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.044277 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.043209 | OT=0.002286 | Ortho=0.000036 | Graph=40.887163 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.042803 | OT=0.002171 | Ortho=0.000035 | Graph=40.596698 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.042220 | OT=0.002081 | Ortho=0.000035 | Graph=40.104622 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.041348 | OT=0.002014 | Ortho=0.000034 | Graph=39.300298 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.039971 | OT=0.001955 | Ortho=0.000032 | Graph=37.983405 | lr=1.25e-04 | Acc=0.9967\n",
            "[Iter  3000] total=0.037820 | OT=0.001870 | Ortho=0.000030 | Graph=35.919309 | lr=1.25e-04 | Acc=0.9967\n",
            "[Iter  3500] total=0.035137 | OT=0.001742 | Ortho=0.000029 | Graph=33.365175 | lr=1.25e-04 | Acc=0.9967\n",
            "[Iter  4000] total=0.032947 | OT=0.001615 | Ortho=0.000074 | Graph=31.258079 | lr=1.25e-04 | Acc=0.9933\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.044290 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.043222 | OT=0.002298 | Ortho=0.000036 | Graph=40.888597 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.042818 | OT=0.002182 | Ortho=0.000035 | Graph=40.600434 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.042239 | OT=0.002091 | Ortho=0.000035 | Graph=40.113397 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.041377 | OT=0.002024 | Ortho=0.000034 | Graph=39.319190 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.040017 | OT=0.001964 | Ortho=0.000033 | Graph=38.020491 | lr=1.25e-04 | Acc=0.9967\n",
            "[Iter  3000] total=0.037885 | OT=0.001878 | Ortho=0.000030 | Graph=35.976506 | lr=1.25e-04 | Acc=0.9967\n",
            "[Iter  3500] total=0.035189 | OT=0.001748 | Ortho=0.000030 | Graph=33.411843 | lr=1.25e-04 | Acc=0.9967\n",
            "[Iter  4000] total=0.032921 | OT=0.001612 | Ortho=0.000025 | Graph=31.283616 | lr=1.25e-04 | Acc=0.9933\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.006744 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.006028 | OT=0.001918 | Ortho=0.000001 | Graph=41.086488 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.005949 | OT=0.001841 | Ortho=0.000001 | Graph=41.060457 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.005877 | OT=0.001774 | Ortho=0.000001 | Graph=41.018562 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.005823 | OT=0.001726 | Ortho=0.000001 | Graph=40.956912 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.005786 | OT=0.001697 | Ortho=0.000001 | Graph=40.868726 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2790 (best@2790 total=0.005771).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.007288 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.006373 | OT=0.002262 | Ortho=0.000003 | Graph=41.082470 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.006266 | OT=0.002157 | Ortho=0.000003 | Graph=41.057268 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.006180 | OT=0.002076 | Ortho=0.000003 | Graph=41.014888 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.006125 | OT=0.002027 | Ortho=0.000003 | Graph=40.951335 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.006088 | OT=0.001999 | Ortho=0.000003 | Graph=40.862876 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2704 (best@2704 total=0.006078).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.007300 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.006384 | OT=0.002274 | Ortho=0.000003 | Graph=41.081812 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.006277 | OT=0.002168 | Ortho=0.000003 | Graph=41.056423 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.006190 | OT=0.002086 | Ortho=0.000003 | Graph=41.014133 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.006134 | OT=0.002036 | Ortho=0.000003 | Graph=40.950876 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.006097 | OT=0.002008 | Ortho=0.000003 | Graph=40.861987 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2630 (best@2620 total=0.006089).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.003045 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002330 | OT=0.001918 | Ortho=0.000001 | Graph=41.093757 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002251 | OT=0.001839 | Ortho=0.000001 | Graph=41.090422 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002184 | OT=0.001772 | Ortho=0.000001 | Graph=41.083086 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002139 | OT=0.001728 | Ortho=0.000001 | Graph=41.070662 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.002112 | OT=0.001701 | Ortho=0.000001 | Graph=41.051414 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2950 (best@2950 total=0.002099).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.003589 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002673 | OT=0.002260 | Ortho=0.000002 | Graph=41.096381 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002571 | OT=0.002158 | Ortho=0.000002 | Graph=41.093931 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002492 | OT=0.002079 | Ortho=0.000002 | Graph=41.087037 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002444 | OT=0.002031 | Ortho=0.000002 | Graph=41.074504 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.002415 | OT=0.002003 | Ortho=0.000002 | Graph=41.056473 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2522 (best@2512 total=0.002415).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.003601 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002685 | OT=0.002272 | Ortho=0.000002 | Graph=41.096019 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002583 | OT=0.002170 | Ortho=0.000002 | Graph=41.092653 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002503 | OT=0.002090 | Ortho=0.000002 | Graph=41.084968 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002454 | OT=0.002041 | Ortho=0.000002 | Graph=41.071690 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.002425 | OT=0.002012 | Ortho=0.000002 | Graph=41.052097 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2827 (best@2817 total=0.002411).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.002675 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001959 | OT=0.001917 | Ortho=0.000001 | Graph=41.094909 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.001880 | OT=0.001838 | Ortho=0.000001 | Graph=41.093915 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.001813 | OT=0.001771 | Ortho=0.000001 | Graph=41.090174 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.001769 | OT=0.001727 | Ortho=0.000001 | Graph=41.082765 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.001743 | OT=0.001701 | Ortho=0.000001 | Graph=41.070310 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2883 (best@2873 total=0.001731).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.003219 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002304 | OT=0.002260 | Ortho=0.000002 | Graph=41.096245 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002202 | OT=0.002159 | Ortho=0.000002 | Graph=41.095726 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002123 | OT=0.002079 | Ortho=0.000002 | Graph=41.091911 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002074 | OT=0.002031 | Ortho=0.000002 | Graph=41.083918 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2426 (best@2426 total=0.002053).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.003231 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002316 | OT=0.002273 | Ortho=0.000002 | Graph=41.097239 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002214 | OT=0.002170 | Ortho=0.000002 | Graph=41.095840 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002133 | OT=0.002090 | Ortho=0.000002 | Graph=41.091295 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002085 | OT=0.002041 | Ortho=0.000002 | Graph=41.082480 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.002056 | OT=0.002013 | Ortho=0.000002 | Graph=41.068963 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2815 (best@2805 total=0.002043).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.002638 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001922 | OT=0.001917 | Ortho=0.000001 | Graph=41.095035 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.001843 | OT=0.001838 | Ortho=0.000001 | Graph=41.094282 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.001776 | OT=0.001771 | Ortho=0.000001 | Graph=41.090926 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.001732 | OT=0.001727 | Ortho=0.000001 | Graph=41.084085 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.001706 | OT=0.001701 | Ortho=0.000001 | Graph=41.072403 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2888 (best@2878 total=0.001694).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.003182 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002267 | OT=0.002260 | Ortho=0.000002 | Graph=41.096323 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002165 | OT=0.002159 | Ortho=0.000002 | Graph=41.096013 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002086 | OT=0.002079 | Ortho=0.000002 | Graph=41.092502 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002038 | OT=0.002031 | Ortho=0.000002 | Graph=41.084934 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2340 (best@2330 total=0.002018).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.003194 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002279 | OT=0.002273 | Ortho=0.000002 | Graph=41.097233 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002177 | OT=0.002170 | Ortho=0.000002 | Graph=41.095939 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002096 | OT=0.002090 | Ortho=0.000002 | Graph=41.091532 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002048 | OT=0.002041 | Ortho=0.000002 | Graph=41.082859 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.002019 | OT=0.002013 | Ortho=0.000002 | Graph=41.069471 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2815 (best@2805 total=0.002006).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.002634 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001918 | OT=0.001917 | Ortho=0.000001 | Graph=41.095066 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.001840 | OT=0.001838 | Ortho=0.000001 | Graph=41.094340 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.001773 | OT=0.001771 | Ortho=0.000001 | Graph=41.091025 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.001729 | OT=0.001727 | Ortho=0.000001 | Graph=41.084239 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.001702 | OT=0.001701 | Ortho=0.000001 | Graph=41.072626 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2892 (best@2882 total=0.001690).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.003178 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002263 | OT=0.002260 | Ortho=0.000002 | Graph=41.096340 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002161 | OT=0.002159 | Ortho=0.000002 | Graph=41.096056 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002082 | OT=0.002079 | Ortho=0.000002 | Graph=41.092580 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002034 | OT=0.002031 | Ortho=0.000002 | Graph=41.085060 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2417 (best@2417 total=0.002013).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.003191 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002275 | OT=0.002273 | Ortho=0.000002 | Graph=41.097254 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.002173 | OT=0.002171 | Ortho=0.000002 | Graph=41.095997 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  1500] total=0.002093 | OT=0.002090 | Ortho=0.000002 | Graph=41.091643 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.002044 | OT=0.002041 | Ortho=0.000002 | Graph=41.083034 | lr=1.25e-04 | Acc=0.9900\n",
            "[Iter  2500] total=0.002015 | OT=0.002013 | Ortho=0.000002 | Graph=41.069721 | lr=1.25e-04 | Acc=0.9900\n",
            "Early stopping at iter=2803 (best@2793 total=0.002003).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.043733 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.034887 | OT=0.001522 | Ortho=0.002614 | Graph=33.103421 | lr=5.00e-04 | Acc=0.9933\n",
            "[Iter  1000] total=0.025656 | OT=0.001151 | Ortho=0.001727 | Graph=24.332161 | lr=5.00e-04 | Acc=0.9800\n",
            "[Iter  1500] total=0.019815 | OT=0.000915 | Ortho=0.001090 | Graph=18.791141 | lr=5.00e-04 | Acc=0.9800\n",
            "[Iter  2000] total=0.013764 | OT=0.000639 | Ortho=0.000531 | Graph=13.072089 | lr=5.00e-04 | Acc=0.9867\n",
            "[Iter  2500] total=0.012653 | OT=0.000558 | Ortho=0.000350 | Graph=12.060139 | lr=2.50e-04 | Acc=0.9800\n",
            "[Iter  3000] total=0.012007 | OT=0.000552 | Ortho=0.000330 | Graph=11.422681 | lr=2.50e-04 | Acc=0.9800\n",
            "[Iter  3500] total=0.011120 | OT=0.000547 | Ortho=0.000302 | Graph=10.542994 | lr=2.50e-04 | Acc=0.9800\n",
            "[Iter  4000] total=0.010066 | OT=0.000520 | Ortho=0.000263 | Graph=9.519590 | lr=2.50e-04 | Acc=0.9800\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.044277 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.036059 | OT=0.001795 | Ortho=0.002828 | Graph=33.981243 | lr=5.00e-04 | Acc=0.9967\n",
            "[Iter  1000] total=0.026099 | OT=0.001245 | Ortho=0.001576 | Graph=24.696269 | lr=5.00e-04 | Acc=0.9833\n",
            "[Iter  1500] total=0.019966 | OT=0.000994 | Ortho=0.001092 | Graph=18.862175 | lr=5.00e-04 | Acc=0.9833\n",
            "[Iter  2000] total=0.014176 | OT=0.000703 | Ortho=0.000554 | Graph=13.417693 | lr=5.00e-04 | Acc=0.9867\n",
            "Early stopping at iter=2311 (best@2301 total=0.012961).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.044290 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.036053 | OT=0.001797 | Ortho=0.002831 | Graph=33.972647 | lr=5.00e-04 | Acc=0.9967\n",
            "[Iter  1000] total=0.026134 | OT=0.001251 | Ortho=0.001633 | Graph=24.719736 | lr=5.00e-04 | Acc=0.9833\n",
            "[Iter  1500] total=0.020022 | OT=0.000996 | Ortho=0.001099 | Graph=18.916280 | lr=5.00e-04 | Acc=0.9833\n",
            "[Iter  2000] total=0.014259 | OT=0.000712 | Ortho=0.000589 | Graph=13.487759 | lr=5.00e-04 | Acc=0.9867\n",
            "Early stopping at iter=2246 (best@2236 total=0.013129).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.006744 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.005715 | OT=0.001653 | Ortho=0.000125 | Graph=40.498651 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=687 (best@677 total=0.005659).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.007288 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.006028 | OT=0.001941 | Ortho=0.000225 | Graph=40.646056 | lr=5.00e-04 | Acc=0.9933\n",
            "[Iter  1000] total=0.005911 | OT=0.001882 | Ortho=0.000205 | Graph=40.087560 | lr=1.25e-04 | Acc=0.9933\n",
            "[Iter  1500] total=0.005853 | OT=0.001854 | Ortho=0.000194 | Graph=39.799499 | lr=1.25e-04 | Acc=0.9933\n",
            "[Iter  2000] total=0.005772 | OT=0.001815 | Ortho=0.000179 | Graph=39.391116 | lr=1.25e-04 | Acc=0.9933\n",
            "[Iter  2500] total=0.005663 | OT=0.001766 | Ortho=0.000157 | Graph=38.810371 | lr=1.25e-04 | Acc=0.9933\n",
            "[Iter  3000] total=0.005514 | OT=0.001709 | Ortho=0.000127 | Graph=37.923380 | lr=1.25e-04 | Acc=0.9867\n",
            "[Iter  3500] total=0.005289 | OT=0.001629 | Ortho=0.000159 | Graph=36.441606 | lr=1.25e-04 | Acc=0.9867\n",
            "[Iter  4000] total=0.004895 | OT=0.001472 | Ortho=0.000100 | Graph=34.128125 | lr=1.25e-04 | Acc=0.9867\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.007300 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.006036 | OT=0.001949 | Ortho=0.000229 | Graph=40.646246 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=790 (best@780 total=0.005951).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.003045 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002079 | OT=0.001662 | Ortho=0.000077 | Graph=40.975316 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=552 (best@542 total=0.002074).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.003589 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002376 | OT=0.001949 | Ortho=0.000171 | Graph=40.985230 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=738 (best@728 total=0.002339).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.003601 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002382 | OT=0.001955 | Ortho=0.000173 | Graph=40.976694 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=624 (best@614 total=0.002362).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.002675 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001711 | OT=0.001662 | Ortho=0.000074 | Graph=41.017563 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=557 (best@547 total=0.001706).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.003219 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002007 | OT=0.001949 | Ortho=0.000168 | Graph=41.016066 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=670 (best@660 total=0.001981).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.003231 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002015 | OT=0.001957 | Ortho=0.000171 | Graph=41.011160 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=637 (best@627 total=0.001993).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.002638 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001674 | OT=0.001662 | Ortho=0.000074 | Graph=41.021855 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=556 (best@546 total=0.001669).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.003182 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001970 | OT=0.001949 | Ortho=0.000168 | Graph=41.020066 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=666 (best@656 total=0.001946).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.003194 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001978 | OT=0.001957 | Ortho=0.000170 | Graph=41.014048 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=643 (best@633 total=0.001956).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.002634 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001670 | OT=0.001662 | Ortho=0.000074 | Graph=41.022243 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=556 (best@546 total=0.001665).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.003178 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001966 | OT=0.001949 | Ortho=0.000168 | Graph=41.020396 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=666 (best@656 total=0.001942).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.003191 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001974 | OT=0.001957 | Ortho=0.000170 | Graph=41.014365 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=641 (best@631 total=0.001952).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.043733 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.020302 | OT=0.000810 | Ortho=0.110358 | Graph=18.388787 | lr=1.00e-03 | Acc=0.9833\n",
            "Early stopping at iter=975 (best@965 total=0.012649).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.044277 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.022253 | OT=0.001023 | Ortho=0.131735 | Graph=19.912676 | lr=1.00e-03 | Acc=0.9833\n",
            "[Iter  1000] total=0.013674 | OT=0.000606 | Ortho=0.047723 | Graph=12.590383 | lr=1.00e-03 | Acc=0.9833\n",
            "Early stopping at iter=1087 (best@1077 total=0.013147).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.044290 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.022314 | OT=0.001002 | Ortho=0.132999 | Graph=19.981782 | lr=1.00e-03 | Acc=0.9833\n",
            "[Iter  1000] total=0.013775 | OT=0.000611 | Ortho=0.049026 | Graph=12.674035 | lr=1.00e-03 | Acc=0.9833\n",
            "Early stopping at iter=1090 (best@1080 total=0.013208).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.006744 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=174 (best@164 total=0.005633).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.007288 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.005828 | OT=0.001772 | Ortho=0.011032 | Graph=39.463790 | lr=5.00e-04 | Acc=0.9933\n",
            "[Iter  1000] total=0.005588 | OT=0.001687 | Ortho=0.009543 | Graph=38.057928 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=1229 (best@1219 total=0.005430).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.007300 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.005838 | OT=0.001775 | Ortho=0.010957 | Graph=39.529972 | lr=2.50e-04 | Acc=0.9933\n",
            "[Iter  1000] total=0.005707 | OT=0.001724 | Ortho=0.010336 | Graph=38.798143 | lr=2.50e-04 | Acc=0.9933\n",
            "[Iter  1500] total=0.005504 | OT=0.001653 | Ortho=0.009227 | Graph=37.590692 | lr=2.50e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.005103 | OT=0.001515 | Ortho=0.007997 | Graph=35.076659 | lr=2.50e-04 | Acc=0.9867\n",
            "[Iter  2500] total=0.004330 | OT=0.001183 | Ortho=0.005912 | Graph=30.879622 | lr=2.50e-04 | Acc=0.9867\n",
            "[Iter  3000] total=0.003991 | OT=0.001091 | Ortho=0.004983 | Graph=28.502131 | lr=2.50e-04 | Acc=0.9900\n",
            "Early stopping at iter=3069 (best@3059 total=0.003969).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.003045 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=483 (best@473 total=0.002001).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.003589 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002266 | OT=0.001802 | Ortho=0.005773 | Graph=40.607956 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=634 (best@624 total=0.002248).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.003601 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002267 | OT=0.001803 | Ortho=0.005763 | Graph=40.585981 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=519 (best@509 total=0.002264).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.002675 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001634 | OT=0.001561 | Ortho=0.003181 | Graph=40.712057 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=671 (best@661 total=0.001622).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.003219 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001901 | OT=0.001805 | Ortho=0.005509 | Graph=40.707395 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=621 (best@611 total=0.001885).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.003231 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=423 (best@413 total=0.001915).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.002638 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001597 | OT=0.001561 | Ortho=0.003162 | Graph=40.727732 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=523 (best@513 total=0.001596).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.003182 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001865 | OT=0.001806 | Ortho=0.005485 | Graph=40.713347 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=620 (best@610 total=0.001849).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.003194 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=416 (best@406 total=0.001880).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.002634 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001593 | OT=0.001561 | Ortho=0.003160 | Graph=40.729256 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=672 (best@662 total=0.001582).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.003178 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001861 | OT=0.001806 | Ortho=0.005482 | Graph=40.714447 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=620 (best@610 total=0.001845).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.003191 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=413 (best@403 total=0.001877).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.043733 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.013477 | OT=0.000124 | Ortho=10.191366 | Graph=3.161275 | lr=1.00e-03 | Acc=0.9800\n",
            "Early stopping at iter=713 (best@703 total=0.012416).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.044277 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.013982 | OT=0.000140 | Ortho=10.941284 | Graph=2.900984 | lr=1.00e-03 | Acc=0.9767\n",
            "[Iter  1000] total=0.012186 | OT=0.000176 | Ortho=8.109235 | Graph=3.900488 | lr=5.00e-04 | Acc=0.9833\n",
            "[Iter  1500] total=0.010951 | OT=0.000216 | Ortho=6.289404 | Graph=4.446421 | lr=5.00e-04 | Acc=0.9900\n",
            "[Iter  2000] total=0.009764 | OT=0.000248 | Ortho=4.595121 | Graph=4.920290 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=2068 (best@2058 total=0.009652).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.044290 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.013947 | OT=0.000106 | Ortho=10.943593 | Graph=2.897681 | lr=1.00e-03 | Acc=0.9767\n",
            "Early stopping at iter=844 (best@834 total=0.012356).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.006744 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=146 (best@136 total=0.005064).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.007288 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=297 (best@287 total=0.005189).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.007300 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.005100 | OT=0.001323 | Ortho=0.621922 | Graph=31.544930 | lr=5.00e-04 | Acc=0.9900\n",
            "[Iter  1000] total=0.004903 | OT=0.001274 | Ortho=0.589700 | Graph=30.395089 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=1412 (best@1402 total=0.004528).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.003045 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=181 (best@171 total=0.001891).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.003589 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002088 | OT=0.001590 | Ortho=0.120319 | Graph=37.830932 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=761 (best@751 total=0.002059).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.003601 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.002090 | OT=0.001591 | Ortho=0.121149 | Graph=37.807686 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=830 (best@820 total=0.002058).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.002675 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "Early stopping at iter=292 (best@282 total=0.001520).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.003219 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001748 | OT=0.001614 | Ortho=0.095309 | Graph=38.430110 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=761 (best@751 total=0.001722).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.003231 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001750 | OT=0.001616 | Ortho=0.095999 | Graph=38.407575 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=724 (best@714 total=0.001725).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.002638 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001471 | OT=0.001399 | Ortho=0.068659 | Graph=38.875101 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=795 (best@785 total=0.001448).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.003182 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001713 | OT=0.001616 | Ortho=0.093069 | Graph=38.490819 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=728 (best@718 total=0.001688).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.003194 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001716 | OT=0.001618 | Ortho=0.093807 | Graph=38.466512 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=780 (best@770 total=0.001687).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.002634 | OT=0.002634 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001468 | OT=0.001399 | Ortho=0.068477 | Graph=38.881545 | lr=5.00e-04 | Acc=0.9900\n",
            "Early stopping at iter=775 (best@765 total=0.001446).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.003178 | OT=0.003178 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001710 | OT=0.001617 | Ortho=0.092849 | Graph=38.496828 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=730 (best@720 total=0.001685).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.003191 | OT=0.003190 | Ortho=0.000000 | Graph=41.099444 | lr=1.00e-03 | Acc=0.9900\n",
            "[Iter   500] total=0.001712 | OT=0.001618 | Ortho=0.093586 | Graph=38.472465 | lr=5.00e-04 | Acc=0.9933\n",
            "Early stopping at iter=758 (best@748 total=0.001684).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    X_normalized\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "  y_normalized\n",
        ")\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "    labels_X=cellTypes_X,\n",
        "    labels_Y=cellTypes_y,\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "yH1rutcd83X9",
      "metadata": {
        "id": "yH1rutcd83X9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        1.000  1.000000e-03    0.1    0.032448  0.993333  0.006100\n",
            "1   8  5        0.100  1.000000e-06    5.0    0.001993  0.993333  0.005639\n",
            "2   8  5        0.100  1.000000e-07    5.0    0.001956  0.993333  0.005644\n",
            "3   8  5        0.100  1.000000e-08    1.0    0.001942  0.993333  0.005667\n",
            "4   8  5        0.100  1.000000e-08    5.0    0.001952  0.993333  0.005644\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-03    5.0    0.013129  0.980000  0.007050\n",
            "68  8  5        0.100  1.000000e-03    1.0    0.012961  0.980000  0.007089\n",
            "69  8  5        0.100  1.000000e-03    0.1    0.010066  0.980000  0.007439\n",
            "70  8  5        0.001  1.000000e-03    0.1    0.012416  0.980000  0.009283\n",
            "71  8  5        0.010  1.000000e-03    0.1    0.012649  0.980000  0.007172\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-08    0.1    0.001446  0.986667  0.005328\n",
            "1   8  5        0.001  1.000000e-07    0.1    0.001448  0.986667  0.005294\n",
            "2   8  5        0.001  1.000000e-06    0.1    0.001520  0.990000  0.005322\n",
            "3   8  5        0.010  1.000000e-08    0.1    0.001582  0.993333  0.005639\n",
            "4   8  5        0.010  1.000000e-07    0.1    0.001596  0.993333  0.005644\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.010  1.000000e-03    1.0    0.013147  0.980000  0.006983\n",
            "68  8  5        0.010  1.000000e-03    5.0    0.013208  0.980000  0.006961\n",
            "69  8  5        1.000  1.000000e-03    0.1    0.032448  0.993333  0.006100\n",
            "70  8  5        1.000  1.000000e-03    1.0    0.032919  0.993333  0.005928\n",
            "71  8  5        1.000  1.000000e-03    5.0    0.032921  0.993333  0.005911\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-07    0.1    0.001448  0.986667  0.005294\n",
            "1   8  5        0.001  1.000000e-05    1.0    0.002059  0.993333  0.005322\n",
            "2   8  5        0.001  1.000000e-06    0.1    0.001520  0.990000  0.005322\n",
            "3   8  5        0.001  1.000000e-08    0.1    0.001446  0.986667  0.005328\n",
            "4   8  5        0.001  1.000000e-05    5.0    0.002058  0.993333  0.005333\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.010  1.000000e-03    0.1    0.012649  0.980000  0.007172\n",
            "68  8  5        0.100  1.000000e-03    0.1    0.010066  0.980000  0.007439\n",
            "69  8  5        0.001  1.000000e-03    1.0    0.009652  0.990000  0.008228\n",
            "70  8  5        0.001  1.000000e-03    5.0    0.012356  0.983333  0.009228\n",
            "71  8  5        0.001  1.000000e-03    0.1    0.012416  0.980000  0.009283\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Geh9Meb83jZ",
      "metadata": {
        "id": "4Geh9Meb83jZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "H1GW6b8V83_Y",
      "metadata": {
        "id": "H1GW6b8V83_Y"
      },
      "source": [
        "# sim-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1qTE-CEB85Kx",
      "metadata": {
        "id": "1qTE-CEB85Kx"
      },
      "outputs": [],
      "source": [
        "X = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s3_mapped1.txt\")\n",
        "y = np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s3_mapped2.txt\")\n",
        "X_normalized = zscore_normalization(X)\n",
        "y_normalized = zscore_normalization(y)\n",
        "cellTypes_X=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s3_label1.txt\", dtype=str)\n",
        "cellTypes_y=np.loadtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/s3_label2.txt\", dtype=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9iGuPphw899P",
      "metadata": {
        "id": "9iGuPphw899P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.036646 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.034908 | OT=0.011428 | Ortho=0.000017 | Graph=23.464078 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1000] total=0.034169 | OT=0.010696 | Ortho=0.000016 | Graph=23.456555 | lr=1.25e-04 | Acc=0.9433\n",
            "[Iter  1500] total=0.033774 | OT=0.010314 | Ortho=0.000014 | Graph=23.444893 | lr=1.25e-04 | Acc=0.9433\n",
            "[Iter  2000] total=0.033432 | OT=0.009990 | Ortho=0.000014 | Graph=23.427514 | lr=1.25e-04 | Acc=0.9267\n",
            "[Iter  2500] total=0.032713 | OT=0.009298 | Ortho=0.000014 | Graph=23.400444 | lr=1.25e-04 | Acc=0.9333\n",
            "[Iter  3000] total=0.032210 | OT=0.008834 | Ortho=0.000014 | Graph=23.362660 | lr=1.25e-04 | Acc=0.9300\n",
            "Early stopping at iter=3493 (best@3493 total=0.031981).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.061194 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.055940 | OT=0.032352 | Ortho=0.000143 | Graph=23.445159 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=592 (best@592 total=0.055928).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.061864 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.056490 | OT=0.032894 | Ortho=0.000152 | Graph=23.444226 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=590 (best@590 total=0.056479).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.015503 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.013755 | OT=0.011403 | Ortho=0.000003 | Graph=23.487351 | lr=1.25e-04 | Acc=0.9400\n",
            "[Iter  1000] total=0.012917 | OT=0.010566 | Ortho=0.000002 | Graph=23.484858 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1500] total=0.012332 | OT=0.009982 | Ortho=0.000002 | Graph=23.480657 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2000] total=0.011845 | OT=0.009496 | Ortho=0.000001 | Graph=23.475162 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  2500] total=0.011425 | OT=0.009077 | Ortho=0.000001 | Graph=23.468268 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  3000] total=0.011153 | OT=0.008806 | Ortho=0.000001 | Graph=23.458964 | lr=1.25e-04 | Acc=0.9233\n",
            "Early stopping at iter=3283 (best@3273 total=0.011062).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040051 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.034850 | OT=0.032387 | Ortho=0.000116 | Graph=23.470706 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=684 (best@684 total=0.034799).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.040720 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.035400 | OT=0.032929 | Ortho=0.000124 | Graph=23.469915 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=686 (best@686 total=0.035349).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.013388 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.011693 | OT=0.011456 | Ortho=0.000003 | Graph=23.489772 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1000] total=0.010922 | OT=0.010684 | Ortho=0.000002 | Graph=23.488942 | lr=1.25e-04 | Acc=0.9400\n",
            "[Iter  1500] total=0.010406 | OT=0.010170 | Ortho=0.000001 | Graph=23.488292 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2000] total=0.009915 | OT=0.009679 | Ortho=0.000001 | Graph=23.486562 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2500] total=0.009444 | OT=0.009208 | Ortho=0.000001 | Graph=23.482286 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  3000] total=0.009113 | OT=0.008877 | Ortho=0.000001 | Graph=23.475974 | lr=1.25e-04 | Acc=0.9267\n",
            "Early stopping at iter=3254 (best@3244 total=0.009013).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.037936 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.032739 | OT=0.032390 | Ortho=0.000114 | Graph=23.473033 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=699 (best@699 total=0.032683).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.038606 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.033285 | OT=0.032928 | Ortho=0.000123 | Graph=23.472353 | lr=2.50e-04 | Acc=0.9300\n",
            "Early stopping at iter=692 (best@692 total=0.033234).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.013177 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.011477 | OT=0.011451 | Ortho=0.000003 | Graph=23.489903 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1000] total=0.010693 | OT=0.010667 | Ortho=0.000002 | Graph=23.489287 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1500] total=0.010173 | OT=0.010149 | Ortho=0.000001 | Graph=23.488831 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2000] total=0.009683 | OT=0.009659 | Ortho=0.000001 | Graph=23.487103 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2500] total=0.009220 | OT=0.009196 | Ortho=0.000001 | Graph=23.482991 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  3000] total=0.008897 | OT=0.008873 | Ortho=0.000001 | Graph=23.476890 | lr=1.25e-04 | Acc=0.9233\n",
            "[Iter  3500] total=0.008760 | OT=0.008735 | Ortho=0.000001 | Graph=23.470850 | lr=6.25e-05 | Acc=0.9233\n",
            "[Iter  4000] total=0.008685 | OT=0.008661 | Ortho=0.000001 | Graph=23.464933 | lr=6.25e-05 | Acc=0.9200\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.037725 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.032529 | OT=0.032391 | Ortho=0.000114 | Graph=23.473236 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=704 (best@704 total=0.032471).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.038394 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.033074 | OT=0.032928 | Ortho=0.000122 | Graph=23.472543 | lr=2.50e-04 | Acc=0.9300\n",
            "Early stopping at iter=692 (best@692 total=0.033023).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.013156 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.011456 | OT=0.011451 | Ortho=0.000003 | Graph=23.489924 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1000] total=0.010672 | OT=0.010667 | Ortho=0.000002 | Graph=23.489287 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1500] total=0.010154 | OT=0.010151 | Ortho=0.000001 | Graph=23.488811 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2000] total=0.009666 | OT=0.009663 | Ortho=0.000001 | Graph=23.487097 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2500] total=0.009202 | OT=0.009199 | Ortho=0.000001 | Graph=23.483004 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  3000] total=0.008877 | OT=0.008874 | Ortho=0.000001 | Graph=23.476919 | lr=1.25e-04 | Acc=0.9233\n",
            "Early stopping at iter=3249 (best@3239 total=0.008782).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.037704 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.032508 | OT=0.032391 | Ortho=0.000114 | Graph=23.473260 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=704 (best@704 total=0.032450).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.038373 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.033053 | OT=0.032928 | Ortho=0.000122 | Graph=23.472568 | lr=2.50e-04 | Acc=0.9300\n",
            "Early stopping at iter=692 (best@692 total=0.033001).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.013154 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.011454 | OT=0.011451 | Ortho=0.000003 | Graph=23.489916 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1000] total=0.010670 | OT=0.010667 | Ortho=0.000002 | Graph=23.489277 | lr=1.25e-04 | Acc=0.9367\n",
            "[Iter  1500] total=0.010153 | OT=0.010151 | Ortho=0.000001 | Graph=23.488798 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2000] total=0.009665 | OT=0.009664 | Ortho=0.000001 | Graph=23.487085 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  2500] total=0.009201 | OT=0.009200 | Ortho=0.000001 | Graph=23.482993 | lr=1.25e-04 | Acc=0.9300\n",
            "[Iter  3000] total=0.008875 | OT=0.008874 | Ortho=0.000001 | Graph=23.476908 | lr=1.25e-04 | Acc=0.9233\n",
            "[Iter  3500] total=0.008710 | OT=0.008709 | Ortho=0.000001 | Graph=23.468958 | lr=7.81e-06 | Acc=0.9233\n",
            "Early stopping at iter=3525 (best@3525 total=0.008709).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.037702 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.032506 | OT=0.032391 | Ortho=0.000114 | Graph=23.473263 | lr=2.50e-04 | Acc=0.9267\n",
            "Early stopping at iter=704 (best@704 total=0.032448).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.038371 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.033051 | OT=0.032928 | Ortho=0.000122 | Graph=23.472570 | lr=2.50e-04 | Acc=0.9300\n",
            "Early stopping at iter=692 (best@692 total=0.032999).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.036646 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.031174 | OT=0.008166 | Ortho=0.001329 | Graph=22.874500 | lr=5.00e-04 | Acc=0.9200\n",
            "[Iter  1000] total=0.029041 | OT=0.007001 | Ortho=0.001444 | Graph=21.895720 | lr=5.00e-04 | Acc=0.9400\n",
            "[Iter  1500] total=0.020283 | OT=0.002907 | Ortho=0.000887 | Graph=17.286580 | lr=5.00e-04 | Acc=0.9467\n",
            "[Iter  2000] total=0.018879 | OT=0.002753 | Ortho=0.000796 | Graph=16.046463 | lr=5.00e-04 | Acc=0.9467\n",
            "[Iter  2500] total=0.013863 | OT=0.002478 | Ortho=0.000440 | Graph=11.341119 | lr=5.00e-04 | Acc=0.9400\n",
            "[Iter  3000] total=0.011086 | OT=0.002226 | Ortho=0.000262 | Graph=8.833981 | lr=5.00e-04 | Acc=0.9133\n",
            "[Iter  3500] total=0.009936 | OT=0.001966 | Ortho=0.000235 | Graph=7.947065 | lr=5.00e-04 | Acc=0.9167\n",
            "[Iter  4000] total=0.007722 | OT=0.001535 | Ortho=0.000181 | Graph=6.168517 | lr=5.00e-04 | Acc=0.8700\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.061194 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.027206 | OT=0.004953 | Ortho=0.001915 | Graph=22.061058 | lr=1.00e-03 | Acc=0.9500\n",
            "Early stopping at iter=646 (best@636 total=0.024488).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.061864 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.028129 | OT=0.005715 | Ortho=0.002577 | Graph=22.155720 | lr=1.00e-03 | Acc=0.9500\n",
            "Early stopping at iter=745 (best@735 total=0.023608).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.015503 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=326 (best@316 total=0.010964).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040051 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.006198 | OT=0.003846 | Ortho=0.000965 | Graph=22.559108 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=604 (best@594 total=0.004712).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.040720 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.007146 | OT=0.004542 | Ortho=0.003391 | Graph=22.651768 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=603 (best@593 total=0.004560).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.013388 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.008856 | OT=0.008615 | Ortho=0.000062 | Graph=23.439607 | lr=5.00e-04 | Acc=0.9200\n",
            "[Iter  1000] total=0.008309 | OT=0.008070 | Ortho=0.000067 | Graph=23.276863 | lr=5.00e-04 | Acc=0.9233\n",
            "[Iter  1500] total=0.006909 | OT=0.006668 | Ortho=0.000146 | Graph=22.648655 | lr=5.00e-04 | Acc=0.9333\n",
            "Early stopping at iter=1799 (best@1789 total=0.003051).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.037936 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.003864 | OT=0.003563 | Ortho=0.000745 | Graph=22.673600 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=630 (best@620 total=0.002568).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.038606 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.005093 | OT=0.004396 | Ortho=0.004701 | Graph=22.717339 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=583 (best@573 total=0.002575).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.013177 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.008646 | OT=0.008617 | Ortho=0.000060 | Graph=23.442273 | lr=5.00e-04 | Acc=0.9200\n",
            "[Iter  1000] total=0.008108 | OT=0.008078 | Ortho=0.000065 | Graph=23.284784 | lr=5.00e-04 | Acc=0.9233\n",
            "[Iter  1500] total=0.007570 | OT=0.007539 | Ortho=0.000084 | Graph=23.037021 | lr=2.50e-04 | Acc=0.9233\n",
            "[Iter  2000] total=0.005329 | OT=0.005277 | Ortho=0.000299 | Graph=22.210965 | lr=2.50e-04 | Acc=0.9267\n",
            "[Iter  2500] total=0.002559 | OT=0.002531 | Ortho=0.000054 | Graph=22.465702 | lr=2.50e-04 | Acc=0.9500\n",
            "Early stopping at iter=2844 (best@2834 total=0.002292).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.037725 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004034 | OT=0.003896 | Ortho=0.001150 | Graph=22.664096 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=586 (best@576 total=0.002526).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.038394 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004914 | OT=0.004250 | Ortho=0.006417 | Graph=22.731353 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=591 (best@581 total=0.002339).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.013156 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.008625 | OT=0.008616 | Ortho=0.000060 | Graph=23.442522 | lr=5.00e-04 | Acc=0.9200\n",
            "[Iter  1000] total=0.008086 | OT=0.008078 | Ortho=0.000065 | Graph=23.284780 | lr=5.00e-04 | Acc=0.9233\n",
            "Early stopping at iter=1031 (best@1021 total=0.008060).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.037704 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004004 | OT=0.003887 | Ortho=0.001147 | Graph=22.664660 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=595 (best@585 total=0.002468).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.038373 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004866 | OT=0.004297 | Ortho=0.005665 | Graph=22.735705 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=631 (best@621 total=0.002231).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.013154 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.008623 | OT=0.008616 | Ortho=0.000060 | Graph=23.442533 | lr=5.00e-04 | Acc=0.9200\n",
            "[Iter  1000] total=0.008084 | OT=0.008077 | Ortho=0.000065 | Graph=23.284525 | lr=5.00e-04 | Acc=0.9233\n",
            "Early stopping at iter=1033 (best@1023 total=0.008055).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.037702 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004001 | OT=0.003887 | Ortho=0.001146 | Graph=22.664718 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=595 (best@585 total=0.002467).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.038371 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004864 | OT=0.004293 | Ortho=0.005708 | Graph=22.735564 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=610 (best@600 total=0.002263).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.036646 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.019028 | OT=0.002707 | Ortho=0.082564 | Graph=15.495789 | lr=1.00e-03 | Acc=0.9467\n",
            "[Iter  1000] total=0.010627 | OT=0.002127 | Ortho=0.026189 | Graph=8.237744 | lr=1.00e-03 | Acc=0.9367\n",
            "Early stopping at iter=1361 (best@1351 total=0.009122).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.061194 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=136 (best@126 total=0.024297).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.061864 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=139 (best@129 total=0.024299).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.015503 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004669 | OT=0.002424 | Ortho=0.003848 | Graph=22.060036 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=608 (best@598 total=0.004429).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040051 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=143 (best@133 total=0.004565).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.040720 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=153 (best@143 total=0.004594).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.013388 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.002755 | OT=0.002512 | Ortho=0.002014 | Graph=22.330170 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=645 (best@635 total=0.002353).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.037936 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=145 (best@135 total=0.002519).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.038606 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=153 (best@143 total=0.002525).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.013177 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.002516 | OT=0.002475 | Ortho=0.001852 | Graph=22.393155 | lr=1.00e-03 | Acc=0.9433\n",
            "Early stopping at iter=556 (best@546 total=0.002360).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.037725 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=145 (best@135 total=0.002291).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.038394 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=153 (best@143 total=0.002324).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.013156 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.002513 | OT=0.002491 | Ortho=0.001998 | Graph=22.397325 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=554 (best@544 total=0.002347).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.037704 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=145 (best@135 total=0.002270).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.038373 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=153 (best@143 total=0.002303).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.013154 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.002486 | OT=0.002471 | Ortho=0.001510 | Graph=22.402150 | lr=1.00e-03 | Acc=0.9467\n",
            "Early stopping at iter=571 (best@561 total=0.002298).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.037702 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=145 (best@135 total=0.002268).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.038371 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "Early stopping at iter=153 (best@143 total=0.002301).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.036646 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.013236 | OT=0.000586 | Ortho=9.071159 | Graph=3.578744 | lr=1.00e-03 | Acc=0.7900\n",
            "[Iter  1000] total=0.008727 | OT=0.000747 | Ortho=3.822857 | Graph=4.157072 | lr=1.00e-03 | Acc=0.9367\n",
            "Early stopping at iter=1488 (best@1478 total=0.007032).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.061194 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.013116 | OT=0.000368 | Ortho=8.345556 | Graph=4.401759 | lr=1.00e-03 | Acc=0.9267\n",
            "[Iter  1000] total=0.011494 | OT=0.000418 | Ortho=6.979200 | Graph=4.096211 | lr=1.00e-03 | Acc=0.9367\n",
            "[Iter  1500] total=0.007896 | OT=0.000552 | Ortho=2.573866 | Graph=4.769983 | lr=1.00e-03 | Acc=0.9367\n",
            "[Iter  2000] total=0.006710 | OT=0.000411 | Ortho=1.885169 | Graph=4.413256 | lr=5.00e-04 | Acc=0.9400\n",
            "[Iter  2500] total=0.006196 | OT=0.000378 | Ortho=1.465275 | Graph=4.353194 | lr=5.00e-04 | Acc=0.9433\n",
            "Early stopping at iter=2913 (best@2903 total=0.005927).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.061864 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.013123 | OT=0.000366 | Ortho=8.399138 | Graph=4.357553 | lr=1.00e-03 | Acc=0.9067\n",
            "[Iter  1000] total=0.011443 | OT=0.000422 | Ortho=7.077615 | Graph=3.943050 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter  1500] total=0.007651 | OT=0.000494 | Ortho=2.405354 | Graph=4.751361 | lr=1.00e-03 | Acc=0.9433\n",
            "Early stopping at iter=1793 (best@1783 total=0.006694).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.015503 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.003750 | OT=0.001455 | Ortho=0.311040 | Graph=19.839676 | lr=1.25e-04 | Acc=0.9400\n",
            "Early stopping at iter=735 (best@735 total=0.003742).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040051 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004036 | OT=0.001713 | Ortho=0.376032 | Graph=19.471196 | lr=5.00e-04 | Acc=0.9467\n",
            "Early stopping at iter=907 (best@897 total=0.004003).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.040720 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.004041 | OT=0.001719 | Ortho=0.374920 | Graph=19.476132 | lr=5.00e-04 | Acc=0.9467\n",
            "Early stopping at iter=855 (best@855 total=0.004016).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.013388 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.001883 | OT=0.001589 | Ortho=0.076462 | Graph=21.836873 | lr=2.50e-04 | Acc=0.9400\n",
            "[Iter  1000] total=0.001853 | OT=0.001559 | Ortho=0.075914 | Graph=21.771107 | lr=2.50e-04 | Acc=0.9400\n",
            "Early stopping at iter=1209 (best@1209 total=0.001845).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.037936 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.002209 | OT=0.001879 | Ortho=0.115441 | Graph=21.416524 | lr=5.00e-04 | Acc=0.9433\n",
            "Early stopping at iter=763 (best@753 total=0.002186).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.038606 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.003894 | OT=0.001703 | Ortho=1.996587 | Graph=19.412952 | lr=2.50e-04 | Acc=0.9467\n",
            "[Iter  1000] total=0.002199 | OT=0.001868 | Ortho=0.116839 | Graph=21.397392 | lr=2.50e-04 | Acc=0.9433\n",
            "Early stopping at iter=1237 (best@1237 total=0.002193).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.013177 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.001687 | OT=0.001602 | Ortho=0.062832 | Graph=22.034867 | lr=2.50e-04 | Acc=0.9400\n",
            "[Iter  1000] total=0.001657 | OT=0.001572 | Ortho=0.062848 | Graph=21.973356 | lr=2.50e-04 | Acc=0.9400\n",
            "Early stopping at iter=1169 (best@1159 total=0.001649).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.037725 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.002016 | OT=0.001895 | Ortho=0.099036 | Graph=21.610351 | lr=5.00e-04 | Acc=0.9433\n",
            "Early stopping at iter=763 (best@753 total=0.001994).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.038394 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.003804 | OT=0.001740 | Ortho=2.044827 | Graph=19.669520 | lr=1.25e-04 | Acc=0.9433\n",
            "[Iter  1000] total=0.002262 | OT=0.001848 | Ortho=0.392483 | Graph=20.926350 | lr=1.25e-04 | Acc=0.9467\n",
            "[Iter  1500] total=0.002006 | OT=0.001884 | Ortho=0.100531 | Graph=21.591929 | lr=1.25e-04 | Acc=0.9433\n",
            "Early stopping at iter=1760 (best@1760 total=0.002000).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.013156 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.001667 | OT=0.001603 | Ortho=0.061685 | Graph=22.054594 | lr=2.50e-04 | Acc=0.9400\n",
            "[Iter  1000] total=0.001637 | OT=0.001573 | Ortho=0.061590 | Graph=21.993978 | lr=2.50e-04 | Acc=0.9400\n",
            "Early stopping at iter=1165 (best@1155 total=0.001630).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.037704 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.001996 | OT=0.001897 | Ortho=0.097468 | Graph=21.629932 | lr=5.00e-04 | Acc=0.9433\n",
            "Early stopping at iter=760 (best@750 total=0.001975).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.038373 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.003787 | OT=0.001741 | Ortho=2.043458 | Graph=19.688004 | lr=1.25e-04 | Acc=0.9433\n",
            "[Iter  1000] total=0.002246 | OT=0.001849 | Ortho=0.394892 | Graph=20.940890 | lr=1.25e-04 | Acc=0.9467\n",
            "[Iter  1500] total=0.001987 | OT=0.001886 | Ortho=0.098969 | Graph=21.611547 | lr=1.25e-04 | Acc=0.9433\n",
            "Early stopping at iter=1765 (best@1765 total=0.001981).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.013154 | OT=0.013154 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.001665 | OT=0.001603 | Ortho=0.061580 | Graph=22.056503 | lr=2.50e-04 | Acc=0.9400\n",
            "[Iter  1000] total=0.001635 | OT=0.001573 | Ortho=0.061464 | Graph=21.995909 | lr=2.50e-04 | Acc=0.9400\n",
            "Early stopping at iter=1175 (best@1165 total=0.001628).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.037702 | OT=0.037702 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.001994 | OT=0.001897 | Ortho=0.097312 | Graph=21.631890 | lr=5.00e-04 | Acc=0.9433\n",
            "Early stopping at iter=794 (best@784 total=0.001972).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.038371 | OT=0.038371 | Ortho=0.000000 | Graph=23.492864 | lr=1.00e-03 | Acc=0.9300\n",
            "[Iter   500] total=0.003785 | OT=0.001742 | Ortho=2.043322 | Graph=19.689853 | lr=1.25e-04 | Acc=0.9433\n",
            "[Iter  1000] total=0.002245 | OT=0.001850 | Ortho=0.395135 | Graph=20.942341 | lr=1.25e-04 | Acc=0.9467\n",
            "[Iter  1500] total=0.001985 | OT=0.001886 | Ortho=0.098813 | Graph=21.613510 | lr=1.25e-04 | Acc=0.9433\n",
            "Early stopping at iter=1765 (best@1765 total=0.001979).\n",
            "\n",
            "Grid search complete. Saved 72 runs to alignment_tuning_results.pkl\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    X_normalized\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "  y_normalized\n",
        ")\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-3,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "   X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "    labels_X=cellTypes_X,\n",
        "    labels_Y=cellTypes_y,\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dd-N6JCb8_L2",
      "metadata": {
        "id": "dd-N6JCb8_L2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-08    5.0    0.001979  0.946667  0.009283\n",
            "1   8  5        0.001  1.000000e-03    1.0    0.005927  0.946667  0.010694\n",
            "2   8  5        0.010  1.000000e-05    0.1    0.002353  0.946667  0.009850\n",
            "3   8  5        0.100  1.000000e-08    5.0    0.002263  0.946667  0.009272\n",
            "4   8  5        0.100  1.000000e-08    1.0    0.002467  0.946667  0.009306\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        0.100  1.000000e-07    0.1    0.008060  0.923333  0.027350\n",
            "68  8  5        1.000  1.000000e-03    0.1    0.031981  0.923333  0.031128\n",
            "69  8  5        1.000  1.000000e-06    0.1    0.008685  0.920000  0.030722\n",
            "70  8  5        0.100  1.000000e-04    0.1    0.010964  0.920000  0.030283\n",
            "71  8  5        0.100  1.000000e-03    0.1    0.007722  0.870000  0.021433\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.001  1.000000e-08    0.1    0.001628  0.940000  0.009367\n",
            "1   8  5        0.001  1.000000e-07    0.1    0.001630  0.940000  0.009367\n",
            "2   8  5        0.001  1.000000e-06    0.1    0.001649  0.940000  0.009372\n",
            "3   8  5        0.001  1.000000e-05    0.1    0.001845  0.940000  0.009378\n",
            "4   8  5        0.001  1.000000e-08    1.0    0.001972  0.943333  0.009256\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        1.000  1.000000e-05    5.0    0.033234  0.926667  0.016061\n",
            "68  8  5        1.000  1.000000e-04    1.0    0.034799  0.926667  0.016067\n",
            "69  8  5        1.000  1.000000e-04    5.0    0.035349  0.926667  0.016056\n",
            "70  8  5        1.000  1.000000e-03    1.0    0.055928  0.926667  0.016044\n",
            "71  8  5        1.000  1.000000e-03    5.0    0.056479  0.926667  0.016056\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k  lambda_topo    lambda_reg  reach  final_loss  accuracy   foscttm\n",
            "0   8  5        0.010  1.000000e-05    5.0    0.002525  0.940000  0.009222\n",
            "1   8  5        0.001  1.000000e-04    5.0    0.004016  0.943333  0.009228\n",
            "2   8  5        0.001  1.000000e-04    1.0    0.004003  0.943333  0.009233\n",
            "3   8  5        0.010  1.000000e-07    1.0    0.002270  0.940000  0.009239\n",
            "4   8  5        0.001  1.000000e-07    1.0    0.001975  0.943333  0.009239\n",
            ".. .. ..          ...           ...    ...         ...       ...       ...\n",
            "67  8  5        1.000  1.000000e-04    0.1    0.011062  0.923333  0.031100\n",
            "68  8  5        1.000  1.000000e-03    0.1    0.031981  0.923333  0.031128\n",
            "69  8  5        1.000  1.000000e-05    0.1    0.009013  0.926667  0.031394\n",
            "70  8  5        1.000  1.000000e-07    0.1    0.008782  0.926667  0.031400\n",
            "71  8  5        0.001  1.000000e-03    0.1    0.007032  0.923333  0.075811\n",
            "\n",
            "[72 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de55f0a3",
      "metadata": {},
      "source": [
        "# mimic real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1vYl43838_UK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vYl43838_UK",
        "outputId": "a2b5995b-965e-4247-96a6-f92da3fb4173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions of input datasets are:  X=  (5000, 50)  y=  (5000, 500)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def zscore_normalization(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    normalized_data = (data - mean) / std\n",
        "    return normalized_data\n",
        "X=np.load(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/splatter_X.npy\")\n",
        "y=np.load(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/splatter_y.npy\")\n",
        "X_normalized = zscore_normalization(X)\n",
        "y_normalized = zscore_normalization(y)\n",
        "print(\"Dimensions of input datasets are: \", \"X= \", X.shape, \" y= \", y.shape)\n",
        "cellTypes_X=np.genfromtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/splatter_labels.csv\")\n",
        "cellTypes_y=np.genfromtxt(\"/Users/aaaaaaaron/Desktop/GROTIA/drive-download-20251119T201410Z-1-001/splatter_labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "Z5_HvAHmSRup",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5_HvAHmSRup",
        "outputId": "dcab7871-5640-4818-a981-4da798dfa627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.076240 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.070630 | OT=0.005844 | Ortho=0.000136 | Graph=64.649812 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  1000] total=0.060452 | OT=0.005084 | Ortho=0.000111 | Graph=55.256212 | lr=5.00e-05 | Acc=0.9866\n",
            "[Iter  1500] total=0.049975 | OT=0.004427 | Ortho=0.000085 | Graph=45.463094 | lr=5.00e-05 | Acc=0.9838\n",
            "[Iter  2000] total=0.039449 | OT=0.003772 | Ortho=0.000064 | Graph=35.613463 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  2500] total=0.031242 | OT=0.003294 | Ortho=0.000039 | Graph=27.909074 | lr=5.00e-05 | Acc=0.9790\n",
            "[Iter  3000] total=0.027447 | OT=0.003534 | Ortho=0.000030 | Graph=23.882577 | lr=5.00e-05 | Acc=0.9771\n",
            "[Iter  3500] total=0.024297 | OT=0.003368 | Ortho=0.000025 | Graph=20.903319 | lr=5.00e-05 | Acc=0.9752\n",
            "[Iter  4000] total=0.020614 | OT=0.002786 | Ortho=0.000021 | Graph=17.806984 | lr=5.00e-05 | Acc=0.9666\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084660 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.070004 | OT=0.010090 | Ortho=0.000143 | Graph=59.770652 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.054133 | OT=0.006732 | Ortho=0.000161 | Graph=47.240224 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1500] total=0.041347 | OT=0.004518 | Ortho=0.000067 | Graph=36.762789 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2000] total=0.033319 | OT=0.003951 | Ortho=0.000113 | Graph=29.255713 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=2007 (best@1997 total=0.033298).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084803 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.070170 | OT=0.010158 | Ortho=0.000139 | Graph=59.873721 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.054286 | OT=0.006740 | Ortho=0.000137 | Graph=47.407930 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1500] total=0.042297 | OT=0.004551 | Ortho=0.000310 | Graph=37.436988 | lr=1.00e-04 | Acc=0.9828\n",
            "Early stopping at iter=1910 (best@1900 total=0.034809).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.014351 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.012696 | OT=0.005834 | Ortho=0.000005 | Graph=68.574524 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  1000] total=0.012471 | OT=0.005633 | Ortho=0.000006 | Graph=68.319197 | lr=2.50e-05 | Acc=0.9847\n",
            "[Iter  1500] total=0.012302 | OT=0.005493 | Ortho=0.000006 | Graph=68.031933 | lr=2.50e-05 | Acc=0.9847\n",
            "[Iter  2000] total=0.012071 | OT=0.005310 | Ortho=0.000009 | Graph=67.525705 | lr=2.50e-05 | Acc=0.9857\n",
            "[Iter  2500] total=0.011727 | OT=0.005050 | Ortho=0.000006 | Graph=66.718034 | lr=2.50e-05 | Acc=0.9866\n",
            "[Iter  3000] total=0.011250 | OT=0.004676 | Ortho=0.000006 | Graph=65.685365 | lr=2.50e-05 | Acc=0.9857\n",
            "[Iter  3500] total=0.010675 | OT=0.004255 | Ortho=0.000005 | Graph=64.151641 | lr=2.50e-05 | Acc=0.9866\n",
            "[Iter  4000] total=0.010254 | OT=0.003990 | Ortho=0.000004 | Graph=62.602945 | lr=1.25e-05 | Acc=0.9866\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.022771 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.017044 | OT=0.010037 | Ortho=0.000020 | Graph=69.869121 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=752 (best@742 total=0.014754).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.022914 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.017199 | OT=0.010200 | Ortho=0.000020 | Graph=69.783216 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=900 (best@890 total=0.014060).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.008162 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.006516 | OT=0.005823 | Ortho=0.000003 | Graph=68.907715 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  1000] total=0.006267 | OT=0.005560 | Ortho=0.000013 | Graph=69.329230 | lr=5.00e-05 | Acc=0.9866\n",
            "Early stopping at iter=1006 (best@996 total=0.006260).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.016582 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010898 | OT=0.010179 | Ortho=0.000018 | Graph=70.174845 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=856 (best@846 total=0.008288).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.016725 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010916 | OT=0.010187 | Ortho=0.000026 | Graph=70.401352 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=803 (best@793 total=0.008523).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.007543 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005895 | OT=0.005823 | Ortho=0.000003 | Graph=68.936054 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  1000] total=0.005634 | OT=0.005562 | Ortho=0.000003 | Graph=69.406076 | lr=5.00e-05 | Acc=0.9876\n",
            "[Iter  1500] total=0.005367 | OT=0.005293 | Ortho=0.000004 | Graph=69.919055 | lr=2.50e-05 | Acc=0.9895\n",
            "[Iter  2000] total=0.005175 | OT=0.005101 | Ortho=0.000004 | Graph=70.148463 | lr=2.50e-05 | Acc=0.9895\n",
            "[Iter  2500] total=0.004859 | OT=0.004785 | Ortho=0.000004 | Graph=70.245274 | lr=2.50e-05 | Acc=0.9904\n",
            "[Iter  3000] total=0.004363 | OT=0.004289 | Ortho=0.000003 | Graph=70.071241 | lr=2.50e-05 | Acc=0.9885\n",
            "[Iter  3500] total=0.003916 | OT=0.003845 | Ortho=0.000002 | Graph=69.428151 | lr=2.50e-05 | Acc=0.9885\n",
            "Early stopping at iter=3602 (best@3592 total=0.003862).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.015963 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010305 | OT=0.010203 | Ortho=0.000032 | Graph=70.219875 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=771 (best@761 total=0.008146).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.016106 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010263 | OT=0.010176 | Ortho=0.000016 | Graph=70.414208 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=810 (best@800 total=0.007861).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.007481 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005833 | OT=0.005823 | Ortho=0.000003 | Graph=68.940680 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  1000] total=0.005571 | OT=0.005561 | Ortho=0.000003 | Graph=69.420332 | lr=5.00e-05 | Acc=0.9876\n",
            "Early stopping at iter=1283 (best@1273 total=0.005421).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.015901 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010259 | OT=0.010164 | Ortho=0.000088 | Graph=70.192052 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=820 (best@810 total=0.007796).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.016044 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010202 | OT=0.010168 | Ortho=0.000027 | Graph=70.409434 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=976 (best@966 total=0.007176).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.007475 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005827 | OT=0.005823 | Ortho=0.000003 | Graph=68.939697 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  1000] total=0.005565 | OT=0.005561 | Ortho=0.000003 | Graph=69.416908 | lr=5.00e-05 | Acc=0.9876\n",
            "Early stopping at iter=1403 (best@1393 total=0.005348).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.015895 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010253 | OT=0.010164 | Ortho=0.000088 | Graph=70.192476 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=835 (best@825 total=0.007706).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.016038 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010195 | OT=0.010168 | Ortho=0.000026 | Graph=70.410007 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=863 (best@853 total=0.007547).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.076240 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.033473 | OT=0.003429 | Ortho=0.004925 | Graph=29.551500 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.016899 | OT=0.002262 | Ortho=0.001247 | Graph=14.512542 | lr=1.00e-04 | Acc=0.8739\n",
            "[Iter  1500] total=0.013406 | OT=0.001364 | Ortho=0.000505 | Graph=11.991623 | lr=1.00e-04 | Acc=0.7832\n",
            "[Iter  2000] total=0.012029 | OT=0.001184 | Ortho=0.000424 | Graph=10.802378 | lr=1.00e-04 | Acc=0.7364\n",
            "[Iter  2500] total=0.010442 | OT=0.001005 | Ortho=0.000320 | Graph=9.405160 | lr=1.00e-04 | Acc=0.7364\n",
            "[Iter  3000] total=0.009291 | OT=0.000833 | Ortho=0.000250 | Graph=8.433796 | lr=1.00e-04 | Acc=0.7612\n",
            "[Iter  3500] total=0.008357 | OT=0.000620 | Ortho=0.000207 | Graph=7.716710 | lr=1.00e-04 | Acc=0.7555\n",
            "[Iter  4000] total=0.007562 | OT=0.000493 | Ortho=0.000170 | Graph=7.052585 | lr=1.00e-04 | Acc=0.7412\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084660 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.037165 | OT=0.004112 | Ortho=0.005906 | Graph=32.462088 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.021548 | OT=0.002511 | Ortho=0.002047 | Graph=18.832758 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  1500] total=0.014213 | OT=0.001409 | Ortho=0.000654 | Graph=12.738108 | lr=1.00e-04 | Acc=0.9093\n",
            "[Iter  2000] total=0.012429 | OT=0.001146 | Ortho=0.000413 | Graph=11.242235 | lr=1.00e-04 | Acc=0.8262\n",
            "[Iter  2500] total=0.011185 | OT=0.000942 | Ortho=0.000344 | Graph=10.208624 | lr=1.00e-04 | Acc=0.7412\n",
            "[Iter  3000] total=0.009976 | OT=0.000781 | Ortho=0.000276 | Graph=9.167756 | lr=1.00e-04 | Acc=0.6963\n",
            "[Iter  3500] total=0.009106 | OT=0.000651 | Ortho=0.000233 | Graph=8.432279 | lr=1.00e-04 | Acc=0.6848\n",
            "[Iter  4000] total=0.008316 | OT=0.000554 | Ortho=0.000202 | Graph=7.741929 | lr=1.00e-04 | Acc=0.6800\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084803 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.037446 | OT=0.004026 | Ortho=0.005996 | Graph=32.820112 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.021217 | OT=0.002357 | Ortho=0.002039 | Graph=18.656208 | lr=1.00e-04 | Acc=0.9513\n",
            "[Iter  1500] total=0.014461 | OT=0.001458 | Ortho=0.000722 | Graph=12.930857 | lr=1.00e-04 | Acc=0.9245\n",
            "[Iter  2000] total=0.012279 | OT=0.001074 | Ortho=0.000396 | Graph=11.165149 | lr=1.00e-04 | Acc=0.7794\n",
            "[Iter  2500] total=0.011067 | OT=0.000917 | Ortho=0.000334 | Graph=10.116488 | lr=1.00e-04 | Acc=0.7354\n",
            "[Iter  3000] total=0.009933 | OT=0.000770 | Ortho=0.000278 | Graph=9.135661 | lr=1.00e-04 | Acc=0.6925\n",
            "[Iter  3500] total=0.009079 | OT=0.000637 | Ortho=0.000234 | Graph=8.418680 | lr=1.00e-04 | Acc=0.6877\n",
            "[Iter  4000] total=0.008345 | OT=0.000573 | Ortho=0.000205 | Graph=7.752071 | lr=1.00e-04 | Acc=0.6886\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.014351 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.010481 | OT=0.004067 | Ortho=0.000435 | Graph=63.713769 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.007736 | OT=0.002681 | Ortho=0.000173 | Graph=50.381676 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1500] total=0.005276 | OT=0.001703 | Ortho=0.000160 | Graph=35.572912 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  2000] total=0.003940 | OT=0.001239 | Ortho=0.000059 | Graph=26.948510 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2500] total=0.003203 | OT=0.001015 | Ortho=0.000035 | Graph=21.848810 | lr=1.00e-04 | Acc=0.9456\n",
            "Early stopping at iter=2693 (best@2683 total=0.003046).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.022771 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.011399 | OT=0.005009 | Ortho=0.000382 | Graph=63.524360 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.009064 | OT=0.003583 | Ortho=0.000262 | Graph=54.551177 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1500] total=0.006160 | OT=0.002284 | Ortho=0.000160 | Graph=38.600900 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.004180 | OT=0.001485 | Ortho=0.000064 | Graph=26.880874 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  2500] total=0.003045 | OT=0.001007 | Ortho=0.000036 | Graph=20.349468 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  3000] total=0.002464 | OT=0.000823 | Ortho=0.000046 | Graph=16.364366 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  3500] total=0.002189 | OT=0.000717 | Ortho=0.000014 | Graph=14.704914 | lr=5.00e-05 | Acc=0.9675\n",
            "[Iter  4000] total=0.002097 | OT=0.000674 | Ortho=0.000013 | Graph=14.221962 | lr=5.00e-05 | Acc=0.9656\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.022914 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.011507 | OT=0.005093 | Ortho=0.000378 | Graph=63.764164 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.009137 | OT=0.003636 | Ortho=0.000251 | Graph=54.757990 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.006427 | OT=0.002388 | Ortho=0.000250 | Graph=40.137683 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  2000] total=0.004229 | OT=0.001474 | Ortho=0.000071 | Graph=27.473675 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2500] total=0.003152 | OT=0.001050 | Ortho=0.000040 | Graph=20.982484 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  3000] total=0.002516 | OT=0.000820 | Ortho=0.000022 | Graph=16.931787 | lr=1.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=3487 (best@3477 total=0.002276).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.008162 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004618 | OT=0.003904 | Ortho=0.000241 | Graph=69.009724 | lr=1.00e-04 | Acc=0.9885\n",
            "[Iter  1000] total=0.003567 | OT=0.002924 | Ortho=0.000041 | Graph=63.863377 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=1122 (best@1112 total=0.003435).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.016582 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.006098 | OT=0.005402 | Ortho=0.000249 | Graph=67.114985 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.004431 | OT=0.003805 | Ortho=0.000062 | Graph=62.012888 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.003491 | OT=0.002920 | Ortho=0.000034 | Graph=56.774904 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.003114 | OT=0.002574 | Ortho=0.000032 | Graph=53.664646 | lr=5.00e-05 | Acc=0.9780\n",
            "[Iter  2500] total=0.002835 | OT=0.002322 | Ortho=0.000028 | Graph=50.973454 | lr=5.00e-05 | Acc=0.9780\n",
            "[Iter  3000] total=0.002498 | OT=0.002026 | Ortho=0.000021 | Graph=46.979462 | lr=5.00e-05 | Acc=0.9761\n",
            "[Iter  3500] total=0.002145 | OT=0.001722 | Ortho=0.000016 | Graph=42.210165 | lr=5.00e-05 | Acc=0.9761\n",
            "Early stopping at iter=3760 (best@3750 total=0.002010).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.016725 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005979 | OT=0.005284 | Ortho=0.000254 | Graph=66.913209 | lr=1.00e-04 | Acc=0.9895\n",
            "[Iter  1000] total=0.004467 | OT=0.003834 | Ortho=0.000122 | Graph=62.020591 | lr=1.00e-04 | Acc=0.9876\n",
            "Early stopping at iter=1365 (best@1355 total=0.003761).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.007543 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.003991 | OT=0.003902 | Ortho=0.000192 | Graph=69.271575 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.003047 | OT=0.002979 | Ortho=0.000032 | Graph=65.114666 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=1310 (best@1300 total=0.002718).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.015963 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005520 | OT=0.005427 | Ortho=0.000257 | Graph=67.430989 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003938 | OT=0.003870 | Ortho=0.000051 | Graph=62.790855 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003118 | OT=0.003057 | Ortho=0.000028 | Graph=58.340064 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=1815 (best@1805 total=0.002749).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.016106 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005434 | OT=0.005347 | Ortho=0.000201 | Graph=67.382142 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003892 | OT=0.003824 | Ortho=0.000048 | Graph=62.839082 | lr=1.00e-04 | Acc=0.9838\n",
            "Early stopping at iter=1306 (best@1296 total=0.003387).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.007481 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.003930 | OT=0.003904 | Ortho=0.000190 | Graph=69.307850 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.002990 | OT=0.002981 | Ortho=0.000030 | Graph=65.243473 | lr=1.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=1367 (best@1357 total=0.002614).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.015901 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005459 | OT=0.005425 | Ortho=0.000276 | Graph=67.444355 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003877 | OT=0.003866 | Ortho=0.000050 | Graph=62.804928 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003212 | OT=0.003203 | Ortho=0.000031 | Graph=59.319195 | lr=5.00e-05 | Acc=0.9847\n",
            "[Iter  2000] total=0.002797 | OT=0.002789 | Ortho=0.000021 | Graph=56.365893 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  2500] total=0.002535 | OT=0.002528 | Ortho=0.000019 | Graph=53.683508 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  3000] total=0.002229 | OT=0.002222 | Ortho=0.000017 | Graph=50.265520 | lr=5.00e-05 | Acc=0.9828\n",
            "[Iter  3500] total=0.001897 | OT=0.001891 | Ortho=0.000014 | Graph=45.943027 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  4000] total=0.001635 | OT=0.001630 | Ortho=0.000008 | Graph=41.685011 | lr=5.00e-05 | Acc=0.9780\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.016044 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005381 | OT=0.005355 | Ortho=0.000194 | Graph=67.420517 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.003872 | OT=0.003861 | Ortho=0.000051 | Graph=62.887677 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.003042 | OT=0.003033 | Ortho=0.000026 | Graph=58.406142 | lr=1.00e-04 | Acc=0.9838\n",
            "Early stopping at iter=1557 (best@1547 total=0.002990).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.007475 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.003922 | OT=0.003903 | Ortho=0.000178 | Graph=69.309217 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.002982 | OT=0.002979 | Ortho=0.000030 | Graph=65.227164 | lr=1.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=1434 (best@1424 total=0.002543).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.015895 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005451 | OT=0.005419 | Ortho=0.000312 | Graph=67.438632 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003882 | OT=0.003877 | Ortho=0.000050 | Graph=62.844523 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=1278 (best@1268 total=0.003393).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.016038 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.005374 | OT=0.005354 | Ortho=0.000198 | Graph=67.424279 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.003865 | OT=0.003859 | Ortho=0.000051 | Graph=62.891069 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.003063 | OT=0.003060 | Ortho=0.000026 | Graph=58.625791 | lr=5.00e-05 | Acc=0.9838\n",
            "[Iter  2000] total=0.002709 | OT=0.002707 | Ortho=0.000022 | Graph=56.009163 | lr=5.00e-05 | Acc=0.9819\n",
            "[Iter  2500] total=0.002402 | OT=0.002400 | Ortho=0.000020 | Graph=53.200288 | lr=5.00e-05 | Acc=0.9819\n",
            "Early stopping at iter=2912 (best@2902 total=0.002165).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.076240 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.028516 | OT=0.002888 | Ortho=0.476322 | Graph=20.864854 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.013781 | OT=0.001422 | Ortho=0.059670 | Graph=11.762283 | lr=1.00e-04 | Acc=0.8883\n",
            "[Iter  1500] total=0.012043 | OT=0.001194 | Ortho=0.044788 | Graph=10.401083 | lr=1.00e-04 | Acc=0.8730\n",
            "[Iter  2000] total=0.010595 | OT=0.001090 | Ortho=0.032991 | Graph=9.175283 | lr=1.00e-04 | Acc=0.8806\n",
            "[Iter  2500] total=0.009535 | OT=0.000898 | Ortho=0.026409 | Graph=8.372159 | lr=1.00e-04 | Acc=0.8730\n",
            "[Iter  3000] total=0.008640 | OT=0.000734 | Ortho=0.021799 | Graph=7.687470 | lr=1.00e-04 | Acc=0.8262\n",
            "[Iter  3500] total=0.007865 | OT=0.000630 | Ortho=0.018663 | Graph=7.048220 | lr=1.00e-04 | Acc=0.8157\n",
            "[Iter  4000] total=0.007180 | OT=0.000549 | Ortho=0.016029 | Graph=6.470576 | lr=1.00e-04 | Acc=0.8300\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084660 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.032665 | OT=0.002816 | Ortho=0.583490 | Graph=24.013642 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.017465 | OT=0.002013 | Ortho=0.151676 | Graph=13.935609 | lr=1.00e-04 | Acc=0.9618\n",
            "[Iter  1500] total=0.013171 | OT=0.001147 | Ortho=0.060508 | Graph=11.419027 | lr=1.00e-04 | Acc=0.8959\n",
            "[Iter  2000] total=0.011252 | OT=0.000983 | Ortho=0.036994 | Graph=9.899776 | lr=1.00e-04 | Acc=0.8596\n",
            "[Iter  2500] total=0.010256 | OT=0.000893 | Ortho=0.029840 | Graph=9.064574 | lr=1.00e-04 | Acc=0.8625\n",
            "[Iter  3000] total=0.009527 | OT=0.000778 | Ortho=0.026367 | Graph=8.485071 | lr=1.00e-04 | Acc=0.8491\n",
            "[Iter  3500] total=0.008765 | OT=0.000657 | Ortho=0.023320 | Graph=7.874723 | lr=1.00e-04 | Acc=0.8395\n",
            "[Iter  4000] total=0.007949 | OT=0.000551 | Ortho=0.019970 | Graph=7.198708 | lr=1.00e-04 | Acc=0.8348\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084803 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.032681 | OT=0.002762 | Ortho=0.586198 | Graph=24.057090 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.017280 | OT=0.001895 | Ortho=0.141956 | Graph=13.965710 | lr=1.00e-04 | Acc=0.9647\n",
            "[Iter  1500] total=0.013180 | OT=0.001171 | Ortho=0.055493 | Graph=11.453951 | lr=1.00e-04 | Acc=0.9169\n",
            "[Iter  2000] total=0.011536 | OT=0.000940 | Ortho=0.042794 | Graph=10.167908 | lr=1.00e-04 | Acc=0.8892\n",
            "[Iter  2500] total=0.010158 | OT=0.000819 | Ortho=0.030464 | Graph=9.033626 | lr=1.00e-04 | Acc=0.8663\n",
            "[Iter  3000] total=0.009322 | OT=0.000714 | Ortho=0.025299 | Graph=8.354941 | lr=1.00e-04 | Acc=0.8453\n",
            "[Iter  3500] total=0.008612 | OT=0.000620 | Ortho=0.022207 | Graph=7.770436 | lr=1.00e-04 | Acc=0.8319\n",
            "[Iter  4000] total=0.007909 | OT=0.000540 | Ortho=0.019241 | Graph=7.176672 | lr=1.00e-04 | Acc=0.8500\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.014351 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.007230 | OT=0.002492 | Ortho=0.016332 | Graph=45.740952 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.003860 | OT=0.001068 | Ortho=0.006583 | Graph=27.263695 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1500] total=0.002767 | OT=0.000779 | Ortho=0.002748 | Graph=19.603440 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  2000] total=0.002278 | OT=0.000654 | Ortho=0.001914 | Graph=16.050725 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=2376 (best@2366 total=0.001948).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.022771 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.009796 | OT=0.003942 | Ortho=0.027464 | Graph=55.787958 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.005900 | OT=0.002153 | Ortho=0.013146 | Graph=36.155785 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1500] total=0.003824 | OT=0.001319 | Ortho=0.006158 | Graph=24.437499 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  2000] total=0.002674 | OT=0.000890 | Ortho=0.002639 | Graph=17.575188 | lr=1.00e-04 | Acc=0.9723\n",
            "[Iter  2500] total=0.002246 | OT=0.000745 | Ortho=0.001449 | Graph=14.862522 | lr=1.00e-04 | Acc=0.9570\n",
            "Early stopping at iter=2719 (best@2709 total=0.002111).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.022914 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.009709 | OT=0.003859 | Ortho=0.026052 | Graph=55.888817 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.006026 | OT=0.002178 | Ortho=0.013925 | Graph=37.091189 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  1500] total=0.004008 | OT=0.001377 | Ortho=0.006416 | Graph=25.666909 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.002877 | OT=0.000989 | Ortho=0.003258 | Graph=18.551823 | lr=1.00e-04 | Acc=0.9713\n",
            "[Iter  2500] total=0.002250 | OT=0.000745 | Ortho=0.001608 | Graph=14.881134 | lr=1.00e-04 | Acc=0.9637\n",
            "Early stopping at iter=2787 (best@2777 total=0.002084).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.008162 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.003569 | OT=0.002903 | Ortho=0.002916 | Graph=63.631766 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.002640 | OT=0.002081 | Ortho=0.001832 | Graph=53.981846 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  1500] total=0.001855 | OT=0.001418 | Ortho=0.001151 | Graph=42.541322 | lr=1.00e-04 | Acc=0.9790\n",
            "Early stopping at iter=1974 (best@1964 total=0.001439).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.016582 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004956 | OT=0.004255 | Ortho=0.007441 | Graph=62.680680 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.003747 | OT=0.003156 | Ortho=0.004747 | Graph=54.407487 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.002656 | OT=0.002182 | Ortho=0.002326 | Graph=45.111344 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2000] total=0.001948 | OT=0.001547 | Ortho=0.001463 | Graph=38.652409 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  2500] total=0.001505 | OT=0.001177 | Ortho=0.000925 | Graph=31.937189 | lr=1.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=2838 (best@2828 total=0.001323).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.016725 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004971 | OT=0.004270 | Ortho=0.007318 | Graph=62.753064 | lr=1.00e-04 | Acc=0.9876\n",
            "Early stopping at iter=916 (best@906 total=0.003897).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.007543 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.003032 | OT=0.002942 | Ortho=0.002505 | Graph=64.764745 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.002221 | OT=0.002150 | Ortho=0.001442 | Graph=56.057574 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1500] total=0.001686 | OT=0.001632 | Ortho=0.000622 | Graph=48.115098 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  2000] total=0.001339 | OT=0.001293 | Ortho=0.000502 | Graph=41.056753 | lr=1.00e-04 | Acc=0.9704\n",
            "Early stopping at iter=2265 (best@2255 total=0.001184).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.015963 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004396 | OT=0.004268 | Ortho=0.006410 | Graph=63.370675 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.003166 | OT=0.003075 | Ortho=0.003509 | Graph=55.943563 | lr=1.00e-04 | Acc=0.9828\n",
            "Early stopping at iter=1073 (best@1063 total=0.003117).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.016106 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004448 | OT=0.004322 | Ortho=0.006194 | Graph=63.296910 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003343 | OT=0.003252 | Ortho=0.003468 | Graph=56.826146 | lr=5.00e-05 | Acc=0.9828\n",
            "Early stopping at iter=1012 (best@1002 total=0.003343).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.007481 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.002979 | OT=0.002948 | Ortho=0.002449 | Graph=64.897624 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.002169 | OT=0.002152 | Ortho=0.001116 | Graph=56.454823 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1500] total=0.001633 | OT=0.001623 | Ortho=0.000535 | Graph=48.104882 | lr=1.00e-04 | Acc=0.9723\n",
            "Early stopping at iter=1964 (best@1954 total=0.001323).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.015901 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004343 | OT=0.004272 | Ortho=0.006436 | Graph=63.389695 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003191 | OT=0.003154 | Ortho=0.003142 | Graph=56.952947 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.002502 | OT=0.002482 | Ortho=0.001557 | Graph=48.820848 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  2000] total=0.001776 | OT=0.001762 | Ortho=0.000983 | Graph=43.093063 | lr=1.00e-04 | Acc=0.9780\n",
            "Early stopping at iter=2400 (best@2390 total=0.001512).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.016044 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004360 | OT=0.004294 | Ortho=0.005976 | Graph=63.312181 | lr=1.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=946 (best@936 total=0.003380).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.007475 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.002973 | OT=0.002948 | Ortho=0.002448 | Graph=64.908510 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.002172 | OT=0.002159 | Ortho=0.001301 | Graph=56.462051 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1500] total=0.001633 | OT=0.001627 | Ortho=0.000573 | Graph=48.139181 | lr=1.00e-04 | Acc=0.9723\n",
            "Early stopping at iter=1780 (best@1770 total=0.001456).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.015895 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004338 | OT=0.004273 | Ortho=0.006434 | Graph=63.397064 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.003199 | OT=0.003166 | Ortho=0.003246 | Graph=57.005590 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.002508 | OT=0.002490 | Ortho=0.001699 | Graph=48.571066 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2000] total=0.001758 | OT=0.001747 | Ortho=0.001031 | Graph=43.114169 | lr=1.00e-04 | Acc=0.9799\n",
            "Early stopping at iter=2194 (best@2184 total=0.001598).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.016038 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004350 | OT=0.004290 | Ortho=0.005933 | Graph=63.314358 | lr=1.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=963 (best@953 total=0.003388).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.076240 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=442 (best@442 total=0.009947).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.084660 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=451 (best@451 total=0.009945).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.084803 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=442 (best@442 total=0.009945).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.014351 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.006830 | OT=0.001364 | Ortho=2.811032 | Graph=26.548448 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.004115 | OT=0.000978 | Ortho=0.914966 | Graph=22.222347 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1500] total=0.003117 | OT=0.000773 | Ortho=0.493072 | Graph=18.514264 | lr=1.00e-04 | Acc=0.9723\n",
            "[Iter  2000] total=0.002444 | OT=0.000668 | Ortho=0.255911 | Graph=15.200630 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  2500] total=0.002016 | OT=0.000559 | Ortho=0.146937 | Graph=13.104191 | lr=1.00e-04 | Acc=0.9675\n",
            "Early stopping at iter=2673 (best@2663 total=0.001939).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.022771 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.007482 | OT=0.000826 | Ortho=4.545234 | Graph=21.110514 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.005506 | OT=0.000881 | Ortho=2.628086 | Graph=19.967389 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1500] total=0.004079 | OT=0.001089 | Ortho=0.813519 | Graph=21.769362 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  2000] total=0.003305 | OT=0.000914 | Ortho=0.526768 | Graph=18.642034 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2500] total=0.002608 | OT=0.000732 | Ortho=0.287622 | Graph=15.881255 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  3000] total=0.002149 | OT=0.000633 | Ortho=0.132675 | Graph=13.827532 | lr=1.00e-04 | Acc=0.9360\n",
            "[Iter  3500] total=0.001927 | OT=0.000546 | Ortho=0.121629 | Graph=12.594199 | lr=1.00e-04 | Acc=0.9465\n",
            "[Iter  4000] total=0.001676 | OT=0.000444 | Ortho=0.091360 | Graph=11.408246 | lr=1.00e-04 | Acc=0.9303\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.022914 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.007443 | OT=0.000907 | Ortho=4.388904 | Graph=21.473521 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.005466 | OT=0.000921 | Ortho=2.455790 | Graph=20.900081 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1500] total=0.004002 | OT=0.001054 | Ortho=0.797052 | Graph=21.503994 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  2000] total=0.003247 | OT=0.000875 | Ortho=0.520604 | Graph=18.515177 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2500] total=0.002614 | OT=0.000729 | Ortho=0.320083 | Graph=15.653417 | lr=1.00e-04 | Acc=0.9723\n",
            "[Iter  3000] total=0.002106 | OT=0.000598 | Ortho=0.143836 | Graph=13.640804 | lr=1.00e-04 | Acc=0.9427\n",
            "Early stopping at iter=3182 (best@3172 total=0.002038).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.008162 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.003259 | OT=0.002473 | Ortho=0.235779 | Graph=55.042771 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.002304 | OT=0.001679 | Ortho=0.162225 | Graph=46.309232 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  1500] total=0.001693 | OT=0.001226 | Ortho=0.095385 | Graph=37.111295 | lr=1.00e-04 | Acc=0.9685\n",
            "[Iter  2000] total=0.001323 | OT=0.000959 | Ortho=0.059337 | Graph=30.473815 | lr=1.00e-04 | Acc=0.9675\n",
            "Early stopping at iter=2092 (best@2082 total=0.001280).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.016582 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004693 | OT=0.001982 | Ortho=2.266964 | Graph=44.311056 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1000] total=0.003655 | OT=0.001699 | Ortho=1.525631 | Graph=43.062052 | lr=1.00e-04 | Acc=0.9723\n",
            "[Iter  1500] total=0.002175 | OT=0.001578 | Ortho=0.195492 | Graph=40.165671 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2000] total=0.001640 | OT=0.001195 | Ortho=0.100153 | Graph=34.533886 | lr=1.00e-04 | Acc=0.9742\n",
            "Early stopping at iter=2159 (best@2149 total=0.001531).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.016725 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004739 | OT=0.002039 | Ortho=2.252903 | Graph=44.636916 | lr=1.00e-04 | Acc=0.9723\n",
            "[Iter  1000] total=0.003722 | OT=0.001766 | Ortho=1.524736 | Graph=43.119510 | lr=1.00e-04 | Acc=0.9713\n",
            "[Iter  1500] total=0.002442 | OT=0.001803 | Ortho=0.213141 | Graph=42.608389 | lr=1.00e-04 | Acc=0.9656\n",
            "[Iter  2000] total=0.001861 | OT=0.001383 | Ortho=0.115321 | Graph=36.263629 | lr=1.00e-04 | Acc=0.9589\n",
            "[Iter  2500] total=0.001428 | OT=0.001052 | Ortho=0.061877 | Graph=31.410334 | lr=1.00e-04 | Acc=0.9599\n",
            "[Iter  3000] total=0.001290 | OT=0.000950 | Ortho=0.045654 | Graph=29.472215 | lr=5.00e-05 | Acc=0.9608\n",
            "[Iter  3500] total=0.001201 | OT=0.000878 | Ortho=0.041835 | Graph=28.181419 | lr=5.00e-05 | Acc=0.9608\n",
            "[Iter  4000] total=0.001117 | OT=0.000814 | Ortho=0.033727 | Graph=26.966415 | lr=5.00e-05 | Acc=0.9628\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.007543 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.002772 | OT=0.002554 | Ortho=0.159884 | Graph=58.203579 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.001984 | OT=0.001828 | Ortho=0.105163 | Graph=50.718481 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  1500] total=0.001492 | OT=0.001376 | Ortho=0.073664 | Graph=42.540203 | lr=1.00e-04 | Acc=0.9713\n",
            "[Iter  2000] total=0.001149 | OT=0.001074 | Ortho=0.039334 | Graph=35.788263 | lr=1.00e-04 | Acc=0.9675\n",
            "Early stopping at iter=2078 (best@2068 total=0.001126).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.015963 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004312 | OT=0.002069 | Ortho=2.195775 | Graph=46.530113 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  1000] total=0.003409 | OT=0.001768 | Ortho=1.595716 | Graph=45.578437 | lr=1.00e-04 | Acc=0.9723\n",
            "[Iter  1500] total=0.001926 | OT=0.001734 | Ortho=0.148927 | Graph=43.237375 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2000] total=0.001432 | OT=0.001321 | Ortho=0.072416 | Graph=38.522557 | lr=1.00e-04 | Acc=0.9685\n",
            "[Iter  2500] total=0.001116 | OT=0.001042 | Ortho=0.038986 | Graph=35.275967 | lr=1.00e-04 | Acc=0.9694\n",
            "Early stopping at iter=2747 (best@2737 total=0.001029).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.016106 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004343 | OT=0.002124 | Ortho=2.171589 | Graph=46.940101 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1000] total=0.003491 | OT=0.001882 | Ortho=1.563724 | Graph=45.485649 | lr=1.00e-04 | Acc=0.9666\n",
            "[Iter  1500] total=0.002125 | OT=0.001920 | Ortho=0.158315 | Graph=46.726444 | lr=1.00e-04 | Acc=0.9656\n",
            "[Iter  2000] total=0.001693 | OT=0.001556 | Ortho=0.095232 | Graph=42.252502 | lr=1.00e-04 | Acc=0.9647\n",
            "[Iter  2500] total=0.001369 | OT=0.001267 | Ortho=0.064153 | Graph=37.573160 | lr=1.00e-04 | Acc=0.9628\n",
            "[Iter  3000] total=0.001117 | OT=0.001039 | Ortho=0.043900 | Graph=33.986879 | lr=1.00e-04 | Acc=0.9599\n",
            "Early stopping at iter=3087 (best@3077 total=0.001088).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.007481 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.002723 | OT=0.002564 | Ortho=0.153131 | Graph=58.332912 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.001945 | OT=0.001839 | Ortho=0.100679 | Graph=51.098066 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1500] total=0.001450 | OT=0.001380 | Ortho=0.066284 | Graph=42.700565 | lr=1.00e-04 | Acc=0.9723\n",
            "Early stopping at iter=1574 (best@1564 total=0.001403).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.015901 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004277 | OT=0.002079 | Ortho=2.192746 | Graph=46.573531 | lr=1.00e-04 | Acc=0.9694\n",
            "[Iter  1000] total=0.003431 | OT=0.001804 | Ortho=1.622286 | Graph=45.909283 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  1500] total=0.001911 | OT=0.001759 | Ortho=0.147982 | Graph=43.683653 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  2000] total=0.001398 | OT=0.001325 | Ortho=0.069569 | Graph=39.031389 | lr=1.00e-04 | Acc=0.9694\n",
            "Early stopping at iter=2342 (best@2332 total=0.001208).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.016044 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004312 | OT=0.002140 | Ortho=2.168056 | Graph=47.038973 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  1000] total=0.003332 | OT=0.001770 | Ortho=1.557829 | Graph=45.342717 | lr=1.00e-04 | Acc=0.9675\n",
            "[Iter  1500] total=0.001972 | OT=0.001839 | Ortho=0.127944 | Graph=45.530259 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  2000] total=0.001561 | OT=0.001483 | Ortho=0.073792 | Graph=41.129222 | lr=1.00e-04 | Acc=0.9675\n",
            "Early stopping at iter=2256 (best@2246 total=0.001416).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.007475 | OT=0.007474 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.002718 | OT=0.002566 | Ortho=0.152260 | Graph=58.377096 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.001941 | OT=0.001839 | Ortho=0.100725 | Graph=51.148354 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1500] total=0.001466 | OT=0.001405 | Ortho=0.059660 | Graph=43.333204 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  2000] total=0.001174 | OT=0.001133 | Ortho=0.040638 | Graph=37.605800 | lr=1.00e-04 | Acc=0.9694\n",
            "[Iter  2500] total=0.001025 | OT=0.000996 | Ortho=0.028183 | Graph=35.064187 | lr=5.00e-05 | Acc=0.9694\n",
            "[Iter  3000] total=0.000896 | OT=0.000869 | Ortho=0.027089 | Graph=31.910792 | lr=5.00e-05 | Acc=0.9704\n",
            "[Iter  3500] total=0.000791 | OT=0.000767 | Ortho=0.024469 | Graph=29.707431 | lr=5.00e-05 | Acc=0.9666\n",
            "[Iter  4000] total=0.000732 | OT=0.000713 | Ortho=0.018850 | Graph=28.750334 | lr=2.50e-05 | Acc=0.9675\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.015895 | OT=0.015894 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004273 | OT=0.002082 | Ortho=2.191262 | Graph=46.582423 | lr=1.00e-04 | Acc=0.9694\n",
            "[Iter  1000] total=0.003423 | OT=0.001801 | Ortho=1.621428 | Graph=45.891780 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1500] total=0.001900 | OT=0.001750 | Ortho=0.149565 | Graph=43.579035 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2000] total=0.001388 | OT=0.001317 | Ortho=0.070726 | Graph=38.920074 | lr=1.00e-04 | Acc=0.9694\n",
            "[Iter  2500] total=0.001091 | OT=0.001050 | Ortho=0.040954 | Graph=35.517905 | lr=1.00e-04 | Acc=0.9704\n",
            "Early stopping at iter=2664 (best@2654 total=0.001039).\n",
            "\n",
            ">>> Hyperparams: p=5, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.016038 | OT=0.016037 | Ortho=0.000000 | Graph=68.765502 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter   500] total=0.004316 | OT=0.002149 | Ortho=2.166330 | Graph=47.183994 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  1000] total=0.003285 | OT=0.001752 | Ortho=1.533101 | Graph=45.563164 | lr=1.00e-04 | Acc=0.9694\n",
            "[Iter  1500] total=0.001980 | OT=0.001836 | Ortho=0.143863 | Graph=45.321634 | lr=1.00e-04 | Acc=0.9694\n",
            "Early stopping at iter=1957 (best@1947 total=0.001590).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.122995 | OT=0.010338 | Ortho=0.000244 | Graph=112.413265 | lr=5.00e-05 | Acc=0.9904\n",
            "[Iter  1000] total=0.111029 | OT=0.009818 | Ortho=0.000220 | Graph=100.990968 | lr=5.00e-05 | Acc=0.9866\n",
            "[Iter  1500] total=0.091098 | OT=0.009016 | Ortho=0.000165 | Graph=81.917292 | lr=5.00e-05 | Acc=0.9828\n",
            "[Iter  2000] total=0.072350 | OT=0.007788 | Ortho=0.000124 | Graph=64.438145 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  2500] total=0.060916 | OT=0.006735 | Ortho=0.000213 | Graph=53.967418 | lr=5.00e-05 | Acc=0.9819\n",
            "[Iter  3000] total=0.052238 | OT=0.005905 | Ortho=0.000075 | Graph=46.257667 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  3500] total=0.043326 | OT=0.004969 | Ortho=0.000062 | Graph=38.295285 | lr=5.00e-05 | Acc=0.9828\n",
            "[Iter  4000] total=0.036783 | OT=0.004099 | Ortho=0.000041 | Graph=32.642549 | lr=5.00e-05 | Acc=0.9790\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.133979 | OT=0.023883 | Ortho=0.000315 | Graph=109.781176 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.100486 | OT=0.016060 | Ortho=0.000228 | Graph=84.197772 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.075491 | OT=0.010965 | Ortho=0.000337 | Graph=64.188948 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  2000] total=0.058555 | OT=0.007507 | Ortho=0.000093 | Graph=50.954409 | lr=1.00e-04 | Acc=0.9799\n",
            "Early stopping at iter=2079 (best@2069 total=0.056959).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.135074 | OT=0.024454 | Ortho=0.000315 | Graph=110.305511 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.101178 | OT=0.016461 | Ortho=0.000221 | Graph=84.496134 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.076147 | OT=0.011211 | Ortho=0.000150 | Graph=64.786118 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  2000] total=0.060881 | OT=0.007989 | Ortho=0.000107 | Graph=52.785697 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  2500] total=0.050022 | OT=0.006088 | Ortho=0.000122 | Graph=43.812219 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  3000] total=0.041020 | OT=0.005063 | Ortho=0.000053 | Graph=35.904650 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=3088 (best@3078 total=0.039766).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.021952 | OT=0.010448 | Ortho=0.000006 | Graph=114.979514 | lr=2.50e-05 | Acc=0.9885\n",
            "Early stopping at iter=914 (best@914 total=0.021853).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.035993 | OT=0.024499 | Ortho=0.000032 | Graph=114.617151 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=782 (best@772 total=0.034624).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.036416 | OT=0.024918 | Ortho=0.000034 | Graph=114.638438 | lr=1.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=786 (best@776 total=0.035009).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.011535 | OT=0.010382 | Ortho=0.000002 | Graph=115.066228 | lr=5.00e-05 | Acc=0.9895\n",
            "[Iter  1000] total=0.011437 | OT=0.010284 | Ortho=0.000002 | Graph=115.044390 | lr=3.13e-06 | Acc=0.9876\n",
            "Early stopping at iter=1026 (best@1026 total=0.011437).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=374 (best@364 total=0.026331).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.026108 | OT=0.024934 | Ortho=0.000025 | Graph=114.902542 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=688 (best@678 total=0.025324).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010500 | OT=0.010383 | Ortho=0.000002 | Graph=115.080685 | lr=5.00e-05 | Acc=0.9895\n",
            "[Iter  1000] total=0.010411 | OT=0.010294 | Ortho=0.000002 | Graph=115.076596 | lr=2.50e-05 | Acc=0.9885\n",
            "[Iter  1500] total=0.010349 | OT=0.010231 | Ortho=0.000002 | Graph=115.066237 | lr=2.50e-05 | Acc=0.9876\n",
            "[Iter  2000] total=0.010264 | OT=0.010147 | Ortho=0.000002 | Graph=115.034264 | lr=2.50e-05 | Acc=0.9876\n",
            "Early stopping at iter=2416 (best@2416 total=0.010191).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.025424 | OT=0.025285 | Ortho=0.000024 | Graph=115.045974 | lr=5.00e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.023986 | OT=0.023848 | Ortho=0.000023 | Graph=114.734294 | lr=5.00e-05 | Acc=0.9847\n",
            "[Iter  1500] total=0.022086 | OT=0.021951 | Ortho=0.000021 | Graph=113.546972 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  2000] total=0.019303 | OT=0.019174 | Ortho=0.000018 | Graph=110.697646 | lr=5.00e-05 | Acc=0.9876\n",
            "[Iter  2500] total=0.016373 | OT=0.016253 | Ortho=0.000014 | Graph=106.233849 | lr=5.00e-05 | Acc=0.9885\n",
            "[Iter  3000] total=0.014872 | OT=0.014760 | Ortho=0.000009 | Graph=102.981550 | lr=2.50e-05 | Acc=0.9876\n",
            "[Iter  3500] total=0.013671 | OT=0.013564 | Ortho=0.000007 | Graph=99.863360 | lr=2.50e-05 | Acc=0.9866\n",
            "[Iter  4000] total=0.012404 | OT=0.012303 | Ortho=0.000006 | Graph=96.264373 | lr=2.50e-05 | Acc=0.9847\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.025089 | OT=0.024948 | Ortho=0.000026 | Graph=114.930041 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=607 (best@597 total=0.024681).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010397 | OT=0.010383 | Ortho=0.000002 | Graph=115.082280 | lr=5.00e-05 | Acc=0.9895\n",
            "Early stopping at iter=910 (best@910 total=0.010321).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.025318 | OT=0.025283 | Ortho=0.000024 | Graph=115.047065 | lr=5.00e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.023886 | OT=0.023851 | Ortho=0.000023 | Graph=114.741420 | lr=5.00e-05 | Acc=0.9847\n",
            "[Iter  1500] total=0.021992 | OT=0.021960 | Ortho=0.000020 | Graph=113.566306 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  2000] total=0.019213 | OT=0.019185 | Ortho=0.000017 | Graph=110.730644 | lr=5.00e-05 | Acc=0.9876\n",
            "Early stopping at iter=2417 (best@2407 total=0.016741).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.025001 | OT=0.024959 | Ortho=0.000031 | Graph=114.936877 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=546 (best@536 total=0.024847).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010386 | OT=0.010383 | Ortho=0.000002 | Graph=115.082425 | lr=5.00e-05 | Acc=0.9895\n",
            "[Iter  1000] total=0.010282 | OT=0.010278 | Ortho=0.000003 | Graph=115.075730 | lr=5.00e-05 | Acc=0.9876\n",
            "Early stopping at iter=1267 (best@1267 total=0.010235).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.025308 | OT=0.025283 | Ortho=0.000024 | Graph=115.047205 | lr=5.00e-05 | Acc=0.9876\n",
            "[Iter  1000] total=0.023875 | OT=0.023851 | Ortho=0.000023 | Graph=114.741675 | lr=5.00e-05 | Acc=0.9847\n",
            "[Iter  1500] total=0.021981 | OT=0.021960 | Ortho=0.000020 | Graph=113.566963 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  2000] total=0.019210 | OT=0.019193 | Ortho=0.000016 | Graph=110.744722 | lr=5.00e-05 | Acc=0.9876\n",
            "[Iter  2500] total=0.016281 | OT=0.016261 | Ortho=0.000019 | Graph=106.278318 | lr=5.00e-05 | Acc=0.9885\n",
            "Early stopping at iter=2510 (best@2500 total=0.016281).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.024977 | OT=0.024951 | Ortho=0.000025 | Graph=114.934438 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=531 (best@521 total=0.024897).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.059595 | OT=0.006397 | Ortho=0.009793 | Graph=52.219019 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.029470 | OT=0.004349 | Ortho=0.002504 | Graph=24.870854 | lr=1.00e-04 | Acc=0.9341\n",
            "[Iter  1500] total=0.023372 | OT=0.003536 | Ortho=0.001134 | Graph=19.722169 | lr=1.00e-04 | Acc=0.9160\n",
            "[Iter  2000] total=0.019333 | OT=0.002187 | Ortho=0.000762 | Graph=17.070553 | lr=1.00e-04 | Acc=0.9398\n",
            "[Iter  2500] total=0.016544 | OT=0.001730 | Ortho=0.000487 | Graph=14.765203 | lr=1.00e-04 | Acc=0.9331\n",
            "[Iter  3000] total=0.015103 | OT=0.001505 | Ortho=0.000412 | Graph=13.556944 | lr=1.00e-04 | Acc=0.9207\n",
            "[Iter  3500] total=0.013800 | OT=0.001272 | Ortho=0.000348 | Graph=12.493646 | lr=1.00e-04 | Acc=0.9265\n",
            "[Iter  4000] total=0.012754 | OT=0.001110 | Ortho=0.000300 | Graph=11.613680 | lr=1.00e-04 | Acc=0.9169\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.066281 | OT=0.008973 | Ortho=0.012115 | Graph=56.096538 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1000] total=0.031986 | OT=0.004340 | Ortho=0.003073 | Graph=27.338688 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  1500] total=0.024382 | OT=0.003033 | Ortho=0.001360 | Graph=21.212170 | lr=1.00e-04 | Acc=0.9628\n",
            "[Iter  2000] total=0.019730 | OT=0.002054 | Ortho=0.000770 | Graph=17.599237 | lr=1.00e-04 | Acc=0.9542\n",
            "[Iter  2500] total=0.017827 | OT=0.001832 | Ortho=0.000575 | Graph=15.937367 | lr=1.00e-04 | Acc=0.9551\n",
            "[Iter  3000] total=0.016410 | OT=0.001660 | Ortho=0.000492 | Graph=14.700750 | lr=1.00e-04 | Acc=0.9570\n",
            "[Iter  3500] total=0.014885 | OT=0.001388 | Ortho=0.000411 | Graph=13.455690 | lr=1.00e-04 | Acc=0.9570\n",
            "[Iter  4000] total=0.013573 | OT=0.001141 | Ortho=0.000347 | Graph=12.396814 | lr=1.00e-04 | Acc=0.9561\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.066356 | OT=0.008823 | Ortho=0.012172 | Graph=56.316029 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.032116 | OT=0.004264 | Ortho=0.003059 | Graph=27.546568 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.024548 | OT=0.003047 | Ortho=0.001376 | Graph=21.363269 | lr=1.00e-04 | Acc=0.9618\n",
            "[Iter  2000] total=0.019855 | OT=0.002078 | Ortho=0.000775 | Graph=17.698932 | lr=1.00e-04 | Acc=0.9599\n",
            "[Iter  2500] total=0.017925 | OT=0.001825 | Ortho=0.000585 | Graph=16.041481 | lr=1.00e-04 | Acc=0.9561\n",
            "[Iter  3000] total=0.016507 | OT=0.001684 | Ortho=0.000503 | Graph=14.773592 | lr=1.00e-04 | Acc=0.9570\n",
            "[Iter  3500] total=0.014971 | OT=0.001428 | Ortho=0.000417 | Graph=13.501882 | lr=1.00e-04 | Acc=0.9580\n",
            "[Iter  4000] total=0.013658 | OT=0.001182 | Ortho=0.000350 | Graph=12.440540 | lr=1.00e-04 | Acc=0.9570\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.020465 | OT=0.009424 | Ortho=0.000621 | Graph=109.789304 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.015086 | OT=0.006604 | Ortho=0.000367 | Graph=84.462235 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.010995 | OT=0.004569 | Ortho=0.000264 | Graph=63.991343 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  2000] total=0.008175 | OT=0.003256 | Ortho=0.000208 | Graph=48.983029 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  2500] total=0.006545 | OT=0.002542 | Ortho=0.000140 | Graph=39.884347 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  3000] total=0.005155 | OT=0.001934 | Ortho=0.000081 | Graph=32.129945 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  3500] total=0.004364 | OT=0.001603 | Ortho=0.000077 | Graph=27.534877 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  4000] total=0.003682 | OT=0.001338 | Ortho=0.000031 | Graph=23.414558 | lr=1.00e-04 | Acc=0.9790\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.024320 | OT=0.014237 | Ortho=0.001487 | Graph=99.341353 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1000] total=0.014435 | OT=0.006897 | Ortho=0.000498 | Graph=74.885410 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.010526 | OT=0.004482 | Ortho=0.000293 | Graph=60.155459 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2000] total=0.008189 | OT=0.003452 | Ortho=0.000194 | Graph=47.173668 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  2500] total=0.006268 | OT=0.002578 | Ortho=0.000276 | Graph=36.622771 | lr=1.00e-04 | Acc=0.9838\n",
            "Early stopping at iter=2742 (best@2732 total=0.005680).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.024019 | OT=0.013962 | Ortho=0.001531 | Graph=99.038291 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.014265 | OT=0.006763 | Ortho=0.000521 | Graph=74.499137 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.010351 | OT=0.004356 | Ortho=0.000316 | Graph=59.627033 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  2000] total=0.007202 | OT=0.002873 | Ortho=0.000169 | Graph=43.122547 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=2179 (best@2169 total=0.006581).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010852 | OT=0.009685 | Ortho=0.000264 | Graph=113.995280 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.009045 | OT=0.007958 | Ortho=0.000240 | Graph=106.206560 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.007313 | OT=0.006353 | Ortho=0.000235 | Graph=93.664656 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  2000] total=0.006178 | OT=0.005331 | Ortho=0.000060 | Graph=84.068316 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  2500] total=0.005454 | OT=0.004667 | Ortho=0.000053 | Graph=78.151247 | lr=5.00e-05 | Acc=0.9819\n",
            "[Iter  3000] total=0.004687 | OT=0.003982 | Ortho=0.000045 | Graph=70.062325 | lr=5.00e-05 | Acc=0.9838\n",
            "[Iter  3500] total=0.003788 | OT=0.003178 | Ortho=0.000038 | Graph=60.623493 | lr=5.00e-05 | Acc=0.9838\n",
            "[Iter  4000] total=0.003187 | OT=0.002640 | Ortho=0.000085 | Graph=53.778438 | lr=5.00e-05 | Acc=0.9809\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.016772 | OT=0.015616 | Ortho=0.001032 | Graph=105.329136 | lr=1.00e-04 | Acc=0.9885\n",
            "[Iter  1000] total=0.008906 | OT=0.008048 | Ortho=0.000239 | Graph=83.382551 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.006036 | OT=0.005298 | Ortho=0.000115 | Graph=72.633535 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  2000] total=0.004799 | OT=0.004136 | Ortho=0.000079 | Graph=65.489929 | lr=1.00e-04 | Acc=0.9799\n",
            "Early stopping at iter=2020 (best@2010 total=0.004787).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.016288 | OT=0.015137 | Ortho=0.001017 | Graph=104.985375 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.009165 | OT=0.008300 | Ortho=0.000266 | Graph=83.828323 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.006069 | OT=0.005330 | Ortho=0.000098 | Graph=72.921096 | lr=1.00e-04 | Acc=0.9838\n",
            "Early stopping at iter=1734 (best@1724 total=0.005437).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009838 | OT=0.009702 | Ortho=0.000217 | Graph=114.253468 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.008242 | OT=0.008124 | Ortho=0.000107 | Graph=108.012391 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.006632 | OT=0.006524 | Ortho=0.000116 | Graph=96.637588 | lr=1.00e-04 | Acc=0.9866\n",
            "Early stopping at iter=1510 (best@1500 total=0.006632).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.016044 | OT=0.015832 | Ortho=0.001060 | Graph=105.966222 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.008397 | OT=0.008256 | Ortho=0.000565 | Graph=84.492466 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.005611 | OT=0.005527 | Ortho=0.000099 | Graph=74.287187 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=1701 (best@1691 total=0.005050).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015495 | OT=0.015292 | Ortho=0.000976 | Graph=105.802686 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.008878 | OT=0.008756 | Ortho=0.000366 | Graph=86.066646 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1500] total=0.005690 | OT=0.005607 | Ortho=0.000090 | Graph=73.809828 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=1982 (best@1972 total=0.004434).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009736 | OT=0.009702 | Ortho=0.000227 | Graph=114.275142 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.008160 | OT=0.008139 | Ortho=0.000106 | Graph=108.174181 | lr=1.00e-04 | Acc=0.9876\n",
            "Early stopping at iter=1371 (best@1361 total=0.006922).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015968 | OT=0.015852 | Ortho=0.001053 | Graph=106.014372 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.008383 | OT=0.008353 | Ortho=0.000217 | Graph=84.750419 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.005577 | OT=0.005560 | Ortho=0.000089 | Graph=74.463686 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=1845 (best@1835 total=0.004701).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015405 | OT=0.015298 | Ortho=0.000964 | Graph=105.852688 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.008816 | OT=0.008777 | Ortho=0.000306 | Graph=86.208463 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1500] total=0.005717 | OT=0.005700 | Ortho=0.000101 | Graph=74.073069 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=1653 (best@1643 total=0.005205).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009726 | OT=0.009702 | Ortho=0.000227 | Graph=114.277602 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.008150 | OT=0.008139 | Ortho=0.000106 | Graph=108.180079 | lr=1.00e-04 | Acc=0.9876\n",
            "[Iter  1500] total=0.006594 | OT=0.006587 | Ortho=0.000055 | Graph=97.333720 | lr=5.00e-05 | Acc=0.9857\n",
            "[Iter  2000] total=0.005949 | OT=0.005943 | Ortho=0.000049 | Graph=91.609012 | lr=5.00e-05 | Acc=0.9819\n",
            "[Iter  2500] total=0.005131 | OT=0.005126 | Ortho=0.000043 | Graph=84.140567 | lr=5.00e-05 | Acc=0.9809\n",
            "[Iter  3000] total=0.004444 | OT=0.004440 | Ortho=0.000035 | Graph=77.471843 | lr=5.00e-05 | Acc=0.9847\n",
            "[Iter  3500] total=0.003784 | OT=0.003780 | Ortho=0.000028 | Graph=70.617510 | lr=5.00e-05 | Acc=0.9866\n",
            "[Iter  4000] total=0.003161 | OT=0.003159 | Ortho=0.000020 | Graph=63.586062 | lr=5.00e-05 | Acc=0.9838\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015963 | OT=0.015857 | Ortho=0.001046 | Graph=106.020950 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.008354 | OT=0.008332 | Ortho=0.000217 | Graph=84.689941 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.005578 | OT=0.005556 | Ortho=0.000204 | Graph=74.466586 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=1798 (best@1788 total=0.004790).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.1, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015393 | OT=0.015295 | Ortho=0.000970 | Graph=105.850824 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.008777 | OT=0.008750 | Ortho=0.000268 | Graph=86.112044 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1500] total=0.005703 | OT=0.005690 | Ortho=0.000125 | Graph=74.016726 | lr=1.00e-04 | Acc=0.9857\n",
            "Early stopping at iter=1682 (best@1672 total=0.005112).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.050322 | OT=0.005123 | Ortho=0.925019 | Graph=35.948125 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.022605 | OT=0.002326 | Ortho=0.122913 | Graph=19.049231 | lr=1.00e-04 | Acc=0.8577\n",
            "[Iter  1500] total=0.019559 | OT=0.001927 | Ortho=0.078948 | Graph=16.843122 | lr=1.00e-04 | Acc=0.8930\n",
            "[Iter  2000] total=0.016916 | OT=0.001636 | Ortho=0.057910 | Graph=14.700222 | lr=1.00e-04 | Acc=0.9007\n",
            "[Iter  2500] total=0.015012 | OT=0.001474 | Ortho=0.043526 | Graph=13.102709 | lr=1.00e-04 | Acc=0.9140\n",
            "[Iter  3000] total=0.013723 | OT=0.001300 | Ortho=0.036217 | Graph=12.060727 | lr=1.00e-04 | Acc=0.9026\n",
            "[Iter  3500] total=0.012637 | OT=0.001167 | Ortho=0.031596 | Graph=11.154665 | lr=1.00e-04 | Acc=0.9054\n",
            "[Iter  4000] total=0.011568 | OT=0.001026 | Ortho=0.026944 | Graph=10.272847 | lr=1.00e-04 | Acc=0.9054\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.055930 | OT=0.006174 | Ortho=1.141641 | Graph=38.340046 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.028787 | OT=0.003488 | Ortho=0.295099 | Graph=22.347875 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1500] total=0.020480 | OT=0.002139 | Ortho=0.091917 | Graph=17.422253 | lr=1.00e-04 | Acc=0.9551\n",
            "[Iter  2000] total=0.018241 | OT=0.001881 | Ortho=0.066085 | Graph=15.699443 | lr=1.00e-04 | Acc=0.9570\n",
            "[Iter  2500] total=0.016464 | OT=0.001682 | Ortho=0.051514 | Graph=14.266583 | lr=1.00e-04 | Acc=0.9427\n",
            "[Iter  3000] total=0.015254 | OT=0.001554 | Ortho=0.042698 | Graph=13.272983 | lr=1.00e-04 | Acc=0.9303\n",
            "[Iter  3500] total=0.014096 | OT=0.001322 | Ortho=0.038055 | Graph=12.393525 | lr=1.00e-04 | Acc=0.9341\n",
            "[Iter  4000] total=0.012864 | OT=0.001108 | Ortho=0.033041 | Graph=11.425371 | lr=1.00e-04 | Acc=0.9331\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.055986 | OT=0.006144 | Ortho=1.137013 | Graph=38.471620 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.027874 | OT=0.003279 | Ortho=0.278545 | Graph=21.809138 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1500] total=0.020665 | OT=0.002120 | Ortho=0.095210 | Graph=17.593053 | lr=1.00e-04 | Acc=0.9351\n",
            "[Iter  2000] total=0.018248 | OT=0.001869 | Ortho=0.066771 | Graph=15.711493 | lr=1.00e-04 | Acc=0.9513\n",
            "[Iter  2500] total=0.016404 | OT=0.001637 | Ortho=0.051404 | Graph=14.253486 | lr=1.00e-04 | Acc=0.9370\n",
            "[Iter  3000] total=0.015190 | OT=0.001469 | Ortho=0.042320 | Graph=13.297560 | lr=1.00e-04 | Acc=0.9074\n",
            "[Iter  3500] total=0.014059 | OT=0.001265 | Ortho=0.037805 | Graph=12.415649 | lr=1.00e-04 | Acc=0.9035\n",
            "[Iter  4000] total=0.012863 | OT=0.001092 | Ortho=0.032633 | Graph=11.444355 | lr=1.00e-04 | Acc=0.9016\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.013136 | OT=0.005412 | Ortho=0.032961 | Graph=73.948424 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1000] total=0.007051 | OT=0.002652 | Ortho=0.015420 | Graph=42.441765 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.005016 | OT=0.001911 | Ortho=0.007503 | Graph=30.308856 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  2000] total=0.003978 | OT=0.001494 | Ortho=0.004208 | Graph=24.418989 | lr=1.00e-04 | Acc=0.9713\n",
            "[Iter  2500] total=0.003300 | OT=0.001184 | Ortho=0.002290 | Graph=20.933919 | lr=1.00e-04 | Acc=0.9742\n",
            "Early stopping at iter=2939 (best@2929 total=0.002998).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.016504 | OT=0.008104 | Ortho=0.067775 | Graph=77.220530 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.009436 | OT=0.003935 | Ortho=0.025057 | Graph=52.501796 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.006440 | OT=0.002571 | Ortho=0.010720 | Graph=37.614815 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  2000] total=0.005079 | OT=0.002018 | Ortho=0.006098 | Graph=30.000580 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  2500] total=0.004297 | OT=0.001698 | Ortho=0.004030 | Graph=25.585085 | lr=1.00e-04 | Acc=0.9694\n",
            "Early stopping at iter=2800 (best@2790 total=0.004058).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.016372 | OT=0.008038 | Ortho=0.067623 | Graph=76.582576 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.009089 | OT=0.003670 | Ortho=0.024199 | Graph=51.777599 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1500] total=0.006597 | OT=0.002559 | Ortho=0.011808 | Graph=39.198975 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  2000] total=0.005347 | OT=0.002063 | Ortho=0.007023 | Graph=32.143320 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  2500] total=0.004554 | OT=0.001748 | Ortho=0.005057 | Graph=27.556204 | lr=1.00e-04 | Acc=0.9885\n",
            "[Iter  3000] total=0.003971 | OT=0.001489 | Ortho=0.003532 | Graph=24.463744 | lr=1.00e-04 | Acc=0.9838\n",
            "Early stopping at iter=3040 (best@3030 total=0.003940).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.007975 | OT=0.006928 | Ortho=0.007044 | Graph=97.636997 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.004780 | OT=0.004018 | Ortho=0.004910 | Graph=71.273305 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1500] total=0.003232 | OT=0.002669 | Ortho=0.002248 | Graph=54.050720 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2000] total=0.002409 | OT=0.001963 | Ortho=0.001096 | Graph=43.430275 | lr=1.00e-04 | Acc=0.9742\n",
            "Early stopping at iter=2335 (best@2325 total=0.002157).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010949 | OT=0.009751 | Ortho=0.031781 | Graph=88.066131 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.005590 | OT=0.004817 | Ortho=0.008297 | Graph=68.964034 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1500] total=0.004028 | OT=0.003407 | Ortho=0.004619 | Graph=57.473271 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2000] total=0.003144 | OT=0.002629 | Ortho=0.002459 | Graph=49.090865 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2500] total=0.002688 | OT=0.002231 | Ortho=0.001651 | Graph=44.040866 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=2723 (best@2713 total=0.002546).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.011405 | OT=0.010130 | Ortho=0.039014 | Graph=88.411167 | lr=1.00e-04 | Acc=0.9857\n",
            "[Iter  1000] total=0.005523 | OT=0.004767 | Ortho=0.007873 | Graph=67.811896 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.004026 | OT=0.003415 | Ortho=0.004691 | Graph=56.404051 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.003012 | OT=0.002520 | Ortho=0.003214 | Graph=45.925899 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=2003 (best@1993 total=0.003004).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.007233 | OT=0.007075 | Ortho=0.005746 | Graph=100.106012 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.004366 | OT=0.004254 | Ortho=0.003683 | Graph=75.296930 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.002858 | OT=0.002782 | Ortho=0.001914 | Graph=57.625558 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.002122 | OT=0.002065 | Ortho=0.000913 | Graph=47.172162 | lr=1.00e-04 | Acc=0.9752\n",
            "Early stopping at iter=2223 (best@2213 total=0.001935).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010137 | OT=0.009765 | Ortho=0.028332 | Graph=88.962721 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.005129 | OT=0.004988 | Ortho=0.007032 | Graph=70.339198 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003698 | OT=0.003602 | Ortho=0.003478 | Graph=60.285140 | lr=1.00e-04 | Acc=0.9828\n",
            "Early stopping at iter=1958 (best@1948 total=0.003050).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010857 | OT=0.010379 | Ortho=0.038821 | Graph=89.803057 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.005119 | OT=0.004975 | Ortho=0.007399 | Graph=69.954025 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  1500] total=0.003709 | OT=0.003610 | Ortho=0.003997 | Graph=59.690823 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2000] total=0.002830 | OT=0.002755 | Ortho=0.002366 | Graph=51.150456 | lr=1.00e-04 | Acc=0.9809\n",
            "Early stopping at iter=2168 (best@2158 total=0.002646).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.007153 | OT=0.007088 | Ortho=0.005551 | Graph=100.363527 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.004321 | OT=0.004277 | Ortho=0.003601 | Graph=75.698313 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.002797 | OT=0.002772 | Ortho=0.001898 | Graph=57.551195 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2000] total=0.002099 | OT=0.002085 | Ortho=0.000951 | Graph=47.779458 | lr=1.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=2010 (best@2000 total=0.002099).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010092 | OT=0.009800 | Ortho=0.028356 | Graph=89.100662 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.005082 | OT=0.005007 | Ortho=0.006762 | Graph=70.489110 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003639 | OT=0.003599 | Ortho=0.003471 | Graph=60.347501 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  2000] total=0.002958 | OT=0.002931 | Ortho=0.002179 | Graph=52.692279 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2500] total=0.002390 | OT=0.002370 | Ortho=0.001533 | Graph=46.491903 | lr=1.00e-04 | Acc=0.9828\n",
            "Early stopping at iter=2688 (best@2678 total=0.002275).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010805 | OT=0.010411 | Ortho=0.038485 | Graph=89.968342 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.005059 | OT=0.004981 | Ortho=0.007132 | Graph=70.126735 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003676 | OT=0.003631 | Ortho=0.003967 | Graph=60.086058 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.002810 | OT=0.002784 | Ortho=0.002118 | Graph=51.289320 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2500] total=0.002285 | OT=0.002267 | Ortho=0.001287 | Graph=46.033542 | lr=1.00e-04 | Acc=0.9847\n",
            "Early stopping at iter=2584 (best@2574 total=0.002220).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.007145 | OT=0.007089 | Ortho=0.005494 | Graph=100.406136 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1000] total=0.004315 | OT=0.004279 | Ortho=0.003544 | Graph=75.743563 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.002792 | OT=0.002772 | Ortho=0.001913 | Graph=57.601068 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2000] total=0.002095 | OT=0.002085 | Ortho=0.000882 | Graph=47.847064 | lr=1.00e-04 | Acc=0.9761\n",
            "Early stopping at iter=2137 (best@2127 total=0.001999).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010057 | OT=0.009777 | Ortho=0.027947 | Graph=89.056682 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  1000] total=0.005068 | OT=0.004999 | Ortho=0.006821 | Graph=70.504040 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003647 | OT=0.003613 | Ortho=0.003360 | Graph=60.428546 | lr=1.00e-04 | Acc=0.9828\n",
            "[Iter  2000] total=0.002948 | OT=0.002925 | Ortho=0.002304 | Graph=52.514549 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  2500] total=0.002392 | OT=0.002375 | Ortho=0.001641 | Graph=46.135263 | lr=1.00e-04 | Acc=0.9819\n",
            "Early stopping at iter=2865 (best@2855 total=0.002167).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.01, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010798 | OT=0.010413 | Ortho=0.038441 | Graph=89.982038 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1000] total=0.005059 | OT=0.004988 | Ortho=0.007013 | Graph=70.160759 | lr=1.00e-04 | Acc=0.9847\n",
            "[Iter  1500] total=0.003675 | OT=0.003635 | Ortho=0.003988 | Graph=60.268345 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  2000] total=0.002816 | OT=0.002796 | Ortho=0.001956 | Graph=51.595628 | lr=1.00e-04 | Acc=0.9780\n",
            "Early stopping at iter=2218 (best@2208 total=0.002561).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=0.1\n",
            "[Iter     1] total=0.126560 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015826 | OT=0.000005 | Ortho=15.645234 | Graph=0.175267 | lr=1.00e-04 | Acc=0.4957\n",
            "[Iter  1000] total=0.015345 | OT=0.000072 | Ortho=14.477115 | Graph=0.795996 | lr=1.00e-04 | Acc=0.3677\n",
            "[Iter  1500] total=0.014520 | OT=0.000157 | Ortho=12.272204 | Graph=2.090775 | lr=1.00e-04 | Acc=0.3973\n",
            "[Iter  2000] total=0.014017 | OT=0.000194 | Ortho=11.049811 | Graph=2.773182 | lr=1.00e-04 | Acc=0.4241\n",
            "[Iter  2500] total=0.013256 | OT=0.000310 | Ortho=9.403769 | Graph=3.542211 | lr=1.00e-04 | Acc=0.4747\n",
            "[Iter  3000] total=0.012314 | OT=0.000459 | Ortho=7.268410 | Graph=4.586244 | lr=1.00e-04 | Acc=0.4938\n",
            "[Iter  3500] total=0.011270 | OT=0.000511 | Ortho=5.459261 | Graph=5.300282 | lr=1.00e-04 | Acc=0.1824\n",
            "[Iter  4000] total=0.010144 | OT=0.000530 | Ortho=3.794723 | Graph=5.819046 | lr=1.00e-04 | Acc=0.1662\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=1.0\n",
            "[Iter     1] total=0.144549 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015848 | OT=0.000004 | Ortho=15.688316 | Graph=0.155675 | lr=1.00e-04 | Acc=0.5559\n",
            "[Iter  1000] total=0.015545 | OT=0.000050 | Ortho=14.948849 | Graph=0.546599 | lr=1.00e-04 | Acc=0.3410\n",
            "[Iter  1500] total=0.014794 | OT=0.000121 | Ortho=12.991798 | Graph=1.681670 | lr=1.00e-04 | Acc=0.2789\n",
            "[Iter  2000] total=0.014285 | OT=0.000205 | Ortho=11.538757 | Graph=2.541637 | lr=1.00e-04 | Acc=0.3037\n",
            "[Iter  2500] total=0.013720 | OT=0.000294 | Ortho=10.211449 | Graph=3.214020 | lr=1.00e-04 | Acc=0.3305\n",
            "[Iter  3000] total=0.013059 | OT=0.000370 | Ortho=8.692967 | Graph=3.995377 | lr=1.00e-04 | Acc=0.3190\n",
            "[Iter  3500] total=0.012360 | OT=0.000442 | Ortho=7.190447 | Graph=4.727223 | lr=1.00e-04 | Acc=0.3333\n",
            "[Iter  4000] total=0.011429 | OT=0.000526 | Ortho=5.603604 | Graph=5.299091 | lr=1.00e-04 | Acc=0.3515\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.001, reach=5.0\n",
            "[Iter     1] total=0.145033 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.015848 | OT=0.000004 | Ortho=15.688247 | Graph=0.155663 | lr=1.00e-04 | Acc=0.5568\n",
            "[Iter  1000] total=0.015539 | OT=0.000050 | Ortho=14.937460 | Graph=0.550895 | lr=1.00e-04 | Acc=0.3801\n",
            "[Iter  1500] total=0.014838 | OT=0.000130 | Ortho=13.042690 | Graph=1.665796 | lr=1.00e-04 | Acc=0.3601\n",
            "[Iter  2000] total=0.014319 | OT=0.000216 | Ortho=11.565615 | Graph=2.537729 | lr=1.00e-04 | Acc=0.3448\n",
            "[Iter  2500] total=0.013741 | OT=0.000266 | Ortho=10.329352 | Graph=3.144886 | lr=1.00e-04 | Acc=0.3400\n",
            "[Iter  3000] total=0.012980 | OT=0.000348 | Ortho=8.638622 | Graph=3.993026 | lr=1.00e-04 | Acc=0.3305\n",
            "[Iter  3500] total=0.012165 | OT=0.000416 | Ortho=6.903128 | Graph=4.845784 | lr=1.00e-04 | Acc=0.3505\n",
            "[Iter  4000] total=0.011202 | OT=0.000488 | Ortho=5.406363 | Graph=5.307059 | lr=1.00e-04 | Acc=0.3582\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=0.1\n",
            "[Iter     1] total=0.022963 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010881 | OT=0.001841 | Ortho=5.987202 | Graph=30.520644 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1000] total=0.007105 | OT=0.002182 | Ortho=1.832762 | Graph=30.897046 | lr=1.00e-04 | Acc=0.9885\n",
            "[Iter  1500] total=0.004810 | OT=0.001668 | Ortho=0.791368 | Graph=23.513082 | lr=1.00e-04 | Acc=0.9866\n",
            "[Iter  2000] total=0.003576 | OT=0.001362 | Ortho=0.316197 | Graph=18.980220 | lr=1.00e-04 | Acc=0.9704\n",
            "[Iter  2500] total=0.003074 | OT=0.001127 | Ortho=0.195740 | Graph=17.504456 | lr=1.00e-04 | Acc=0.9618\n",
            "Early stopping at iter=2733 (best@2723 total=0.002922).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=1.0\n",
            "[Iter     1] total=0.040952 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.013068 | OT=0.001610 | Ortho=8.905785 | Graph=25.523944 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1000] total=0.009842 | OT=0.001743 | Ortho=5.345158 | Graph=27.539236 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  1500] total=0.007044 | OT=0.001648 | Ortho=2.649714 | Graph=27.467429 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2000] total=0.005542 | OT=0.001660 | Ortho=1.074905 | Graph=28.069263 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2500] total=0.004441 | OT=0.001307 | Ortho=0.690027 | Graph=24.432834 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  3000] total=0.003642 | OT=0.001117 | Ortho=0.401482 | Graph=21.234801 | lr=1.00e-04 | Acc=0.9780\n",
            "Early stopping at iter=3213 (best@3203 total=0.003464).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=0.0001, reach=5.0\n",
            "[Iter     1] total=0.041437 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.013063 | OT=0.001526 | Ortho=8.988256 | Graph=25.487952 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1000] total=0.009969 | OT=0.001724 | Ortho=5.588968 | Graph=26.557203 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1500] total=0.006870 | OT=0.001793 | Ortho=2.259075 | Graph=28.187454 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  2000] total=0.005451 | OT=0.001680 | Ortho=1.063515 | Graph=27.081769 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2500] total=0.004239 | OT=0.001274 | Ortho=0.616617 | Graph=23.488571 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  3000] total=0.003601 | OT=0.001111 | Ortho=0.364746 | Graph=21.257271 | lr=1.00e-04 | Acc=0.9713\n",
            "[Iter  3500] total=0.003219 | OT=0.000991 | Ortho=0.280980 | Graph=19.474928 | lr=1.00e-04 | Acc=0.9723\n",
            "Early stopping at iter=3880 (best@3870 total=0.002996).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=0.1\n",
            "[Iter     1] total=0.012604 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.006489 | OT=0.005029 | Ortho=0.711120 | Graph=74.911437 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1000] total=0.003772 | OT=0.002840 | Ortho=0.355303 | Graph=57.661699 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1500] total=0.002868 | OT=0.002194 | Ortho=0.188398 | Graph=48.519298 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2000] total=0.002380 | OT=0.001842 | Ortho=0.123707 | Graph=41.495526 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  2500] total=0.002196 | OT=0.001707 | Ortho=0.096371 | Graph=39.246270 | lr=5.00e-05 | Acc=0.9752\n",
            "[Iter  3000] total=0.001977 | OT=0.001532 | Ortho=0.082435 | Graph=36.244001 | lr=5.00e-05 | Acc=0.9752\n",
            "[Iter  3500] total=0.001786 | OT=0.001375 | Ortho=0.076051 | Graph=33.447583 | lr=5.00e-05 | Acc=0.9752\n",
            "[Iter  4000] total=0.001587 | OT=0.001212 | Ortho=0.066163 | Graph=30.886937 | lr=5.00e-05 | Acc=0.9694\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=1.0\n",
            "[Iter     1] total=0.030593 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010068 | OT=0.003373 | Ortho=6.194322 | Graph=50.022595 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  1000] total=0.007297 | OT=0.002494 | Ortho=4.327316 | Graph=47.546423 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  1500] total=0.004917 | OT=0.003077 | Ortho=1.350089 | Graph=48.924383 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.003305 | OT=0.002523 | Ortho=0.333200 | Graph=44.799645 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2500] total=0.002687 | OT=0.002054 | Ortho=0.227979 | Graph=40.568083 | lr=1.00e-04 | Acc=0.9761\n",
            "Early stopping at iter=2657 (best@2647 total=0.002557).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-05, reach=5.0\n",
            "[Iter     1] total=0.031077 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.010111 | OT=0.003362 | Ortho=6.252950 | Graph=49.642882 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  1000] total=0.007209 | OT=0.002423 | Ortho=4.321067 | Graph=46.484012 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1500] total=0.004573 | OT=0.003114 | Ortho=0.967028 | Graph=49.175259 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2000] total=0.003306 | OT=0.002521 | Ortho=0.335308 | Graph=45.036171 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2500] total=0.002751 | OT=0.002120 | Ortho=0.211634 | Graph=41.998424 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  3000] total=0.002398 | OT=0.001842 | Ortho=0.157836 | Graph=39.843294 | lr=5.00e-05 | Acc=0.9733\n",
            "[Iter  3500] total=0.002224 | OT=0.001703 | Ortho=0.136507 | Graph=38.440740 | lr=5.00e-05 | Acc=0.9723\n",
            "[Iter  4000] total=0.002033 | OT=0.001550 | Ortho=0.120260 | Graph=36.206748 | lr=5.00e-05 | Acc=0.9733\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=0.1\n",
            "[Iter     1] total=0.011568 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.005960 | OT=0.005331 | Ortho=0.548378 | Graph=80.538916 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  1000] total=0.003472 | OT=0.003127 | Ortho=0.282698 | Graph=62.237434 | lr=1.00e-04 | Acc=0.9838\n",
            "[Iter  1500] total=0.002565 | OT=0.002357 | Ortho=0.155243 | Graph=52.246934 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  2000] total=0.002024 | OT=0.001898 | Ortho=0.081239 | Graph=45.162446 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2500] total=0.001797 | OT=0.001689 | Ortho=0.065545 | Graph=41.908518 | lr=5.00e-05 | Acc=0.9771\n",
            "[Iter  3000] total=0.001679 | OT=0.001584 | Ortho=0.055234 | Graph=40.285795 | lr=5.00e-05 | Acc=0.9780\n",
            "[Iter  3500] total=0.001562 | OT=0.001474 | Ortho=0.048939 | Graph=38.944914 | lr=5.00e-05 | Acc=0.9771\n",
            "[Iter  4000] total=0.001446 | OT=0.001367 | Ortho=0.041887 | Graph=37.862179 | lr=5.00e-05 | Acc=0.9733\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=1.0\n",
            "[Iter     1] total=0.029557 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009528 | OT=0.003657 | Ortho=5.818474 | Graph=53.288695 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  1000] total=0.006992 | OT=0.002673 | Ortho=4.269759 | Graph=50.017425 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  1500] total=0.004537 | OT=0.003096 | Ortho=1.390816 | Graph=50.593351 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2000] total=0.003032 | OT=0.002667 | Ortho=0.316900 | Graph=48.035742 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2500] total=0.002388 | OT=0.002183 | Ortho=0.159430 | Graph=45.117451 | lr=1.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=2654 (best@2644 total=0.002304).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-06, reach=5.0\n",
            "[Iter     1] total=0.030041 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009808 | OT=0.003660 | Ortho=6.095733 | Graph=52.946258 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  1000] total=0.006974 | OT=0.002635 | Ortho=4.288769 | Graph=50.164878 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1500] total=0.004358 | OT=0.003221 | Ortho=1.085082 | Graph=52.039528 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  2000] total=0.003032 | OT=0.002753 | Ortho=0.231032 | Graph=48.358326 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2500] total=0.002397 | OT=0.002195 | Ortho=0.159019 | Graph=43.514488 | lr=1.00e-04 | Acc=0.9742\n",
            "Early stopping at iter=2906 (best@2896 total=0.002135).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=0.1\n",
            "[Iter     1] total=0.011464 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.005901 | OT=0.005354 | Ortho=0.538269 | Graph=80.973412 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1000] total=0.003413 | OT=0.003132 | Ortho=0.274789 | Graph=62.532014 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.002530 | OT=0.002383 | Ortho=0.142445 | Graph=52.972237 | lr=1.00e-04 | Acc=0.9742\n",
            "Early stopping at iter=1901 (best@1891 total=0.002171).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=1.0\n",
            "[Iter     1] total=0.029453 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009476 | OT=0.003692 | Ortho=5.778506 | Graph=53.633766 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  1000] total=0.006941 | OT=0.002664 | Ortho=4.271904 | Graph=49.859589 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  1500] total=0.004374 | OT=0.003293 | Ortho=1.075278 | Graph=51.767874 | lr=1.00e-04 | Acc=0.9771\n",
            "[Iter  2000] total=0.002804 | OT=0.002544 | Ortho=0.254903 | Graph=47.530053 | lr=1.00e-04 | Acc=0.9790\n",
            "[Iter  2500] total=0.002349 | OT=0.002203 | Ortho=0.141107 | Graph=45.386059 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  3000] total=0.002060 | OT=0.001938 | Ortho=0.117730 | Graph=43.158781 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  3500] total=0.001834 | OT=0.001741 | Ortho=0.088938 | Graph=40.969143 | lr=5.00e-05 | Acc=0.9761\n",
            "[Iter  4000] total=0.001737 | OT=0.001651 | Ortho=0.081657 | Graph=39.907785 | lr=5.00e-05 | Acc=0.9771\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-07, reach=5.0\n",
            "[Iter     1] total=0.029937 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009724 | OT=0.003621 | Ortho=6.097614 | Graph=52.715924 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1000] total=0.006890 | OT=0.002645 | Ortho=4.240381 | Graph=50.373877 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  1500] total=0.004258 | OT=0.003167 | Ortho=1.086607 | Graph=51.882793 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2000] total=0.002803 | OT=0.002599 | Ortho=0.199989 | Graph=47.196699 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2500] total=0.002360 | OT=0.002209 | Ortho=0.146350 | Graph=43.638891 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  3000] total=0.002067 | OT=0.001952 | Ortho=0.110970 | Graph=41.870318 | lr=1.00e-04 | Acc=0.9752\n",
            "Early stopping at iter=3012 (best@3002 total=0.002067).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=0.1\n",
            "[Iter     1] total=0.011454 | OT=0.011453 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.005895 | OT=0.005356 | Ortho=0.538268 | Graph=80.992959 | lr=1.00e-04 | Acc=0.9799\n",
            "[Iter  1000] total=0.003406 | OT=0.003132 | Ortho=0.273064 | Graph=62.593487 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter  1500] total=0.002531 | OT=0.002394 | Ortho=0.136573 | Graph=53.265761 | lr=1.00e-04 | Acc=0.9761\n",
            "[Iter  2000] total=0.002073 | OT=0.001974 | Ortho=0.098793 | Graph=46.383245 | lr=1.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=2289 (best@2279 total=0.001856).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=1.0\n",
            "[Iter     1] total=0.029443 | OT=0.029442 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009500 | OT=0.003678 | Ortho=5.821128 | Graph=53.660446 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  1000] total=0.007030 | OT=0.002783 | Ortho=4.247310 | Graph=50.750404 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1500] total=0.004395 | OT=0.003463 | Ortho=0.931194 | Graph=53.149466 | lr=1.00e-04 | Acc=0.9752\n",
            "[Iter  2000] total=0.002829 | OT=0.002585 | Ortho=0.244001 | Graph=48.157477 | lr=1.00e-04 | Acc=0.9780\n",
            "[Iter  2500] total=0.002350 | OT=0.002212 | Ortho=0.137732 | Graph=46.172738 | lr=1.00e-04 | Acc=0.9771\n",
            "Early stopping at iter=2780 (best@2770 total=0.002188).\n",
            "\n",
            ">>> Hyperparams: p=8, k=5, lambda_topo=0.001, lambda_reg=1e-08, reach=5.0\n",
            "[Iter     1] total=0.029927 | OT=0.029926 | Ortho=0.000000 | Graph=115.107389 | lr=1.00e-04 | Acc=0.9819\n",
            "[Iter   500] total=0.009716 | OT=0.003615 | Ortho=6.100901 | Graph=52.693413 | lr=1.00e-04 | Acc=0.9809\n",
            "[Iter  1000] total=0.006894 | OT=0.002656 | Ortho=4.236669 | Graph=50.531364 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  1500] total=0.004358 | OT=0.003189 | Ortho=1.168893 | Graph=52.068696 | lr=1.00e-04 | Acc=0.9742\n",
            "[Iter  2000] total=0.002773 | OT=0.002554 | Ortho=0.219345 | Graph=46.393107 | lr=1.00e-04 | Acc=0.9733\n",
            "[Iter  2500] total=0.002312 | OT=0.002171 | Ortho=0.141139 | Graph=44.077241 | lr=1.00e-04 | Acc=0.9733\n",
            "Early stopping at iter=2890 (best@2880 total=0.002113).\n",
            "\n",
            "Grid search complete. Saved 144 runs to alignment_tuning_results.pkl\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "res_x = compute_centered_rbf_kernel(\n",
        "    X_normalized\n",
        ")\n",
        "\n",
        "res_y = compute_centered_rbf_kernel(\n",
        "  y_normalized\n",
        ")\n",
        "\n",
        "\n",
        "# Grid search example\n",
        "grid = GridConfig(\n",
        "    p_values=[5,8],\n",
        "    k_values=[5],\n",
        "    lambda_topo_values=[1,1e-1,1e-2,1e-3],\n",
        "    lambda_reg_values=[1e-3,1e-4,1e-5,1e-6,1e-7,1e-8],\n",
        "    reach_values=[0.1,1.0,5.0],\n",
        "    iterations=4000,\n",
        "    lr=1e-4,\n",
        "    patience=10,\n",
        "    print_every=500,\n",
        "    dtype=torch.float64,\n",
        "    seed=50,\n",
        "    save_path=\"alignment_tuning_results.pkl\",\n",
        ")\n",
        "\n",
        "results = run_alignment_grid(\n",
        "   res_x['K_centered'], res_y['K_centered'],\n",
        "X_features= res_x['K_original'],\n",
        "    Y_features= res_y['K_original'],\n",
        "    labels_X=cellTypes_X,\n",
        "    labels_Y=cellTypes_y,\n",
        "    grid=grid,\n",
        "    device=device_str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d1b5e89e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{(8,\n",
              "  5,\n",
              "  1,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 0.44916751, -0.17579775,  0.01710016, ...,  0.07764716,\n",
              "           0.03773541, -0.01927316],\n",
              "         [-0.25998782,  0.26051028, -0.24093678, ..., -0.12824009,\n",
              "           0.04096042, -0.00856509],\n",
              "         [-0.08622245,  0.48258176, -0.23463979, ..., -0.07417583,\n",
              "           0.03057318,  0.03486404],\n",
              "         ...,\n",
              "         [-0.09815228,  0.34523271, -0.13503189, ...,  0.14684538,\n",
              "           0.00529904, -0.16545479],\n",
              "         [-0.3189362 , -0.12868701, -0.00065395, ..., -0.04786453,\n",
              "           0.03522305,  0.0641283 ],\n",
              "         [-0.26786635, -0.07687235,  0.01685982, ..., -0.0146406 ,\n",
              "          -0.02616994, -0.03807175]]), 'mapped_Y': array([[ 0.53409127, -0.10725799, -0.01985043, ...,  0.04375425,\n",
              "           0.02283597, -0.07434571],\n",
              "         [-0.42901335, -0.26227161, -0.07959843, ...,  0.04591436,\n",
              "          -0.0082818 , -0.04910707],\n",
              "         [ 0.03087475,  0.16930478,  0.02369686, ..., -0.12799068,\n",
              "          -0.01939926,  0.12247898],\n",
              "         ...,\n",
              "         [-0.11959769,  0.44573316, -0.26167589, ...,  0.05091334,\n",
              "           0.0142087 , -0.03912676],\n",
              "         [-0.36424636, -0.1927672 , -0.05251403, ...,  0.2856953 ,\n",
              "           0.06247917,  0.06090656],\n",
              "         [-0.3603886 , -0.20570436, -0.06074534, ..., -0.12507362,\n",
              "          -0.03537898, -0.009538  ]]), 'alpha': tensor([[ 4.1883e-03,  6.4974e-03, -3.8693e-04,  ...,  1.0992e-02,\n",
              "            4.1905e-03,  1.5743e-03],\n",
              "          [ 6.6853e-03,  2.1939e-03, -2.3954e-03,  ..., -2.8739e-02,\n",
              "            2.7840e-03, -1.0191e-02],\n",
              "          [ 9.4860e-05,  7.8103e-03, -1.8402e-02,  ..., -7.4960e-04,\n",
              "            4.1667e-03,  1.1303e-03],\n",
              "          ...,\n",
              "          [ 3.5418e-03,  5.9598e-03,  1.2601e-02,  ...,  1.9824e-02,\n",
              "            3.1687e-05, -1.4123e-02],\n",
              "          [-1.0448e-03,  4.9441e-03,  2.6940e-02,  ..., -1.3672e-02,\n",
              "            1.2566e-02,  5.9177e-03],\n",
              "          [ 8.9555e-04, -1.4225e-02,  1.5389e-02,  ..., -1.3780e-02,\n",
              "           -1.3062e-03, -1.2801e-02]], dtype=torch.float64), 'beta': tensor([[ 3.0895e-03, -5.8552e-05, -2.6414e-05,  ...,  1.3011e-02,\n",
              "            6.2734e-03, -7.4973e-03],\n",
              "          [-1.6186e-03, -3.4265e-03,  4.5747e-03,  ..., -2.7354e-03,\n",
              "           -1.2590e-03, -7.9727e-03],\n",
              "          [ 1.1677e-04,  9.0009e-04,  1.6578e-02,  ..., -1.3282e-02,\n",
              "           -1.9498e-03,  1.7581e-02],\n",
              "          ...,\n",
              "          [-5.4426e-03,  8.5751e-03, -1.4732e-02,  ...,  9.6456e-03,\n",
              "            6.4670e-03, -7.0449e-03],\n",
              "          [-3.0864e-03,  9.5345e-03, -7.0475e-03,  ...,  3.4548e-02,\n",
              "            1.6981e-02,  1.0486e-02],\n",
              "          [-2.9166e-03, -1.6465e-02,  8.0925e-04,  ..., -2.2197e-03,\n",
              "           -9.7936e-03, -6.6942e-03]], dtype=torch.float64), 'final_loss': 0.08329752267119764, 'loss_breakdown': {'ot': 0.00870889318655124,\n",
              "   'ortho': 0.00014675730303000676,\n",
              "   'graph': 74.44187218161639}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.1494313584362106}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[ 4.42079284e-01, -1.91689340e-01, -1.69867758e-02, ...,\n",
              "           1.46826878e-01,  9.04452448e-02,  6.47156640e-02],\n",
              "         [-2.42997623e-01,  2.42904406e-01, -2.56529975e-01, ...,\n",
              "          -1.44756044e-01, -3.20408007e-02, -9.47171767e-02],\n",
              "         [-5.69717066e-02,  4.06492726e-01, -2.54286724e-01, ...,\n",
              "          -9.82355941e-02, -6.17368035e-02, -4.92214772e-02],\n",
              "         ...,\n",
              "         [-7.46081104e-02,  2.83442262e-01, -1.42438523e-01, ...,\n",
              "           1.66692396e-04, -4.93427946e-02, -9.11549755e-02],\n",
              "         [-3.29909380e-01, -5.00138366e-02, -4.65582741e-02, ...,\n",
              "          -9.76043947e-02,  1.12257076e-01,  2.24221622e-04],\n",
              "         [-2.68850970e-01, -2.59243151e-02, -7.08012017e-03, ...,\n",
              "          -1.03184088e-01, -1.01259557e-02, -1.99775807e-02]]), 'mapped_Y': array([[ 0.50279793, -0.14047757,  0.00501755, ...,  0.10247757,\n",
              "           0.07481954,  0.0036934 ],\n",
              "         [-0.44082605, -0.18367304, -0.02366752, ..., -0.04522098,\n",
              "           0.04763542,  0.03759469],\n",
              "         [ 0.03863665,  0.16188317, -0.01706967, ..., -0.09905576,\n",
              "           0.01249232,  0.06780925],\n",
              "         ...,\n",
              "         [-0.09138161,  0.38702862, -0.28108605, ..., -0.03280754,\n",
              "          -0.06452994, -0.12878898],\n",
              "         [-0.38421951, -0.09064052, -0.01956559, ...,  0.20902004,\n",
              "           0.10564217,  0.1088576 ],\n",
              "         [-0.37705464, -0.16609327, -0.01299528, ..., -0.10616125,\n",
              "           0.02255027, -0.03171033]]), 'alpha': tensor([[ 0.0097,  0.0174, -0.0149,  ...,  0.0142,  0.0131, -0.0003],\n",
              "          [ 0.0112,  0.0076, -0.0121,  ..., -0.0433, -0.0156, -0.0213],\n",
              "          [-0.0010,  0.0060, -0.0189,  ...,  0.0104, -0.0020, -0.0039],\n",
              "          ...,\n",
              "          [ 0.0120,  0.0115, -0.0009,  ..., -0.0118,  0.0199,  0.0038],\n",
              "          [ 0.0004,  0.0203, -0.0013,  ..., -0.0372,  0.0542, -0.0091],\n",
              "          [ 0.0042,  0.0010, -0.0034,  ..., -0.0509,  0.0377, -0.0052]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0021,  0.0002,  0.0042,  ...,  0.0065,  0.0104, -0.0146],\n",
              "          [ 0.0008,  0.0007,  0.0085,  ..., -0.0139,  0.0064,  0.0038],\n",
              "          [ 0.0070,  0.0150,  0.0142,  ..., -0.0191,  0.0155,  0.0212],\n",
              "          ...,\n",
              "          [-0.0024,  0.0047, -0.0136,  ...,  0.0102,  0.0046, -0.0363],\n",
              "          [ 0.0009,  0.0409, -0.0077,  ...,  0.0438,  0.0335,  0.0026],\n",
              "          [-0.0046, -0.0172,  0.0058,  ..., -0.0060, -0.0123,  0.0023]],\n",
              "         dtype=torch.float64), 'final_loss': 0.06665802587241434, 'loss_breakdown': {'ot': 0.009829771655984951,\n",
              "   'ortho': 0.0001654387607119984,\n",
              "   'graph': 56.66281545571739}, 'best_iter': 3828, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9608404966571156,\n",
              "   'accuracy_raw': 0.9608404966571156,\n",
              "   'foscttm': 0.14554615041474753}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[ 0.43361359, -0.19556428,  0.02108467, ...,  0.15259823,\n",
              "           0.07662026,  0.0671226 ],\n",
              "         [-0.20519635,  0.23893237, -0.26620847, ..., -0.13524696,\n",
              "          -0.03654164, -0.08912093],\n",
              "         [-0.01995864,  0.39987435, -0.25527436, ..., -0.09567002,\n",
              "          -0.06806903, -0.04410381],\n",
              "         ...,\n",
              "         [-0.03966857,  0.27586086, -0.14338564, ..., -0.02856872,\n",
              "          -0.04727839, -0.04116277],\n",
              "         [-0.3338581 , -0.05250484, -0.0712105 , ..., -0.07690167,\n",
              "           0.1340264 , -0.03145731],\n",
              "         [-0.26742656, -0.03290965, -0.03296121, ..., -0.09660038,\n",
              "          -0.00543151, -0.02101494]]), 'mapped_Y': array([[ 0.49723745, -0.14827141,  0.06099979, ...,  0.11881811,\n",
              "           0.05314235,  0.01276605],\n",
              "         [-0.44166466, -0.16566265, -0.04397807, ..., -0.06605451,\n",
              "           0.07453178,  0.03151287],\n",
              "         [ 0.0369498 ,  0.15637306, -0.01604438, ..., -0.08169804,\n",
              "           0.01644159,  0.07055081],\n",
              "         ...,\n",
              "         [-0.05211415,  0.3872281 , -0.29277742, ..., -0.03953027,\n",
              "          -0.07626243, -0.12887081],\n",
              "         [-0.38713744, -0.08656215, -0.04539331, ...,  0.16426254,\n",
              "           0.13586591,  0.10462809],\n",
              "         [-0.38055331, -0.15082985, -0.03073413, ..., -0.08155278,\n",
              "           0.02488021, -0.034779  ]]), 'alpha': tensor([[ 0.0109,  0.0182, -0.0159,  ...,  0.0136,  0.0145, -0.0021],\n",
              "          [ 0.0132,  0.0082, -0.0126,  ..., -0.0406, -0.0147, -0.0223],\n",
              "          [-0.0001,  0.0066, -0.0205,  ...,  0.0090, -0.0031, -0.0037],\n",
              "          ...,\n",
              "          [ 0.0161,  0.0118, -0.0008,  ..., -0.0167,  0.0238,  0.0078],\n",
              "          [ 0.0010,  0.0171, -0.0043,  ..., -0.0330,  0.0528, -0.0198],\n",
              "          [ 0.0062, -0.0025, -0.0063,  ..., -0.0466,  0.0308, -0.0076]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0021,  0.0009,  0.0057,  ...,  0.0069,  0.0092, -0.0142],\n",
              "          [ 0.0006,  0.0021,  0.0102,  ..., -0.0166,  0.0105,  0.0027],\n",
              "          [ 0.0046,  0.0170,  0.0190,  ..., -0.0163,  0.0200,  0.0222],\n",
              "          ...,\n",
              "          [-0.0005,  0.0044, -0.0146,  ...,  0.0107,  0.0038, -0.0415],\n",
              "          [ 0.0015,  0.0442, -0.0097,  ...,  0.0438,  0.0387,  0.0066],\n",
              "          [-0.0049, -0.0164,  0.0070,  ..., -0.0038, -0.0144,  0.0004]],\n",
              "         dtype=torch.float64), 'final_loss': 0.06348042054783729, 'loss_breakdown': {'ot': 0.009041395189666224,\n",
              "   'ortho': 0.00011186285711164906,\n",
              "   'graph': 54.32716250105941}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.14607661495207575}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 2.1304e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5955e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4841e-03, -7.1046e-03,  ..., -1.2457e-02,\n",
              "            5.0021e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8313e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6872e-03, -3.2819e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5337e-03,\n",
              "            6.6289e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5819e-05,  ..., -7.8933e-03,\n",
              "           -2.8828e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5337e-04,\n",
              "            3.3084e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5453e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.5165e-02],\n",
              "          [-4.3881e-04,  1.5218e-03,  1.3888e-03,  ..., -8.5209e-03,\n",
              "           -3.0654e-03,  9.5026e-03],\n",
              "          ...,\n",
              "          [-1.2333e-03,  5.5055e-03, -8.6818e-03,  ...,  5.3526e-03,\n",
              "            2.5763e-03, -7.7908e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7910e-04,  ...,  3.1974e-02,\n",
              "            6.7755e-03, -3.2531e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3695e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.022963324343481292, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.40682737, -0.3165658 , -0.09090918, ..., -0.01114761,\n",
              "           0.0298235 , -0.01078256],\n",
              "         [-0.25338186,  0.35465251, -0.22912647, ..., -0.07631054,\n",
              "           0.0178064 , -0.03414748],\n",
              "         [-0.04075069,  0.51551405, -0.2392966 , ...,  0.00511837,\n",
              "           0.01411449, -0.00222815],\n",
              "         ...,\n",
              "         [-0.06863136,  0.37010033, -0.14356569, ...,  0.21132909,\n",
              "          -0.03733966, -0.23258463],\n",
              "         [-0.36581416, -0.08094738, -0.01278633, ..., -0.10030975,\n",
              "           0.0362571 ,  0.04258773],\n",
              "         [-0.29180828, -0.01055144,  0.03544098, ..., -0.16631658,\n",
              "          -0.06978126, -0.07653587]]), 'mapped_Y': array([[ 0.48537983, -0.23851336, -0.10616545, ..., -0.01311577,\n",
              "           0.03564153, -0.00064413],\n",
              "         [-0.49410195, -0.15924297,  0.0153101 , ...,  0.10166302,\n",
              "          -0.00245592, -0.11552766],\n",
              "         [ 0.09796447,  0.19315084, -0.04168134, ..., -0.08893309,\n",
              "          -0.0532922 ,  0.1504747 ],\n",
              "         ...,\n",
              "         [-0.07672796,  0.49821845, -0.23255937, ...,  0.08923664,\n",
              "           0.03357394, -0.13070253],\n",
              "         [-0.42045932, -0.20238384,  0.10868678, ...,  0.31053751,\n",
              "          -0.00666386,  0.02957889],\n",
              "         [-0.40840136, -0.08640204, -0.01787896, ..., -0.18206616,\n",
              "           0.01068925, -0.00327095]]), 'alpha': tensor([[ 0.0017,  0.0012, -0.0024,  ..., -0.0005,  0.0022, -0.0010],\n",
              "          [ 0.0014,  0.0036, -0.0061,  ..., -0.0157,  0.0032, -0.0010],\n",
              "          [-0.0005,  0.0084, -0.0073,  ..., -0.0034,  0.0050,  0.0033],\n",
              "          ...,\n",
              "          [-0.0003,  0.0014, -0.0022,  ...,  0.0241, -0.0045, -0.0335],\n",
              "          [-0.0038,  0.0030, -0.0047,  ..., -0.0204,  0.0101,  0.0008],\n",
              "          [-0.0026, -0.0041, -0.0070,  ..., -0.0549, -0.0044, -0.0214]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0024, -0.0042,  0.0002,  ...,  0.0011,  0.0023,  0.0013],\n",
              "          [-0.0024, -0.0006, -0.0001,  ...,  0.0064, -0.0013, -0.0134],\n",
              "          [ 0.0043,  0.0112, -0.0022,  ..., -0.0123, -0.0073,  0.0174],\n",
              "          ...,\n",
              "          [-0.0025,  0.0042, -0.0082,  ...,  0.0047,  0.0018, -0.0098],\n",
              "          [ 0.0008,  0.0045,  0.0044,  ...,  0.0359,  0.0046, -0.0005],\n",
              "          [-0.0043, -0.0050, -0.0024,  ..., -0.0190,  0.0025, -0.0007]],\n",
              "         dtype=torch.float64), 'final_loss': 0.032394473886182634, 'loss_breakdown': {'ot': 0.021226854814010206,\n",
              "   'ortho': 3.273443571010245e-05,\n",
              "   'graph': 111.34884636462326}, 'best_iter': 2921, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452722,\n",
              "   'accuracy_raw': 0.9656160458452722,\n",
              "   'foscttm': 0.15160384561703105}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 0.44062329, -0.28400735, -0.05354682, ..., -0.00569028,\n",
              "           0.03520458, -0.01238925],\n",
              "         [-0.26404437,  0.33021863, -0.25156113, ..., -0.07865221,\n",
              "           0.02706911, -0.03990362],\n",
              "         [-0.06912594,  0.50924356, -0.25012146, ...,  0.00330471,\n",
              "           0.0257661 , -0.00826301],\n",
              "         ...,\n",
              "         [-0.09394996,  0.35898998, -0.14690422, ...,  0.22114844,\n",
              "          -0.03444754, -0.23015117],\n",
              "         [-0.35895117, -0.1105307 , -0.04127112, ..., -0.09053447,\n",
              "           0.02724558,  0.0378102 ],\n",
              "         [-0.29667344, -0.03322044,  0.02206282, ..., -0.13952966,\n",
              "          -0.08552553, -0.07824574]]), 'mapped_Y': array([[ 0.51284102, -0.19755596, -0.06378719, ...,  0.00992562,\n",
              "           0.03892736, -0.00372128],\n",
              "         [-0.47856478, -0.20030317, -0.01715029, ...,  0.08620594,\n",
              "          -0.01045686, -0.11299723],\n",
              "         [ 0.09066121,  0.19856009, -0.04004247, ..., -0.07377821,\n",
              "          -0.07052019,  0.15535033],\n",
              "         ...,\n",
              "         [-0.1123649 ,  0.48942343, -0.24596793, ...,  0.07137989,\n",
              "           0.06589217, -0.13944805],\n",
              "         [-0.40371058, -0.24249373,  0.07766084, ...,  0.28956583,\n",
              "          -0.0311181 ,  0.02789033],\n",
              "         [-0.39534062, -0.11534095, -0.04184069, ..., -0.17876635,\n",
              "           0.01279202,  0.00117684]]), 'alpha': tensor([[ 0.0016,  0.0011, -0.0019,  ...,  0.0007,  0.0023, -0.0009],\n",
              "          [ 0.0014,  0.0036, -0.0059,  ..., -0.0160,  0.0031, -0.0013],\n",
              "          [-0.0007,  0.0084, -0.0075,  ..., -0.0012,  0.0053,  0.0031],\n",
              "          ...,\n",
              "          [-0.0008,  0.0004, -0.0013,  ...,  0.0258, -0.0052, -0.0328],\n",
              "          [-0.0036,  0.0020, -0.0051,  ..., -0.0119,  0.0095, -0.0005],\n",
              "          [-0.0022, -0.0044, -0.0051,  ..., -0.0239, -0.0057, -0.0222]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6866e-03, -3.5683e-03,  7.0086e-04,  ...,  4.1515e-03,\n",
              "            3.5311e-03,  1.4332e-03],\n",
              "          [-2.4488e-03, -8.0130e-04, -2.5713e-04,  ...,  4.5676e-03,\n",
              "           -2.6341e-03, -1.3442e-02],\n",
              "          [ 6.9322e-03,  1.2873e-02, -2.5862e-03,  ..., -7.1262e-03,\n",
              "           -1.1279e-02,  1.9074e-02],\n",
              "          ...,\n",
              "          [-2.9987e-03,  3.5298e-03, -8.3279e-03,  ...,  3.0145e-03,\n",
              "            2.4348e-03, -1.0119e-02],\n",
              "          [ 1.9419e-05,  5.0451e-03,  4.5083e-03,  ...,  3.5998e-02,\n",
              "            3.7776e-03, -6.4703e-04],\n",
              "          [-3.8431e-03, -4.6202e-03, -2.4012e-03,  ..., -1.8825e-02,\n",
              "            2.0285e-03, -8.6501e-04]], dtype=torch.float64), 'final_loss': 0.032328476176943115, 'loss_breakdown': {'ot': 0.021177230351997752,\n",
              "   'ortho': 2.8754457927897465e-05,\n",
              "   'graph': 111.22491367017464}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9670487106017192,\n",
              "   'accuracy_raw': 0.9670487106017192,\n",
              "   'foscttm': 0.15095524667285162}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 2.1325e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4842e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0022e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5821e-05,  ..., -9.8922e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5201e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5215e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  9.5043e-03],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3529e-03,\n",
              "            2.5763e-03, -9.6741e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3681e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.012603659323351942, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[ 0.44934628, -0.27651103, -0.02612143, ..., -0.01771472,\n",
              "           0.02345851, -0.00678979],\n",
              "         [-0.2622041 ,  0.31480836, -0.27533135, ..., -0.07485498,\n",
              "           0.02881775, -0.03625084],\n",
              "         [-0.06836455,  0.49912993, -0.26878353, ...,  0.00658945,\n",
              "           0.02518306, -0.00586929],\n",
              "         ...,\n",
              "         [-0.09153192,  0.35585883, -0.17551315, ...,  0.20996844,\n",
              "          -0.03216965, -0.23903532],\n",
              "         [-0.35188344, -0.12606709, -0.04620898, ..., -0.09736362,\n",
              "           0.03116828,  0.04457811],\n",
              "         [-0.30022753, -0.02977012, -0.00317946, ..., -0.16986181,\n",
              "          -0.07481256, -0.07922804]]), 'mapped_Y': array([[ 0.518099  , -0.18920633, -0.03978221, ..., -0.01644933,\n",
              "           0.03529828,  0.00889645],\n",
              "         [-0.47056215, -0.21285087, -0.03386668, ...,  0.10254617,\n",
              "          -0.00589046, -0.11840615],\n",
              "         [ 0.08137589,  0.20791925, -0.02948989, ..., -0.0929088 ,\n",
              "          -0.05303206,  0.14912271],\n",
              "         ...,\n",
              "         [-0.10148253,  0.47646036, -0.27155061, ...,  0.09135988,\n",
              "           0.03889934, -0.13662126],\n",
              "         [-0.40103195, -0.25349762,  0.0704455 , ...,  0.30905452,\n",
              "          -0.00297697,  0.03677685],\n",
              "         [-0.3928889 , -0.12854917, -0.05916484, ..., -0.1786186 ,\n",
              "           0.0028619 , -0.00642924]]), 'alpha': tensor([[ 0.0015, -0.0002, -0.0015,  ..., -0.0013,  0.0018, -0.0009],\n",
              "          [ 0.0011,  0.0036, -0.0065,  ..., -0.0146,  0.0040, -0.0007],\n",
              "          [-0.0005,  0.0078, -0.0072,  ..., -0.0033,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0010, -0.0035,  ...,  0.0242, -0.0045, -0.0338],\n",
              "          [-0.0035,  0.0009, -0.0054,  ..., -0.0206,  0.0087,  0.0006],\n",
              "          [-0.0026, -0.0032, -0.0093,  ..., -0.0649, -0.0080, -0.0217]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0026, -0.0036,  0.0001,  ...,  0.0014,  0.0024,  0.0002],\n",
              "          [-0.0024, -0.0002, -0.0003,  ...,  0.0056, -0.0018, -0.0139],\n",
              "          [ 0.0036,  0.0107, -0.0018,  ..., -0.0126, -0.0083,  0.0164],\n",
              "          ...,\n",
              "          [-0.0024,  0.0018, -0.0085,  ...,  0.0046,  0.0013, -0.0097],\n",
              "          [ 0.0002,  0.0054,  0.0049,  ...,  0.0358,  0.0028,  0.0003],\n",
              "          [-0.0040, -0.0041, -0.0030,  ..., -0.0206,  0.0034, -0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.02295015864255374, 'loss_breakdown': {'ot': 0.021797927656383817,\n",
              "   'ortho': 2.0467180776737993e-05,\n",
              "   'graph': 113.1763805393187}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15194502143295668}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.44866595, -0.27760688, -0.04128264, ..., -0.02336191,\n",
              "           0.02636059, -0.00425162],\n",
              "         [-0.28074093,  0.30304812, -0.270202  , ..., -0.06754164,\n",
              "           0.02780877, -0.04096341],\n",
              "         [-0.08973226,  0.48561178, -0.28780778, ...,  0.02202539,\n",
              "           0.02806762, -0.01250478],\n",
              "         ...,\n",
              "         [-0.10565754,  0.33609421, -0.1837918 , ...,  0.21899964,\n",
              "          -0.03205358, -0.2423617 ],\n",
              "         [-0.35401435, -0.12231927, -0.01846866, ..., -0.11174727,\n",
              "           0.02872299,  0.03722996],\n",
              "         [-0.29601729, -0.02475819,  0.02761264, ..., -0.17473672,\n",
              "          -0.07861233, -0.083202  ]]), 'mapped_Y': array([[ 0.51604571, -0.18723647, -0.06355566, ..., -0.00512066,\n",
              "           0.03817112,  0.00980729],\n",
              "         [-0.47109945, -0.21720186,  0.01499258, ...,  0.09126264,\n",
              "          -0.01701203, -0.11705721],\n",
              "         [ 0.08235482,  0.21034683, -0.05259305, ..., -0.07177481,\n",
              "          -0.06507895,  0.14641036],\n",
              "         ...,\n",
              "         [-0.12699577,  0.45564413, -0.28449239, ...,  0.09426283,\n",
              "           0.05441354, -0.14570136],\n",
              "         [-0.39737715, -0.26806736,  0.10951866, ...,  0.28944646,\n",
              "          -0.02135569,  0.0344148 ],\n",
              "         [-0.39246775, -0.11869342, -0.02221701, ..., -0.18302786,\n",
              "           0.00494836, -0.00386487]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0016,  ..., -0.0009,  0.0018, -0.0008],\n",
              "          [ 0.0009,  0.0037, -0.0064,  ..., -0.0136,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0075,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0003, -0.0017, -0.0029,  ...,  0.0232, -0.0048, -0.0336],\n",
              "          [-0.0036,  0.0013, -0.0051,  ..., -0.0229,  0.0087, -0.0013],\n",
              "          [-0.0024, -0.0026, -0.0064,  ..., -0.0522, -0.0079, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7590e-03, -3.2607e-03,  3.1551e-04,  ...,  3.0454e-03,\n",
              "            3.0126e-03,  5.3556e-04],\n",
              "          [-2.3071e-03, -3.2202e-04,  6.1196e-04,  ...,  5.9430e-03,\n",
              "           -3.2559e-03, -1.3639e-02],\n",
              "          [ 4.8931e-03,  9.7670e-03, -2.7539e-03,  ..., -6.9770e-03,\n",
              "           -1.1701e-02,  1.6507e-02],\n",
              "          ...,\n",
              "          [-3.0179e-03, -2.7999e-04, -8.5313e-03,  ...,  3.0589e-03,\n",
              "            2.2181e-03, -9.9754e-03],\n",
              "          [-7.0419e-05,  3.4373e-03,  5.1385e-03,  ...,  3.5834e-02,\n",
              "            1.7305e-03, -2.5815e-04],\n",
              "          [-3.7618e-03, -3.1639e-03, -1.8382e-03,  ..., -2.0082e-02,\n",
              "            2.7728e-03, -1.0686e-03]], dtype=torch.float64), 'final_loss': 0.022839207437031304, 'loss_breakdown': {'ot': 0.02168905732396601,\n",
              "   'ortho': 2.1819755612675134e-05,\n",
              "   'graph': 112.83303574526151}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.15143553829607312}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 4.1302e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4844e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0023e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5822e-05,  ..., -9.8928e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5117e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5216e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  1.1481e-02],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3530e-03,\n",
              "            2.5763e-03, -9.7894e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3679e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.011567692821339006, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.45623646, -0.26713212, -0.01775362, ..., -0.0168603 ,\n",
              "           0.02325861, -0.0070635 ],\n",
              "         [-0.26473789,  0.30795836, -0.28038785, ..., -0.07650139,\n",
              "           0.02931083, -0.03586998],\n",
              "         [-0.07527952,  0.49708557, -0.27150666, ...,  0.00430422,\n",
              "           0.0263963 , -0.00640449],\n",
              "         ...,\n",
              "         [-0.09741532,  0.35382605, -0.17784027, ...,  0.20971647,\n",
              "          -0.03072183, -0.23892929],\n",
              "         [-0.34839079, -0.13397149, -0.05234588, ..., -0.09536098,\n",
              "           0.03018952,  0.04480457],\n",
              "         [-0.30013581, -0.03642445, -0.00844652, ..., -0.16719354,\n",
              "          -0.07498915, -0.07935764]]), 'mapped_Y': array([[ 5.23040158e-01, -1.78489559e-01, -3.06737748e-02, ...,\n",
              "          -1.68624068e-02,  3.50187606e-02,  8.31956680e-03],\n",
              "         [-4.64838726e-01, -2.21902786e-01, -4.15800356e-02, ...,\n",
              "           1.03710039e-01, -5.68943978e-03, -1.17600282e-01],\n",
              "         [ 7.74080563e-02,  2.10196384e-01, -2.60215047e-02, ...,\n",
              "          -9.46018644e-02, -5.45309017e-02,  1.48323749e-01],\n",
              "         ...,\n",
              "         [-1.08214254e-01,  4.72907034e-01, -2.76356668e-01, ...,\n",
              "           9.00258352e-02,  4.12410454e-02, -1.36937465e-01],\n",
              "         [-3.94779596e-01, -2.62003757e-01,  6.45730880e-02, ...,\n",
              "           3.10416107e-01, -1.11899642e-03,  3.94652334e-02],\n",
              "         [-3.89190018e-01, -1.36982521e-01, -6.53426255e-02, ...,\n",
              "          -1.78813647e-01,  9.67513619e-06, -6.44953750e-03]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0014,  ..., -0.0014,  0.0017, -0.0009],\n",
              "          [ 0.0010,  0.0036, -0.0065,  ..., -0.0145,  0.0041, -0.0006],\n",
              "          [-0.0006,  0.0077, -0.0071,  ..., -0.0034,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0009, -0.0036,  ...,  0.0244, -0.0044, -0.0337],\n",
              "          [-0.0035,  0.0008, -0.0056,  ..., -0.0197,  0.0085,  0.0003],\n",
              "          [-0.0026, -0.0033, -0.0094,  ..., -0.0633, -0.0081, -0.0218]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6616e-03, -3.5415e-03,  1.5091e-04,  ...,  1.1958e-03,\n",
              "            2.3460e-03,  8.5193e-05],\n",
              "          [-2.4134e-03,  1.6518e-05, -2.8851e-04,  ...,  5.6403e-03,\n",
              "           -1.6873e-03, -1.4090e-02],\n",
              "          [ 3.6682e-03,  1.0130e-02, -1.6752e-03,  ..., -1.2702e-02,\n",
              "           -8.5709e-03,  1.6225e-02],\n",
              "          ...,\n",
              "          [-2.4348e-03,  1.2859e-03, -8.5312e-03,  ...,  4.6950e-03,\n",
              "            1.3529e-03, -9.7317e-03],\n",
              "          [ 1.1649e-04,  5.4134e-03,  4.9854e-03,  ...,  3.5974e-02,\n",
              "            2.8509e-03,  4.6260e-04],\n",
              "          [-3.9797e-03, -4.1669e-03, -3.0046e-03,  ..., -2.0793e-02,\n",
              "            3.1225e-03, -1.3760e-03]], dtype=torch.float64), 'final_loss': 0.021989337146263985, 'loss_breakdown': {'ot': 0.021856234610300545,\n",
              "   'ortho': 1.9795436407280467e-05,\n",
              "   'graph': 113.30709955615993}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15196782730300518}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.4505758 , -0.27521515, -0.0398706 , ..., -0.02432067,\n",
              "           0.02658821, -0.0060944 ],\n",
              "         [-0.28378532,  0.29904848, -0.27177766, ..., -0.06822371,\n",
              "           0.02703751, -0.03958535],\n",
              "         [-0.09361845,  0.48310993, -0.29131738, ...,  0.02158354,\n",
              "           0.02684226, -0.01105906],\n",
              "         ...,\n",
              "         [-0.10916482,  0.3338745 , -0.18757315, ...,  0.21873053,\n",
              "          -0.03362663, -0.2405884 ],\n",
              "         [-0.35244735, -0.12368436, -0.01598552, ..., -0.1125398 ,\n",
              "           0.02906869,  0.03745973],\n",
              "         [-0.2952116 , -0.02478029,  0.03016883, ..., -0.17567123,\n",
              "          -0.07790118, -0.08185218]]), 'mapped_Y': array([[ 0.51727359, -0.18394674, -0.06345396, ..., -0.00262515,\n",
              "           0.03832247,  0.0082302 ],\n",
              "         [-0.46996866, -0.22033555,  0.01690478, ...,  0.08701522,\n",
              "          -0.0163923 , -0.1188799 ],\n",
              "         [ 0.08080654,  0.20957705, -0.05315305, ..., -0.06830086,\n",
              "          -0.06833589,  0.14533449],\n",
              "         ...,\n",
              "         [-0.13072436,  0.45363498, -0.28869542, ...,  0.091509  ,\n",
              "           0.05255035, -0.14401419],\n",
              "         [-0.39587818, -0.27320764,  0.10922787, ...,  0.28415356,\n",
              "          -0.02007329,  0.0332718 ],\n",
              "         [-0.39130172, -0.12004521, -0.01836885, ..., -0.18165041,\n",
              "           0.00382527, -0.00270028]]), 'alpha': tensor([[ 0.0015, -0.0004, -0.0015,  ..., -0.0010,  0.0018, -0.0008],\n",
              "          [ 0.0008,  0.0037, -0.0064,  ..., -0.0133,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0074,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0004, -0.0018, -0.0030,  ...,  0.0230, -0.0049, -0.0334],\n",
              "          [-0.0035,  0.0014, -0.0051,  ..., -0.0236,  0.0086, -0.0013],\n",
              "          [-0.0024, -0.0024, -0.0062,  ..., -0.0520, -0.0080, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7885e-03, -3.1983e-03,  3.0808e-04,  ...,  3.6234e-03,\n",
              "            2.8640e-03,  4.3346e-04],\n",
              "          [-2.3315e-03, -3.6203e-04,  5.7311e-04,  ...,  5.5508e-03,\n",
              "           -3.2684e-03, -1.4026e-02],\n",
              "          [ 4.9259e-03,  9.2545e-03, -2.7952e-03,  ..., -6.3937e-03,\n",
              "           -1.2076e-02,  1.6332e-02],\n",
              "          ...,\n",
              "          [-3.0792e-03, -5.3974e-04, -8.5378e-03,  ...,  2.7738e-03,\n",
              "            2.3166e-03, -9.9703e-03],\n",
              "          [-7.4717e-05,  2.9472e-03,  4.9189e-03,  ...,  3.5469e-02,\n",
              "            1.4843e-03, -2.5153e-04],\n",
              "          [-3.7419e-03, -3.0790e-03, -1.5356e-03,  ..., -1.9926e-02,\n",
              "            2.7856e-03, -9.9450e-04]], dtype=torch.float64), 'final_loss': 0.02182549750719424, 'loss_breakdown': {'ot': 0.021691372764482953,\n",
              "   'ortho': 2.1231509878038317e-05,\n",
              "   'graph': 112.89323283324744}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.15142732818285565}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 4.1302e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4844e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0023e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5822e-05,  ..., -9.8928e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5107e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5216e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  1.1493e-02],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3530e-03,\n",
              "            2.5763e-03, -9.7895e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3678e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.011464096171137713, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.4571143 , -0.26575638, -0.01733357, ..., -0.01657534,\n",
              "           0.02306865, -0.00708779],\n",
              "         [-0.26497805,  0.30774931, -0.28034554, ..., -0.07630425,\n",
              "           0.02918566, -0.03594088],\n",
              "         [-0.07611997,  0.49747427, -0.27057487, ...,  0.00404016,\n",
              "           0.02647528, -0.00635527],\n",
              "         ...,\n",
              "         [-0.09807281,  0.35395936, -0.17731334, ...,  0.20968969,\n",
              "          -0.03043114, -0.23862196],\n",
              "         [-0.34799463, -0.13494363, -0.05339687, ..., -0.09320618,\n",
              "           0.03014091,  0.04490067],\n",
              "         [-0.30014737, -0.03709003, -0.0095811 , ..., -0.16583226,\n",
              "          -0.07506941, -0.07934665]]), 'mapped_Y': array([[ 5.23672052e-01, -1.76910129e-01, -2.98470668e-02, ...,\n",
              "          -1.69493587e-02,  3.51033348e-02,  8.37674106e-03],\n",
              "         [-4.63950089e-01, -2.22928987e-01, -4.31949866e-02, ...,\n",
              "           1.04551559e-01, -5.71174200e-03, -1.17456832e-01],\n",
              "         [ 7.67117985e-02,  2.10285211e-01, -2.52963539e-02, ...,\n",
              "          -9.58846506e-02, -5.39676805e-02,  1.48064502e-01],\n",
              "         ...,\n",
              "         [-1.09053019e-01,  4.73222141e-01, -2.75588998e-01, ...,\n",
              "           9.08358885e-02,  4.09681011e-02, -1.36560728e-01],\n",
              "         [-3.93703600e-01, -2.62749685e-01,  6.31975492e-02, ...,\n",
              "           3.10047011e-01, -6.43042380e-04,  4.00499925e-02],\n",
              "         [-3.88765128e-01, -1.38241916e-01, -6.65950247e-02, ...,\n",
              "          -1.78334617e-01, -2.57563856e-04, -6.78878459e-03]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0014,  ..., -0.0015,  0.0017, -0.0009],\n",
              "          [ 0.0010,  0.0036, -0.0065,  ..., -0.0146,  0.0040, -0.0006],\n",
              "          [-0.0006,  0.0077, -0.0071,  ..., -0.0034,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0009, -0.0036,  ...,  0.0244, -0.0044, -0.0336],\n",
              "          [-0.0035,  0.0007, -0.0056,  ..., -0.0187,  0.0084,  0.0003],\n",
              "          [-0.0026, -0.0033, -0.0095,  ..., -0.0618, -0.0082, -0.0218]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6631e-03, -3.5472e-03,  1.5186e-04,  ...,  1.2211e-03,\n",
              "            2.3418e-03,  9.3135e-05],\n",
              "          [-2.4105e-03,  4.3088e-05, -3.0964e-04,  ...,  5.7187e-03,\n",
              "           -1.6653e-03, -1.4083e-02],\n",
              "          [ 3.6502e-03,  1.0029e-02, -1.6495e-03,  ..., -1.2799e-02,\n",
              "           -8.5191e-03,  1.6151e-02],\n",
              "          ...,\n",
              "          [-2.4354e-03,  1.2903e-03, -8.5261e-03,  ...,  4.7600e-03,\n",
              "            1.3520e-03, -9.7023e-03],\n",
              "          [ 1.2906e-04,  5.4160e-03,  5.0022e-03,  ...,  3.5847e-02,\n",
              "            2.9406e-03,  5.2141e-04],\n",
              "          [-3.9831e-03, -4.1730e-03, -3.0431e-03,  ..., -2.0722e-02,\n",
              "            3.0515e-03, -1.4186e-03]], dtype=torch.float64), 'final_loss': 0.021919344614518516, 'loss_breakdown': {'ot': 0.021888248960522633,\n",
              "   'ortho': 1.9759404276883053e-05,\n",
              "   'graph': 113.36249718999812}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15199610658186533}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[ 0.45052781, -0.27539442, -0.03959662, ..., -0.02421996,\n",
              "           0.02648991, -0.00642587],\n",
              "         [-0.28344474,  0.29926156, -0.27181381, ..., -0.06850882,\n",
              "           0.02708461, -0.0394025 ],\n",
              "         [-0.09318893,  0.48340441, -0.29109121, ...,  0.02127276,\n",
              "           0.02690496, -0.01087424],\n",
              "         ...,\n",
              "         [-0.10901716,  0.33434382, -0.18752504, ...,  0.21835218,\n",
              "          -0.03365181, -0.24036328],\n",
              "         [-0.35243716, -0.12362116, -0.01642589, ..., -0.1124646 ,\n",
              "           0.02905878,  0.03760857],\n",
              "         [-0.29537263, -0.0244755 ,  0.02970424, ..., -0.17616194,\n",
              "          -0.07789116, -0.08152916]]), 'mapped_Y': array([[ 0.51727444, -0.18409876, -0.06317101, ..., -0.00286851,\n",
              "           0.03838821,  0.00783078],\n",
              "         [-0.47013855, -0.22006519,  0.01631937, ...,  0.08732   ,\n",
              "          -0.01653939, -0.11885669],\n",
              "         [ 0.08099701,  0.20941403, -0.05275718, ..., -0.06845435,\n",
              "          -0.06832474,  0.14522969],\n",
              "         ...,\n",
              "         [-0.13035234,  0.45411745, -0.28851624, ...,  0.09136192,\n",
              "           0.0523776 , -0.14372534],\n",
              "         [-0.39607829, -0.27317299,  0.10861317, ...,  0.28467867,\n",
              "          -0.02028736,  0.03320928],\n",
              "         [-0.391328  , -0.11995175, -0.01878548, ..., -0.18174615,\n",
              "           0.00366785, -0.00244941]]), 'alpha': tensor([[ 0.0015, -0.0004, -0.0015,  ..., -0.0010,  0.0018, -0.0008],\n",
              "          [ 0.0008,  0.0037, -0.0064,  ..., -0.0133,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0074,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0005, -0.0018, -0.0031,  ...,  0.0230, -0.0049, -0.0334],\n",
              "          [-0.0035,  0.0014, -0.0051,  ..., -0.0237,  0.0086, -0.0012],\n",
              "          [-0.0024, -0.0024, -0.0062,  ..., -0.0539, -0.0080, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7877e-03, -3.2013e-03,  3.0605e-04,  ...,  3.5724e-03,\n",
              "            2.8634e-03,  4.1755e-04],\n",
              "          [-2.3394e-03, -3.4586e-04,  5.6782e-04,  ...,  5.5862e-03,\n",
              "           -3.3102e-03, -1.4050e-02],\n",
              "          [ 4.9002e-03,  9.1734e-03, -2.7777e-03,  ..., -6.3997e-03,\n",
              "           -1.2108e-02,  1.6310e-02],\n",
              "          ...,\n",
              "          [-3.0729e-03, -5.1903e-04, -8.5332e-03,  ...,  2.7807e-03,\n",
              "            2.3009e-03, -9.9624e-03],\n",
              "          [-7.7511e-05,  2.9454e-03,  4.9263e-03,  ...,  3.5498e-02,\n",
              "            1.3785e-03, -2.5866e-04],\n",
              "          [-3.7431e-03, -3.0729e-03, -1.5434e-03,  ..., -1.9957e-02,\n",
              "            2.8275e-03, -9.7872e-04]], dtype=torch.float64), 'final_loss': 0.021728892178650684, 'loss_breakdown': {'ot': 0.021696404656399968,\n",
              "   'ortho': 2.11968031627531e-05,\n",
              "   'graph': 112.90719087964948}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.1514296087698605}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 4.1302e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4844e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0023e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5822e-05,  ..., -9.8928e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5105e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5216e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  1.1494e-02],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3530e-03,\n",
              "            2.5763e-03, -9.7895e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3678e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.011453736506117584, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.45713125, -0.26573401, -0.01730553, ..., -0.01658666,\n",
              "           0.02306238, -0.00708587],\n",
              "         [-0.26497279,  0.30774592, -0.28035551, ..., -0.0762933 ,\n",
              "           0.0291928 , -0.03593726],\n",
              "         [-0.07612367,  0.49748134, -0.27056165, ...,  0.00404929,\n",
              "           0.02647697, -0.00635153],\n",
              "         ...,\n",
              "         [-0.09807421,  0.35396103, -0.17731102, ...,  0.20969164,\n",
              "          -0.03043135, -0.23862141],\n",
              "         [-0.34798557, -0.13496059, -0.05343217, ..., -0.09320067,\n",
              "           0.0301478 ,  0.04489568],\n",
              "         [-0.30014984, -0.03709722, -0.00961658, ..., -0.16584001,\n",
              "          -0.07506382, -0.07934852]]), 'mapped_Y': array([[ 5.23684973e-01, -1.76881010e-01, -2.98114686e-02, ...,\n",
              "          -1.69694766e-02,  3.51012861e-02,  8.37985632e-03],\n",
              "         [-4.63929774e-01, -2.22955004e-01, -4.32457744e-02, ...,\n",
              "           1.04551337e-01, -5.69595865e-03, -1.17460658e-01],\n",
              "         [ 7.66957166e-02,  2.10287973e-01, -2.52855045e-02, ...,\n",
              "          -9.58954751e-02, -5.39609572e-02,  1.48067541e-01],\n",
              "         ...,\n",
              "         [-1.09054291e-01,  4.73228466e-01, -2.75577108e-01, ...,\n",
              "           9.08553444e-02,  4.09653459e-02, -1.36559441e-01],\n",
              "         [-3.93680603e-01, -2.62778970e-01,  6.31578568e-02, ...,\n",
              "           3.10050133e-01, -6.33912154e-04,  4.00498018e-02],\n",
              "         [-3.88757312e-01, -1.38258168e-01, -6.66362929e-02, ...,\n",
              "          -1.78334876e-01, -2.43595490e-04, -6.79102671e-03]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0014,  ..., -0.0015,  0.0017, -0.0009],\n",
              "          [ 0.0010,  0.0036, -0.0065,  ..., -0.0146,  0.0040, -0.0006],\n",
              "          [-0.0006,  0.0077, -0.0071,  ..., -0.0034,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0009, -0.0036,  ...,  0.0244, -0.0044, -0.0336],\n",
              "          [-0.0035,  0.0007, -0.0056,  ..., -0.0188,  0.0084,  0.0003],\n",
              "          [-0.0026, -0.0033, -0.0095,  ..., -0.0618, -0.0082, -0.0218]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6631e-03, -3.5475e-03,  1.5165e-04,  ...,  1.2197e-03,\n",
              "            2.3419e-03,  9.3385e-05],\n",
              "          [-2.4104e-03,  4.3070e-05, -3.1058e-04,  ...,  5.7169e-03,\n",
              "           -1.6640e-03, -1.4083e-02],\n",
              "          [ 3.6494e-03,  1.0031e-02, -1.6500e-03,  ..., -1.2802e-02,\n",
              "           -8.5165e-03,  1.6150e-02],\n",
              "          ...,\n",
              "          [-2.4349e-03,  1.2912e-03, -8.5256e-03,  ...,  4.7618e-03,\n",
              "            1.3493e-03, -9.7018e-03],\n",
              "          [ 1.2983e-04,  5.4161e-03,  5.0022e-03,  ...,  3.5846e-02,\n",
              "            2.9397e-03,  5.2155e-04],\n",
              "          [-3.9833e-03, -4.1720e-03, -3.0441e-03,  ..., -2.0724e-02,\n",
              "            3.0560e-03, -1.4189e-03]], dtype=torch.float64), 'final_loss': 0.021909168769622903, 'loss_breakdown': {'ot': 0.021888280919326056,\n",
              "   'ortho': 1.975421944222744e-05,\n",
              "   'graph': 113.36308546197554}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15199565046446434}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.4505207 , -0.27540944, -0.03959522, ..., -0.02422116,\n",
              "           0.02648632, -0.00642506],\n",
              "         [-0.28343253,  0.29927654, -0.27181079, ..., -0.06851023,\n",
              "           0.02708719, -0.03940201],\n",
              "         [-0.09317089,  0.48341476, -0.29108154, ...,  0.02126745,\n",
              "           0.02690956, -0.01087007],\n",
              "         ...,\n",
              "         [-0.10900352,  0.33435389, -0.18752049, ...,  0.21835413,\n",
              "          -0.03364638, -0.24035815],\n",
              "         [-0.35244174, -0.12361261, -0.01643605, ..., -0.11244294,\n",
              "           0.02905679,  0.03760112],\n",
              "         [-0.2953768 , -0.02446112,  0.02969462, ..., -0.17615164,\n",
              "          -0.07789188, -0.08153433]]), 'mapped_Y': array([[ 0.51726983, -0.18411317, -0.06316899, ..., -0.0028797 ,\n",
              "           0.03838862,  0.00783481],\n",
              "         [-0.47014557, -0.22005216,  0.01630544, ...,  0.08733454,\n",
              "          -0.01654229, -0.11886318],\n",
              "         [ 0.08100397,  0.20941189, -0.05274798, ..., -0.06846007,\n",
              "          -0.06832099,  0.14523185],\n",
              "         ...,\n",
              "         [-0.13033373,  0.45413042, -0.2885086 , ...,  0.09136884,\n",
              "           0.05237353, -0.14372176],\n",
              "         [-0.39608863, -0.27316777,  0.10860165, ...,  0.28468098,\n",
              "          -0.02028552,  0.03320316],\n",
              "         [-0.39133225, -0.11994076, -0.01879467, ..., -0.18175049,\n",
              "           0.00366259, -0.00245189]]), 'alpha': tensor([[ 0.0015, -0.0004, -0.0015,  ..., -0.0010,  0.0018, -0.0008],\n",
              "          [ 0.0008,  0.0037, -0.0064,  ..., -0.0133,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0074,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0005, -0.0018, -0.0031,  ...,  0.0230, -0.0049, -0.0334],\n",
              "          [-0.0035,  0.0014, -0.0051,  ..., -0.0237,  0.0086, -0.0012],\n",
              "          [-0.0024, -0.0024, -0.0062,  ..., -0.0539, -0.0080, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7877e-03, -3.2016e-03,  3.0579e-04,  ...,  3.5707e-03,\n",
              "            2.8628e-03,  4.1804e-04],\n",
              "          [-2.3395e-03, -3.4586e-04,  5.6744e-04,  ...,  5.5889e-03,\n",
              "           -3.3105e-03, -1.4050e-02],\n",
              "          [ 4.9003e-03,  9.1726e-03, -2.7777e-03,  ..., -6.4002e-03,\n",
              "           -1.2109e-02,  1.6310e-02],\n",
              "          ...,\n",
              "          [-3.0725e-03, -5.1853e-04, -8.5329e-03,  ...,  2.7807e-03,\n",
              "            2.3005e-03, -9.9620e-03],\n",
              "          [-7.7623e-05,  2.9445e-03,  4.9267e-03,  ...,  3.5497e-02,\n",
              "            1.3772e-03, -2.5872e-04],\n",
              "          [-3.7431e-03, -3.0720e-03, -1.5436e-03,  ..., -1.9958e-02,\n",
              "            2.8280e-03, -9.7874e-04]], dtype=torch.float64), 'final_loss': 0.021719251844675297, 'loss_breakdown': {'ot': 0.02169693067928813,\n",
              "   'ortho': 2.119207752708022e-05,\n",
              "   'graph': 112.90878600849769}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.15142869653505858}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 1.03651683e-01,  1.11209706e-01, -1.84105350e-02, ...,\n",
              "          -2.93382762e-03,  4.58605023e-02, -1.07756081e-02],\n",
              "         [ 2.55487200e-02,  6.54471793e-02, -1.78565632e-02, ...,\n",
              "          -2.12124096e-02,  2.25949763e-02, -1.84572856e-02],\n",
              "         [-3.85178928e-02,  1.13826682e-01, -8.15998571e-02, ...,\n",
              "           2.47021548e-02,  2.22420306e-02,  1.48625714e-02],\n",
              "         ...,\n",
              "         [-1.35639252e-02,  9.55461831e-02,  2.11668639e-02, ...,\n",
              "          -1.70505893e-02, -4.22183074e-02,  7.55415132e-04],\n",
              "         [-5.12321489e-02, -6.51616022e-02,  3.75571893e-02, ...,\n",
              "          -1.71246774e-02,  3.74635717e-02,  1.04188442e-05],\n",
              "         [-1.41586612e-02, -2.22600746e-02,  4.84511756e-02, ...,\n",
              "          -3.13918799e-02, -3.35072976e-03, -1.10973115e-02]]), 'mapped_Y': array([[ 1.07011403e-01,  5.38386170e-02, -2.38239099e-02, ...,\n",
              "          -2.12703440e-02,  2.49504184e-02, -1.42521768e-02],\n",
              "         [-3.88977393e-02, -6.53481068e-02,  6.43798500e-03, ...,\n",
              "           4.83146842e-03, -2.00359233e-02, -3.28281512e-04],\n",
              "         [ 2.46518213e-02,  4.55931737e-02,  3.87767533e-02, ...,\n",
              "           2.65239261e-02, -5.63069419e-03,  2.10929755e-02],\n",
              "         ...,\n",
              "         [-1.49563529e-01,  1.17142657e-01, -8.94491906e-02, ...,\n",
              "           2.60144441e-02,  2.76989566e-02, -4.32189083e-02],\n",
              "         [-4.87522143e-02, -3.53205197e-02, -4.20164431e-02, ...,\n",
              "           8.49233158e-02, -1.26801916e-03,  3.95898944e-02],\n",
              "         [-5.47794295e-02, -9.21412866e-02, -4.77726073e-05, ...,\n",
              "           2.41414996e-02, -1.78537491e-02,  1.60480150e-02]]), 'alpha': tensor([[ 0.0092,  0.0529, -0.0045,  ..., -0.0021, -0.0023, -0.0031],\n",
              "          [ 0.0419,  0.0254,  0.0548,  ..., -0.0126,  0.0028, -0.0050],\n",
              "          [ 0.0110,  0.0047, -0.0532,  ...,  0.0212, -0.0043,  0.0056],\n",
              "          ...,\n",
              "          [ 0.0305,  0.0220,  0.0887,  ..., -0.0626, -0.1526,  0.0385],\n",
              "          [-0.0098, -0.0156,  0.0168,  ..., -0.0148,  0.0532, -0.0061],\n",
              "          [ 0.0031,  0.0502,  0.0376,  ..., -0.0563, -0.0102, -0.0278]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0008,  0.0447, -0.0047,  ...,  0.0062, -0.0033,  0.0111],\n",
              "          [ 0.0106,  0.0201,  0.0137,  ...,  0.0016, -0.0013, -0.0094],\n",
              "          [-0.0328, -0.0178,  0.0376,  ...,  0.1749,  0.0475,  0.0544],\n",
              "          ...,\n",
              "          [-0.0456,  0.0081, -0.0134,  ...,  0.0061,  0.0049, -0.0301],\n",
              "          [ 0.0108,  0.0086, -0.0306,  ...,  0.1144,  0.0179,  0.0334],\n",
              "          [-0.0137, -0.0366, -0.0043,  ...,  0.0351, -0.0111,  0.0213]],\n",
              "         dtype=torch.float64), 'final_loss': 0.016700805984667125, 'loss_breakdown': {'ot': 0.0017831612022955726,\n",
              "   'ortho': 0.0005140300204805091,\n",
              "   'graph': 14.866241780323502}, 'best_iter': 2249, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9140401146131805,\n",
              "   'accuracy_raw': 0.9140401146131805,\n",
              "   'foscttm': 0.23228873326163169}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[ 0.18198085,  0.01241892, -0.05521487, ..., -0.00728813,\n",
              "           0.03303289, -0.01549646],\n",
              "         [ 0.0286781 ,  0.07833217, -0.06277039, ...,  0.00925781,\n",
              "          -0.00474958, -0.00082885],\n",
              "         [-0.05019246,  0.11135643, -0.12309915, ...,  0.0532202 ,\n",
              "           0.06296541, -0.00155023],\n",
              "         ...,\n",
              "         [-0.02866489,  0.1113097 , -0.02913302, ..., -0.00387556,\n",
              "           0.00149385, -0.01060091],\n",
              "         [-0.07718538, -0.00299592,  0.05140044, ..., -0.02982554,\n",
              "           0.08115389, -0.01113562],\n",
              "         [-0.03264689, -0.00608067,  0.04398757, ..., -0.03267536,\n",
              "          -0.00809924, -0.0109475 ]]), 'mapped_Y': array([[ 0.13076031, -0.04191924, -0.04216054, ..., -0.02222821,\n",
              "           0.01449442, -0.02844858],\n",
              "         [-0.05165797, -0.03023923,  0.05256777, ...,  0.01675627,\n",
              "          -0.0194894 ,  0.0105071 ],\n",
              "         [ 0.06158309,  0.05331902,  0.02349233, ...,  0.000433  ,\n",
              "           0.0090966 ,  0.02461331],\n",
              "         ...,\n",
              "         [-0.10056563,  0.12724617, -0.13681074, ...,  0.08914067,\n",
              "           0.0579615 , -0.04556172],\n",
              "         [-0.08325187,  0.03466722,  0.05996793, ...,  0.01102948,\n",
              "           0.03582326, -0.00938127],\n",
              "         [-0.09901036, -0.04515213,  0.02785364, ...,  0.00979859,\n",
              "          -0.03998946,  0.00325972]]), 'alpha': tensor([[ 0.0779,  0.0409, -0.0222,  ...,  0.0034,  0.0058,  0.0004],\n",
              "          [ 0.1111,  0.0229,  0.0249,  ..., -0.0166, -0.0340,  0.0170],\n",
              "          [-0.0009, -0.0022, -0.0295,  ...,  0.0366,  0.0141,  0.0082],\n",
              "          ...,\n",
              "          [-0.0008,  0.0554,  0.0234,  ..., -0.1081, -0.0677,  0.0331],\n",
              "          [-0.0170,  0.0007,  0.0061,  ..., -0.0202,  0.0862, -0.0104],\n",
              "          [ 0.0221, -0.0028,  0.0080,  ..., -0.0361, -0.0122, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0025,  0.0388, -0.0027,  ..., -0.0053, -0.0057, -0.0108],\n",
              "          [ 0.0228, -0.0031,  0.0168,  ...,  0.0043,  0.0063, -0.0014],\n",
              "          [ 0.0054,  0.0275,  0.0772,  ...,  0.0296,  0.0504, -0.0012],\n",
              "          ...,\n",
              "          [-0.0212,  0.0048, -0.0516,  ...,  0.0461, -0.0028, -0.0260],\n",
              "          [ 0.0029,  0.0495,  0.0453,  ...,  0.0119,  0.0440, -0.0128],\n",
              "          [-0.0232, -0.0138,  0.0152,  ...,  0.0031, -0.0247,  0.0067]],\n",
              "         dtype=torch.float64), 'final_loss': 0.01702765525307524, 'loss_breakdown': {'ot': 0.0018854237719168555,\n",
              "   'ortho': 0.0005340547060996303,\n",
              "   'graph': 15.088826010548422}, 'best_iter': 2751, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.893505253104107,\n",
              "   'accuracy_raw': 0.893505253104107,\n",
              "   'foscttm': 0.22474546368438864}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[ 0.18181075,  0.03942655, -0.03008099, ...,  0.0051249 ,\n",
              "           0.02585563, -0.01614375],\n",
              "         [ 0.0260092 ,  0.08455763, -0.06845369, ...,  0.01911589,\n",
              "           0.00350098, -0.00284337],\n",
              "         [-0.0495549 ,  0.09574931, -0.14206614, ...,  0.0730881 ,\n",
              "           0.08154083,  0.01534522],\n",
              "         ...,\n",
              "         [-0.03763228,  0.10919169, -0.035688  , ...,  0.0185789 ,\n",
              "           0.01387999, -0.00990931],\n",
              "         [-0.07177027, -0.0254615 ,  0.03252559, ..., -0.05292368,\n",
              "           0.05686183, -0.01527464],\n",
              "         [-0.02862806, -0.01475428,  0.04079225, ..., -0.03493182,\n",
              "           0.00164178, -0.01369572]]), 'mapped_Y': array([[ 0.14802694, -0.02361864, -0.03577785, ..., -0.01285785,\n",
              "           0.00394921, -0.02342211],\n",
              "         [-0.06182915, -0.04664739,  0.04469097, ..., -0.00519768,\n",
              "          -0.02294096,  0.00062741],\n",
              "         [ 0.04593729,  0.07753036,  0.03919087, ...,  0.00129934,\n",
              "           0.00524207,  0.01045026],\n",
              "         ...,\n",
              "         [-0.09363357,  0.10598964, -0.15930356, ...,  0.11990637,\n",
              "           0.07778109, -0.02211168],\n",
              "         [-0.0750097 , -0.01240468,  0.03137369, ..., -0.00688302,\n",
              "           0.04373245, -0.01538295],\n",
              "         [-0.11126377, -0.05984833,  0.01526437, ..., -0.00242865,\n",
              "          -0.03894849,  0.00371931]]), 'alpha': tensor([[ 0.0633,  0.0422, -0.0188,  ...,  0.0068,  0.0065, -0.0029],\n",
              "          [ 0.1039,  0.0363,  0.0334,  ..., -0.0118, -0.0304,  0.0095],\n",
              "          [ 0.0003, -0.0045, -0.0323,  ...,  0.0364,  0.0198,  0.0156],\n",
              "          ...,\n",
              "          [-0.0107,  0.0662,  0.0371,  ..., -0.0735, -0.0591,  0.0321],\n",
              "          [-0.0023, -0.0040, -0.0018,  ..., -0.0335,  0.0600, -0.0100],\n",
              "          [ 0.0377,  0.0054,  0.0221,  ..., -0.0348, -0.0171, -0.0251]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0055,  0.0238, -0.0198,  ..., -0.0021, -0.0014, -0.0052],\n",
              "          [ 0.0198,  0.0039,  0.0230,  ...,  0.0041,  0.0017, -0.0027],\n",
              "          [ 0.0007,  0.0336,  0.0944,  ...,  0.0414,  0.0570, -0.0126],\n",
              "          ...,\n",
              "          [-0.0172,  0.0083, -0.0445,  ...,  0.0598, -0.0076, -0.0193],\n",
              "          [-0.0015,  0.0346,  0.0235,  ...,  0.0109,  0.0459, -0.0092],\n",
              "          [-0.0291, -0.0179,  0.0118,  ..., -0.0026, -0.0233,  0.0053]],\n",
              "         dtype=torch.float64), 'final_loss': 0.016761661073106185, 'loss_breakdown': {'ot': 0.0017002008192278976,\n",
              "   'ortho': 0.0005205243585209047,\n",
              "   'graph': 15.009407818026197}, 'best_iter': 2776, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9097421203438396,\n",
              "   'accuracy_raw': 0.9097421203438396,\n",
              "   'foscttm': 0.21446457746652325}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 3.13428105e-01, -1.37598909e-01, -7.79359440e-02, ...,\n",
              "           1.77373214e-02,  1.81050986e-01,  5.34241751e-02],\n",
              "         [-1.10140132e-01,  2.46286013e-01, -1.27827663e-01, ...,\n",
              "          -1.61851166e-01, -1.72569949e-01, -8.96924105e-02],\n",
              "         [ 1.17045916e-01,  3.25404829e-01, -1.10599380e-01, ...,\n",
              "          -2.02771253e-02, -1.55179448e-01, -6.42182158e-02],\n",
              "         ...,\n",
              "         [ 3.52650276e-02,  2.32253352e-01, -6.26125865e-02, ...,\n",
              "           6.19248127e-02, -1.34672086e-01, -2.18696611e-01],\n",
              "         [-3.26407997e-01,  4.79742239e-02, -3.68696929e-02, ...,\n",
              "          -1.85000387e-01,  5.59870470e-03,  8.50486015e-02],\n",
              "         [-3.01023880e-01, -2.18564652e-02, -1.36713066e-04, ...,\n",
              "          -1.02098264e-01, -1.17942234e-02, -5.57545639e-02]]), 'mapped_Y': array([[ 0.37284964, -0.14765815, -0.060977  , ..., -0.01605146,\n",
              "           0.16995512,  0.03613869],\n",
              "         [-0.43350231, -0.01440383, -0.05273131, ..., -0.08421818,\n",
              "          -0.0580925 ,  0.05359114],\n",
              "         [ 0.13408416,  0.10988757,  0.04744167, ..., -0.05456968,\n",
              "          -0.04290526,  0.09918356],\n",
              "         ...,\n",
              "         [ 0.05953521,  0.34272496, -0.17521479, ..., -0.02795522,\n",
              "          -0.20539043, -0.21694412],\n",
              "         [-0.35317732,  0.0236546 , -0.05996943, ...,  0.0582864 ,\n",
              "           0.05416703,  0.07021289],\n",
              "         [-0.37928313, -0.01915598, -0.06051121, ..., -0.09403323,\n",
              "          -0.05261811,  0.04601853]]), 'alpha': tensor([[ 0.0116,  0.0369, -0.0046,  ..., -0.0046,  0.0199, -0.0030],\n",
              "          [ 0.0146, -0.0102,  0.0128,  ..., -0.0514, -0.0155, -0.0113],\n",
              "          [ 0.0053,  0.0110, -0.0190,  ...,  0.0117,  0.0103, -0.0047],\n",
              "          ...,\n",
              "          [ 0.0035,  0.0142, -0.0051,  ..., -0.0102,  0.0037, -0.0173],\n",
              "          [-0.0042,  0.0311, -0.0005,  ..., -0.0782,  0.0218,  0.0005],\n",
              "          [-0.0118,  0.0094, -0.0124,  ..., -0.0957,  0.0080, -0.0271]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0020,  0.0054, -0.0017,  ..., -0.0039,  0.0133, -0.0039],\n",
              "          [ 0.0039,  0.0056,  0.0155,  ..., -0.0135, -0.0039,  0.0041],\n",
              "          [ 0.0094,  0.0228,  0.0263,  ..., -0.0138,  0.0014,  0.0282],\n",
              "          ...,\n",
              "          [-0.0065, -0.0008, -0.0209,  ..., -0.0111,  0.0015, -0.0402],\n",
              "          [ 0.0202,  0.0289, -0.0102,  ...,  0.0193,  0.0289,  0.0126],\n",
              "          [-0.0129, -0.0078, -0.0015,  ...,  0.0026, -0.0167, -0.0029]],\n",
              "         dtype=torch.float64), 'final_loss': 0.010055181810349022, 'loss_breakdown': {'ot': 0.004073461345692896,\n",
              "   'ortho': 0.00026495448067697394,\n",
              "   'graph': 59.55225016588429}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9641833810888252,\n",
              "   'accuracy_raw': 0.9641833810888252,\n",
              "   'foscttm': 0.14932827590359138}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.41298459, -0.12186621, -0.04126788, ...,  0.06281958,\n",
              "           0.05283706, -0.07345341],\n",
              "         [-0.15324665,  0.3125831 , -0.10533071, ..., -0.15828474,\n",
              "          -0.031899  ,  0.0338134 ],\n",
              "         [ 0.01512793,  0.42096262, -0.04238972, ..., -0.07220389,\n",
              "           0.01872665, -0.01811808],\n",
              "         ...,\n",
              "         [-0.05181581,  0.30809525, -0.00997699, ..., -0.01656339,\n",
              "          -0.00092069, -0.14092272],\n",
              "         [-0.33378606, -0.03354724, -0.1413909 , ..., -0.07052344,\n",
              "           0.06968183,  0.12857662],\n",
              "         [-0.29713227, -0.02725229, -0.05970838, ..., -0.10194547,\n",
              "           0.03734593,  0.06348242]]), 'mapped_Y': array([[ 0.46322231, -0.13109298, -0.01520073, ...,  0.03307947,\n",
              "           0.10498787, -0.11969483],\n",
              "         [-0.42658019, -0.09091626, -0.08758033, ..., -0.04698286,\n",
              "          -0.04745635,  0.12363353],\n",
              "         [ 0.07982671,  0.18373717,  0.06352868, ..., -0.04179336,\n",
              "          -0.018268  ,  0.00483562],\n",
              "         ...,\n",
              "         [-0.05879871,  0.39033076, -0.06513107, ..., -0.01806648,\n",
              "           0.04031785, -0.02745692],\n",
              "         [-0.38406744, -0.11428798,  0.02970206, ...,  0.16461817,\n",
              "          -0.06714018,  0.13144337],\n",
              "         [-0.29357823, -0.04298766, -0.12328921, ..., -0.10519443,\n",
              "           0.05768751,  0.1817275 ]]), 'alpha': tensor([[ 0.0044,  0.0291,  0.0145,  ..., -0.0006,  0.0074, -0.0051],\n",
              "          [ 0.0112,  0.0057,  0.0144,  ..., -0.0512, -0.0106, -0.0020],\n",
              "          [-0.0007,  0.0131, -0.0077,  ...,  0.0107,  0.0028, -0.0060],\n",
              "          ...,\n",
              "          [ 0.0029,  0.0233,  0.0010,  ...,  0.0101,  0.0025, -0.0186],\n",
              "          [-0.0127,  0.0028, -0.0130,  ..., -0.0577,  0.0578, -0.0005],\n",
              "          [-0.0132, -0.0036, -0.0226,  ..., -0.0799,  0.0567, -0.0185]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0001,  0.0027,  0.0033,  ...,  0.0029,  0.0244, -0.0051],\n",
              "          [-0.0037,  0.0046,  0.0117,  ..., -0.0076, -0.0070, -0.0060],\n",
              "          [ 0.0121,  0.0267,  0.0200,  ...,  0.0014, -0.0125, -0.0014],\n",
              "          ...,\n",
              "          [-0.0097, -0.0009, -0.0069,  ...,  0.0252,  0.0057,  0.0088],\n",
              "          [-0.0010,  0.0191,  0.0168,  ...,  0.0418,  0.0075, -0.0088],\n",
              "          [-0.0014, -0.0065, -0.0354,  ..., -0.0262,  0.0429,  0.0107]],\n",
              "         dtype=torch.float64), 'final_loss': 0.012173315885574396, 'loss_breakdown': {'ot': 0.0055687774059445735,\n",
              "   'ortho': 0.00041309293395638916,\n",
              "   'graph': 65.63229186234182}, 'best_iter': 2176, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.1491631614044402}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 4.55292095e-01, -1.09173089e-01,  7.09081830e-02, ...,\n",
              "           2.37450420e-02,  6.68289975e-02, -2.84796433e-02],\n",
              "         [-2.03000893e-01,  3.16771968e-01, -1.50668988e-01, ...,\n",
              "          -1.24159707e-01, -5.17260174e-02, -3.33291385e-02],\n",
              "         [-9.31279969e-02,  4.38968729e-01, -9.65926883e-06, ...,\n",
              "          -1.20246859e-01, -1.52463195e-02, -9.88376761e-02],\n",
              "         ...,\n",
              "         [-1.11212558e-01,  3.50870783e-01,  1.14323904e-02, ...,\n",
              "           5.47578764e-03,  9.62190998e-03, -2.05377240e-01],\n",
              "         [-2.57857615e-01, -3.43128765e-02, -2.16397950e-01, ...,\n",
              "          -3.63082219e-02,  5.34514932e-02,  1.07064934e-01],\n",
              "         [-2.62416904e-01, -4.71237221e-03, -1.91872525e-01, ...,\n",
              "          -6.19295946e-02,  3.20080736e-02,  1.25009781e-02]]), 'mapped_Y': array([[ 0.461907  , -0.12342557,  0.12686685, ..., -0.02016597,\n",
              "           0.10112678, -0.06062113],\n",
              "         [-0.312591  , -0.08352261, -0.23102981, ...,  0.17117016,\n",
              "          -0.04892941,  0.10527289],\n",
              "         [ 0.01113668,  0.15056485,  0.11793917, ..., -0.1137166 ,\n",
              "          -0.03263215,  0.05553335],\n",
              "         ...,\n",
              "         [-0.1486836 ,  0.43339905, -0.06727019, ..., -0.06072143,\n",
              "           0.00406985, -0.17731573],\n",
              "         [-0.25179479, -0.10652781, -0.1232977 , ...,  0.39417581,\n",
              "          -0.05572552,  0.15212104],\n",
              "         [-0.2507035 , -0.04197664, -0.20536974, ..., -0.06852555,\n",
              "           0.08491924,  0.13613691]]), 'alpha': tensor([[ 0.0016,  0.0236,  0.0138,  ..., -0.0021,  0.0074, -0.0032],\n",
              "          [ 0.0061,  0.0026,  0.0056,  ..., -0.0424, -0.0111, -0.0049],\n",
              "          [-0.0023,  0.0132, -0.0039,  ...,  0.0101,  0.0040, -0.0093],\n",
              "          ...,\n",
              "          [ 0.0043,  0.0251, -0.0011,  ...,  0.0011,  0.0062, -0.0163],\n",
              "          [-0.0113, -0.0002, -0.0201,  ..., -0.0636,  0.0352,  0.0002],\n",
              "          [-0.0096, -0.0005, -0.0454,  ..., -0.0778,  0.0397, -0.0179]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0016,  0.0009,  0.0059,  ...,  0.0018,  0.0197, -0.0016],\n",
              "          [-0.0043,  0.0036,  0.0118,  ...,  0.0021, -0.0114, -0.0039],\n",
              "          [ 0.0047,  0.0167,  0.0271,  ..., -0.0043, -0.0147,  0.0052],\n",
              "          ...,\n",
              "          [-0.0083, -0.0019, -0.0161,  ...,  0.0062,  0.0042, -0.0053],\n",
              "          [ 0.0012,  0.0197,  0.0188,  ...,  0.0633,  0.0119, -0.0062],\n",
              "          [-0.0040, -0.0052, -0.0235,  ..., -0.0332,  0.0430,  0.0044]],\n",
              "         dtype=torch.float64), 'final_loss': 0.012899038346348679, 'loss_breakdown': {'ot': 0.005924604929475512,\n",
              "   'ortho': 0.0005357569706564845,\n",
              "   'graph': 69.20857719807518}, 'best_iter': 2166, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9641833810888252,\n",
              "   'accuracy_raw': 0.9641833810888252,\n",
              "   'foscttm': 0.15042158931371666}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[ 4.03108397e-01, -2.48860587e-01, -1.45344392e-02, ...,\n",
              "          -4.48877052e-04,  5.32152459e-02, -1.05249115e-01],\n",
              "         [-1.31812645e-01,  3.38404074e-01, -1.80000954e-01, ...,\n",
              "          -1.28206465e-01,  1.20839836e-02,  6.09699483e-02],\n",
              "         [ 4.22082062e-02,  4.70465008e-01, -7.28972598e-02, ...,\n",
              "          -5.44724570e-02,  3.08356751e-02,  1.00710787e-01],\n",
              "         ...,\n",
              "         [-2.73241737e-02,  3.86866491e-01, -1.90511023e-02, ...,\n",
              "           1.46176455e-01, -3.13772040e-03, -1.84750819e-01],\n",
              "         [-3.32635163e-01, -1.04495444e-02, -1.84573971e-01, ...,\n",
              "          -5.71228237e-02, -4.89873880e-02,  6.86484150e-02],\n",
              "         [-3.26117580e-01, -2.96752671e-02, -6.15661076e-02, ...,\n",
              "          -1.53253622e-01, -1.39494054e-01, -7.09638956e-02]]), 'mapped_Y': array([[ 0.44331169, -0.20188916,  0.02367685, ..., -0.02438182,\n",
              "           0.02631806, -0.08034338],\n",
              "         [-0.39139875, -0.09979583, -0.21257443, ...,  0.10541274,\n",
              "          -0.03476285, -0.07129809],\n",
              "         [ 0.10361429,  0.1393885 ,  0.0554125 , ..., -0.16416367,\n",
              "          -0.02381328,  0.17705629],\n",
              "         ...,\n",
              "         [-0.01148333,  0.52255434, -0.10854634, ...,  0.06745781,\n",
              "           0.02757403, -0.05243914],\n",
              "         [-0.31131531, -0.15020317, -0.12858255, ...,  0.39363703,\n",
              "          -0.04710066,  0.06137313],\n",
              "         [-0.3594838 , -0.04220961, -0.17484526, ..., -0.19737704,\n",
              "          -0.03821031, -0.00391474]]), 'alpha': tensor([[ 0.0018,  0.0085, -0.0009,  ..., -0.0003,  0.0043, -0.0017],\n",
              "          [ 0.0040, -0.0042,  0.0035,  ..., -0.0198,  0.0017,  0.0020],\n",
              "          [ 0.0016,  0.0078, -0.0086,  ..., -0.0027,  0.0061,  0.0042],\n",
              "          ...,\n",
              "          [-0.0018,  0.0139, -0.0020,  ...,  0.0217, -0.0017, -0.0358],\n",
              "          [-0.0034,  0.0112, -0.0090,  ..., -0.0201,  0.0090,  0.0020],\n",
              "          [-0.0052, -0.0055, -0.0111,  ..., -0.0650, -0.0055, -0.0246]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-5.9063e-04,  7.6581e-05, -6.6126e-04,  ..., -1.4462e-03,\n",
              "           -5.6709e-04, -9.4621e-04],\n",
              "          [ 2.5673e-03, -9.8596e-04, -7.5067e-04,  ...,  5.9060e-04,\n",
              "            2.4130e-03, -8.7189e-03],\n",
              "          [ 6.5857e-03,  6.6667e-03,  6.4351e-03,  ..., -2.5021e-02,\n",
              "           -5.5976e-03,  1.8973e-02],\n",
              "          ...,\n",
              "          [-2.8111e-03,  6.5046e-03, -8.9583e-03,  ...,  9.3525e-03,\n",
              "            2.2264e-03, -1.4625e-02],\n",
              "          [ 7.7975e-03,  6.4120e-03,  3.6495e-03,  ...,  3.9288e-02,\n",
              "            1.1184e-02,  1.0514e-02],\n",
              "          [-1.0621e-02, -1.2398e-03, -2.9415e-03,  ..., -2.2126e-02,\n",
              "           -2.7604e-03, -6.3272e-03]], dtype=torch.float64), 'final_loss': 0.008852531632137355, 'loss_breakdown': {'ot': 0.007793378137720305,\n",
              "   'ortho': 7.712657426278367e-05,\n",
              "   'graph': 105.14408369907716}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.1542196789115944}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[ 4.00091961e-01, -1.67302630e-01, -6.14447370e-02, ...,\n",
              "           3.70331186e-02,  4.57844418e-02,  6.99632420e-02],\n",
              "         [-1.96921630e-01,  3.10330594e-01, -1.25294628e-01, ...,\n",
              "          -1.47262152e-01, -3.79142339e-02, -3.26913817e-02],\n",
              "         [-1.67224148e-04,  4.62988682e-01, -1.03428191e-01, ...,\n",
              "          -6.88577000e-02,  8.65849213e-03, -2.07712049e-02],\n",
              "         ...,\n",
              "         [-1.18768535e-03,  3.52702501e-01, -4.31777328e-02, ...,\n",
              "           8.50326478e-02, -3.29943462e-02, -2.00710483e-01],\n",
              "         [-3.64501668e-01, -7.53007749e-02, -1.01101071e-01, ...,\n",
              "          -5.36661652e-02,  9.63231398e-02, -2.51760711e-02],\n",
              "         [-2.82635631e-01,  1.61189395e-02, -3.71374087e-02, ...,\n",
              "          -1.44595443e-01, -2.86198074e-02, -9.55387882e-02]]), 'mapped_Y': array([[ 0.44336918, -0.15834665, -0.04061779, ...,  0.00840655,\n",
              "           0.08841198,  0.08193664],\n",
              "         [-0.45107714, -0.12065817, -0.0248481 , ...,  0.09832478,\n",
              "          -0.08854352, -0.10682798],\n",
              "         [ 0.07106133,  0.16717763,  0.03288149, ..., -0.07444215,\n",
              "          -0.01820832,  0.06909221],\n",
              "         ...,\n",
              "         [-0.04088803,  0.45218573, -0.12439934, ...,  0.01342313,\n",
              "          -0.01903507, -0.08836057],\n",
              "         [-0.40971391, -0.13832896,  0.10531932, ...,  0.26526167,\n",
              "          -0.11959988, -0.0029968 ],\n",
              "         [-0.37744983, -0.07025439, -0.07062286, ..., -0.08482601,\n",
              "           0.07087444, -0.02457877]]), 'alpha': tensor([[ 2.7325e-03,  2.1883e-02,  8.0525e-03,  ..., -6.7718e-05,\n",
              "            1.0800e-02,  3.7868e-03],\n",
              "          [ 7.4704e-03,  2.4094e-03, -1.8868e-03,  ..., -4.6869e-02,\n",
              "           -8.6106e-03,  8.2988e-03],\n",
              "          [-1.5246e-03,  1.6543e-02, -3.8456e-03,  ...,  5.7498e-03,\n",
              "            9.8250e-03, -2.5877e-03],\n",
              "          ...,\n",
              "          [ 9.2835e-03,  1.7851e-02, -6.4772e-03,  ...,  1.7214e-02,\n",
              "           -1.2258e-02, -2.1016e-02],\n",
              "          [-7.7703e-03,  4.9437e-03, -1.6273e-02,  ..., -5.1422e-02,\n",
              "            5.9420e-02, -9.4444e-03],\n",
              "          [-4.6853e-03,  2.4631e-03, -2.6266e-02,  ..., -8.4300e-02,\n",
              "            2.6732e-02, -3.0350e-02]], dtype=torch.float64), 'beta': tensor([[-0.0015,  0.0007,  0.0016,  ...,  0.0055,  0.0158,  0.0048],\n",
              "          [-0.0018,  0.0029,  0.0076,  ...,  0.0047, -0.0139, -0.0094],\n",
              "          [ 0.0062,  0.0118,  0.0099,  ..., -0.0049, -0.0092, -0.0006],\n",
              "          ...,\n",
              "          [-0.0041, -0.0005, -0.0070,  ...,  0.0137, -0.0071,  0.0049],\n",
              "          [ 0.0034,  0.0173,  0.0191,  ...,  0.0450, -0.0072, -0.0082],\n",
              "          [-0.0078, -0.0074, -0.0169,  ..., -0.0222,  0.0420, -0.0071]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00751295471857496, 'loss_breakdown': {'ot': 0.006695307670638678,\n",
              "   'ortho': 0.00026584743397392206,\n",
              "   'graph': 79.10623045388897}, 'best_iter': 2144, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076409,\n",
              "   'accuracy_raw': 0.9646609360076409,\n",
              "   'foscttm': 0.15417999669771001}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.39968743, -0.19152064,  0.0173504 , ...,  0.00078452,\n",
              "           0.01760464,  0.07473511],\n",
              "         [-0.15509502,  0.30499803, -0.15609328, ..., -0.09281004,\n",
              "          -0.02273375, -0.00913687],\n",
              "         [ 0.04392821,  0.4579213 , -0.10129326, ..., -0.02488936,\n",
              "           0.03018684, -0.02355869],\n",
              "         ...,\n",
              "         [ 0.01394499,  0.33653342, -0.02889766, ...,  0.0628317 ,\n",
              "           0.01764604, -0.16665172],\n",
              "         [-0.32079148, -0.04618707, -0.17743271, ..., -0.07446535,\n",
              "           0.08049315, -0.0481606 ],\n",
              "         [-0.28898359,  0.02225951, -0.05307401, ..., -0.15777752,\n",
              "          -0.0164521 , -0.03010444]]), 'mapped_Y': array([[ 0.43404849, -0.17929134,  0.05821316, ..., -0.022305  ,\n",
              "           0.04660368,  0.07218718],\n",
              "         [-0.42676001, -0.10136016, -0.16601184, ...,  0.07258889,\n",
              "          -0.08901373, -0.10254988],\n",
              "         [ 0.08220929,  0.15444724,  0.04469956, ..., -0.05123872,\n",
              "          -0.04410374,  0.07937982],\n",
              "         ...,\n",
              "         [ 0.00078742,  0.4442202 , -0.13757254, ...,  0.01643942,\n",
              "           0.03100141, -0.09400224],\n",
              "         [-0.42340605, -0.12129248, -0.02666789, ...,  0.30117537,\n",
              "          -0.07975514, -0.04116398],\n",
              "         [-0.34038822, -0.0538557 , -0.14073732, ..., -0.09775748,\n",
              "           0.05949143,  0.02375859]]), 'alpha': tensor([[ 0.0037,  0.0221,  0.0059,  ..., -0.0023,  0.0093,  0.0079],\n",
              "          [ 0.0081,  0.0011,  0.0070,  ..., -0.0332, -0.0137,  0.0101],\n",
              "          [ 0.0002,  0.0178, -0.0064,  ...,  0.0090,  0.0117, -0.0041],\n",
              "          ...,\n",
              "          [ 0.0088,  0.0166, -0.0019,  ..., -0.0012, -0.0061, -0.0166],\n",
              "          [-0.0054,  0.0055, -0.0163,  ..., -0.0781,  0.0416, -0.0058],\n",
              "          [-0.0062,  0.0014, -0.0227,  ..., -0.1166,  0.0167, -0.0048]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0018,  0.0009,  0.0016,  ...,  0.0021,  0.0119,  0.0084],\n",
              "          [-0.0012,  0.0033,  0.0009,  ..., -0.0022, -0.0191, -0.0113],\n",
              "          [ 0.0096,  0.0081,  0.0081,  ..., -0.0068, -0.0303,  0.0004],\n",
              "          ...,\n",
              "          [-0.0050,  0.0012, -0.0101,  ...,  0.0066, -0.0012,  0.0034],\n",
              "          [ 0.0026,  0.0138,  0.0162,  ...,  0.0503, -0.0031, -0.0135],\n",
              "          [-0.0062, -0.0072, -0.0109,  ..., -0.0274,  0.0348,  0.0021]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007457687783924975, 'loss_breakdown': {'ot': 0.006628237613178076,\n",
              "   'ortho': 0.00040860022620895246,\n",
              "   'graph': 78.85901481260032}, 'best_iter': 2239, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.1541070179135548}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[ 0.3893139 , -0.26940013, -0.06097192, ..., -0.00240933,\n",
              "           0.03587313, -0.10356863],\n",
              "         [-0.13177991,  0.3526478 , -0.15483416, ..., -0.12279145,\n",
              "           0.02798435,  0.06036887],\n",
              "         [ 0.05899285,  0.47281593, -0.05599806, ..., -0.04506784,\n",
              "           0.04297753,  0.10016871],\n",
              "         ...,\n",
              "         [-0.01090133,  0.3922942 , -0.00132309, ...,  0.14529566,\n",
              "           0.00859921, -0.18813633],\n",
              "         [-0.35068354,  0.00734091, -0.15514688, ..., -0.05469242,\n",
              "          -0.04002386,  0.06730491],\n",
              "         [-0.32967989, -0.00685723, -0.03521372, ..., -0.16479109,\n",
              "          -0.1287823 , -0.07477948]]), 'mapped_Y': array([[ 0.43606741, -0.22340495, -0.02595766, ..., -0.02237715,\n",
              "           0.00752182, -0.07746994],\n",
              "         [-0.4175347 , -0.07613883, -0.17631949, ...,  0.10648048,\n",
              "          -0.02470728, -0.07573972],\n",
              "         [ 0.11446174,  0.13767612,  0.04760518, ..., -0.16367004,\n",
              "          -0.02618397,  0.17542093],\n",
              "         ...,\n",
              "         [ 0.00314226,  0.52634913, -0.08565716, ...,  0.07512706,\n",
              "           0.04274862, -0.05155288],\n",
              "         [-0.3388038 , -0.13961988, -0.10496971, ...,  0.38793981,\n",
              "          -0.04683515,  0.0565664 ],\n",
              "         [-0.37513872, -0.01937463, -0.14192666, ..., -0.2008868 ,\n",
              "          -0.02398672, -0.00501696]]), 'alpha': tensor([[ 0.0037,  0.0070, -0.0012,  ..., -0.0006,  0.0040, -0.0017],\n",
              "          [ 0.0038, -0.0033,  0.0023,  ..., -0.0184,  0.0019,  0.0023],\n",
              "          [ 0.0016,  0.0073, -0.0076,  ..., -0.0027,  0.0061,  0.0044],\n",
              "          ...,\n",
              "          [-0.0009,  0.0147, -0.0017,  ...,  0.0211, -0.0004, -0.0365],\n",
              "          [-0.0036,  0.0113, -0.0082,  ..., -0.0198,  0.0088,  0.0023],\n",
              "          [-0.0053, -0.0041, -0.0108,  ..., -0.0532, -0.0058, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0008, -0.0006, -0.0011,  ..., -0.0015, -0.0010, -0.0007],\n",
              "          [ 0.0024, -0.0008, -0.0006,  ...,  0.0015,  0.0023, -0.0090],\n",
              "          [ 0.0069,  0.0066,  0.0049,  ..., -0.0240, -0.0056,  0.0199],\n",
              "          ...,\n",
              "          [-0.0030,  0.0067, -0.0080,  ...,  0.0093,  0.0021, -0.0139],\n",
              "          [ 0.0070,  0.0048,  0.0035,  ...,  0.0389,  0.0100,  0.0099],\n",
              "          [-0.0108, -0.0004, -0.0019,  ..., -0.0226, -0.0020, -0.0060]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007998882094159396, 'loss_breakdown': {'ot': 0.007886214016709563,\n",
              "   'ortho': 6.196777317430332e-05,\n",
              "   'graph': 106.47130013240233}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.15435788248408835}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.37816272, -0.17229253, -0.07565505, ...,  0.04648673,\n",
              "           0.04791399,  0.09708982],\n",
              "         [-0.18773551,  0.30266079, -0.120343  , ..., -0.15746917,\n",
              "          -0.03531433, -0.04763794],\n",
              "         [ 0.01976812,  0.45064546, -0.08777132, ..., -0.10096737,\n",
              "           0.00145232, -0.03643835],\n",
              "         ...,\n",
              "         [ 0.02473806,  0.35383438, -0.03351434, ...,  0.07939733,\n",
              "          -0.03745475, -0.20279985],\n",
              "         [-0.3713113 , -0.05491075, -0.09788897, ..., -0.04912868,\n",
              "           0.09081965, -0.02028568],\n",
              "         [-0.28362169,  0.0263522 , -0.02896068, ..., -0.14272917,\n",
              "          -0.01835876, -0.09243558]]), 'mapped_Y': array([[ 0.41945873, -0.17364541, -0.05862407, ...,  0.01532848,\n",
              "           0.09151672,  0.09490923],\n",
              "         [-0.45344915, -0.09685088, -0.01560408, ...,  0.14220189,\n",
              "          -0.08514443, -0.0914494 ],\n",
              "         [ 0.06971329,  0.16973681,  0.02555468, ..., -0.09528623,\n",
              "          -0.01332589,  0.04367161],\n",
              "         ...,\n",
              "         [-0.01439887,  0.44290187, -0.1018126 , ..., -0.01503458,\n",
              "          -0.03192282, -0.09507641],\n",
              "         [-0.40947443, -0.11808688,  0.11528102, ...,  0.2840979 ,\n",
              "          -0.13150849,  0.0302092 ],\n",
              "         [-0.38507741, -0.05466163, -0.07052768, ..., -0.06511258,\n",
              "           0.08074278, -0.02798734]]), 'alpha': tensor([[ 0.0026,  0.0223,  0.0098,  ..., -0.0026,  0.0097,  0.0041],\n",
              "          [ 0.0069,  0.0010, -0.0024,  ..., -0.0457, -0.0062,  0.0076],\n",
              "          [-0.0015,  0.0170, -0.0027,  ...,  0.0035,  0.0083, -0.0019],\n",
              "          ...,\n",
              "          [ 0.0112,  0.0174, -0.0069,  ...,  0.0215, -0.0119, -0.0215],\n",
              "          [-0.0088,  0.0041, -0.0224,  ..., -0.0462,  0.0617, -0.0110],\n",
              "          [-0.0059,  0.0017, -0.0316,  ..., -0.0730,  0.0321, -0.0305]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0025,  0.0009,  0.0006,  ...,  0.0059,  0.0162,  0.0044],\n",
              "          [-0.0023,  0.0037,  0.0078,  ...,  0.0063, -0.0118, -0.0097],\n",
              "          [ 0.0051,  0.0136,  0.0108,  ..., -0.0095, -0.0062, -0.0067],\n",
              "          ...,\n",
              "          [-0.0037, -0.0006, -0.0073,  ...,  0.0079, -0.0090,  0.0063],\n",
              "          [ 0.0039,  0.0204,  0.0204,  ...,  0.0429, -0.0079, -0.0047],\n",
              "          [-0.0087, -0.0088, -0.0204,  ..., -0.0201,  0.0447, -0.0079]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006573553555535974, 'loss_breakdown': {'ot': 0.006478244786346401,\n",
              "   'ortho': 0.00016736792586094542,\n",
              "   'graph': 78.57197660347812}, 'best_iter': 2294, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076409,\n",
              "   'accuracy_raw': 0.9646609360076409,\n",
              "   'foscttm': 0.15420143421555563}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.38481909, -0.20429378,  0.05584875, ...,  0.00161789,\n",
              "           0.01707513,  0.03689579],\n",
              "         [-0.10900457,  0.33001425, -0.16035579, ..., -0.08615176,\n",
              "          -0.02046848, -0.00464813],\n",
              "         [ 0.08058447,  0.45956617, -0.04123384, ..., -0.02908328,\n",
              "           0.04204424, -0.03187419],\n",
              "         ...,\n",
              "         [ 0.0271718 ,  0.33518577, -0.00748388, ...,  0.08228128,\n",
              "           0.02267564, -0.20259983],\n",
              "         [-0.28437797, -0.024409  , -0.24239057, ..., -0.09134341,\n",
              "           0.0706177 ,  0.00066033],\n",
              "         [-0.25854683,  0.03389383, -0.10007795, ..., -0.16500521,\n",
              "          -0.0495409 , -0.0176306 ]]), 'mapped_Y': array([[ 0.41426533, -0.19560703,  0.11249125, ..., -0.01729947,\n",
              "           0.0478276 ,  0.03470128],\n",
              "         [-0.39240769, -0.07003641, -0.2456764 , ...,  0.08254449,\n",
              "          -0.08782902, -0.07470767],\n",
              "         [ 0.07741801,  0.16054216,  0.06104103, ..., -0.05536745,\n",
              "          -0.03691349,  0.07131489],\n",
              "         ...,\n",
              "         [ 0.04973981,  0.44328124, -0.08076981, ...,  0.01012945,\n",
              "           0.03661407, -0.10670474],\n",
              "         [-0.41518994, -0.09517355, -0.11381915, ...,  0.31109088,\n",
              "          -0.08886995,  0.02116975],\n",
              "         [-0.29289435, -0.02818219, -0.20623875, ..., -0.1006173 ,\n",
              "           0.05608803,  0.0544347 ]]), 'alpha': tensor([[ 0.0032,  0.0208,  0.0064,  ..., -0.0034,  0.0086,  0.0055],\n",
              "          [ 0.0070,  0.0021,  0.0073,  ..., -0.0280, -0.0139,  0.0061],\n",
              "          [ 0.0010,  0.0162, -0.0052,  ...,  0.0059,  0.0122, -0.0015],\n",
              "          ...,\n",
              "          [ 0.0074,  0.0137, -0.0012,  ...,  0.0027, -0.0077, -0.0231],\n",
              "          [-0.0041,  0.0069, -0.0185,  ..., -0.0769,  0.0418, -0.0048],\n",
              "          [-0.0031,  0.0021, -0.0221,  ..., -0.1170,  0.0102, -0.0157]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0016,  0.0005,  0.0015,  ...,  0.0032,  0.0118,  0.0074],\n",
              "          [-0.0024,  0.0035,  0.0012,  ..., -0.0017, -0.0180, -0.0148],\n",
              "          [ 0.0102,  0.0088,  0.0076,  ..., -0.0088, -0.0285, -0.0005],\n",
              "          ...,\n",
              "          [-0.0023,  0.0012, -0.0092,  ...,  0.0025, -0.0032,  0.0072],\n",
              "          [ 0.0005,  0.0135,  0.0144,  ...,  0.0474, -0.0043, -0.0101],\n",
              "          [-0.0051, -0.0063, -0.0103,  ..., -0.0253,  0.0322,  0.0021]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00752270650333117, 'loss_breakdown': {'ot': 0.007409927647808364,\n",
              "   'ortho': 0.0003008846814356423,\n",
              "   'graph': 82.69038737924139}, 'best_iter': 2114, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076408,\n",
              "   'accuracy_raw': 0.9646609360076408,\n",
              "   'foscttm': 0.1543574263666874}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[ 3.86415720e-01, -2.72859555e-01, -6.26827317e-02, ...,\n",
              "          -1.62598585e-03,  3.64280631e-02, -1.03143145e-01],\n",
              "         [-1.28273862e-01,  3.54091362e-01, -1.52467244e-01, ...,\n",
              "          -1.24336193e-01,  2.75517410e-02,  5.95268762e-02],\n",
              "         [ 6.34940944e-02,  4.71940900e-01, -5.32045513e-02, ...,\n",
              "          -4.74522521e-02,  4.17079406e-02,  9.83870438e-02],\n",
              "         ...,\n",
              "         [-7.20882168e-03,  3.92151773e-01,  3.37872417e-04, ...,\n",
              "           1.43806497e-01,  7.44213183e-03, -1.89285903e-01],\n",
              "         [-3.50877677e-01,  1.12706934e-02, -1.55279330e-01, ...,\n",
              "          -5.45086870e-02, -3.97406472e-02,  6.83665540e-02],\n",
              "         [-3.30188853e-01, -5.24221319e-03, -3.60189859e-02, ...,\n",
              "          -1.64358045e-01, -1.29109140e-01, -7.43637584e-02]]), 'mapped_Y': array([[ 0.43365656, -0.22743115, -0.0277192 , ..., -0.02199337,\n",
              "           0.00775048, -0.07762717],\n",
              "         [-0.41885319, -0.07063175, -0.17694132, ...,  0.10662659,\n",
              "          -0.02294376, -0.07495167],\n",
              "         [ 0.11590485,  0.1365024 ,  0.04932817, ..., -0.16523563,\n",
              "          -0.02625177,  0.17431893],\n",
              "         ...,\n",
              "         [ 0.00817634,  0.52639744, -0.08319113, ...,  0.07322163,\n",
              "           0.04128455, -0.05318419],\n",
              "         [-0.33971266, -0.13372319, -0.10573389, ...,  0.38832177,\n",
              "          -0.04566144,  0.05811334],\n",
              "         [-0.37552715, -0.0158646 , -0.14167472, ..., -0.20060984,\n",
              "          -0.02315475, -0.00401442]]), 'alpha': tensor([[ 0.0037,  0.0069, -0.0011,  ..., -0.0007,  0.0039, -0.0017],\n",
              "          [ 0.0038, -0.0034,  0.0022,  ..., -0.0182,  0.0020,  0.0023],\n",
              "          [ 0.0016,  0.0073, -0.0074,  ..., -0.0027,  0.0060,  0.0043],\n",
              "          ...,\n",
              "          [-0.0007,  0.0146, -0.0016,  ...,  0.0211, -0.0005, -0.0365],\n",
              "          [-0.0035,  0.0113, -0.0081,  ..., -0.0197,  0.0087,  0.0024],\n",
              "          [-0.0054, -0.0043, -0.0109,  ..., -0.0527, -0.0059, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0008, -0.0006, -0.0011,  ..., -0.0015, -0.0011, -0.0007],\n",
              "          [ 0.0022, -0.0007, -0.0006,  ...,  0.0015,  0.0024, -0.0092],\n",
              "          [ 0.0070,  0.0065,  0.0051,  ..., -0.0240, -0.0055,  0.0196],\n",
              "          ...,\n",
              "          [-0.0029,  0.0068, -0.0079,  ...,  0.0093,  0.0020, -0.0138],\n",
              "          [ 0.0070,  0.0048,  0.0035,  ...,  0.0387,  0.0100,  0.0100],\n",
              "          [-0.0109, -0.0004, -0.0019,  ..., -0.0227, -0.0020, -0.0060]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007900440214632227, 'loss_breakdown': {'ot': 0.007883735829703208,\n",
              "   'ortho': 6.0511400878951945e-05,\n",
              "   'graph': 106.53244841124291}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.1543601630710932}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.38851221, -0.16520584, -0.07529317, ...,  0.05541937,\n",
              "           0.04405229,  0.0787194 ],\n",
              "         [-0.19805966,  0.30645764, -0.11927083, ..., -0.1573685 ,\n",
              "          -0.0342426 , -0.03307142],\n",
              "         [ 0.00469961,  0.4516895 , -0.09329705, ..., -0.09576362,\n",
              "           0.00796445, -0.02078996],\n",
              "         ...,\n",
              "         [ 0.00735644,  0.35204413, -0.03380488, ...,  0.08286409,\n",
              "          -0.03038919, -0.19329998],\n",
              "         [-0.36970273, -0.06792925, -0.09986375, ..., -0.05489029,\n",
              "           0.08946714, -0.0185552 ],\n",
              "         [-0.28240876,  0.01342522, -0.03818504, ..., -0.14092663,\n",
              "          -0.02364683, -0.08666668]]), 'mapped_Y': array([[ 0.42843874, -0.16470996, -0.05803779, ...,  0.02333425,\n",
              "           0.08611627,  0.08133318],\n",
              "         [-0.45387974, -0.10442775, -0.0071366 , ...,  0.13480898,\n",
              "          -0.08650631, -0.09296636],\n",
              "         [ 0.07328331,  0.1746736 ,  0.02627605, ..., -0.09517415,\n",
              "          -0.01495976,  0.04855423],\n",
              "         ...,\n",
              "         [-0.03654152,  0.44043488, -0.10932378, ..., -0.01258544,\n",
              "          -0.02244845, -0.07907373],\n",
              "         [-0.4061693 , -0.1190501 ,  0.12693597, ...,  0.28055696,\n",
              "          -0.13690555,  0.02747007],\n",
              "         [-0.38310293, -0.06606691, -0.06812271, ..., -0.06833008,\n",
              "           0.08218666, -0.02160965]]), 'alpha': tensor([[ 0.0029,  0.0221,  0.0091,  ..., -0.0015,  0.0100,  0.0036],\n",
              "          [ 0.0070,  0.0010, -0.0037,  ..., -0.0447, -0.0073,  0.0075],\n",
              "          [-0.0016,  0.0169, -0.0029,  ...,  0.0046,  0.0091, -0.0018],\n",
              "          ...,\n",
              "          [ 0.0104,  0.0163, -0.0070,  ...,  0.0206, -0.0115, -0.0218],\n",
              "          [-0.0086,  0.0039, -0.0230,  ..., -0.0478,  0.0604, -0.0104],\n",
              "          [-0.0058,  0.0012, -0.0334,  ..., -0.0745,  0.0297, -0.0304]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-2.1127e-03,  8.4870e-04,  1.0804e-03,  ...,  5.7593e-03,\n",
              "            1.5693e-02,  4.7527e-03],\n",
              "          [-2.2016e-03,  3.2493e-03,  7.5365e-03,  ...,  5.9611e-03,\n",
              "           -1.2419e-02, -1.0123e-02],\n",
              "          [ 6.0229e-03,  1.2793e-02,  1.0249e-02,  ..., -8.8761e-03,\n",
              "           -7.5023e-03, -5.4794e-03],\n",
              "          ...,\n",
              "          [-4.4663e-03,  9.7183e-05, -7.2789e-03,  ...,  7.4951e-03,\n",
              "           -8.0801e-03,  6.4443e-03],\n",
              "          [ 3.8915e-03,  1.9550e-02,  2.0376e-02,  ...,  4.2791e-02,\n",
              "           -9.6878e-03, -4.3872e-03],\n",
              "          [-8.6891e-03, -9.1057e-03, -2.0045e-02,  ..., -1.9523e-02,\n",
              "            4.4760e-02, -6.9527e-03]], dtype=torch.float64), 'final_loss': 0.006658301938330267, 'loss_breakdown': {'ot': 0.006634716106676823,\n",
              "   'ortho': 0.00015666028275497767,\n",
              "   'graph': 79.1980337794579}, 'best_iter': 2244, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.1541996097459517}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[ 0.38299794, -0.19549059,  0.07757556, ..., -0.00733391,\n",
              "           0.02077709,  0.04233613],\n",
              "         [-0.10871915,  0.3109606 , -0.17410429, ..., -0.08355409,\n",
              "          -0.03584922, -0.00750163],\n",
              "         [ 0.08316286,  0.44848563, -0.08487913, ..., -0.01943675,\n",
              "           0.02847085, -0.03162774],\n",
              "         ...,\n",
              "         [ 0.03065145,  0.33101296, -0.02789995, ...,  0.07210807,\n",
              "           0.0123141 , -0.18447594],\n",
              "         [-0.29085304, -0.04104197, -0.23347204, ..., -0.07489434,\n",
              "           0.08435209, -0.0098657 ],\n",
              "         [-0.26259052,  0.03766699, -0.09313527, ..., -0.15874744,\n",
              "          -0.02364167, -0.00962052]]), 'mapped_Y': array([[ 0.41363422, -0.1882549 ,  0.12384375, ..., -0.02622705,\n",
              "           0.04853617,  0.03622629],\n",
              "         [-0.40199382, -0.08098815, -0.2273606 , ...,  0.07462406,\n",
              "          -0.07807507, -0.07630312],\n",
              "         [ 0.08298548,  0.16133888,  0.05700999, ..., -0.05438841,\n",
              "          -0.04138399,  0.07192989],\n",
              "         ...,\n",
              "         [ 0.04397911,  0.4346902 , -0.12678425, ...,  0.02119004,\n",
              "           0.03143948, -0.09558793],\n",
              "         [-0.4144794 , -0.10531163, -0.09177057, ...,  0.2973583 ,\n",
              "          -0.07126109,  0.00979117],\n",
              "         [-0.30780121, -0.03898202, -0.19580903, ..., -0.09127239,\n",
              "           0.06108939,  0.05817176]]), 'alpha': tensor([[ 0.0037,  0.0224,  0.0077,  ..., -0.0035,  0.0087,  0.0062],\n",
              "          [ 0.0077,  0.0026,  0.0102,  ..., -0.0307, -0.0172,  0.0061],\n",
              "          [ 0.0012,  0.0172, -0.0060,  ...,  0.0076,  0.0119, -0.0025],\n",
              "          ...,\n",
              "          [ 0.0084,  0.0160, -0.0014,  ..., -0.0005, -0.0080, -0.0197],\n",
              "          [-0.0049,  0.0058, -0.0191,  ..., -0.0772,  0.0458, -0.0035],\n",
              "          [-0.0037,  0.0038, -0.0221,  ..., -0.1173,  0.0140, -0.0115]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0021,  0.0012,  0.0018,  ...,  0.0028,  0.0125,  0.0074],\n",
              "          [-0.0025,  0.0047,  0.0020,  ..., -0.0032, -0.0167, -0.0140],\n",
              "          [ 0.0104,  0.0098,  0.0088,  ..., -0.0094, -0.0307, -0.0013],\n",
              "          ...,\n",
              "          [-0.0026,  0.0021, -0.0101,  ...,  0.0057, -0.0016,  0.0096],\n",
              "          [ 0.0006,  0.0153,  0.0155,  ...,  0.0458,  0.0002, -0.0101],\n",
              "          [-0.0057, -0.0073, -0.0122,  ..., -0.0252,  0.0350,  0.0043]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006627303909794436, 'loss_breakdown': {'ot': 0.006593943859537494,\n",
              "   'ortho': 0.0002543979193698486,\n",
              "   'graph': 79.20258319957401}, 'best_iter': 2293, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15486052385995736}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[ 0.38491379, -0.27455988, -0.06354162, ..., -0.0010183 ,\n",
              "           0.03710309, -0.10256499],\n",
              "         [-0.1261279 ,  0.35498613, -0.15082024, ..., -0.12531956,\n",
              "           0.02694141,  0.05914713],\n",
              "         [ 0.0659041 ,  0.47161921, -0.05114842, ..., -0.04830337,\n",
              "           0.04094075,  0.09774955],\n",
              "         ...,\n",
              "         [-0.00529303,  0.39201309,  0.00126538, ...,  0.1432185 ,\n",
              "           0.00696377, -0.18987539],\n",
              "         [-0.35062463,  0.01348426, -0.15540214, ..., -0.05512471,\n",
              "          -0.04003144,  0.06870432],\n",
              "         [-0.3302543 , -0.00409733, -0.03620717, ..., -0.1645494 ,\n",
              "          -0.12898013, -0.07446886]]), 'mapped_Y': array([[ 0.43237167, -0.22948332, -0.02835544, ..., -0.02130423,\n",
              "           0.00825059, -0.07723911],\n",
              "         [-0.41923338, -0.06781691, -0.17787816, ...,  0.1057001 ,\n",
              "          -0.02279477, -0.07488242],\n",
              "         [ 0.11665994,  0.13582116,  0.0505366 , ..., -0.16551091,\n",
              "          -0.02622867,  0.17399151],\n",
              "         ...,\n",
              "         [ 0.01091307,  0.52646444, -0.08151796, ...,  0.07227651,\n",
              "           0.04028035, -0.05384834],\n",
              "         [-0.3404406 , -0.13091544, -0.10710658, ...,  0.38771096,\n",
              "          -0.04531135,  0.05827983],\n",
              "         [-0.37528826, -0.01376664, -0.14168262, ..., -0.20112292,\n",
              "          -0.0232616 , -0.00379766]]), 'alpha': tensor([[ 0.0037,  0.0068, -0.0010,  ..., -0.0007,  0.0039, -0.0017],\n",
              "          [ 0.0038, -0.0034,  0.0023,  ..., -0.0182,  0.0020,  0.0023],\n",
              "          [ 0.0017,  0.0074, -0.0074,  ..., -0.0028,  0.0060,  0.0043],\n",
              "          ...,\n",
              "          [-0.0007,  0.0146, -0.0016,  ...,  0.0210, -0.0004, -0.0365],\n",
              "          [-0.0035,  0.0114, -0.0080,  ..., -0.0198,  0.0086,  0.0024],\n",
              "          [-0.0054, -0.0043, -0.0109,  ..., -0.0526, -0.0059, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0008, -0.0006, -0.0011,  ..., -0.0015, -0.0010, -0.0007],\n",
              "          [ 0.0021, -0.0007, -0.0006,  ...,  0.0014,  0.0025, -0.0092],\n",
              "          [ 0.0070,  0.0064,  0.0052,  ..., -0.0240, -0.0055,  0.0196],\n",
              "          ...,\n",
              "          [-0.0029,  0.0069, -0.0079,  ...,  0.0093,  0.0020, -0.0138],\n",
              "          [ 0.0070,  0.0048,  0.0035,  ...,  0.0387,  0.0100,  0.0100],\n",
              "          [-0.0109, -0.0004, -0.0019,  ..., -0.0227, -0.0019, -0.0061]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007888257250492912, 'loss_breakdown': {'ot': 0.00788115221406727,\n",
              "   'ortho': 6.039804737855732e-05,\n",
              "   'graph': 106.52316877876099}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.15437612718012717}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.38553507, -0.16622241, -0.0793837 , ...,  0.05695866,\n",
              "           0.04537759,  0.08227922],\n",
              "         [-0.19550588,  0.30706044, -0.11674107, ..., -0.15837408,\n",
              "          -0.03484334, -0.03565624],\n",
              "         [ 0.00833802,  0.45092825, -0.0922556 , ..., -0.09573745,\n",
              "           0.00656823, -0.02361725],\n",
              "         ...,\n",
              "         [ 0.01068626,  0.35094527, -0.03344912, ...,  0.08135619,\n",
              "          -0.0306501 , -0.1953438 ],\n",
              "         [-0.3708862 , -0.06516527, -0.09625968, ..., -0.05594927,\n",
              "           0.08991177, -0.01853892],\n",
              "         [-0.28121118,  0.01611807, -0.03450485, ..., -0.14164152,\n",
              "          -0.02183544, -0.08669763]]), 'mapped_Y': array([[ 0.42612142, -0.16627339, -0.06283366, ...,  0.02499819,\n",
              "           0.08779715,  0.08445911],\n",
              "         [-0.45456686, -0.10218737, -0.00324262, ...,  0.13281793,\n",
              "          -0.08584939, -0.09318935],\n",
              "         [ 0.07302174,  0.17445617,  0.02573967, ..., -0.09455803,\n",
              "          -0.01521396,  0.04732152],\n",
              "         ...,\n",
              "         [-0.03328561,  0.43956275, -0.10741218, ..., -0.0128386 ,\n",
              "          -0.02323373, -0.08132919],\n",
              "         [-0.40562451, -0.11761493,  0.12961958, ...,  0.27800257,\n",
              "          -0.13602845,  0.02682843],\n",
              "         [-0.38475244, -0.06355869, -0.06501739, ..., -0.06942704,\n",
              "           0.08202435, -0.02192622]]), 'alpha': tensor([[ 0.0030,  0.0222,  0.0091,  ..., -0.0015,  0.0100,  0.0037],\n",
              "          [ 0.0071,  0.0011, -0.0036,  ..., -0.0451, -0.0073,  0.0076],\n",
              "          [-0.0016,  0.0170, -0.0029,  ...,  0.0046,  0.0089, -0.0019],\n",
              "          ...,\n",
              "          [ 0.0106,  0.0163, -0.0072,  ...,  0.0206, -0.0113, -0.0217],\n",
              "          [-0.0087,  0.0039, -0.0230,  ..., -0.0481,  0.0611, -0.0100],\n",
              "          [-0.0057,  0.0013, -0.0332,  ..., -0.0748,  0.0302, -0.0301]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0022,  0.0009,  0.0009,  ...,  0.0058,  0.0158,  0.0048],\n",
              "          [-0.0022,  0.0033,  0.0076,  ...,  0.0059, -0.0122, -0.0100],\n",
              "          [ 0.0060,  0.0130,  0.0103,  ..., -0.0089, -0.0075, -0.0057],\n",
              "          ...,\n",
              "          [-0.0045,  0.0002, -0.0072,  ...,  0.0077, -0.0080,  0.0065],\n",
              "          [ 0.0041,  0.0196,  0.0204,  ...,  0.0426, -0.0093, -0.0045],\n",
              "          [-0.0088, -0.0092, -0.0201,  ..., -0.0195,  0.0450, -0.0068]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006578775353811989, 'loss_breakdown': {'ot': 0.006561659899255983,\n",
              "   'ortho': 0.00016326828155060783,\n",
              "   'graph': 78.86264009452579}, 'best_iter': 2265, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9641833810888252,\n",
              "   'accuracy_raw': 0.9641833810888252,\n",
              "   'foscttm': 0.15422652067260897}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.38512238, -0.19418099,  0.07687728, ..., -0.00779309,\n",
              "           0.01968246,  0.04254   ],\n",
              "         [-0.11029782,  0.31227096, -0.17307592, ..., -0.0829489 ,\n",
              "          -0.03463715, -0.00672472],\n",
              "         [ 0.07976234,  0.45012814, -0.08076431, ..., -0.01932218,\n",
              "           0.03029713, -0.03061048],\n",
              "         ...,\n",
              "         [ 0.02902774,  0.33171264, -0.02546405, ...,  0.07427057,\n",
              "           0.01248928, -0.18494056],\n",
              "         [-0.28912398, -0.04033789, -0.23514941, ..., -0.07607464,\n",
              "           0.0836381 , -0.01054267],\n",
              "         [-0.26153877,  0.03663073, -0.09377861, ..., -0.15785575,\n",
              "          -0.02615249, -0.0118952 ]]), 'mapped_Y': array([[ 0.41435028, -0.18648827,  0.12430693, ..., -0.02663038,\n",
              "           0.04826627,  0.03682622],\n",
              "         [-0.39880436, -0.0811814 , -0.23132837, ...,  0.07538169,\n",
              "          -0.07949576, -0.07664026],\n",
              "         [ 0.08144662,  0.16122686,  0.05828284, ..., -0.05472207,\n",
              "          -0.04037908,  0.07203642],\n",
              "         ...,\n",
              "         [ 0.04169924,  0.43650068, -0.12262207, ...,  0.02109365,\n",
              "           0.03238122, -0.09509761],\n",
              "         [-0.41251815, -0.1063129 , -0.09616608, ...,  0.29839652,\n",
              "          -0.07375804,  0.00998211],\n",
              "         [-0.30555763, -0.03937576, -0.19765993, ..., -0.09141961,\n",
              "           0.0609715 ,  0.05718237]]), 'alpha': tensor([[ 3.6408e-03,  2.2323e-02,  7.6158e-03,  ..., -3.4859e-03,\n",
              "            8.6142e-03,  6.1756e-03],\n",
              "          [ 7.6548e-03,  2.5631e-03,  1.0114e-02,  ..., -3.0540e-02,\n",
              "           -1.7098e-02,  5.9853e-03],\n",
              "          [ 1.1033e-03,  1.7152e-02, -5.9026e-03,  ...,  7.5305e-03,\n",
              "            1.1928e-02, -2.4336e-03],\n",
              "          ...,\n",
              "          [ 8.4097e-03,  1.5932e-02, -1.2936e-03,  ..., -1.1210e-04,\n",
              "           -8.1763e-03, -1.9918e-02],\n",
              "          [-4.8468e-03,  5.9468e-03, -1.8979e-02,  ..., -7.7150e-02,\n",
              "            4.5571e-02, -3.8194e-03],\n",
              "          [-3.6198e-03,  3.7435e-03, -2.2029e-02,  ..., -1.1690e-01,\n",
              "            1.3496e-02, -1.2107e-02]], dtype=torch.float64), 'beta': tensor([[-0.0021,  0.0012,  0.0018,  ...,  0.0029,  0.0124,  0.0074],\n",
              "          [-0.0024,  0.0046,  0.0018,  ..., -0.0032, -0.0167, -0.0140],\n",
              "          [ 0.0104,  0.0098,  0.0089,  ..., -0.0094, -0.0305, -0.0013],\n",
              "          ...,\n",
              "          [-0.0025,  0.0021, -0.0101,  ...,  0.0055, -0.0017,  0.0096],\n",
              "          [ 0.0006,  0.0152,  0.0155,  ...,  0.0458, -0.0002, -0.0101],\n",
              "          [-0.0056, -0.0073, -0.0122,  ..., -0.0253,  0.0349,  0.0042]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006676959019140021, 'loss_breakdown': {'ot': 0.006647514765728472,\n",
              "   'ortho': 0.00028649752663242574,\n",
              "   'graph': 79.4500748306029}, 'best_iter': 2281, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.1547396527487003}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 0.10260591,  0.11534476, -0.02115489, ..., -0.00141052,\n",
              "           0.02107278, -0.0335997 ],\n",
              "         [ 0.03544818,  0.0808323 , -0.02417903, ..., -0.01548103,\n",
              "          -0.0001315 , -0.01888213],\n",
              "         [-0.03368331,  0.10375662, -0.08201993, ...,  0.03460288,\n",
              "           0.0107769 ,  0.02296324],\n",
              "         ...,\n",
              "         [-0.02993269,  0.09280697,  0.01541533, ...,  0.00967281,\n",
              "          -0.03590849,  0.00880392],\n",
              "         [-0.04122785, -0.05853474,  0.02899599, ..., -0.01509054,\n",
              "           0.10924559,  0.01335118],\n",
              "         [-0.01171442, -0.02877517,  0.04229777, ..., -0.03122296,\n",
              "           0.01249254,  0.00858972]]), 'mapped_Y': array([[ 0.11998867,  0.01317396, -0.03639536, ..., -0.00714075,\n",
              "          -0.01002729, -0.05218   ],\n",
              "         [-0.03986441, -0.08640409,  0.0209756 , ..., -0.01216654,\n",
              "          -0.03420021, -0.00742193],\n",
              "         [ 0.01433921,  0.03544743,  0.06145865, ..., -0.00552315,\n",
              "          -0.0135029 ,  0.01843835],\n",
              "         ...,\n",
              "         [-0.10263605,  0.10993354, -0.09837878, ...,  0.04655535,\n",
              "          -0.0013929 , -0.02348552],\n",
              "         [-0.07437603,  0.03462116,  0.02184102, ...,  0.01855495,\n",
              "           0.03973114,  0.05623363],\n",
              "         [-0.05271966, -0.09908023, -0.0129132 , ...,  0.00177649,\n",
              "          -0.04207364,  0.00583254]]), 'alpha': tensor([[ 8.9066e-03,  7.7248e-02, -6.4290e-03,  ...,  1.1119e-03,\n",
              "            1.2943e-02, -5.7688e-03],\n",
              "          [ 4.3340e-02,  5.2620e-02,  3.9356e-02,  ..., -2.8826e-02,\n",
              "           -2.6995e-02, -2.7113e-02],\n",
              "          [ 7.1967e-03,  6.8297e-03, -5.0824e-02,  ...,  2.4626e-02,\n",
              "           -9.9916e-03,  9.3212e-03],\n",
              "          ...,\n",
              "          [ 5.2460e-03,  3.8979e-02,  8.7320e-02,  ..., -3.4817e-02,\n",
              "           -1.0433e-01,  3.2341e-02],\n",
              "          [ 3.3309e-06, -9.2227e-03,  1.1190e-02,  ..., -7.9737e-03,\n",
              "            1.0146e-01, -9.4556e-03],\n",
              "          [ 1.2896e-02,  1.3548e-02,  3.4180e-02,  ..., -4.0937e-02,\n",
              "           -1.3384e-03, -1.4826e-02]], dtype=torch.float64), 'beta': tensor([[ 0.0097,  0.0145, -0.0050,  ..., -0.0045, -0.0037,  0.0036],\n",
              "          [ 0.0128,  0.0006,  0.0122,  ...,  0.0045, -0.0159, -0.0151],\n",
              "          [-0.0308, -0.0142,  0.0490,  ...,  0.0551,  0.0427, -0.0065],\n",
              "          ...,\n",
              "          [-0.0245,  0.0118, -0.0293,  ..., -0.0131, -0.0071, -0.0185],\n",
              "          [-0.0065,  0.0464,  0.0129,  ...,  0.0267,  0.0185,  0.0188],\n",
              "          [-0.0071, -0.0220, -0.0143,  ...,  0.0157, -0.0246,  0.0047]],\n",
              "         dtype=torch.float64), 'final_loss': 0.019131423511841692, 'loss_breakdown': {'ot': 0.0020501235327894415,\n",
              "   'ortho': 0.07537734699949561,\n",
              "   'graph': 16.327526509057293}, 'best_iter': 399, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.8810888252148997,\n",
              "   'accuracy_raw': 0.8810888252148997,\n",
              "   'foscttm': 0.2425235516219991}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[-0.02989091, -0.06810103, -0.04303009, ..., -0.01370794,\n",
              "           0.02887652, -0.00154708],\n",
              "         [ 0.0519554 , -0.04080461, -0.01884525, ..., -0.05219643,\n",
              "           0.0316447 , -0.01019225],\n",
              "         [-0.00732741,  0.01197961, -0.08188218, ..., -0.00896563,\n",
              "           0.00355431,  0.02445523],\n",
              "         ...,\n",
              "         [-0.05335286,  0.01888023, -0.0099866 , ..., -0.01185122,\n",
              "           0.0007975 ,  0.01184405],\n",
              "         [ 0.11366305,  0.01725917,  0.03682959, ..., -0.00814572,\n",
              "           0.00137785,  0.03676126],\n",
              "         [ 0.04332575, -0.00155062,  0.03858097, ..., -0.01895095,\n",
              "          -0.00228002,  0.00303209]]), 'mapped_Y': array([[ 0.05328385,  0.02718242,  0.00442176, ..., -0.00107409,\n",
              "          -0.03981582, -0.01487038],\n",
              "         [-0.00589337, -0.06910801, -0.00475604, ..., -0.00030439,\n",
              "           0.01925808, -0.00881903],\n",
              "         [ 0.01976046,  0.05819609,  0.0422435 , ..., -0.01973898,\n",
              "           0.04207477,  0.03411308],\n",
              "         ...,\n",
              "         [-0.06910487, -0.02718739, -0.10507695, ...,  0.06974805,\n",
              "           0.01178125,  0.0133876 ],\n",
              "         [-0.02018793,  0.0436918 , -0.079965  , ...,  0.01669661,\n",
              "           0.02031723, -0.0051538 ],\n",
              "         [ 0.00342419, -0.12094974, -0.01406979, ..., -0.00646565,\n",
              "          -0.00193245, -0.01464156]]), 'alpha': tensor([[-0.0101,  0.0003, -0.0101,  ..., -0.0042,  0.0098, -0.0027],\n",
              "          [ 0.0066, -0.0275,  0.0364,  ..., -0.0296,  0.0537, -0.0078],\n",
              "          [ 0.0181, -0.0066, -0.0363,  ...,  0.0035, -0.0042, -0.0012],\n",
              "          ...,\n",
              "          [-0.0830,  0.0019,  0.0352,  ..., -0.0471, -0.0085, -0.0132],\n",
              "          [ 0.0575, -0.0075,  0.0225,  ..., -0.0101,  0.0216,  0.0324],\n",
              "          [ 0.0145, -0.0166,  0.0303,  ..., -0.0352, -0.0040, -0.0261]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0034,  0.0052, -0.0055,  ..., -0.0048, -0.0103, -0.0026],\n",
              "          [ 0.0053,  0.0093,  0.0152,  ...,  0.0034,  0.0022, -0.0011],\n",
              "          [-0.0060,  0.0127,  0.0282,  ...,  0.0476,  0.0602,  0.0082],\n",
              "          ...,\n",
              "          [ 0.0036, -0.0315, -0.0385,  ...,  0.0267, -0.0200, -0.0088],\n",
              "          [-0.0058,  0.0559, -0.0163,  ...,  0.0143,  0.0094,  0.0072],\n",
              "          [ 0.0067, -0.0352, -0.0011,  ..., -0.0043, -0.0080, -0.0023]],\n",
              "         dtype=torch.float64), 'final_loss': 0.019587027837700083, 'loss_breakdown': {'ot': 0.002135398159244065,\n",
              "   'ortho': 0.08535479703280291,\n",
              "   'graph': 16.59808170812799}, 'best_iter': 671, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.20487106017191978,\n",
              "   'accuracy_raw': 0.20487106017191978,\n",
              "   'foscttm': 0.5610736638724916}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[ 0.12483233, -0.03000143, -0.02476031, ..., -0.00603041,\n",
              "           0.0303138 , -0.03909476],\n",
              "         [ 0.07936076,  0.00781851, -0.06402075, ...,  0.00058108,\n",
              "           0.06681164, -0.02967091],\n",
              "         [ 0.03740755,  0.0612012 , -0.12388114, ...,  0.02845631,\n",
              "           0.02431829,  0.02230984],\n",
              "         ...,\n",
              "         [ 0.02155738,  0.07707694, -0.05776607, ..., -0.03336138,\n",
              "          -0.01334056,  0.01042393],\n",
              "         [-0.04598323,  0.00159637,  0.03145397, ...,  0.0132368 ,\n",
              "           0.00736862,  0.04275775],\n",
              "         [-0.04757807,  0.00719007,  0.0221133 , ..., -0.00428933,\n",
              "           0.00173298,  0.0352356 ]]), 'mapped_Y': array([[-8.26777797e-02,  2.64319769e-04, -4.15824357e-03, ...,\n",
              "           8.46116340e-03, -1.63181301e-02, -6.08096298e-03],\n",
              "         [ 5.17569504e-02, -6.87715316e-02,  1.26920900e-02, ...,\n",
              "          -1.14822383e-02,  2.20738616e-02, -1.45616150e-02],\n",
              "         [-3.17174106e-02,  6.73361653e-02, -1.06551607e-02, ...,\n",
              "           3.23107119e-02,  2.59401110e-02, -5.28638543e-03],\n",
              "         ...,\n",
              "         [ 6.42160874e-02,  8.01381162e-02, -1.06213375e-01, ...,\n",
              "           4.41083719e-02,  4.76731056e-02,  4.33891160e-02],\n",
              "         [ 7.85085255e-03, -2.61546056e-02, -1.12925976e-02, ...,\n",
              "           3.35797773e-02,  3.40237286e-03, -1.16278997e-03],\n",
              "         [ 8.31539950e-02, -7.86082803e-02, -6.07072689e-03, ...,\n",
              "          -3.27063476e-02, -4.39800707e-05, -6.30384936e-03]]), 'alpha': tensor([[ 0.0440,  0.0194, -0.0190,  ..., -0.0070,  0.0197, -0.0175],\n",
              "          [ 0.0813, -0.0080,  0.0433,  ..., -0.0099,  0.0727, -0.0427],\n",
              "          [ 0.0052, -0.0073, -0.0306,  ...,  0.0285,  0.0079,  0.0005],\n",
              "          ...,\n",
              "          [-0.0094,  0.0296, -0.0075,  ..., -0.0907, -0.0360,  0.0208],\n",
              "          [ 0.0076, -0.0055,  0.0243,  ...,  0.0184,  0.0154,  0.0302],\n",
              "          [-0.0115, -0.0044,  0.0022,  ..., -0.0194, -0.0183,  0.0126]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0019,  0.0040, -0.0125,  ...,  0.0023, -0.0069,  0.0060],\n",
              "          [-0.0100,  0.0076,  0.0105,  ...,  0.0090,  0.0067, -0.0078],\n",
              "          [-0.0191,  0.0166,  0.0321,  ...,  0.0742,  0.0597, -0.0227],\n",
              "          ...,\n",
              "          [ 0.0062, -0.0055, -0.0307,  ...,  0.0258,  0.0058,  0.0188],\n",
              "          [-0.0175,  0.0230, -0.0047,  ...,  0.0373,  0.0042,  0.0041],\n",
              "          [ 0.0155, -0.0179, -0.0032,  ..., -0.0110, -0.0097,  0.0037]],\n",
              "         dtype=torch.float64), 'final_loss': 0.019388765822687837, 'loss_breakdown': {'ot': 0.0021827905509761276,\n",
              "   'ortho': 0.07587308169773195,\n",
              "   'graph': 16.44724445473439}, 'best_iter': 677, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.31852913085004775,\n",
              "   'accuracy_raw': 0.31852913085004775,\n",
              "   'foscttm': 0.5007421030113783}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 0.41384121, -0.01002607, -0.08795606, ...,  0.01745137,\n",
              "           0.02392837,  0.00276837],\n",
              "         [-0.24675842,  0.13806963, -0.12745634, ..., -0.1236863 ,\n",
              "          -0.01531404, -0.06364705],\n",
              "         [-0.09500709,  0.2659466 , -0.11978112, ..., -0.01423602,\n",
              "          -0.05472282, -0.03098076],\n",
              "         ...,\n",
              "         [-0.0922918 ,  0.20137013, -0.04804347, ..., -0.02273908,\n",
              "          -0.02539857, -0.06460199],\n",
              "         [-0.28511565, -0.05806404, -0.03710649, ..., -0.08454301,\n",
              "           0.11103326,  0.06020068],\n",
              "         [-0.21641456, -0.03958053,  0.00126977, ..., -0.06065756,\n",
              "           0.05228288,  0.00992185]]), 'mapped_Y': array([[ 0.43659231, -0.04699945, -0.05433822, ..., -0.02775977,\n",
              "           0.01972514, -0.01081871],\n",
              "         [-0.37750313, -0.11732048, -0.06008006, ..., -0.08811618,\n",
              "           0.0392882 ,  0.0359678 ],\n",
              "         [ 0.05967555,  0.12881683, -0.00669427, ..., -0.06384829,\n",
              "          -0.02283632,  0.094947  ],\n",
              "         ...,\n",
              "         [-0.16919019,  0.26062509, -0.1341338 , ..., -0.02895805,\n",
              "          -0.04057565, -0.14759904],\n",
              "         [-0.28456814, -0.03445057, -0.04025735, ...,  0.02009079,\n",
              "           0.10123787,  0.04666557],\n",
              "         [-0.33492267, -0.11827152, -0.06859341, ..., -0.03626567,\n",
              "           0.00865925,  0.0254939 ]]), 'alpha': tensor([[ 1.4120e-02,  4.7756e-02, -1.0477e-02,  ..., -3.8960e-05,\n",
              "            1.4779e-02, -4.6520e-03],\n",
              "          [ 2.4745e-02, -5.2073e-04,  2.3171e-02,  ..., -4.8309e-02,\n",
              "           -5.6363e-03, -1.3544e-02],\n",
              "          [ 4.1209e-03,  6.0917e-03, -1.9040e-02,  ...,  1.6523e-02,\n",
              "           -3.6150e-03, -7.2249e-03],\n",
              "          ...,\n",
              "          [ 4.6799e-03,  2.8784e-02, -7.8444e-03,  ..., -2.6540e-02,\n",
              "            2.3550e-02,  1.6491e-02],\n",
              "          [-9.7809e-03,  2.2900e-02, -6.9181e-03,  ..., -6.2198e-02,\n",
              "            4.4687e-02,  4.8960e-03],\n",
              "          [-9.6543e-03,  1.1559e-02, -2.1027e-02,  ..., -9.6190e-02,\n",
              "            3.1215e-02, -2.0319e-02]], dtype=torch.float64), 'beta': tensor([[-2.6028e-04,  7.9509e-03, -1.5888e-03,  ..., -3.6976e-03,\n",
              "            1.3484e-02, -7.9457e-03],\n",
              "          [ 3.0331e-03,  8.0453e-03,  6.7373e-03,  ..., -1.8459e-02,\n",
              "            2.9963e-04,  3.6815e-03],\n",
              "          [ 1.4225e-02,  3.1692e-02,  6.5277e-03,  ..., -2.2012e-02,\n",
              "            1.3239e-02,  3.0537e-02],\n",
              "          ...,\n",
              "          [-6.3467e-03, -2.3076e-03, -1.4604e-02,  ..., -1.0218e-02,\n",
              "            6.4408e-03, -4.1524e-02],\n",
              "          [ 1.1111e-02,  5.5278e-02, -5.6567e-03,  ...,  1.5755e-02,\n",
              "            3.1226e-02,  1.2075e-02],\n",
              "          [-1.2726e-02, -1.8960e-02, -4.8621e-05,  ...,  1.0015e-02,\n",
              "           -2.1242e-02, -4.0853e-03]], dtype=torch.float64), 'final_loss': 0.007060483097766743, 'loss_breakdown': {'ot': 0.002751012195681888,\n",
              "   'ortho': 0.015073557022380491,\n",
              "   'graph': 41.587353318610496}, 'best_iter': 884, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.15029205197184112}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.26119607, -0.05434652,  0.03562691, ...,  0.0081415 ,\n",
              "           0.05384102, -0.04228252],\n",
              "         [ 0.00157884,  0.17427062, -0.05329301, ..., -0.02025951,\n",
              "           0.03128617, -0.01354059],\n",
              "         [ 0.08343558,  0.14630231,  0.01806458, ...,  0.07505959,\n",
              "          -0.03640862, -0.02528699],\n",
              "         ...,\n",
              "         [ 0.1126512 ,  0.14139815,  0.0254624 , ...,  0.06523673,\n",
              "          -0.03985494, -0.02017736],\n",
              "         [-0.27239187,  0.1051357 , -0.11854628, ..., -0.06617756,\n",
              "           0.09853125,  0.08342661],\n",
              "         [-0.19815918,  0.09216043, -0.09557969, ..., -0.05882819,\n",
              "           0.08460736,  0.08709362]]), 'mapped_Y': array([[ 2.82829535e-01, -1.48944347e-01,  5.86468759e-02, ...,\n",
              "          -2.93157028e-02,  5.11028325e-02, -6.62963596e-02],\n",
              "         [-3.43716971e-01,  6.38468253e-02, -1.04273886e-01, ...,\n",
              "          -3.61529872e-02,  3.22218320e-02,  6.23778075e-02],\n",
              "         [ 7.75946734e-02,  8.93706114e-02,  7.27964096e-02, ...,\n",
              "           1.78556161e-02, -3.16897338e-02,  1.55729428e-02],\n",
              "         ...,\n",
              "         [ 5.18942791e-02,  1.39390532e-01, -2.80933958e-04, ...,\n",
              "           7.62323909e-02, -3.47308053e-03,  1.51883792e-02],\n",
              "         [-2.39240210e-01,  9.84791628e-02, -9.43836810e-02, ...,\n",
              "           2.76735228e-02,  6.11467604e-02,  1.03896261e-01],\n",
              "         [-2.99301935e-01,  4.43189572e-02, -1.48223780e-01, ...,\n",
              "          -3.10100819e-02,  4.50308711e-02,  5.73512056e-02]]), 'alpha': tensor([[ 0.0069,  0.0266,  0.0149,  ...,  0.0041,  0.0116, -0.0122],\n",
              "          [ 0.0499,  0.0054,  0.0266,  ..., -0.0449,  0.0067, -0.0038],\n",
              "          [-0.0085,  0.0128, -0.0097,  ...,  0.0352,  0.0056, -0.0110],\n",
              "          ...,\n",
              "          [ 0.0251,  0.0506, -0.0067,  ...,  0.0263,  0.0325,  0.0183],\n",
              "          [-0.0118,  0.0173,  0.0008,  ..., -0.0413,  0.0315, -0.0045],\n",
              "          [-0.0015,  0.0350, -0.0098,  ..., -0.0618,  0.0320, -0.0248]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0039,  0.0014,  0.0052,  ..., -0.0016,  0.0143, -0.0058],\n",
              "          [-0.0021,  0.0041,  0.0155,  ..., -0.0036, -0.0061, -0.0017],\n",
              "          [ 0.0086, -0.0030,  0.0380,  ...,  0.0256,  0.0092,  0.0264],\n",
              "          ...,\n",
              "          [-0.0127,  0.0012, -0.0140,  ...,  0.0186,  0.0148, -0.0006],\n",
              "          [ 0.0263,  0.0331,  0.0021,  ...,  0.0030,  0.0251,  0.0213],\n",
              "          [-0.0139, -0.0153, -0.0145,  ..., -0.0003, -0.0024, -0.0087]],\n",
              "         dtype=torch.float64), 'final_loss': 0.005416502418174256, 'loss_breakdown': {'ot': 0.0022351741934886573,\n",
              "   'ortho': 0.006679281831511557,\n",
              "   'graph': 31.145354063704826}, 'best_iter': 1833, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1546634811427383}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 0.1895026 ,  0.08942193, -0.19682242, ..., -0.05692716,\n",
              "           0.15325328,  0.03608999],\n",
              "         [-0.04634017,  0.11392103,  0.01617181, ...,  0.05377212,\n",
              "          -0.08002038, -0.11279586],\n",
              "         [ 0.06930898,  0.11370955, -0.01242709, ...,  0.12837302,\n",
              "          -0.09854093, -0.12393224],\n",
              "         ...,\n",
              "         [ 0.08227783,  0.05514049,  0.02941383, ...,  0.10346936,\n",
              "          -0.0789587 , -0.06228115],\n",
              "         [-0.25945483,  0.0692413 ,  0.11235946, ..., -0.06204242,\n",
              "           0.01477924,  0.00093593],\n",
              "         [-0.16214701,  0.05225219,  0.11079476, ..., -0.05736436,\n",
              "           0.04166233,  0.02403245]]), 'mapped_Y': array([[ 0.23504389,  0.00396858, -0.22121991, ..., -0.08005366,\n",
              "           0.1688431 ,  0.0420129 ],\n",
              "         [-0.36108099,  0.02490376,  0.12117733, ..., -0.01806526,\n",
              "           0.02031389,  0.04381497],\n",
              "         [ 0.08142171,  0.08359641,  0.04593722, ...,  0.01260564,\n",
              "          -0.03221233, -0.01638058],\n",
              "         ...,\n",
              "         [ 0.03873691,  0.03722892,  0.01764747, ...,  0.17821075,\n",
              "          -0.12016252, -0.13139604],\n",
              "         [-0.29602821,  0.06193028,  0.10889485, ...,  0.05952345,\n",
              "           0.0695815 ,  0.0778914 ],\n",
              "         [-0.29007285,  0.0018953 ,  0.05931654, ..., -0.01487503,\n",
              "           0.03632796,  0.04968431]]), 'alpha': tensor([[ 0.0065,  0.0298,  0.0127,  ...,  0.0007,  0.0093, -0.0257],\n",
              "          [ 0.0505,  0.0142,  0.0070,  ..., -0.0381, -0.0100, -0.0113],\n",
              "          [-0.0110,  0.0254, -0.0127,  ...,  0.0346,  0.0136, -0.0242],\n",
              "          ...,\n",
              "          [ 0.0356,  0.0336,  0.0159,  ...,  0.0026,  0.0037,  0.0582],\n",
              "          [-0.0021,  0.0218,  0.0109,  ..., -0.0374,  0.0135, -0.0239],\n",
              "          [ 0.0082,  0.0189,  0.0056,  ..., -0.0588,  0.0079, -0.0142]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0032,  0.0020, -0.0003,  ...,  0.0031,  0.0192, -0.0080],\n",
              "          [ 0.0019,  0.0093,  0.0148,  ..., -0.0048, -0.0005, -0.0021],\n",
              "          [ 0.0130, -0.0075,  0.0468,  ...,  0.0312, -0.0023, -0.0037],\n",
              "          ...,\n",
              "          [-0.0198, -0.0188, -0.0039,  ...,  0.0569,  0.0188, -0.0064],\n",
              "          [ 0.0174,  0.0317,  0.0083,  ...,  0.0089,  0.0172, -0.0019],\n",
              "          [-0.0064, -0.0105, -0.0192,  ...,  0.0031,  0.0134,  0.0175]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006167081885117918, 'loss_breakdown': {'ot': 0.0025671419772376972,\n",
              "   'ortho': 0.00933002620113353,\n",
              "   'graph': 35.06639645868884}, 'best_iter': 1588, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.1525936203771361}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[ 0.3874703 , -0.08038856, -0.07243101, ...,  0.048181  ,\n",
              "           0.14366095, -0.0179895 ],\n",
              "         [-0.13197535,  0.1799317 , -0.07906091, ..., -0.13605139,\n",
              "          -0.12682304, -0.01644663],\n",
              "         [ 0.04948953,  0.27872698, -0.00342382, ..., -0.0349231 ,\n",
              "          -0.06787946, -0.0573802 ],\n",
              "         ...,\n",
              "         [-0.03032207,  0.2463012 ,  0.05956052, ...,  0.05756913,\n",
              "          -0.09483515, -0.25375446],\n",
              "         [-0.31283581,  0.00483465, -0.12519443, ..., -0.15348981,\n",
              "          -0.03188685,  0.03602584],\n",
              "         [-0.31958267, -0.0241411 , -0.04182832, ..., -0.18771172,\n",
              "          -0.0467403 , -0.09715989]]), 'mapped_Y': array([[ 0.44122776, -0.12836901, -0.01902101, ...,  0.01089878,\n",
              "           0.11426454, -0.00752942],\n",
              "         [-0.40836205, -0.01872729, -0.17248712, ...,  0.02642502,\n",
              "          -0.13150438,  0.02335223],\n",
              "         [ 0.09773144,  0.13819055,  0.03414265, ..., -0.07652419,\n",
              "           0.01403635,  0.10399069],\n",
              "         ...,\n",
              "         [-0.00973905,  0.26439579,  0.00289023, ...,  0.01554638,\n",
              "          -0.12803517, -0.1703926 ],\n",
              "         [-0.32609151,  0.04206678, -0.11993977, ...,  0.2594956 ,\n",
              "          -0.10860598,  0.07897696],\n",
              "         [-0.35025875, -0.0403749 , -0.15884153, ..., -0.18231182,\n",
              "          -0.04011998,  0.0431742 ]]), 'alpha': tensor([[ 0.0061,  0.0386, -0.0003,  ..., -0.0045,  0.0130, -0.0014],\n",
              "          [ 0.0121, -0.0190,  0.0287,  ..., -0.0359, -0.0092,  0.0086],\n",
              "          [ 0.0018,  0.0091, -0.0151,  ...,  0.0093,  0.0178, -0.0073],\n",
              "          ...,\n",
              "          [ 0.0057,  0.0303, -0.0007,  ...,  0.0042, -0.0193, -0.0248],\n",
              "          [-0.0016,  0.0177, -0.0036,  ..., -0.0681,  0.0174, -0.0099],\n",
              "          [-0.0048,  0.0094, -0.0182,  ..., -0.1192,  0.0003, -0.0381]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0014,  0.0042, -0.0008,  ..., -0.0070,  0.0066,  0.0030],\n",
              "          [ 0.0008,  0.0074,  0.0023,  ..., -0.0033, -0.0002,  0.0004],\n",
              "          [ 0.0190,  0.0202,  0.0128,  ..., -0.0342,  0.0052,  0.0136],\n",
              "          ...,\n",
              "          [-0.0087, -0.0139, -0.0158,  ...,  0.0062,  0.0016, -0.0090],\n",
              "          [ 0.0068,  0.0382,  0.0093,  ...,  0.0523,  0.0155,  0.0050],\n",
              "          [-0.0071, -0.0126, -0.0116,  ..., -0.0296, -0.0056, -0.0053]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004920154618248535, 'loss_breakdown': {'ot': 0.0041329806397392786,\n",
              "   'ortho': 0.0052075332066982925,\n",
              "   'graph': 73.50986464422739}, 'best_iter': 1338, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076409,\n",
              "   'accuracy_raw': 0.9646609360076409,\n",
              "   'foscttm': 0.15513236983093553}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[ 0.24067478, -0.13762797,  0.01439955, ...,  0.10106249,\n",
              "           0.00683973, -0.12622696],\n",
              "         [-0.02755026,  0.22265284, -0.15904172, ..., -0.13853272,\n",
              "           0.06840324,  0.05528907],\n",
              "         [ 0.16997188,  0.25938426, -0.11132459, ..., -0.04152298,\n",
              "           0.06732905,  0.02598961],\n",
              "         ...,\n",
              "         [ 0.0870851 ,  0.15986979, -0.01713814, ...,  0.00322293,\n",
              "           0.04569071, -0.02366576],\n",
              "         [-0.28600393,  0.10443394, -0.12433066, ..., -0.08165025,\n",
              "           0.05554891,  0.03034958],\n",
              "         [-0.20273348,  0.0299664 , -0.05719677, ..., -0.12643436,\n",
              "           0.06520039,  0.04153283]]), 'mapped_Y': array([[ 0.2867433 , -0.18426493,  0.03667252, ...,  0.07242787,\n",
              "           0.01403453, -0.14865472],\n",
              "         [-0.46273404,  0.01164517, -0.06713518, ..., -0.01598468,\n",
              "          -0.05116718,  0.02217928],\n",
              "         [ 0.10965028,  0.15425317,  0.04686286, ..., -0.07422069,\n",
              "          -0.03151123,  0.04325118],\n",
              "         ...,\n",
              "         [ 0.1309607 ,  0.25034567, -0.14408288, ...,  0.01911685,\n",
              "           0.10616442,  0.03364795],\n",
              "         [-0.44095718, -0.01323187,  0.04647224, ...,  0.11273062,\n",
              "          -0.07274717,  0.09143962],\n",
              "         [-0.32038735,  0.0430528 , -0.11997705, ..., -0.12260527,\n",
              "           0.03695816,  0.09410725]]), 'alpha': tensor([[ 0.0036,  0.0229,  0.0142,  ..., -0.0009,  0.0089, -0.0120],\n",
              "          [ 0.0284,  0.0011,  0.0042,  ..., -0.0549,  0.0006,  0.0055],\n",
              "          [-0.0048,  0.0151, -0.0057,  ...,  0.0258,  0.0062, -0.0107],\n",
              "          ...,\n",
              "          [ 0.0154,  0.0195, -0.0014,  ..., -0.0093,  0.0058,  0.0246],\n",
              "          [-0.0004,  0.0159, -0.0026,  ..., -0.0394,  0.0297, -0.0152],\n",
              "          [ 0.0025,  0.0183, -0.0134,  ..., -0.0734,  0.0398, -0.0351]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0048,  0.0017,  0.0054,  ..., -0.0003,  0.0122, -0.0062],\n",
              "          [-0.0051,  0.0049,  0.0098,  ...,  0.0001, -0.0124, -0.0104],\n",
              "          [ 0.0069,  0.0014,  0.0167,  ...,  0.0076, -0.0291, -0.0158],\n",
              "          ...,\n",
              "          [-0.0117,  0.0195, -0.0106,  ...,  0.0182,  0.0059,  0.0121],\n",
              "          [ 0.0020,  0.0201,  0.0234,  ...,  0.0220, -0.0002, -0.0047],\n",
              "          [-0.0026, -0.0088, -0.0148,  ..., -0.0128,  0.0153,  0.0063]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00453323671723355, 'loss_breakdown': {'ot': 0.0038804924323803665,\n",
              "   'ortho': 0.005237201345970055,\n",
              "   'graph': 60.03722713934821}, 'best_iter': 1351, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9584527220630372,\n",
              "   'accuracy_raw': 0.9584527220630372,\n",
              "   'foscttm': 0.1513178600066228}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.15299889, -0.01355182, -0.05181193, ..., -0.10870453,\n",
              "           0.1622605 , -0.00624464],\n",
              "         [-0.00435663,  0.23282758, -0.01222562, ..., -0.00969051,\n",
              "          -0.02660235, -0.00258557],\n",
              "         [ 0.12129414,  0.26043119, -0.03066189, ...,  0.03429971,\n",
              "          -0.01569463,  0.00303221],\n",
              "         ...,\n",
              "         [ 0.11889911,  0.1299913 ,  0.03070488, ...,  0.09026626,\n",
              "          -0.03327838,  0.03521325],\n",
              "         [-0.22415569,  0.06354227, -0.03270841, ...,  0.0063054 ,\n",
              "          -0.04541687,  0.00573463],\n",
              "         [-0.15542369,  0.04998232,  0.1055485 , ..., -0.03147841,\n",
              "          -0.09009418, -0.03213918]]), 'mapped_Y': array([[ 1.82618585e-01, -6.58442093e-02, -6.32803900e-02, ...,\n",
              "          -1.41661186e-01,  1.89781187e-01, -2.51120645e-02],\n",
              "         [-3.88318063e-01, -1.77681245e-02,  3.68814988e-02, ...,\n",
              "           1.57462592e-02, -7.54166874e-02,  1.95031777e-02],\n",
              "         [ 8.95858730e-02,  9.37376509e-02,  6.46471111e-02, ...,\n",
              "          -5.12517712e-04, -4.89712433e-02,  1.16821989e-02],\n",
              "         ...,\n",
              "         [ 1.15378038e-01,  2.36475931e-01, -5.96773010e-02, ...,\n",
              "           1.03103040e-01,  1.19001992e-02,  2.61477297e-02],\n",
              "         [-3.45782275e-01,  1.76549229e-04,  1.48343656e-01, ...,\n",
              "           3.51909941e-02,  3.90318465e-02,  7.91283092e-02],\n",
              "         [-2.91120837e-01, -3.48518500e-03, -5.71129157e-02, ...,\n",
              "           4.60147899e-02, -5.91509709e-02,  2.72820181e-02]]), 'alpha': tensor([[ 0.0055,  0.0320,  0.0156,  ...,  0.0024,  0.0102, -0.0070],\n",
              "          [ 0.0361,  0.0137,  0.0232,  ..., -0.0408, -0.0036, -0.0216],\n",
              "          [-0.0089,  0.0295, -0.0086,  ..., -0.0122, -0.0076, -0.0054],\n",
              "          ...,\n",
              "          [ 0.0046,  0.0331,  0.0175,  ...,  0.0514,  0.0541,  0.0480],\n",
              "          [ 0.0059,  0.0143, -0.0133,  ..., -0.0225, -0.0028, -0.0289],\n",
              "          [ 0.0020,  0.0331,  0.0245,  ..., -0.0310,  0.0198, -0.0383]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-4.5172e-03,  4.2877e-03,  4.2800e-03,  ...,  5.1676e-03,\n",
              "            1.7562e-02, -4.5476e-03],\n",
              "          [-7.8489e-03,  4.0168e-03,  2.0111e-02,  ..., -6.2584e-03,\n",
              "           -7.5944e-03, -5.8401e-03],\n",
              "          [ 9.6355e-05, -8.5623e-03,  4.9850e-02,  ...,  1.8409e-02,\n",
              "           -2.7244e-02, -2.3650e-02],\n",
              "          ...,\n",
              "          [-1.5080e-02,  4.4502e-03, -1.7816e-03,  ...,  5.3514e-02,\n",
              "            3.0896e-02,  1.6101e-02],\n",
              "          [ 7.1461e-03,  3.0137e-02,  3.7994e-02,  ..., -5.7476e-04,\n",
              "            3.2952e-02,  1.0460e-02],\n",
              "          [-5.7667e-03, -1.3356e-02, -2.9079e-02,  ...,  4.2544e-03,\n",
              "           -1.0138e-03,  2.3984e-03]], dtype=torch.float64), 'final_loss': 0.00265985716785953, 'loss_breakdown': {'ot': 0.0022203354906340945,\n",
              "   'ortho': 0.0017786493489056856,\n",
              "   'graph': 42.17351837363786}, 'best_iter': 3134, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.15306524576973918}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[ 0.41743848, -0.06718089, -0.02466989, ...,  0.04629329,\n",
              "           0.09477247, -0.05751697],\n",
              "         [-0.14031953,  0.10642931, -0.09533496, ..., -0.11250293,\n",
              "          -0.01324269,  0.00056977],\n",
              "         [-0.02976122,  0.18753722, -0.02580948, ..., -0.04379949,\n",
              "           0.06897472, -0.07113489],\n",
              "         ...,\n",
              "         [-0.09098775,  0.1778785 ,  0.07329628, ...,  0.01705117,\n",
              "           0.01636392, -0.22182167],\n",
              "         [-0.29510281,  0.00749732, -0.15444756, ..., -0.12577533,\n",
              "          -0.0433251 ,  0.0749597 ],\n",
              "         [-0.35585423, -0.00804636, -0.06536277, ..., -0.13362689,\n",
              "          -0.03609498, -0.09450111]]), 'mapped_Y': array([[ 0.44691176, -0.1373563 ,  0.0158942 , ...,  0.00385219,\n",
              "           0.07463061, -0.0419812 ],\n",
              "         [-0.29842352,  0.05851146, -0.17499536, ...,  0.06319777,\n",
              "          -0.19157528,  0.09369729],\n",
              "         [ 0.07272905,  0.1099683 ,  0.04724569, ..., -0.05498101,\n",
              "           0.01386991,  0.07346748],\n",
              "         ...,\n",
              "         [-0.08474245,  0.17795042, -0.02983331, ..., -0.01443502,\n",
              "           0.05066187, -0.13201509],\n",
              "         [-0.19657555,  0.11062633, -0.12366189, ...,  0.19991458,\n",
              "          -0.1354345 ,  0.17837721],\n",
              "         [-0.33649574, -0.01901209, -0.16974459, ..., -0.11029651,\n",
              "          -0.09902014,  0.05331803]]), 'alpha': tensor([[ 1.2663e-02,  4.0212e-02,  4.7244e-05,  ..., -7.1448e-03,\n",
              "            1.9762e-02, -3.2669e-03],\n",
              "          [ 1.7250e-02, -2.8802e-02,  2.8600e-02,  ..., -3.3523e-02,\n",
              "            8.4215e-03,  1.8715e-02],\n",
              "          [ 6.6089e-04,  3.8992e-03, -1.4193e-02,  ...,  1.2164e-02,\n",
              "            1.8110e-02, -1.3158e-02],\n",
              "          ...,\n",
              "          [ 9.2444e-03,  4.0336e-02, -3.9632e-03,  ..., -2.9121e-03,\n",
              "           -2.2056e-02, -1.9387e-02],\n",
              "          [-4.7386e-03,  1.1792e-02, -8.3382e-03,  ..., -7.4337e-02,\n",
              "            1.1943e-02, -5.2877e-03],\n",
              "          [-1.1257e-02,  1.6060e-03, -2.7910e-02,  ..., -1.0625e-01,\n",
              "           -6.3250e-03, -3.3639e-02]], dtype=torch.float64), 'beta': tensor([[ 0.0042,  0.0036, -0.0044,  ..., -0.0077,  0.0075,  0.0061],\n",
              "          [ 0.0108,  0.0137,  0.0053,  ..., -0.0001, -0.0061,  0.0058],\n",
              "          [ 0.0226,  0.0254,  0.0174,  ..., -0.0246, -0.0004,  0.0189],\n",
              "          ...,\n",
              "          [-0.0047, -0.0094, -0.0255,  ...,  0.0027,  0.0057,  0.0072],\n",
              "          [ 0.0177,  0.0450,  0.0126,  ...,  0.0443,  0.0121,  0.0166],\n",
              "          [-0.0109, -0.0182, -0.0135,  ..., -0.0264, -0.0166, -0.0079]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003130564729998714, 'loss_breakdown': {'ot': 0.0030433671587924843,\n",
              "   'ortho': 0.002228887138812262,\n",
              "   'graph': 64.90869981810692}, 'best_iter': 1838, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.16021853496915278}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.41319133, -0.05479018, -0.0071554 , ...,  0.09328461,\n",
              "           0.08848415, -0.10633554],\n",
              "         [-0.20894304,  0.22906198, -0.07664707, ..., -0.18151793,\n",
              "          -0.00875913,  0.0579003 ],\n",
              "         [-0.04432785,  0.28688348,  0.00688983, ..., -0.13319394,\n",
              "           0.01281165,  0.04554772],\n",
              "         ...,\n",
              "         [-0.09959934,  0.18253321,  0.07629009, ..., -0.03073387,\n",
              "          -0.00696484, -0.0686403 ],\n",
              "         [-0.30313052,  0.02735437, -0.19977168, ..., -0.03334684,\n",
              "           0.04007281,  0.04948416],\n",
              "         [-0.30168655, -0.07734528, -0.01763133, ..., -0.13523899,\n",
              "           0.0050032 ,  0.07893622]]), 'mapped_Y': array([[ 0.43690202, -0.08677497,  0.02044428, ...,  0.04388588,\n",
              "           0.11076359, -0.13962839],\n",
              "         [-0.40270728, -0.05525683, -0.12907938, ...,  0.10792177,\n",
              "          -0.08392908,  0.005848  ],\n",
              "         [ 0.07379469,  0.14086052,  0.07590552, ..., -0.10239541,\n",
              "          -0.01669292,  0.05837247],\n",
              "         ...,\n",
              "         [-0.11921747,  0.30312802, -0.02206014, ..., -0.07150492,\n",
              "           0.01339797,  0.02015216],\n",
              "         [-0.31497525, -0.04963147, -0.0327121 , ...,  0.26908995,\n",
              "          -0.12488792,  0.07297912],\n",
              "         [-0.34100608, -0.04923036, -0.15654593, ..., -0.09815731,\n",
              "           0.01213774,  0.1010462 ]]), 'alpha': tensor([[ 0.0030,  0.0202,  0.0152,  ...,  0.0004,  0.0133, -0.0010],\n",
              "          [ 0.0130,  0.0023,  0.0058,  ..., -0.0486, -0.0012,  0.0006],\n",
              "          [-0.0059,  0.0118,  0.0010,  ...,  0.0192,  0.0035, -0.0050],\n",
              "          ...,\n",
              "          [ 0.0028,  0.0240, -0.0031,  ..., -0.0084,  0.0014,  0.0086],\n",
              "          [-0.0085,  0.0120, -0.0130,  ..., -0.0426,  0.0435, -0.0119],\n",
              "          [-0.0093,  0.0153, -0.0147,  ..., -0.0725,  0.0460, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0037,  0.0017,  0.0047,  ...,  0.0021,  0.0165, -0.0046],\n",
              "          [-0.0025,  0.0024,  0.0095,  ...,  0.0040, -0.0109, -0.0110],\n",
              "          [ 0.0072,  0.0014,  0.0205,  ...,  0.0095, -0.0221, -0.0110],\n",
              "          ...,\n",
              "          [-0.0080,  0.0354, -0.0069,  ...,  0.0102, -0.0013,  0.0072],\n",
              "          [ 0.0055,  0.0198,  0.0247,  ...,  0.0329, -0.0069, -0.0037],\n",
              "          [-0.0058, -0.0098, -0.0163,  ..., -0.0239,  0.0204,  0.0020]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004596046255826277, 'loss_breakdown': {'ot': 0.00447185734488361,\n",
              "   'ortho': 0.005797066757339252,\n",
              "   'graph': 66.21824336927489}, 'best_iter': 1197, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9617956064947468,\n",
              "   'accuracy_raw': 0.9617956064947468,\n",
              "   'foscttm': 0.15293707678006657}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.26611059, -0.04175348, -0.04671782, ..., -0.02967666,\n",
              "           0.21831183,  0.06007523],\n",
              "         [-0.10809485,  0.23443593, -0.05168513, ..., -0.08189833,\n",
              "          -0.11393315,  0.01616001],\n",
              "         [ 0.043981  ,  0.32790155, -0.00453834, ..., -0.01095861,\n",
              "          -0.0771028 ,  0.01592267],\n",
              "         ...,\n",
              "         [ 0.07578124,  0.13474472,  0.09140016, ...,  0.08358343,\n",
              "          -0.10825784, -0.03063501],\n",
              "         [-0.27250535,  0.04447394, -0.11531279, ..., -0.00964819,\n",
              "          -0.01636927, -0.06510549],\n",
              "         [-0.20234296, -0.00829306,  0.0484424 , ..., -0.14521241,\n",
              "          -0.13707128, -0.02526842]]), 'mapped_Y': array([[ 0.28500538, -0.06862644, -0.04734766, ..., -0.0635179 ,\n",
              "           0.22460212,  0.04254775],\n",
              "         [-0.36085409, -0.10692329, -0.07988843, ...,  0.06614606,\n",
              "          -0.09486073, -0.09463893],\n",
              "         [ 0.07172212,  0.13679849,  0.07164528, ..., -0.06220001,\n",
              "          -0.07747336,  0.03525826],\n",
              "         ...,\n",
              "         [ 0.0391904 ,  0.28727289, -0.01855905, ...,  0.07680573,\n",
              "          -0.08341922,  0.00464827],\n",
              "         [-0.35778146, -0.11964489,  0.07158391, ...,  0.15427306,\n",
              "          -0.01618001, -0.00147172],\n",
              "         [-0.32097074, -0.02606085, -0.10594825, ..., -0.04788574,\n",
              "          -0.04928448, -0.01205119]]), 'alpha': tensor([[ 0.0023,  0.0248,  0.0215,  ...,  0.0015,  0.0135, -0.0080],\n",
              "          [ 0.0242,  0.0082,  0.0137,  ..., -0.0465, -0.0145, -0.0120],\n",
              "          [-0.0065,  0.0278, -0.0025,  ...,  0.0231,  0.0113, -0.0133],\n",
              "          ...,\n",
              "          [ 0.0138,  0.0097,  0.0111,  ...,  0.0161, -0.0029,  0.0247],\n",
              "          [ 0.0026,  0.0162, -0.0108,  ..., -0.0298, -0.0013, -0.0244],\n",
              "          [-0.0001,  0.0222,  0.0061,  ..., -0.0569,  0.0051, -0.0419]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0044,  0.0017,  0.0024,  ..., -0.0009,  0.0147, -0.0067],\n",
              "          [-0.0014,  0.0001,  0.0095,  ...,  0.0021, -0.0133, -0.0140],\n",
              "          [ 0.0003, -0.0059,  0.0182,  ...,  0.0076, -0.0332, -0.0292],\n",
              "          ...,\n",
              "          [-0.0113,  0.0117, -0.0005,  ...,  0.0290,  0.0083,  0.0117],\n",
              "          [ 0.0027,  0.0192,  0.0359,  ...,  0.0199,  0.0113, -0.0048],\n",
              "          [-0.0047, -0.0087, -0.0212,  ..., -0.0103, -0.0016,  0.0062]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0042754565889782424, 'loss_breakdown': {'ot': 0.004167305688327747,\n",
              "   'ortho': 0.004554190741641801,\n",
              "   'graph': 62.608993234077744}, 'best_iter': 1387, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.15291381479261712}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[ 0.36474287, -0.0965209 , -0.1734355 , ...,  0.07005282,\n",
              "           0.05230488,  0.01535436],\n",
              "         [-0.17738957,  0.16151381, -0.0442366 , ..., -0.18862245,\n",
              "           0.00503206,  0.03606605],\n",
              "         [ 0.02455828,  0.26221588, -0.02716489, ..., -0.10428765,\n",
              "           0.06062082,  0.02030679],\n",
              "         ...,\n",
              "         [ 0.00778351,  0.24499458,  0.04149434, ...,  0.0181127 ,\n",
              "           0.02255736, -0.21385799],\n",
              "         [-0.35815123, -0.0068414 , -0.01846423, ..., -0.13913773,\n",
              "          -0.03899971, -0.01776641],\n",
              "         [-0.31224997, -0.03075067,  0.07153226, ..., -0.1813409 ,\n",
              "          -0.01922172, -0.15855131]]), 'mapped_Y': array([[ 0.41611118, -0.14702293, -0.14488032, ...,  0.02608966,\n",
              "           0.02569064,  0.04133286],\n",
              "         [-0.42620128,  0.02400081, -0.04883452, ...,  0.09560326,\n",
              "          -0.17883689, -0.03915916],\n",
              "         [ 0.09683491,  0.13408936,  0.00785444, ..., -0.09208832,\n",
              "           0.01296819,  0.15320785],\n",
              "         ...,\n",
              "         [-0.01497831,  0.25979523, -0.02381272, ..., -0.06043389,\n",
              "           0.02294906, -0.07517434],\n",
              "         [-0.35297317,  0.04035753,  0.01779459, ...,  0.28367484,\n",
              "          -0.07495116, -0.00076521],\n",
              "         [-0.39205941, -0.02452515, -0.04934257, ..., -0.15808476,\n",
              "          -0.05826184,  0.01165408]]), 'alpha': tensor([[ 0.0099,  0.0361, -0.0010,  ..., -0.0064,  0.0148, -0.0008],\n",
              "          [ 0.0133, -0.0273,  0.0218,  ..., -0.0393, -0.0012,  0.0130],\n",
              "          [-0.0007,  0.0086, -0.0131,  ...,  0.0071,  0.0170, -0.0072],\n",
              "          ...,\n",
              "          [ 0.0154,  0.0330, -0.0038,  ...,  0.0062, -0.0085, -0.0252],\n",
              "          [-0.0014,  0.0100, -0.0063,  ..., -0.0672,  0.0143, -0.0095],\n",
              "          [-0.0028, -0.0012, -0.0208,  ..., -0.0996,  0.0035, -0.0395]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.0431e-03,  3.1406e-03, -2.8559e-03,  ..., -7.2523e-03,\n",
              "            2.7289e-03,  4.0891e-03],\n",
              "          [ 5.0783e-03,  1.2226e-02,  1.3599e-05,  ...,  4.0903e-03,\n",
              "           -1.2303e-02,  2.9155e-03],\n",
              "          [ 1.6741e-02,  2.0761e-02,  7.3277e-03,  ..., -2.7015e-02,\n",
              "           -4.6348e-03,  1.8958e-02],\n",
              "          ...,\n",
              "          [-1.0614e-02, -8.0331e-03, -1.6657e-02,  ...,  4.1463e-03,\n",
              "            2.3734e-03,  2.6200e-03],\n",
              "          [ 1.0634e-02,  3.4704e-02,  1.4175e-02,  ...,  4.6840e-02,\n",
              "            1.7369e-02,  9.3781e-03],\n",
              "          [-8.5921e-03, -1.2578e-02, -1.1793e-02,  ..., -3.0867e-02,\n",
              "           -1.4449e-02, -8.1653e-05]], dtype=torch.float64), 'final_loss': 0.004122044949812211, 'loss_breakdown': {'ot': 0.004080968367052204,\n",
              "   'ortho': 0.003348155230062078,\n",
              "   'graph': 75.95030459385717}, 'best_iter': 1451, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.15720496730094352}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.38115265, -0.0308977 , -0.07257841, ...,  0.12160429,\n",
              "           0.10934346, -0.02589723],\n",
              "         [-0.19451181,  0.23758634, -0.06580833, ..., -0.19071504,\n",
              "          -0.02929657, -0.01453326],\n",
              "         [-0.02877319,  0.31283256, -0.0096105 , ..., -0.11482084,\n",
              "           0.00677656, -0.00528897],\n",
              "         ...,\n",
              "         [-0.08776098,  0.19534814,  0.02558753, ..., -0.00854576,\n",
              "          -0.00622754, -0.11507589],\n",
              "         [-0.31967499,  0.00964195, -0.12399036, ..., -0.07995213,\n",
              "           0.02175874,  0.0239827 ],\n",
              "         [-0.30712602, -0.05006342, -0.01736314, ..., -0.17115634,\n",
              "           0.00445893,  0.06187037]]), 'mapped_Y': array([[ 0.41817977, -0.06028068, -0.05715864, ...,  0.08646756,\n",
              "           0.13688036, -0.0410274 ],\n",
              "         [-0.41669541, -0.08148984, -0.06339875, ...,  0.06327411,\n",
              "          -0.10940667, -0.03705633],\n",
              "         [ 0.08955217,  0.14807337,  0.08112295, ..., -0.11032267,\n",
              "          -0.01949148,  0.04822817],\n",
              "         ...,\n",
              "         [-0.09773045,  0.31247842, -0.04490489, ..., -0.04563385,\n",
              "           0.00469501, -0.04450577],\n",
              "         [-0.34653769, -0.06642544,  0.02342728, ...,  0.2395652 ,\n",
              "          -0.1471374 ,  0.04120139],\n",
              "         [-0.3512882 , -0.06164028, -0.09778013, ..., -0.14833116,\n",
              "          -0.00089188,  0.06477074]]), 'alpha': tensor([[ 7.3487e-04,  2.1658e-02,  1.5523e-02,  ...,  1.8019e-04,\n",
              "            1.2963e-02, -3.2797e-03],\n",
              "          [ 1.4118e-02,  2.2462e-03,  3.2353e-03,  ..., -4.8220e-02,\n",
              "           -3.9484e-03, -4.9722e-03],\n",
              "          [-6.6655e-03,  1.5211e-02,  1.5258e-03,  ...,  1.8409e-02,\n",
              "            2.8363e-03, -5.9721e-03],\n",
              "          ...,\n",
              "          [ 6.1011e-05,  2.7412e-02, -1.0426e-02,  ..., -8.3826e-03,\n",
              "            7.7973e-04,  5.6544e-03],\n",
              "          [-7.3138e-03,  1.3360e-02, -9.8224e-03,  ..., -4.3536e-02,\n",
              "            4.7004e-02, -1.0260e-02],\n",
              "          [-9.2202e-03,  1.6664e-02, -2.0199e-02,  ..., -7.2475e-02,\n",
              "            4.9163e-02, -2.4632e-02]], dtype=torch.float64), 'beta': tensor([[-0.0032,  0.0014,  0.0044,  ...,  0.0031,  0.0154, -0.0025],\n",
              "          [-0.0015,  0.0031,  0.0091,  ...,  0.0037, -0.0111, -0.0106],\n",
              "          [ 0.0072,  0.0037,  0.0213,  ...,  0.0050, -0.0218, -0.0115],\n",
              "          ...,\n",
              "          [-0.0063,  0.0280, -0.0070,  ...,  0.0110, -0.0006,  0.0070],\n",
              "          [ 0.0041,  0.0216,  0.0241,  ...,  0.0338, -0.0086, -0.0038],\n",
              "          [-0.0048, -0.0106, -0.0171,  ..., -0.0253,  0.0247,  0.0047]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00453931032568706, 'loss_breakdown': {'ot': 0.004479151013132293,\n",
              "   'ortho': 0.00534988712001718,\n",
              "   'graph': 66.60441354595605}, 'best_iter': 1201, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.1540354074816025}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[ 2.41223125e-01, -1.03359165e-01, -3.20320684e-02, ...,\n",
              "          -9.94481882e-06,  1.69433514e-01,  2.36195004e-02],\n",
              "         [-7.33607724e-02,  2.73906542e-01, -2.65342270e-02, ...,\n",
              "          -9.21004765e-02, -9.56099539e-02,  4.14835915e-02],\n",
              "         [ 7.92614613e-02,  3.49748878e-01,  7.83706880e-03, ...,\n",
              "          -4.07665948e-02, -3.87177081e-02,  3.49487437e-02],\n",
              "         ...,\n",
              "         [ 8.12623180e-02,  1.87984384e-01,  7.38948918e-02, ...,\n",
              "           7.73730627e-02, -4.28720477e-02, -4.62385647e-02],\n",
              "         [-2.91321506e-01,  6.17002305e-02, -1.43798171e-01, ...,\n",
              "          -3.37551480e-02, -7.77649980e-03, -1.71195058e-02],\n",
              "         [-2.42029674e-01, -2.75688213e-03,  9.73434519e-02, ...,\n",
              "          -1.29790053e-01, -1.33209126e-01, -1.97214254e-02]]), 'mapped_Y': array([[ 0.27051637, -0.12930829, -0.04669868, ..., -0.03926309,\n",
              "           0.18718693,  0.00152572],\n",
              "         [-0.37503092, -0.07420433, -0.07402541, ...,  0.07383264,\n",
              "          -0.11510986, -0.04819167],\n",
              "         [ 0.07885684,  0.13627574,  0.08593893, ..., -0.06734708,\n",
              "          -0.06255584,  0.04305829],\n",
              "         ...,\n",
              "         [ 0.07058222,  0.3407094 , -0.0161181 , ...,  0.04172155,\n",
              "          -0.02597562,  0.02150074],\n",
              "         [-0.32976344, -0.08191843,  0.07407067, ...,  0.16411649,\n",
              "          -0.0380396 ,  0.046957  ],\n",
              "         [-0.33371792, -0.00170987, -0.09814094, ..., -0.05750808,\n",
              "          -0.05946519,  0.02531596]]), 'alpha': tensor([[ 0.0027,  0.0240,  0.0237,  ..., -0.0004,  0.0128, -0.0083],\n",
              "          [ 0.0235,  0.0079,  0.0152,  ..., -0.0446, -0.0089, -0.0103],\n",
              "          [-0.0066,  0.0270, -0.0013,  ...,  0.0161,  0.0073, -0.0130],\n",
              "          ...,\n",
              "          [ 0.0102,  0.0187,  0.0076,  ...,  0.0417,  0.0214,  0.0285],\n",
              "          [ 0.0022,  0.0164, -0.0237,  ..., -0.0353,  0.0014, -0.0206],\n",
              "          [-0.0028,  0.0214,  0.0118,  ..., -0.0561,  0.0098, -0.0350]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0044,  0.0020,  0.0020,  ..., -0.0010,  0.0149, -0.0043],\n",
              "          [-0.0031, -0.0022,  0.0114,  ...,  0.0022, -0.0140, -0.0134],\n",
              "          [-0.0055, -0.0040,  0.0249,  ...,  0.0096, -0.0332, -0.0265],\n",
              "          ...,\n",
              "          [-0.0095,  0.0234,  0.0013,  ...,  0.0225,  0.0138,  0.0130],\n",
              "          [ 0.0095,  0.0206,  0.0366,  ...,  0.0166,  0.0175,  0.0025],\n",
              "          [-0.0048, -0.0098, -0.0211,  ..., -0.0084, -0.0026,  0.0068]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003918619088752267, 'loss_breakdown': {'ot': 0.003877231555061904,\n",
              "   'ortho': 0.003523994193558363,\n",
              "   'graph': 61.47591754779758}, 'best_iter': 1551, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.15303377366907223}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[ 0.38113047, -0.08296633, -0.15674622, ...,  0.07413147,\n",
              "           0.03821323,  0.00590741],\n",
              "         [-0.18649465,  0.14124351, -0.05822695, ..., -0.17341674,\n",
              "           0.0129565 ,  0.01723889],\n",
              "         [ 0.01192657,  0.24173402, -0.03725612, ..., -0.09709241,\n",
              "           0.08372275,  0.01546698],\n",
              "         ...,\n",
              "         [ 0.01257996,  0.22368227,  0.06390244, ...,  0.00373265,\n",
              "           0.04634429, -0.23098228],\n",
              "         [-0.35304641, -0.00932811, -0.04075635, ..., -0.11953203,\n",
              "          -0.0289393 , -0.0111474 ],\n",
              "         [-0.30377351, -0.03431705,  0.05035178, ..., -0.16221886,\n",
              "           0.00353562, -0.17068942]]), 'mapped_Y': array([[ 0.43202538, -0.13477127, -0.132769  , ...,  0.02599039,\n",
              "           0.0144707 ,  0.04435765],\n",
              "         [-0.41059323,  0.02797825, -0.04537012, ...,  0.10959282,\n",
              "          -0.16922306, -0.07406889],\n",
              "         [ 0.08096295,  0.13007698,  0.0049031 , ..., -0.08328393,\n",
              "           0.0124048 ,  0.15315658],\n",
              "         ...,\n",
              "         [-0.0226876 ,  0.24444336, -0.0294279 , ..., -0.06269767,\n",
              "           0.05099458, -0.07939151],\n",
              "         [-0.32781792,  0.04979623,  0.01637986, ...,  0.28019367,\n",
              "          -0.07414332, -0.03156818],\n",
              "         [-0.39123632, -0.02899597, -0.05689972, ..., -0.13287958,\n",
              "          -0.07315582, -0.01166537]]), 'alpha': tensor([[ 0.0109,  0.0372, -0.0020,  ..., -0.0069,  0.0155, -0.0001],\n",
              "          [ 0.0135, -0.0297,  0.0199,  ..., -0.0376, -0.0011,  0.0146],\n",
              "          [-0.0008,  0.0077, -0.0133,  ...,  0.0088,  0.0181, -0.0065],\n",
              "          ...,\n",
              "          [ 0.0201,  0.0338, -0.0031,  ...,  0.0020, -0.0098, -0.0273],\n",
              "          [-0.0022,  0.0106, -0.0087,  ..., -0.0661,  0.0151, -0.0064],\n",
              "          [-0.0031, -0.0005, -0.0269,  ..., -0.1040,  0.0018, -0.0422]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0024,  0.0038, -0.0041,  ..., -0.0075,  0.0040,  0.0052],\n",
              "          [ 0.0059,  0.0133,  0.0014,  ...,  0.0053, -0.0100,  0.0021],\n",
              "          [ 0.0173,  0.0229,  0.0085,  ..., -0.0235, -0.0047,  0.0191],\n",
              "          ...,\n",
              "          [-0.0126, -0.0055, -0.0209,  ...,  0.0033,  0.0026,  0.0034],\n",
              "          [ 0.0134,  0.0367,  0.0153,  ...,  0.0490,  0.0197,  0.0066],\n",
              "          [-0.0100, -0.0141, -0.0120,  ..., -0.0280, -0.0177, -0.0033]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0037543048050595698, 'loss_breakdown': {'ot': 0.0037268716741743054,\n",
              "   'ortho': 0.002670343949261255,\n",
              "   'graph': 72.9691392651748}, 'best_iter': 1570, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.1573915193179403}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.38415143, -0.00715777, -0.071156  , ...,  0.10755308,\n",
              "           0.10822918, -0.04256894],\n",
              "         [-0.19616954,  0.20671122, -0.0656073 , ..., -0.18054198,\n",
              "          -0.01815969,  0.0064078 ],\n",
              "         [-0.03178037,  0.27946223,  0.00047036, ..., -0.09709138,\n",
              "           0.01261201,  0.00771277],\n",
              "         ...,\n",
              "         [-0.08528415,  0.17992307,  0.01418679, ..., -0.00193443,\n",
              "           0.00750953, -0.08452341],\n",
              "         [-0.32049224,  0.0117184 , -0.11861621, ..., -0.0842783 ,\n",
              "           0.01558204,  0.02717532],\n",
              "         [-0.29789745, -0.04519554, -0.01964794, ..., -0.16722694,\n",
              "           0.00654881,  0.07657154]]), 'mapped_Y': array([[ 0.42076311, -0.04672831, -0.05190159, ...,  0.08181022,\n",
              "           0.14209664, -0.06370028],\n",
              "         [-0.4159877 , -0.07282845, -0.08855689, ...,  0.05040308,\n",
              "          -0.10671772, -0.01901284],\n",
              "         [ 0.08099016,  0.13471749,  0.09534399, ..., -0.10069629,\n",
              "          -0.02041911,  0.04988265],\n",
              "         ...,\n",
              "         [-0.1020575 ,  0.28219416, -0.04479854, ..., -0.03144159,\n",
              "           0.01555587, -0.0251903 ],\n",
              "         [-0.34548278, -0.05051893, -0.01279092, ...,  0.21557846,\n",
              "          -0.13977608,  0.03966484],\n",
              "         [-0.34913148, -0.06281401, -0.10096633, ..., -0.14976247,\n",
              "          -0.00686446,  0.08511538]]), 'alpha': tensor([[ 0.0004,  0.0233,  0.0147,  ..., -0.0013,  0.0127, -0.0042],\n",
              "          [ 0.0164,  0.0002,  0.0044,  ..., -0.0495, -0.0015, -0.0047],\n",
              "          [-0.0075,  0.0150,  0.0017,  ...,  0.0179,  0.0009, -0.0071],\n",
              "          ...,\n",
              "          [ 0.0030,  0.0330, -0.0139,  ..., -0.0063,  0.0045,  0.0129],\n",
              "          [-0.0082,  0.0141, -0.0087,  ..., -0.0455,  0.0468, -0.0100],\n",
              "          [-0.0087,  0.0200, -0.0205,  ..., -0.0745,  0.0502, -0.0225]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0035,  0.0016,  0.0040,  ...,  0.0030,  0.0147, -0.0034],\n",
              "          [-0.0015,  0.0032,  0.0086,  ...,  0.0033, -0.0102, -0.0096],\n",
              "          [ 0.0072,  0.0034,  0.0258,  ...,  0.0075, -0.0237, -0.0137],\n",
              "          ...,\n",
              "          [-0.0077,  0.0304, -0.0066,  ...,  0.0098, -0.0007,  0.0060],\n",
              "          [ 0.0052,  0.0225,  0.0220,  ...,  0.0315, -0.0045, -0.0058],\n",
              "          [-0.0050, -0.0112, -0.0177,  ..., -0.0254,  0.0248,  0.0077]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0041195525235278845, 'loss_breakdown': {'ot': 0.004077343006565635,\n",
              "   'ortho': 0.004157256465297991,\n",
              "   'graph': 63.69523092697355}, 'best_iter': 1328, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.1546146765808345}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.24416483, -0.09130391, -0.04040269, ..., -0.00226556,\n",
              "           0.17566631,  0.03254906],\n",
              "         [-0.07930892,  0.2673709 , -0.02320284, ..., -0.08970919,\n",
              "          -0.10162456,  0.03825022],\n",
              "         [ 0.07269183,  0.3475463 ,  0.01297589, ..., -0.0404966 ,\n",
              "          -0.04741259,  0.03313801],\n",
              "         ...,\n",
              "         [ 0.07838322,  0.18670804,  0.07639223, ...,  0.07539666,\n",
              "          -0.04622491, -0.05034731],\n",
              "         [-0.29478354,  0.05729625, -0.13699192, ..., -0.02940985,\n",
              "          -0.00718279, -0.02486201],\n",
              "         [-0.24470582, -0.0067935 ,  0.09732947, ..., -0.12966764,\n",
              "          -0.1317964 , -0.02221951]]), 'mapped_Y': array([[ 0.27330654, -0.11673669, -0.0548772 , ..., -0.04251874,\n",
              "           0.19189096,  0.01116861],\n",
              "         [-0.37540587, -0.08174004, -0.07268897, ...,  0.07678869,\n",
              "          -0.1105735 , -0.05532667],\n",
              "         [ 0.07675418,  0.13502001,  0.08737879, ..., -0.06733847,\n",
              "          -0.06634778,  0.04274326],\n",
              "         ...,\n",
              "         [ 0.0654425 ,  0.33667365, -0.01045945, ...,  0.04298893,\n",
              "          -0.03415506,  0.01902184],\n",
              "         [-0.33030317, -0.0865055 ,  0.07245347, ...,  0.16617031,\n",
              "          -0.0311722 ,  0.04005354],\n",
              "         [-0.3357009 , -0.00815749, -0.0933637 , ..., -0.05426752,\n",
              "          -0.06142503,  0.01935813]]), 'alpha': tensor([[ 0.0029,  0.0242,  0.0238,  ..., -0.0005,  0.0126, -0.0083],\n",
              "          [ 0.0235,  0.0082,  0.0145,  ..., -0.0447, -0.0091, -0.0099],\n",
              "          [-0.0065,  0.0271, -0.0011,  ...,  0.0158,  0.0069, -0.0130],\n",
              "          ...,\n",
              "          [ 0.0100,  0.0197,  0.0076,  ...,  0.0414,  0.0215,  0.0280],\n",
              "          [ 0.0020,  0.0165, -0.0231,  ..., -0.0351,  0.0015, -0.0208],\n",
              "          [-0.0029,  0.0215,  0.0112,  ..., -0.0560,  0.0097, -0.0350]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0042,  0.0021,  0.0020,  ..., -0.0011,  0.0148, -0.0041],\n",
              "          [-0.0029, -0.0024,  0.0111,  ...,  0.0021, -0.0137, -0.0133],\n",
              "          [-0.0051, -0.0043,  0.0249,  ...,  0.0101, -0.0333, -0.0269],\n",
              "          ...,\n",
              "          [-0.0096,  0.0233,  0.0010,  ...,  0.0230,  0.0138,  0.0133],\n",
              "          [ 0.0094,  0.0208,  0.0363,  ...,  0.0166,  0.0178,  0.0023],\n",
              "          [-0.0048, -0.0099, -0.0209,  ..., -0.0086, -0.0029,  0.0070]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00391545868184422, 'loss_breakdown': {'ot': 0.0038802001507189667,\n",
              "   'ortho': 0.0034644006263963517,\n",
              "   'graph': 61.45248612902982}, 'best_iter': 1549, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.15322032568606897}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 1.64226932e-03,  4.09708336e-03,  1.17700326e-03, ...,\n",
              "           3.26476999e-03, -4.33736145e-04, -1.40919349e-03],\n",
              "         [ 4.91901191e-04,  6.67295935e-04,  1.99843284e-03, ...,\n",
              "           7.60628460e-05,  2.51436197e-03,  5.91306653e-03],\n",
              "         [ 7.40621305e-04,  1.84995248e-03,  4.55434871e-03, ...,\n",
              "          -1.71042581e-03,  3.34391269e-03,  1.67299089e-03],\n",
              "         ...,\n",
              "         [-5.59224643e-04, -2.86627218e-04,  2.10936279e-03, ...,\n",
              "          -3.18744450e-03,  3.52134576e-03,  1.31135768e-02],\n",
              "         [ 2.56821127e-04, -9.42126337e-04, -1.24033108e-03, ...,\n",
              "           2.66757294e-03, -9.19377866e-04, -3.52708579e-03],\n",
              "         [-2.78127447e-05, -7.54128439e-04, -3.24544139e-03, ...,\n",
              "           2.72787439e-03, -7.48955787e-04, -1.11017061e-03]]), 'mapped_Y': array([[-7.49225750e-04, -1.53861865e-03,  6.85699769e-04, ...,\n",
              "           3.20731873e-03, -2.22478906e-03, -2.80163254e-04],\n",
              "         [ 6.11555957e-04,  8.91185267e-04,  1.28281903e-04, ...,\n",
              "          -1.45377856e-03,  4.29747121e-04, -3.29466506e-03],\n",
              "         [-1.61038364e-03, -2.37132879e-03,  3.02488830e-03, ...,\n",
              "           8.02433285e-03,  5.34011213e-03, -3.90238588e-03],\n",
              "         ...,\n",
              "         [ 2.55346402e-04,  2.06211691e-03, -5.87676896e-03, ...,\n",
              "          -2.42671401e-03, -5.11568677e-03,  4.67272453e-03],\n",
              "         [ 4.00599214e-04,  3.98458719e-03, -3.85369059e-03, ...,\n",
              "           8.53468963e-03,  9.40991303e-04, -3.58016455e-03],\n",
              "         [ 1.77839504e-03,  8.90518565e-04,  1.94156549e-05, ...,\n",
              "          -6.07924156e-03, -1.17916805e-03,  1.43756912e-03]]), 'alpha': tensor([[ 1.9284e-04,  8.2589e-04,  2.1737e-03,  ...,  1.4352e-03,\n",
              "            2.9960e-04, -9.1048e-04],\n",
              "          [ 2.2909e-06, -9.3711e-04,  1.0128e-03,  ...,  3.9877e-03,\n",
              "           -1.1974e-02, -1.6836e-03],\n",
              "          [ 8.5812e-04,  2.4297e-03,  1.8891e-03,  ...,  9.2630e-03,\n",
              "           -7.1911e-03, -1.0698e-02],\n",
              "          ...,\n",
              "          [-1.0446e-04,  9.7417e-05,  2.2610e-03,  ...,  7.1394e-03,\n",
              "            6.5819e-03, -4.1232e-03],\n",
              "          [ 1.2342e-03,  2.0411e-03,  1.9008e-03,  ...,  3.7331e-03,\n",
              "           -1.1859e-03, -2.3430e-03],\n",
              "          [ 1.2355e-03,  1.7515e-03, -1.7582e-03,  ...,  5.8998e-03,\n",
              "            7.8404e-04,  8.8520e-04]], dtype=torch.float64), 'beta': tensor([[-2.3186e-04,  8.7286e-04, -7.8339e-04,  ...,  8.9071e-04,\n",
              "           -1.8726e-03,  2.2192e-03],\n",
              "          [-5.5091e-04, -5.9897e-04,  4.5028e-04,  ..., -4.7780e-04,\n",
              "            2.5675e-04, -3.0183e-03],\n",
              "          [-1.0639e-03, -1.2466e-03, -4.6940e-03,  ...,  1.0243e-02,\n",
              "            5.4247e-03, -8.9751e-03],\n",
              "          ...,\n",
              "          [ 8.1399e-05,  1.9621e-03, -3.3996e-03,  ..., -5.4970e-03,\n",
              "           -3.1234e-03,  7.3990e-03],\n",
              "          [-1.9746e-06, -1.1297e-04, -9.2124e-04,  ...,  1.4985e-02,\n",
              "            2.1911e-03, -3.6076e-03],\n",
              "          [ 2.9246e-04, -4.2443e-04,  4.5345e-04,  ..., -9.3254e-04,\n",
              "            3.6333e-04,  3.1449e-03]], dtype=torch.float64), 'final_loss': 0.015893395661103826, 'loss_breakdown': {'ot': 4.310033354048703e-06,\n",
              "   'ortho': 15.792292661716116,\n",
              "   'graph': 0.09679296603366136}, 'best_iter': 177, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.08930276981852914,\n",
              "   'accuracy_raw': 0.08930276981852914,\n",
              "   'foscttm': 0.6178707709934876}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[ 2.41062806e-04,  1.97937471e-03, -4.15382497e-03, ...,\n",
              "          -1.18343461e-02, -2.48600714e-03,  4.23056610e-03],\n",
              "         [ 1.10354546e-03,  1.90878672e-03,  1.95418763e-03, ...,\n",
              "          -4.63517867e-03,  2.50872968e-03,  1.10362411e-02],\n",
              "         [-6.97695753e-04,  7.17396533e-04,  3.01058360e-03, ...,\n",
              "           4.67377526e-03, -9.85120431e-06,  5.52998593e-03],\n",
              "         ...,\n",
              "         [-6.77080987e-04,  8.57212224e-04,  2.01638080e-03, ...,\n",
              "          -7.73247883e-03,  4.74900299e-03,  2.23525653e-02],\n",
              "         [ 6.63874924e-04, -2.93580138e-05, -8.30277270e-04, ...,\n",
              "           5.35399178e-04,  2.07182609e-03, -4.51372383e-03],\n",
              "         [ 1.05049416e-03, -6.88632849e-04, -1.67463344e-03, ...,\n",
              "           4.20854528e-03,  7.19489021e-04, -8.60896637e-03]]), 'mapped_Y': array([[ 1.50873569e-04, -8.40501177e-04, -1.58776161e-03, ...,\n",
              "          -1.02760186e-02, -1.22718785e-03,  1.60036423e-03],\n",
              "         [-3.08587897e-05, -6.47907514e-04,  1.99283103e-03, ...,\n",
              "           5.65480682e-03,  2.12121725e-03, -6.07064682e-03],\n",
              "         [-1.17457783e-03, -6.26689178e-04,  8.92542351e-04, ...,\n",
              "           2.88029176e-02,  4.69699388e-03, -8.27890512e-03],\n",
              "         ...,\n",
              "         [ 1.04763217e-03, -1.38864032e-04, -5.30723698e-03, ...,\n",
              "          -2.12355125e-02, -2.67320169e-03,  6.09394514e-03],\n",
              "         [-3.96697487e-04, -4.61153773e-04, -9.04921117e-04, ...,\n",
              "           2.06332054e-02,  3.44400900e-03, -8.19406211e-03],\n",
              "         [ 9.33049824e-04,  1.22662579e-04,  1.99086179e-03, ...,\n",
              "          -7.96536472e-03, -1.05823865e-03,  2.64764987e-03]]), 'alpha': tensor([[-1.4716e-04,  3.8237e-04, -3.7016e-04,  ...,  1.0702e-03,\n",
              "            1.4063e-04, -1.0619e-04],\n",
              "          [ 7.7765e-04,  7.8990e-04,  2.3321e-04,  ...,  5.5155e-03,\n",
              "           -2.2314e-03,  9.5326e-04],\n",
              "          [-2.8780e-05, -2.8478e-04, -5.9058e-04,  ...,  1.1798e-02,\n",
              "           -1.0548e-02, -7.0886e-03],\n",
              "          ...,\n",
              "          [-2.7777e-05, -1.3763e-03,  1.0942e-03,  ...,  9.1525e-05,\n",
              "            4.5502e-03,  4.1159e-03],\n",
              "          [ 1.0234e-03, -6.5282e-04,  8.4180e-05,  ..., -6.1985e-04,\n",
              "            3.3983e-03, -7.6087e-04],\n",
              "          [ 1.6581e-03, -4.9808e-04, -2.7035e-03,  ...,  2.7942e-03,\n",
              "           -9.3543e-04, -8.1248e-03]], dtype=torch.float64), 'beta': tensor([[-1.3498e-04, -2.0496e-03, -8.7655e-04,  ...,  1.2982e-04,\n",
              "           -9.7079e-04,  3.4835e-03],\n",
              "          [-4.5518e-04, -1.9146e-03,  4.7678e-04,  ...,  6.1086e-03,\n",
              "            6.8545e-04, -5.8363e-03],\n",
              "          [-5.2610e-04, -3.1974e-03, -7.8852e-04,  ...,  2.5878e-02,\n",
              "            6.6182e-03, -1.1375e-02],\n",
              "          ...,\n",
              "          [ 1.9780e-05, -1.0578e-03, -3.2610e-03,  ..., -1.6015e-02,\n",
              "           -1.1102e-03,  8.2888e-03],\n",
              "          [-9.3944e-05, -1.0778e-03, -2.7469e-04,  ...,  1.7657e-02,\n",
              "            4.0308e-03, -5.3993e-03],\n",
              "          [ 3.1118e-04, -8.3331e-04,  6.9319e-04,  ..., -3.5966e-03,\n",
              "           -1.0347e-03,  6.5258e-03]], dtype=torch.float64), 'final_loss': 0.015210292109196567, 'loss_breakdown': {'ot': 9.701259246737545e-05,\n",
              "   'ortho': 14.313575791623887,\n",
              "   'graph': 0.7997037251053045}, 'best_iter': 459, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.4140401146131805,\n",
              "   'accuracy_raw': 0.4140401146131805,\n",
              "   'foscttm': 0.42452762201368544}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[-8.36036924e-05, -2.36679546e-05, -1.98083074e-03, ...,\n",
              "           4.84839679e-03,  1.29087166e-03, -4.53100147e-03],\n",
              "         [ 9.55524001e-04,  3.50507702e-03,  7.48501917e-04, ...,\n",
              "          -7.78108327e-03, -2.17812441e-03,  5.91918533e-03],\n",
              "         [-1.03850637e-03,  2.43222053e-03, -1.47074219e-05, ...,\n",
              "          -2.29891945e-02, -3.31249615e-03,  7.33362729e-03],\n",
              "         ...,\n",
              "         [-7.21708715e-04,  2.32385823e-03, -3.66010146e-04, ...,\n",
              "          -3.26816740e-02,  1.80994283e-03,  2.25423199e-02],\n",
              "         [ 7.82528359e-04,  6.69813500e-04, -5.90797024e-05, ...,\n",
              "           1.08985418e-02, -4.19791428e-04, -3.47790461e-03],\n",
              "         [ 1.14938516e-03, -1.13819375e-04, -1.37861351e-03, ...,\n",
              "           1.09501560e-02, -1.52763264e-03, -7.81435134e-03]]), 'mapped_Y': array([[ 7.21495437e-04, -2.36762350e-03,  7.35719875e-04, ...,\n",
              "          -1.59528583e-03,  1.76694089e-03, -7.88495245e-03],\n",
              "         [ 6.41218398e-05,  4.26939477e-04,  7.90139205e-04, ...,\n",
              "           1.74644963e-02, -3.03527900e-03, -5.15591522e-03],\n",
              "         [-1.13571854e-03, -7.98069381e-04,  3.60770400e-04, ...,\n",
              "           2.20771477e-02,  6.54411417e-03, -4.61653358e-03],\n",
              "         ...,\n",
              "         [-6.91982474e-04,  6.98771207e-04, -4.68111078e-03, ...,\n",
              "          -2.84823605e-02, -1.90323816e-03,  1.49999201e-02],\n",
              "         [-6.68987806e-04,  5.61670190e-04, -1.25726929e-03, ...,\n",
              "           3.58364765e-02, -1.20906584e-03, -1.08124838e-02],\n",
              "         [ 1.03625402e-03,  7.99822962e-04,  1.11135600e-03, ...,\n",
              "           1.88960495e-03, -4.53062411e-03,  3.07931468e-03]]), 'alpha': tensor([[-2.9668e-04,  2.8604e-04, -4.5946e-04,  ...,  1.8191e-03,\n",
              "            4.0914e-04, -5.9924e-04],\n",
              "          [ 7.0136e-04,  7.2359e-04,  4.0622e-04,  ...,  9.2153e-03,\n",
              "           -3.1287e-03, -1.2101e-03],\n",
              "          [-2.4251e-04, -2.4252e-04, -5.4075e-04,  ...,  1.8040e-02,\n",
              "           -1.1174e-02, -8.2026e-03],\n",
              "          ...,\n",
              "          [ 1.0559e-05, -1.4467e-03,  9.3034e-04,  ..., -3.8362e-03,\n",
              "            5.4962e-03,  4.2027e-03],\n",
              "          [ 1.0123e-03, -6.3800e-04,  3.7543e-06,  ..., -1.7598e-03,\n",
              "            3.3285e-03, -1.4610e-03],\n",
              "          [ 1.6269e-03, -4.9181e-04, -2.6288e-03,  ..., -3.0105e-04,\n",
              "           -1.1100e-03, -8.7560e-03]], dtype=torch.float64), 'beta': tensor([[-0.0002, -0.0021, -0.0008,  ...,  0.0003, -0.0010,  0.0032],\n",
              "          [-0.0004, -0.0019,  0.0003,  ...,  0.0060,  0.0004, -0.0055],\n",
              "          [-0.0005, -0.0032, -0.0010,  ...,  0.0258,  0.0073, -0.0116],\n",
              "          ...,\n",
              "          [-0.0003, -0.0011, -0.0030,  ..., -0.0138, -0.0013,  0.0056],\n",
              "          [-0.0002, -0.0011, -0.0002,  ...,  0.0183,  0.0039, -0.0061],\n",
              "          [ 0.0003, -0.0007,  0.0005,  ..., -0.0039, -0.0011,  0.0069]],\n",
              "         dtype=torch.float64), 'final_loss': 0.015368976210562317, 'loss_breakdown': {'ot': 0.00013529706632578638,\n",
              "   'ortho': 14.485157830867884,\n",
              "   'graph': 0.7485213133686466}, 'best_iter': 453, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.5415472779369628,\n",
              "   'accuracy_raw': 0.5415472779369628,\n",
              "   'foscttm': 0.36539200097791574}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 0.07290468,  0.00913756, -0.02741372, ..., -0.16568545,\n",
              "          -0.14964641, -0.25988526],\n",
              "         [-0.04729957, -0.07450585, -0.10127616, ...,  0.09951518,\n",
              "           0.16910646,  0.14883194],\n",
              "         [-0.03474224, -0.05889328, -0.08615874, ...,  0.02169828,\n",
              "           0.08234362,  0.14636306],\n",
              "         ...,\n",
              "         [-0.02446684, -0.0060269 , -0.01284015, ...,  0.11773975,\n",
              "           0.02924389,  0.04539186],\n",
              "         [-0.04182637, -0.06828958, -0.10816554, ...,  0.09810502,\n",
              "           0.08506559,  0.131125  ],\n",
              "         [-0.03876226, -0.02420862,  0.00448474, ...,  0.003583  ,\n",
              "           0.15445675,  0.07172539]]), 'mapped_Y': array([[-0.03853662, -0.02480446, -0.03991469, ...,  0.14672042,\n",
              "           0.15048522,  0.14453487],\n",
              "         [ 0.07760353, -0.00225067, -0.03358196, ..., -0.14687479,\n",
              "          -0.1255962 , -0.32249912],\n",
              "         [-0.0217424 ,  0.00378703,  0.0136209 , ...,  0.0027669 ,\n",
              "           0.02381012,  0.17609717],\n",
              "         ...,\n",
              "         [-0.04219093, -0.05558715, -0.10255119, ...,  0.13858994,\n",
              "           0.08025194,  0.10039079],\n",
              "         [ 0.07321777,  0.01277249, -0.01067202, ..., -0.13819573,\n",
              "          -0.07338607, -0.28716575],\n",
              "         [ 0.05435685, -0.01292464, -0.03827228, ..., -0.14966802,\n",
              "          -0.12443483, -0.18781482]]), 'alpha': tensor([[-2.0857e-03,  1.1715e-04, -1.3605e-03,  ..., -5.7819e-03,\n",
              "           -3.7930e-03,  1.8118e-03],\n",
              "          [-8.5747e-04, -4.2612e-03, -4.8028e-05,  ..., -1.8050e-03,\n",
              "            1.5764e-02, -1.3739e-02],\n",
              "          [-2.2168e-03, -2.4769e-03, -8.0540e-03,  ..., -8.7639e-03,\n",
              "            4.6256e-03,  3.4176e-03],\n",
              "          ...,\n",
              "          [ 2.3888e-04,  3.4071e-04,  2.4935e-04,  ...,  2.3578e-02,\n",
              "           -6.2281e-03, -9.5579e-03],\n",
              "          [-2.0967e-03, -3.2296e-03, -4.3621e-03,  ..., -4.9110e-03,\n",
              "           -2.1141e-03,  9.6383e-04],\n",
              "          [-1.1351e-03, -3.1126e-03, -5.0035e-03,  ..., -7.6527e-03,\n",
              "            9.6649e-03, -1.6768e-02]], dtype=torch.float64), 'beta': tensor([[-1.3043e-03, -1.5401e-03,  9.1135e-04,  ...,  5.7126e-03,\n",
              "            7.5259e-03,  6.4793e-04],\n",
              "          [ 4.9194e-05,  4.0606e-04,  4.9880e-03,  ..., -2.0027e-04,\n",
              "            2.9059e-03, -6.6383e-03],\n",
              "          [-1.9660e-03, -4.1928e-03,  1.1708e-03,  ..., -1.8864e-03,\n",
              "            1.0717e-02,  9.1833e-03],\n",
              "          ...,\n",
              "          [-2.4990e-03, -2.1064e-03, -1.0053e-02,  ...,  1.2490e-02,\n",
              "           -8.8225e-04, -1.8411e-03],\n",
              "          [-1.4908e-03, -2.9818e-03, -1.9352e-03,  ...,  2.6072e-03,\n",
              "            7.5298e-03, -1.1917e-03],\n",
              "          [ 1.0398e-03,  1.3180e-04,  1.4605e-03,  ...,  3.1670e-03,\n",
              "           -4.5790e-03, -8.5198e-04]], dtype=torch.float64), 'final_loss': 0.012243261657900847, 'loss_breakdown': {'ot': 0.0018517228163622348,\n",
              "   'ortho': 7.475738025268635,\n",
              "   'graph': 29.158008162699772}, 'best_iter': 224, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.26599808978032474,\n",
              "   'accuracy_raw': 0.26599808978032474,\n",
              "   'foscttm': 0.5906236858117384}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.16943958,  0.02403396,  0.26611709, ...,  0.12204789,\n",
              "           0.03663011, -0.19080616],\n",
              "         [-0.08388161,  0.00770291, -0.13976479, ..., -0.23182228,\n",
              "          -0.09181233, -0.019223  ],\n",
              "         [-0.07239435, -0.02922134, -0.06411156, ..., -0.1681128 ,\n",
              "          -0.21464761,  0.0039582 ],\n",
              "         ...,\n",
              "         [-0.06089889, -0.019983  , -0.06795781, ..., -0.10579313,\n",
              "          -0.19741848, -0.03381223],\n",
              "         [-0.06078446,  0.01797533, -0.06962488, ..., -0.08903709,\n",
              "           0.10641156,  0.15294943],\n",
              "         [-0.08350277,  0.02303821, -0.08230868, ..., -0.17615297,\n",
              "           0.00085411,  0.05156803]]), 'mapped_Y': array([[ 0.18414776, -0.02841719,  0.26526873, ...,  0.1578718 ,\n",
              "           0.04159578, -0.20979976],\n",
              "         [-0.09142393,  0.02218382, -0.15696878, ...,  0.00164538,\n",
              "           0.05325625,  0.10454052],\n",
              "         [-0.02106791, -0.00819566,  0.02333893, ...,  0.00266327,\n",
              "          -0.09212973,  0.03388108],\n",
              "         ...,\n",
              "         [-0.08932457, -0.04664129, -0.09295711, ..., -0.19785356,\n",
              "          -0.22447385, -0.01128878],\n",
              "         [-0.08077528, -0.01212493, -0.1008595 , ...,  0.05604948,\n",
              "           0.07217883,  0.19595772],\n",
              "         [-0.08066768,  0.02416398, -0.14928559, ..., -0.07773467,\n",
              "           0.03844399,  0.07369708]]), 'alpha': tensor([[-0.0012,  0.0043,  0.0066,  ..., -0.0126,  0.0004, -0.0066],\n",
              "          [ 0.0088,  0.0215, -0.0004,  ..., -0.0455,  0.0310, -0.0304],\n",
              "          [ 0.0018,  0.0050,  0.0019,  ..., -0.0062, -0.0041, -0.0068],\n",
              "          ...,\n",
              "          [ 0.0019,  0.0133, -0.0070,  ..., -0.0095, -0.0084,  0.0024],\n",
              "          [ 0.0005,  0.0079,  0.0006,  ..., -0.0178,  0.0169,  0.0012],\n",
              "          [-0.0011, -0.0011, -0.0067,  ..., -0.0258,  0.0141, -0.0304]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 1.8597e-03, -8.2800e-03, -1.2971e-03,  ...,  1.3248e-03,\n",
              "            2.4709e-03, -1.7440e-03],\n",
              "          [-1.8773e-03, -1.7282e-03,  9.7364e-04,  ...,  1.3990e-02,\n",
              "           -3.9480e-03, -4.0151e-03],\n",
              "          [-4.5669e-03, -1.8381e-03,  8.8327e-03,  ...,  1.6353e-02,\n",
              "           -1.7770e-03,  1.8024e-02],\n",
              "          ...,\n",
              "          [-4.2013e-03, -3.9446e-02, -5.6402e-03,  ..., -2.3341e-02,\n",
              "           -7.9231e-03, -1.1263e-02],\n",
              "          [-2.7607e-03, -1.3130e-02,  1.6115e-02,  ...,  1.0270e-02,\n",
              "           -1.5026e-02,  1.6497e-02],\n",
              "          [ 5.4543e-04,  7.5761e-03, -9.7711e-03,  ...,  1.6605e-03,\n",
              "            5.3600e-03, -5.9753e-05]], dtype=torch.float64), 'final_loss': 0.008508342118745675, 'loss_breakdown': {'ot': 0.0019450775743573565,\n",
              "   'ortho': 3.9009354974687125,\n",
              "   'graph': 26.62329046919605}, 'best_iter': 880, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.828080229226361,\n",
              "   'accuracy_raw': 0.828080229226361,\n",
              "   'foscttm': 0.19275430141514985}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 0.20144948, -0.02378857, -0.04863276, ...,  0.02360538,\n",
              "           0.11557676, -0.09881091],\n",
              "         [-0.11741668,  0.08526179,  0.08962548, ..., -0.00191056,\n",
              "           0.03156329,  0.10308366],\n",
              "         [ 0.01556335,  0.00306338,  0.08851313, ...,  0.00406962,\n",
              "          -0.04684586,  0.18006523],\n",
              "         ...,\n",
              "         [ 0.00355327,  0.02437702,  0.04637601, ...,  0.00486812,\n",
              "          -0.07065571,  0.05498048],\n",
              "         [-0.1943119 ,  0.04106491,  0.05465909, ..., -0.06031389,\n",
              "           0.03315375,  0.10101284],\n",
              "         [-0.17022974,  0.06552574,  0.04565143, ..., -0.06200931,\n",
              "           0.02405298,  0.02240893]]), 'mapped_Y': array([[ 0.22371933, -0.05166176, -0.06810865, ...,  0.04015278,\n",
              "           0.12376535, -0.1411798 ],\n",
              "         [-0.2941718 ,  0.08387818,  0.00533658, ..., -0.01913603,\n",
              "           0.02409908, -0.01079007],\n",
              "         [ 0.03076962,  0.02155916,  0.03634528, ...,  0.07477908,\n",
              "          -0.08218039,  0.0138039 ],\n",
              "         ...,\n",
              "         [ 0.0106043 , -0.0151441 ,  0.08830331, ..., -0.10274508,\n",
              "          -0.03674389,  0.21622674],\n",
              "         [-0.2533519 ,  0.04618128,  0.03901708, ..., -0.0414514 ,\n",
              "           0.01922822,  0.02469128],\n",
              "         [-0.23686796,  0.0914836 ,  0.01814489, ..., -0.01882481,\n",
              "           0.0249708 ,  0.04712186]]), 'alpha': tensor([[ 0.0052, -0.0002,  0.0164,  ..., -0.0078, -0.0088,  0.0036],\n",
              "          [ 0.0138,  0.0113,  0.0120,  ..., -0.0149,  0.0135, -0.0190],\n",
              "          [ 0.0038, -0.0064,  0.0068,  ..., -0.0117,  0.0010,  0.0112],\n",
              "          ...,\n",
              "          [ 0.0118,  0.0168, -0.0006,  ..., -0.0183, -0.0003, -0.0037],\n",
              "          [ 0.0022,  0.0011,  0.0069,  ..., -0.0068,  0.0072,  0.0030],\n",
              "          [ 0.0016,  0.0038,  0.0056,  ..., -0.0044,  0.0183, -0.0213]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0009, -0.0054,  0.0025,  ..., -0.0027, -0.0035,  0.0007],\n",
              "          [-0.0040,  0.0006, -0.0024,  ...,  0.0077, -0.0062, -0.0158],\n",
              "          [-0.0021,  0.0048,  0.0078,  ...,  0.0119, -0.0051,  0.0043],\n",
              "          ...,\n",
              "          [-0.0020, -0.0180,  0.0018,  ..., -0.0571,  0.0006,  0.0179],\n",
              "          [ 0.0044, -0.0099,  0.0153,  ...,  0.0074, -0.0042,  0.0063],\n",
              "          [-0.0051,  0.0052, -0.0062,  ...,  0.0005,  0.0025, -0.0009]],\n",
              "         dtype=torch.float64), 'final_loss': 0.009048966159274772, 'loss_breakdown': {'ot': 0.0017462449489529807,\n",
              "   'ortho': 4.713956381319267,\n",
              "   'graph': 25.88764829002524}, 'best_iter': 705, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9555873925501432,\n",
              "   'accuracy_raw': 0.9555873925501432,\n",
              "   'foscttm': 0.1506218248527425}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[-0.20866582,  0.16343142,  0.32246205, ...,  0.00417728,\n",
              "          -0.04732432, -0.19412133],\n",
              "         [ 0.12389843,  0.03034395, -0.30006258, ..., -0.05806108,\n",
              "          -0.01303448,  0.05548043],\n",
              "         [ 0.05028971, -0.03552046, -0.24258963, ...,  0.03832265,\n",
              "          -0.03470315,  0.10957211],\n",
              "         ...,\n",
              "         [ 0.18897799,  0.11823917, -0.09747738, ...,  0.1250357 ,\n",
              "          -0.00639392,  0.1096732 ],\n",
              "         [-0.00212729, -0.12359089, -0.18533453, ...,  0.04622721,\n",
              "           0.00569611,  0.00343389],\n",
              "         [ 0.0646727 , -0.02355445, -0.15720655, ..., -0.14535209,\n",
              "           0.13038902, -0.03135404]]), 'mapped_Y': array([[ 0.0778452 ,  0.05904291, -0.19838537, ..., -0.09036864,\n",
              "          -0.03372383,  0.11464443],\n",
              "         [-0.20047488,  0.12939818,  0.30915618, ...,  0.06940086,\n",
              "          -0.06716129, -0.20302985],\n",
              "         [ 0.06083932,  0.0416418 , -0.0923673 , ..., -0.06625283,\n",
              "          -0.05518232,  0.11441023],\n",
              "         ...,\n",
              "         [ 0.07865328, -0.02635766, -0.23796819, ...,  0.02347141,\n",
              "           0.0830346 ,  0.10348976],\n",
              "         [-0.12806185,  0.14052713,  0.29161924, ...,  0.19234557,\n",
              "          -0.03522666, -0.13980427],\n",
              "         [-0.22829636,  0.06442679,  0.18387353, ..., -0.05798719,\n",
              "           0.0008879 , -0.14120731]]), 'alpha': tensor([[ 0.0018,  0.0002,  0.0090,  ..., -0.0041, -0.0085, -0.0047],\n",
              "          [ 0.0087, -0.0101,  0.0083,  ..., -0.0133,  0.0041, -0.0246],\n",
              "          [ 0.0007,  0.0046, -0.0088,  ..., -0.0015,  0.0057,  0.0010],\n",
              "          ...,\n",
              "          [ 0.0179,  0.0074,  0.0015,  ...,  0.0046, -0.0204, -0.0247],\n",
              "          [-0.0042, -0.0193, -0.0042,  ...,  0.0165, -0.0012,  0.0061],\n",
              "          [ 0.0154, -0.0047, -0.0201,  ..., -0.0073,  0.0155, -0.0258]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0033,  0.0003, -0.0032,  ..., -0.0133, -0.0023,  0.0058],\n",
              "          [-0.0008,  0.0031,  0.0071,  ...,  0.0022, -0.0125, -0.0016],\n",
              "          [-0.0024,  0.0101, -0.0085,  ..., -0.0021, -0.0198,  0.0096],\n",
              "          ...,\n",
              "          [ 0.0001,  0.0086, -0.0056,  ...,  0.0011,  0.0132,  0.0255],\n",
              "          [ 0.0136,  0.0159, -0.0012,  ...,  0.0328,  0.0008,  0.0102],\n",
              "          [-0.0125, -0.0036, -0.0018,  ..., -0.0144,  0.0053, -0.0011]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004890108478772638, 'loss_breakdown': {'ot': 0.0038648310483435076,\n",
              "   'ortho': 0.41838096030312066,\n",
              "   'graph': 60.68964701260096}, 'best_iter': 655, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.19866284622731614,\n",
              "   'accuracy_raw': 0.19866284622731614,\n",
              "   'foscttm': 0.5520895194255839}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[-0.15821302,  0.01316817,  0.15258428, ...,  0.09260005,\n",
              "           0.23282118, -0.21861018],\n",
              "         [ 0.10318421, -0.02274126, -0.07351736, ..., -0.200353  ,\n",
              "           0.01735187,  0.21733897],\n",
              "         [ 0.07189771, -0.05754219,  0.16794115, ..., -0.19029335,\n",
              "           0.04799433,  0.19720115],\n",
              "         ...,\n",
              "         [-0.02811956, -0.05133808,  0.07772835, ..., -0.13025609,\n",
              "          -0.03874637,  0.06128744],\n",
              "         [ 0.10539609,  0.03121051, -0.24624766, ...,  0.00160794,\n",
              "          -0.10465468,  0.15251915],\n",
              "         [ 0.20449223,  0.06833442, -0.1231519 , ..., -0.04827388,\n",
              "          -0.07501009,  0.14308316]]), 'mapped_Y': array([[-0.1422686 , -0.0232259 ,  0.18036822, ...,  0.07496109,\n",
              "           0.26250197, -0.27834647],\n",
              "         [ 0.06377264,  0.03171029, -0.32158334, ...,  0.10183205,\n",
              "          -0.25757744,  0.10481892],\n",
              "         [-0.03753616, -0.00543432,  0.0937573 , ..., -0.12985327,\n",
              "          -0.00177497,  0.04756688],\n",
              "         ...,\n",
              "         [ 0.09631323, -0.0864475 ,  0.16636713, ..., -0.14329819,\n",
              "           0.03639254,  0.20490607],\n",
              "         [ 0.05829344,  0.0495795 , -0.23751207, ...,  0.07294365,\n",
              "          -0.19852991,  0.12648362],\n",
              "         [ 0.10596343,  0.01182831, -0.29157536, ...,  0.04307959,\n",
              "          -0.17223488,  0.13756806]]), 'alpha': tensor([[ 0.0018, -0.0031,  0.0180,  ..., -0.0176,  0.0024,  0.0032],\n",
              "          [ 0.0125,  0.0197, -0.0074,  ..., -0.0421,  0.0408, -0.0075],\n",
              "          [ 0.0189, -0.0106,  0.0126,  ..., -0.0070, -0.0013,  0.0002],\n",
              "          ...,\n",
              "          [-0.0125,  0.0379, -0.0096,  ..., -0.0129,  0.0109,  0.0075],\n",
              "          [-0.0020,  0.0092, -0.0154,  ..., -0.0238,  0.0178,  0.0017],\n",
              "          [ 0.0121, -0.0095, -0.0257,  ..., -0.0418,  0.0348, -0.0154]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0021, -0.0083,  0.0015,  ..., -0.0018, -0.0018, -0.0087],\n",
              "          [ 0.0001,  0.0007,  0.0049,  ...,  0.0030, -0.0148, -0.0095],\n",
              "          [ 0.0181,  0.0099,  0.0206,  ...,  0.0140, -0.0086, -0.0009],\n",
              "          ...,\n",
              "          [ 0.0156, -0.0532,  0.0146,  ...,  0.0118,  0.0053,  0.0011],\n",
              "          [ 0.0018, -0.0055,  0.0243,  ..., -0.0062, -0.0015,  0.0035],\n",
              "          [-0.0018,  0.0025, -0.0101,  ...,  0.0064, -0.0103, -0.0015]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004447857030225301, 'loss_breakdown': {'ot': 0.0031654165681884714,\n",
              "   'ortho': 0.7735283126642577,\n",
              "   'graph': 50.89121493725719}, 'best_iter': 924, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9579751671442216,\n",
              "   'accuracy_raw': 0.9579751671442216,\n",
              "   'foscttm': 0.15131649165441993}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.22847676, -0.0500847 ,  0.12754868, ...,  0.14015682,\n",
              "           0.13518358, -0.20397233],\n",
              "         [-0.06246445,  0.03054162, -0.05246559, ..., -0.26689918,\n",
              "           0.07980798,  0.16318274],\n",
              "         [ 0.13631355, -0.00507768,  0.08298501, ..., -0.26822997,\n",
              "          -0.0223042 ,  0.18434642],\n",
              "         ...,\n",
              "         [ 0.00207119, -0.01605112,  0.07886596, ..., -0.1664508 ,\n",
              "          -0.02226172,  0.03272646],\n",
              "         [-0.24328308,  0.0471755 , -0.16623946, ..., -0.0437783 ,\n",
              "          -0.00407476,  0.13541886],\n",
              "         [-0.11615373,  0.11546695, -0.14336431, ..., -0.0624912 ,\n",
              "          -0.03904928,  0.18580017]]), 'mapped_Y': array([[ 0.29557106, -0.07908146,  0.10600669, ...,  0.15864374,\n",
              "           0.11928426, -0.2375887 ],\n",
              "         [-0.39352831,  0.04271748, -0.18017146, ...,  0.07034707,\n",
              "          -0.06302393,  0.08507707],\n",
              "         [ 0.02740754,  0.01829474,  0.11017338, ..., -0.13816351,\n",
              "          -0.00621299, -0.00645851],\n",
              "         ...,\n",
              "         [ 0.12497809, -0.0392341 ,  0.07994199, ..., -0.21480582,\n",
              "          -0.04117782,  0.23220474],\n",
              "         [-0.37001245,  0.0553634 , -0.05371146, ...,  0.04985586,\n",
              "          -0.04130072,  0.09285823],\n",
              "         [-0.28228756,  0.03729956, -0.18887893, ...,  0.00634595,\n",
              "          -0.02065745,  0.14165462]]), 'alpha': tensor([[ 5.3236e-03, -1.6180e-03,  1.7649e-02,  ..., -2.0588e-02,\n",
              "           -1.6504e-03, -3.1727e-03],\n",
              "          [ 1.3478e-02,  2.1063e-02, -9.2085e-03,  ..., -3.5422e-02,\n",
              "            4.4415e-02, -1.8484e-02],\n",
              "          [ 1.9000e-02, -1.2957e-02, -2.4261e-03,  ..., -1.7087e-02,\n",
              "           -2.2226e-02,  6.2580e-03],\n",
              "          ...,\n",
              "          [-1.0588e-02,  4.8527e-02,  1.0471e-02,  ..., -2.4299e-02,\n",
              "            4.7865e-02, -1.3775e-02],\n",
              "          [ 6.8016e-05,  8.1747e-03, -1.9763e-02,  ..., -1.5073e-02,\n",
              "            1.1410e-02,  1.8565e-04],\n",
              "          [ 8.2524e-03, -5.9569e-03, -2.4152e-02,  ..., -2.9149e-02,\n",
              "            1.9301e-02, -1.3843e-02]], dtype=torch.float64), 'beta': tensor([[ 3.1706e-03, -9.2312e-03, -1.0701e-03,  ...,  4.9987e-05,\n",
              "           -7.4244e-03, -2.2450e-03],\n",
              "          [-4.6071e-03,  1.4806e-03,  2.6271e-03,  ...,  6.0423e-03,\n",
              "           -1.3149e-02, -1.0612e-02],\n",
              "          [ 6.4837e-03,  1.1250e-02,  1.6453e-02,  ...,  1.4482e-02,\n",
              "           -5.8263e-03,  9.2398e-03],\n",
              "          ...,\n",
              "          [ 2.8969e-03, -4.7751e-02,  1.7637e-02,  ...,  2.1405e-02,\n",
              "           -7.9301e-03,  1.6601e-02],\n",
              "          [-1.3073e-03, -6.9182e-03,  4.0851e-02,  ..., -2.3188e-03,\n",
              "           -1.0300e-02,  1.1945e-03],\n",
              "          [-5.3487e-03,  1.2812e-03, -1.4318e-02,  ...,  7.9347e-03,\n",
              "           -3.3838e-03,  5.9269e-03]], dtype=torch.float64), 'final_loss': 0.004423854637037205, 'loss_breakdown': {'ot': 0.0030360616553695803,\n",
              "   'ortho': 0.892000812088026,\n",
              "   'graph': 49.579216957959844}, 'best_iter': 955, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9555873925501432,\n",
              "   'accuracy_raw': 0.9555873925501432,\n",
              "   'foscttm': 0.1508913902367158}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[-0.09176252,  0.13417843,  0.02168085, ...,  0.03903911,\n",
              "           0.10350716,  0.01159994],\n",
              "         [-0.01226267,  0.116599  , -0.09368487, ..., -0.04927521,\n",
              "           0.00462847,  0.03365105],\n",
              "         [-0.03548835,  0.30936676, -0.0003346 , ...,  0.04196456,\n",
              "          -0.02307297,  0.04138872],\n",
              "         ...,\n",
              "         [-0.02731463,  0.17117823,  0.10032486, ...,  0.19126645,\n",
              "          -0.06592676, -0.15971401],\n",
              "         [ 0.15902601, -0.19745799, -0.20519162, ..., -0.03245779,\n",
              "          -0.06625183,  0.09274955],\n",
              "         [ 0.03280203, -0.13895979, -0.19361794, ..., -0.12042485,\n",
              "          -0.06736683, -0.01766509]]), 'mapped_Y': array([[-0.01909216,  0.22551494,  0.0450907 , ...,  0.03654679,\n",
              "           0.04087629, -0.01548602],\n",
              "         [ 0.17324436, -0.3643995 , -0.13479744, ...,  0.06828531,\n",
              "          -0.05286097,  0.00739882],\n",
              "         [-0.08988026,  0.12397156,  0.03966803, ..., -0.09215483,\n",
              "           0.02097956,  0.03788616],\n",
              "         ...,\n",
              "         [-0.02690521,  0.25915857, -0.0228463 , ...,  0.08438407,\n",
              "           0.04696469, -0.01024011],\n",
              "         [ 0.14147278, -0.34198267,  0.00897289, ...,  0.18377213,\n",
              "          -0.00309339,  0.03452342],\n",
              "         [ 0.07243428, -0.27435907, -0.23555907, ..., -0.1060237 ,\n",
              "          -0.04323265,  0.03344137]]), 'alpha': tensor([[-6.3818e-03,  4.7534e-03,  1.3247e-02,  ...,  5.7568e-04,\n",
              "            1.5899e-02,  1.7353e-02],\n",
              "          [ 2.2186e-02,  2.2872e-02,  2.1121e-02,  ..., -4.0575e-02,\n",
              "            2.9842e-02,  1.2662e-02],\n",
              "          [ 1.5316e-03,  2.7687e-03, -5.0154e-03,  ...,  1.1448e-03,\n",
              "            1.2066e-02,  3.8385e-03],\n",
              "          ...,\n",
              "          [-3.5097e-03,  9.2606e-03, -2.0002e-03,  ...,  2.4487e-02,\n",
              "           -1.1389e-02, -6.5868e-03],\n",
              "          [ 1.6264e-02,  1.0109e-02, -6.0397e-03,  ..., -1.5458e-02,\n",
              "           -8.7287e-05,  7.2508e-03],\n",
              "          [ 1.4053e-02,  1.9759e-02, -3.0037e-02,  ..., -4.1336e-02,\n",
              "           -1.8392e-02, -3.8044e-02]], dtype=torch.float64), 'beta': tensor([[ 8.2555e-03, -2.3777e-04, -1.0312e-03,  ..., -6.5514e-05,\n",
              "            8.2832e-03, -7.3495e-04],\n",
              "          [ 7.2631e-03,  1.3119e-03,  6.4146e-03,  ...,  8.9579e-04,\n",
              "           -9.0724e-03, -2.9318e-03],\n",
              "          [-1.0717e-02,  1.9644e-02, -1.1996e-03,  ..., -1.2691e-02,\n",
              "           -1.4580e-02,  2.0837e-03],\n",
              "          ...,\n",
              "          [-1.9280e-02, -2.5397e-03, -1.1128e-02,  ...,  2.0997e-02,\n",
              "            4.8128e-03,  5.4188e-03],\n",
              "          [ 9.1753e-03,  1.6617e-02,  1.6001e-02,  ...,  1.7192e-02,\n",
              "            9.6921e-03,  2.0834e-03],\n",
              "          [-7.1237e-04, -8.5072e-03, -1.3727e-02,  ..., -1.0202e-02,\n",
              "           -1.4179e-02, -8.2024e-03]], dtype=torch.float64), 'final_loss': 0.004801277576682456, 'loss_breakdown': {'ot': 0.004381184726572963,\n",
              "   'ortho': 0.3480400512612566,\n",
              "   'graph': 72.05279884823615}, 'best_iter': 584, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.718720152817574,\n",
              "   'accuracy_raw': 0.718720152817574,\n",
              "   'foscttm': 0.22083608144067415}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.01218003, -0.01288242,  0.16177622, ...,  0.10062004,\n",
              "           0.22443824, -0.25534355],\n",
              "         [ 0.00588026, -0.00337013, -0.10134778, ..., -0.18645729,\n",
              "           0.05719743,  0.22867147],\n",
              "         [ 0.06658811, -0.07635522,  0.13565622, ..., -0.1818008 ,\n",
              "           0.08705722,  0.23159173],\n",
              "         ...,\n",
              "         [-0.05360778, -0.03583017,  0.0913606 , ..., -0.11891368,\n",
              "           0.0162875 ,  0.07042495],\n",
              "         [-0.02792193,  0.05474361, -0.25175577, ..., -0.0219117 ,\n",
              "          -0.13299973,  0.16681166],\n",
              "         [ 0.10089123,  0.09122986, -0.14558093, ..., -0.05426322,\n",
              "          -0.10050104,  0.17778495]]), 'mapped_Y': array([[ 0.05198147, -0.06011232,  0.1789416 , ...,  0.09761292,\n",
              "           0.2344729 , -0.30658115],\n",
              "         [-0.0949066 ,  0.07397111, -0.30911541, ...,  0.05098154,\n",
              "          -0.27983834,  0.10368091],\n",
              "         [-0.03342089,  0.00495144,  0.10251112, ..., -0.11286248,\n",
              "           0.05086792,  0.05219237],\n",
              "         ...,\n",
              "         [ 0.08202822, -0.11035188,  0.13364224, ..., -0.13674636,\n",
              "           0.05911355,  0.25172272],\n",
              "         [-0.07286587,  0.09935871, -0.22186942, ...,  0.04474968,\n",
              "          -0.22226898,  0.13506464],\n",
              "         [-0.04973303,  0.04900832, -0.28062528, ...,  0.01277509,\n",
              "          -0.18437119,  0.15584131]]), 'alpha': tensor([[ 0.0038, -0.0019,  0.0174,  ..., -0.0210,  0.0058,  0.0020],\n",
              "          [ 0.0129,  0.0230, -0.0160,  ..., -0.0335,  0.0480, -0.0125],\n",
              "          [ 0.0196, -0.0241,  0.0096,  ..., -0.0173, -0.0068,  0.0042],\n",
              "          ...,\n",
              "          [-0.0093,  0.0584, -0.0077,  ..., -0.0050,  0.0251, -0.0118],\n",
              "          [-0.0008,  0.0100, -0.0176,  ..., -0.0219,  0.0180,  0.0013],\n",
              "          [ 0.0140, -0.0039, -0.0281,  ..., -0.0373,  0.0301, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0036, -0.0085,  0.0014,  ..., -0.0051, -0.0046, -0.0059],\n",
              "          [ 0.0016,  0.0010,  0.0040,  ...,  0.0007, -0.0144, -0.0097],\n",
              "          [ 0.0144,  0.0110,  0.0170,  ...,  0.0136, -0.0036,  0.0087],\n",
              "          ...,\n",
              "          [ 0.0132, -0.0500,  0.0151,  ...,  0.0092, -0.0038,  0.0082],\n",
              "          [ 0.0027, -0.0026,  0.0276,  ..., -0.0050,  0.0012,  0.0079],\n",
              "          [-0.0035,  0.0029, -0.0088,  ...,  0.0065, -0.0096,  0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003985990031385569, 'loss_breakdown': {'ot': 0.003266397022125316,\n",
              "   'ortho': 0.6665152880301284,\n",
              "   'graph': 53.07772123012346}, 'best_iter': 929, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065903,\n",
              "   'accuracy_raw': 0.9570200573065903,\n",
              "   'foscttm': 0.15203031538693806}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.21984703, -0.02841732,  0.03858052, ...,  0.07765432,\n",
              "           0.32668293, -0.08555402],\n",
              "         [-0.08505639,  0.00909836, -0.09402541, ..., -0.23953589,\n",
              "          -0.09800277,  0.14310221],\n",
              "         [ 0.1189141 , -0.01539879,  0.03000713, ..., -0.26585275,\n",
              "          -0.10395719,  0.21389242],\n",
              "         ...,\n",
              "         [-0.00899312, -0.03042679,  0.09048303, ..., -0.16504731,\n",
              "          -0.05033928,  0.04419085],\n",
              "         [-0.23652351,  0.04532768, -0.14632593, ...,  0.01527725,\n",
              "          -0.16074181,  0.04608834],\n",
              "         [-0.12345405,  0.08842364, -0.11181844, ...,  0.00172591,\n",
              "          -0.184701  ,  0.07755448]]), 'mapped_Y': array([[ 0.28374899, -0.06544634,  0.02091055, ...,  0.08144759,\n",
              "           0.32359413, -0.12020503],\n",
              "         [-0.37381977,  0.04470596, -0.12932263, ...,  0.15284589,\n",
              "          -0.19242879, -0.02459728],\n",
              "         [ 0.01221492,  0.00152211,  0.10785818, ..., -0.14044562,\n",
              "           0.01422007,  0.02097367],\n",
              "         ...,\n",
              "         [ 0.12391319, -0.04457461,  0.03065973, ..., -0.2149744 ,\n",
              "          -0.12449807,  0.25280228],\n",
              "         [-0.35346572,  0.0628981 , -0.0332414 , ...,  0.15805878,\n",
              "          -0.12355186,  0.02218385],\n",
              "         [-0.28181495,  0.03110399, -0.13608268, ...,  0.05011909,\n",
              "          -0.17932898,  0.02774614]]), 'alpha': tensor([[ 5.7986e-03, -2.3735e-03,  1.5155e-02,  ..., -2.1011e-02,\n",
              "            6.2397e-04,  2.7053e-05],\n",
              "          [ 1.0862e-02,  1.5342e-02, -1.1271e-02,  ..., -4.2090e-02,\n",
              "            2.5384e-02, -1.7048e-02],\n",
              "          [ 1.7761e-02, -6.2548e-03, -2.9939e-03,  ..., -1.4795e-02,\n",
              "           -1.9532e-02,  5.0175e-03],\n",
              "          ...,\n",
              "          [-1.0558e-02,  4.2583e-02,  1.0071e-02,  ..., -1.7134e-02,\n",
              "            3.9638e-02, -1.3366e-02],\n",
              "          [-8.4135e-04,  8.7690e-03, -2.1992e-02,  ..., -1.6003e-02,\n",
              "            3.7883e-03, -7.3270e-04],\n",
              "          [ 5.5034e-03, -8.1915e-03, -3.1966e-02,  ..., -2.9575e-02,\n",
              "            7.1662e-03, -1.8648e-02]], dtype=torch.float64), 'beta': tensor([[ 3.4969e-03, -9.6724e-03,  2.7034e-03,  ..., -9.0572e-05,\n",
              "           -2.9508e-03, -2.9463e-03],\n",
              "          [-3.1298e-03,  6.0664e-04,  6.1913e-03,  ...,  8.0310e-03,\n",
              "           -7.2590e-03, -1.2593e-02],\n",
              "          [ 3.1565e-03,  8.3314e-03,  2.2099e-02,  ...,  1.9272e-02,\n",
              "            4.0733e-04,  5.1796e-03],\n",
              "          ...,\n",
              "          [ 7.0803e-03, -5.3419e-02,  1.3523e-02,  ...,  1.6038e-02,\n",
              "            8.0279e-03,  1.6727e-02],\n",
              "          [-6.3596e-04, -5.8538e-03,  3.7703e-02,  ...,  3.7558e-03,\n",
              "            7.5782e-04,  8.8740e-03],\n",
              "          [-4.7784e-03,  1.0200e-03, -1.0483e-02,  ...,  4.9943e-03,\n",
              "           -8.4016e-03, -3.0268e-03]], dtype=torch.float64), 'final_loss': 0.004306103582639219, 'loss_breakdown': {'ot': 0.0033659146866381754,\n",
              "   'ortho': 0.8869742242008327,\n",
              "   'graph': 53.21467180021143}, 'best_iter': 947, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065902,\n",
              "   'accuracy_raw': 0.9570200573065902,\n",
              "   'foscttm': 0.15137624303394698}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[-0.14582654,  0.1391885 , -0.0720575 , ..., -0.02129762,\n",
              "           0.0876595 ,  0.0272386 ],\n",
              "         [ 0.02866534,  0.00774457, -0.12884177, ..., -0.11514699,\n",
              "          -0.01674113,  0.04922391],\n",
              "         [-0.10663809,  0.16993629, -0.13898879, ..., -0.08883319,\n",
              "           0.06386119,  0.0857945 ],\n",
              "         ...,\n",
              "         [-0.15058222,  0.1667532 ,  0.04832057, ...,  0.0455581 ,\n",
              "           0.05297123, -0.10759996],\n",
              "         [ 0.23588079, -0.2176923 , -0.04871325, ...,  0.0382682 ,\n",
              "          -0.13808761,  0.02136873],\n",
              "         [ 0.15428498, -0.21749942, -0.01225954, ..., -0.06021215,\n",
              "          -0.1313088 , -0.01820634]]), 'mapped_Y': array([[-0.16240875,  0.20924118, -0.10060054, ..., -0.08707393,\n",
              "           0.06483956, -0.00807786],\n",
              "         [ 0.30774452, -0.22450081,  0.03306977, ...,  0.1888554 ,\n",
              "          -0.10150466, -0.11202711],\n",
              "         [-0.09094221,  0.06337898, -0.0227864 , ..., -0.10105356,\n",
              "          -0.02670444,  0.078226  ],\n",
              "         ...,\n",
              "         [-0.11391403,  0.16826797, -0.13482412, ...,  0.02164842,\n",
              "           0.12881487,  0.05253273],\n",
              "         [ 0.26180021, -0.10114685,  0.12198364, ...,  0.33921481,\n",
              "          -0.04902667, -0.0527101 ],\n",
              "         [ 0.20835557, -0.29527862, -0.06101347, ...,  0.02460533,\n",
              "          -0.15098285, -0.04200004]]), 'alpha': tensor([[-0.0025,  0.0100,  0.0090,  ..., -0.0078,  0.0039,  0.0209],\n",
              "          [ 0.0256,  0.0143,  0.0163,  ..., -0.0469, -0.0088,  0.0316],\n",
              "          [ 0.0015,  0.0022, -0.0105,  ..., -0.0038,  0.0094, -0.0003],\n",
              "          ...,\n",
              "          [-0.0183,  0.0217, -0.0014,  ...,  0.0154,  0.0092, -0.0075],\n",
              "          [ 0.0130,  0.0063, -0.0029,  ..., -0.0137, -0.0132,  0.0079],\n",
              "          [ 0.0161,  0.0037, -0.0123,  ..., -0.0446, -0.0180, -0.0207]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 1.2177e-03,  5.4502e-03, -5.5597e-04,  ..., -3.9725e-03,\n",
              "            1.5749e-03,  6.8978e-04],\n",
              "          [ 7.9616e-03,  8.3681e-03,  5.7347e-03,  ...,  1.6433e-03,\n",
              "           -7.1096e-03, -6.3686e-03],\n",
              "          [-1.1821e-02,  1.0561e-02, -4.3014e-03,  ..., -2.2402e-03,\n",
              "           -1.7502e-02,  5.4994e-05],\n",
              "          ...,\n",
              "          [-1.5085e-02, -3.9616e-03, -9.5538e-03,  ...,  3.1236e-02,\n",
              "            7.3385e-03,  8.6030e-03],\n",
              "          [ 7.2272e-03,  2.7161e-02,  1.4868e-02,  ...,  3.0018e-02,\n",
              "            1.1080e-04,  1.5289e-02],\n",
              "          [-5.2693e-04, -1.5569e-02, -7.4629e-03,  ..., -8.2930e-03,\n",
              "           -1.8978e-02, -1.2606e-02]], dtype=torch.float64), 'final_loss': 0.004625350758739602, 'loss_breakdown': {'ot': 0.004270821900445233,\n",
              "   'ortho': 0.34708806851165375,\n",
              "   'graph': 74.40789782714802}, 'best_iter': 588, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.7874880611270296,\n",
              "   'accuracy_raw': 0.7874880611270296,\n",
              "   'foscttm': 0.20954398294485815}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.00534337, -0.01114434,  0.16188133, ...,  0.09907231,\n",
              "           0.22133992, -0.25908428],\n",
              "         [ 0.00879436, -0.00400449, -0.10152138, ..., -0.18558793,\n",
              "           0.05937577,  0.23000074],\n",
              "         [ 0.06494516, -0.07827163,  0.13603309, ..., -0.1828474 ,\n",
              "           0.08994986,  0.2314345 ],\n",
              "         ...,\n",
              "         [-0.05375514, -0.0348176 ,  0.08970452, ..., -0.11932022,\n",
              "           0.01665956,  0.07078206],\n",
              "         [-0.02153751,  0.05380624, -0.25116278, ..., -0.0189279 ,\n",
              "          -0.13113497,  0.16930497],\n",
              "         [ 0.10544146,  0.0902087 , -0.14362128, ..., -0.05291406,\n",
              "          -0.09763265,  0.18014534]]), 'mapped_Y': array([[ 0.04396651, -0.05819344,  0.17962012, ...,  0.09548421,\n",
              "           0.23432852, -0.31101005],\n",
              "         [-0.08591372,  0.0731698 , -0.30905771, ...,  0.05420324,\n",
              "          -0.28194714,  0.1083246 ],\n",
              "         [-0.03406442,  0.00511229,  0.10173387, ..., -0.11308359,\n",
              "           0.05149892,  0.05176868],\n",
              "         ...,\n",
              "         [ 0.08101204, -0.1128702 ,  0.13411561, ..., -0.13745421,\n",
              "           0.06222965,  0.25194302],\n",
              "         [-0.06550268,  0.09935679, -0.22089972, ...,  0.04727036,\n",
              "          -0.22350481,  0.1394964 ],\n",
              "         [-0.04259811,  0.04808145, -0.28033831, ...,  0.01520596,\n",
              "          -0.18575078,  0.15891648]]), 'alpha': tensor([[ 0.0038, -0.0019,  0.0176,  ..., -0.0209,  0.0058,  0.0020],\n",
              "          [ 0.0131,  0.0232, -0.0162,  ..., -0.0333,  0.0478, -0.0126],\n",
              "          [ 0.0195, -0.0255,  0.0099,  ..., -0.0176, -0.0067,  0.0042],\n",
              "          ...,\n",
              "          [-0.0090,  0.0606, -0.0083,  ..., -0.0045,  0.0250, -0.0120],\n",
              "          [-0.0007,  0.0103, -0.0178,  ..., -0.0217,  0.0179,  0.0012],\n",
              "          [ 0.0142, -0.0034, -0.0280,  ..., -0.0371,  0.0303, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0037, -0.0085,  0.0015,  ..., -0.0051, -0.0046, -0.0058],\n",
              "          [ 0.0018,  0.0010,  0.0041,  ...,  0.0008, -0.0144, -0.0095],\n",
              "          [ 0.0146,  0.0107,  0.0172,  ...,  0.0139, -0.0035,  0.0084],\n",
              "          ...,\n",
              "          [ 0.0134, -0.0504,  0.0155,  ...,  0.0093, -0.0036,  0.0082],\n",
              "          [ 0.0027, -0.0026,  0.0277,  ..., -0.0049,  0.0013,  0.0079],\n",
              "          [-0.0034,  0.0029, -0.0088,  ...,  0.0065, -0.0097,  0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003939969831868576, 'loss_breakdown': {'ot': 0.0032809458752675984,\n",
              "   'ortho': 0.6536969995839013,\n",
              "   'graph': 53.269570170763615}, 'best_iter': 932, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065903,\n",
              "   'accuracy_raw': 0.9570200573065903,\n",
              "   'foscttm': 0.15214297638497767}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[-0.08023488, -0.02574555,  0.10185766, ...,  0.07331466,\n",
              "           0.35592786, -0.10678085],\n",
              "         [ 0.06298459, -0.01740854, -0.12466853, ..., -0.26927691,\n",
              "          -0.105817  ,  0.1150663 ],\n",
              "         [ 0.09529184, -0.02519532,  0.08214664, ..., -0.3086844 ,\n",
              "           0.00067058,  0.15826809],\n",
              "         ...,\n",
              "         [-0.01762972, -0.03049303,  0.08115233, ..., -0.15110379,\n",
              "          -0.0585594 ,  0.00307048],\n",
              "         [ 0.01747373,  0.02766079, -0.2057337 , ...,  0.01670326,\n",
              "          -0.2269756 ,  0.08647254],\n",
              "         [ 0.10225711,  0.07066691, -0.16546975, ..., -0.00200048,\n",
              "          -0.18498374,  0.08962084]]), 'mapped_Y': array([[-0.05680747, -0.04895205,  0.12190812, ...,  0.07466961,\n",
              "           0.40636732, -0.15594232],\n",
              "         [-0.02848608,  0.01437455, -0.2649387 , ...,  0.16248261,\n",
              "          -0.34556755,  0.0390163 ],\n",
              "         [-0.04384248, -0.01085627,  0.1026278 , ..., -0.14074819,\n",
              "          -0.01048635, -0.00445986],\n",
              "         ...,\n",
              "         [ 0.12514297, -0.03764534,  0.08429145, ..., -0.261053  ,\n",
              "          -0.00793857,  0.19348995],\n",
              "         [-0.03009198,  0.02640466, -0.17295212, ...,  0.1782865 ,\n",
              "          -0.30871553,  0.09394532],\n",
              "         [ 0.00169907,  0.01008168, -0.23982763, ...,  0.05049521,\n",
              "          -0.26658694,  0.06943743]]), 'alpha': tensor([[ 0.0049, -0.0041,  0.0154,  ..., -0.0227, -0.0004, -0.0015],\n",
              "          [ 0.0138,  0.0141, -0.0132,  ..., -0.0439,  0.0227, -0.0223],\n",
              "          [ 0.0199, -0.0113,  0.0015,  ..., -0.0211, -0.0073,  0.0029],\n",
              "          ...,\n",
              "          [-0.0126,  0.0444,  0.0026,  ..., -0.0013,  0.0163, -0.0148],\n",
              "          [-0.0002,  0.0105, -0.0173,  ..., -0.0153,  0.0050, -0.0009],\n",
              "          [ 0.0103, -0.0072, -0.0314,  ..., -0.0291,  0.0094, -0.0199]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0035, -0.0094,  0.0031,  ..., -0.0005, -0.0012, -0.0047],\n",
              "          [ 0.0002, -0.0002,  0.0031,  ...,  0.0063, -0.0108, -0.0128],\n",
              "          [ 0.0076,  0.0068,  0.0164,  ...,  0.0127, -0.0044,  0.0026],\n",
              "          ...,\n",
              "          [ 0.0132, -0.0503,  0.0120,  ...,  0.0117,  0.0098,  0.0110],\n",
              "          [ 0.0022, -0.0070,  0.0344,  ...,  0.0046, -0.0096,  0.0096],\n",
              "          [-0.0034,  0.0014, -0.0118,  ...,  0.0050, -0.0059, -0.0029]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0041812513654202075, 'loss_breakdown': {'ot': 0.0033176769312503606,\n",
              "   'ortho': 0.8581889319592769,\n",
              "   'graph': 53.855022105704116}, 'best_iter': 941, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9584527220630372,\n",
              "   'accuracy_raw': 0.9584527220630372,\n",
              "   'foscttm': 0.15105559250106504}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[-0.16417657,  0.14218078, -0.01855154, ..., -0.02082507,\n",
              "           0.08275012, -0.00211923],\n",
              "         [ 0.00058363,  0.02381958, -0.13416458, ..., -0.10671171,\n",
              "          -0.00302414,  0.03691979],\n",
              "         [-0.14080952,  0.1846456 , -0.10557153, ..., -0.10202345,\n",
              "           0.06482828,  0.06959061],\n",
              "         ...,\n",
              "         [-0.14775166,  0.1435518 ,  0.09113591, ...,  0.04431002,\n",
              "           0.04266529, -0.12000286],\n",
              "         [ 0.24057867, -0.21021455, -0.12524155, ...,  0.0460538 ,\n",
              "          -0.12466786,  0.04779546],\n",
              "         [ 0.15976268, -0.22867302, -0.0722782 , ..., -0.06190279,\n",
              "          -0.0921932 , -0.01024161]]), 'mapped_Y': array([[-0.17804157,  0.21209684, -0.04115743, ..., -0.08702622,\n",
              "           0.05849435, -0.04585263],\n",
              "         [ 0.30919296, -0.21368048, -0.04154351, ...,  0.22766647,\n",
              "          -0.08686524, -0.07389907],\n",
              "         [-0.09459356,  0.055863  , -0.01095479, ..., -0.11032854,\n",
              "          -0.02220503,  0.06726557],\n",
              "         ...,\n",
              "         [-0.15927628,  0.18535188, -0.09333263, ...,  0.00769276,\n",
              "           0.12706326,  0.03238509],\n",
              "         [ 0.28239612, -0.09544707,  0.07121426, ...,  0.36960988,\n",
              "          -0.05081758, -0.01688011],\n",
              "         [ 0.20203891, -0.28352546, -0.13117319, ...,  0.03009503,\n",
              "          -0.12137653, -0.01711945]]), 'alpha': tensor([[-0.0017,  0.0093,  0.0094,  ..., -0.0069,  0.0010,  0.0199],\n",
              "          [ 0.0248,  0.0151,  0.0129,  ..., -0.0442, -0.0081,  0.0275],\n",
              "          [ 0.0009,  0.0038, -0.0092,  ..., -0.0039,  0.0093, -0.0002],\n",
              "          ...,\n",
              "          [-0.0151,  0.0151,  0.0035,  ...,  0.0128,  0.0037, -0.0120],\n",
              "          [ 0.0133,  0.0059, -0.0048,  ..., -0.0138, -0.0130,  0.0076],\n",
              "          [ 0.0153,  0.0017, -0.0163,  ..., -0.0430, -0.0152, -0.0245]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0017,  0.0055, -0.0002,  ..., -0.0037,  0.0015, -0.0002],\n",
              "          [ 0.0074,  0.0086,  0.0043,  ...,  0.0043, -0.0075, -0.0064],\n",
              "          [-0.0106,  0.0124, -0.0056,  ..., -0.0040, -0.0192,  0.0012],\n",
              "          ...,\n",
              "          [-0.0183, -0.0051, -0.0066,  ...,  0.0293,  0.0065,  0.0083],\n",
              "          [ 0.0100,  0.0300,  0.0143,  ...,  0.0318, -0.0021,  0.0151],\n",
              "          [-0.0030, -0.0166, -0.0091,  ..., -0.0085, -0.0176, -0.0132]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0047186547256221545, 'loss_breakdown': {'ot': 0.004350556247558694,\n",
              "   'ortho': 0.3673454118013586,\n",
              "   'graph': 75.30662621020038}, 'best_iter': 571, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.7788920725883477,\n",
              "   'accuracy_raw': 0.7788920725883477,\n",
              "   'foscttm': 0.21019440635864142}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.00216754, -0.00971746,  0.16094702, ...,  0.09937866,\n",
              "           0.22249102, -0.26014456],\n",
              "         [ 0.01024908, -0.00487838, -0.10076776, ..., -0.18575203,\n",
              "           0.05888276,  0.23059933],\n",
              "         [ 0.06451681, -0.07888663,  0.13689581, ..., -0.1832817 ,\n",
              "           0.09063728,  0.23105278],\n",
              "         ...,\n",
              "         [-0.05369672, -0.03510398,  0.08964553, ..., -0.11984538,\n",
              "           0.0162696 ,  0.07080284],\n",
              "         [-0.01868622,  0.05300878, -0.25069607, ..., -0.01848177,\n",
              "          -0.13241031,  0.1703165 ],\n",
              "         [ 0.1075587 ,  0.08944112, -0.14241592, ..., -0.05297758,\n",
              "          -0.09803363,  0.18086115]]), 'mapped_Y': array([[ 0.04027558, -0.05643732,  0.17866586, ...,  0.09601095,\n",
              "           0.23436479, -0.31234737],\n",
              "         [-0.08191258,  0.07223884, -0.30843785, ...,  0.05430418,\n",
              "          -0.28195447,  0.11026913],\n",
              "         [-0.03430957,  0.00494666,  0.10158368, ..., -0.11322264,\n",
              "           0.05147621,  0.0516049 ],\n",
              "         ...,\n",
              "         [ 0.08072401, -0.11406054,  0.13502355, ..., -0.13796919,\n",
              "           0.0630185 ,  0.25157336],\n",
              "         [-0.06205221,  0.09883265, -0.22021543, ...,  0.04735214,\n",
              "          -0.223221  ,  0.14146239],\n",
              "         [-0.03942214,  0.04714971, -0.27966723, ...,  0.01527599,\n",
              "          -0.18582833,  0.16017309]]), 'alpha': tensor([[ 0.0038, -0.0019,  0.0176,  ..., -0.0208,  0.0058,  0.0019],\n",
              "          [ 0.0132,  0.0232, -0.0162,  ..., -0.0333,  0.0478, -0.0126],\n",
              "          [ 0.0195, -0.0256,  0.0100,  ..., -0.0176, -0.0066,  0.0042],\n",
              "          ...,\n",
              "          [-0.0090,  0.0608, -0.0085,  ..., -0.0045,  0.0248, -0.0120],\n",
              "          [-0.0007,  0.0103, -0.0178,  ..., -0.0217,  0.0178,  0.0012],\n",
              "          [ 0.0142, -0.0034, -0.0279,  ..., -0.0371,  0.0303, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0037, -0.0085,  0.0015,  ..., -0.0051, -0.0046, -0.0058],\n",
              "          [ 0.0019,  0.0010,  0.0041,  ...,  0.0008, -0.0143, -0.0095],\n",
              "          [ 0.0146,  0.0107,  0.0172,  ...,  0.0139, -0.0033,  0.0084],\n",
              "          ...,\n",
              "          [ 0.0135, -0.0504,  0.0155,  ...,  0.0093, -0.0035,  0.0082],\n",
              "          [ 0.0027, -0.0026,  0.0277,  ..., -0.0049,  0.0014,  0.0079],\n",
              "          [-0.0034,  0.0029, -0.0087,  ...,  0.0066, -0.0098,  0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003934803149900844, 'loss_breakdown': {'ot': 0.003280798694890467,\n",
              "   'ortho': 0.6534715129674039,\n",
              "   'graph': 53.294204297341984}, 'best_iter': 932, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065903,\n",
              "   'accuracy_raw': 0.9570200573065903,\n",
              "   'foscttm': 0.1521105920495088}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.07134933, -0.03142097, -0.12450511, ...,  0.02159739,\n",
              "           0.13215612, -0.10413529],\n",
              "         [-0.02791859,  0.01299618, -0.02637497, ..., -0.20612598,\n",
              "           0.04206703,  0.14127951],\n",
              "         [ 0.07915154,  0.05840755,  0.02887138, ..., -0.24063567,\n",
              "           0.06028877,  0.20745533],\n",
              "         ...,\n",
              "         [-0.01360092, -0.01329102,  0.09378947, ..., -0.13485624,\n",
              "           0.06270578,  0.06001437],\n",
              "         [-0.0907309 , -0.01577685, -0.01688269, ...,  0.02685944,\n",
              "          -0.0682515 ,  0.0449937 ],\n",
              "         [-0.03672468,  0.02311376, -0.03492318, ..., -0.0602708 ,\n",
              "          -0.06542615,  0.10927534]]), 'mapped_Y': array([[ 0.1087566 , -0.0158491 , -0.15042091, ...,  0.05315685,\n",
              "           0.12440481, -0.11849459],\n",
              "         [-0.1731945 , -0.08264042,  0.00458996, ...,  0.11586951,\n",
              "          -0.27359902,  0.02952711],\n",
              "         [-0.00734271,  0.01204538,  0.08055379, ..., -0.12209421,\n",
              "           0.02206344,  0.01846864],\n",
              "         ...,\n",
              "         [ 0.082341  ,  0.0363145 ,  0.04439574, ..., -0.20946889,\n",
              "           0.09029236,  0.23526945],\n",
              "         [-0.14341179, -0.07115163,  0.10190093, ...,  0.12925009,\n",
              "          -0.23275125,  0.02420856],\n",
              "         [-0.16261121, -0.04484086, -0.00395934, ...,  0.07906791,\n",
              "          -0.13419864,  0.04361122]]), 'alpha': tensor([[ 0.0080, -0.0081,  0.0171,  ..., -0.0328,  0.0047, -0.0027],\n",
              "          [ 0.0154,  0.0137, -0.0059,  ..., -0.0412,  0.0457, -0.0238],\n",
              "          [ 0.0234, -0.0064, -0.0039,  ..., -0.0210, -0.0258,  0.0147],\n",
              "          ...,\n",
              "          [-0.0158,  0.0318,  0.0100,  ..., -0.0054,  0.0335, -0.0153],\n",
              "          [-0.0030,  0.0039, -0.0376,  ..., -0.0193,  0.0125, -0.0092],\n",
              "          [ 0.0027, -0.0178, -0.0321,  ..., -0.0511,  0.0185, -0.0260]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0043, -0.0082,  0.0079,  ..., -0.0016, -0.0023,  0.0003],\n",
              "          [ 0.0025, -0.0016,  0.0032,  ..., -0.0036, -0.0169, -0.0017],\n",
              "          [ 0.0197,  0.0048,  0.0342,  ...,  0.0176, -0.0199,  0.0184],\n",
              "          ...,\n",
              "          [ 0.0109, -0.0640,  0.0090,  ...,  0.0018,  0.0103,  0.0076],\n",
              "          [ 0.0056, -0.0064,  0.0401,  ..., -0.0067,  0.0012,  0.0066],\n",
              "          [-0.0075,  0.0007, -0.0088,  ...,  0.0175, -0.0059, -0.0047]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0025451572757359707, 'loss_breakdown': {'ot': 0.0023576431224919077,\n",
              "   'ortho': 0.18705466704489487,\n",
              "   'graph': 45.948619916819816}, 'best_iter': 2049, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9603629417383,\n",
              "   'accuracy_raw': 0.9603629417383,\n",
              "   'foscttm': 0.15507353068621038}}}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "42e83761",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "def plot_lambda_grid(df, metric_name=\"accuracy\", title=None):\n",
        "    \"\"\"\n",
        "    Scatter plot of lambda_topo vs lambda_reg with color = metric.\n",
        "    x/y ticks are shown in 1eXX style (e.g. 1e-3, 1e-4).\n",
        "    \"\"\"\n",
        "    x = df[\"lambda_topo\"].values\n",
        "    y = df[\"lambda_reg\"].values\n",
        "    m = df[metric_name].values\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "    sc = ax.scatter(\n",
        "        x, y,\n",
        "        c=m,\n",
        "        s=80,\n",
        "        cmap=\"viridis\",\n",
        "        edgecolors=\"k\"\n",
        "    )\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    # Use unique lambda values as ticks\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    # Formatter: 1e-3, 1e-4, ...\n",
        "    def exp_notation(val, pos):\n",
        "        if val == 0:\n",
        "            return \"0\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(metric_name)\n",
        "\n",
        "    if title is None:\n",
        "        unique_p = df[\"p\"].unique()\n",
        "        unique_k = df[\"k\"].unique()\n",
        "        unique_reach = df[\"reach\"].unique()\n",
        "        title = r\"Grid over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(unique_p) == 1 and len(unique_k) == 1 and len(unique_reach) == 1:\n",
        "            title += f\" (p={unique_p[0]}, k={unique_k[0]}, reach={unique_reach[0]})\"\n",
        "\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "df = extract_lambda_grid_df(results, p=8, k=5, reach=5.0, metric_name=\"accuracy\")\n",
        "plot_lambda_grid(df, metric_name=\"accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sTsh7-Q6STJm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTsh7-Q6STJm",
        "outputId": "852a246c-9e51-45fc-ccc0-067395dbc541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ranked by accuracy (desc) ===\n",
            "    p  k   lambda_topo    lambda_reg  reach  final_loss  accuracy  \\\n",
            "0   8  5  1.000000e-01  1.000000e-07    5.0    0.003150    0.9974   \n",
            "1   8  5  1.000000e-01  1.000000e-05    1.0    0.009318    0.9970   \n",
            "2   8  5  1.000000e-01  1.000000e-05    5.0    0.009353    0.9968   \n",
            "3   8  5  1.000000e-01  1.000000e-07    1.0    0.000963    0.9968   \n",
            "4   8  5  1.000000e-03  1.000000e-07    0.1    0.000291    0.9960   \n",
            "5   8  5  1.000000e-01  1.000000e-05    0.1    0.006542    0.9958   \n",
            "6   8  5  1.000000e-03  1.000000e-05    0.1    0.003443    0.9936   \n",
            "7   8  5  1.000000e-01  1.000000e-07    0.1    0.003630    0.9882   \n",
            "8   8  5  1.000000e-07  1.000000e-05    0.1    0.000002    0.8018   \n",
            "9   8  5  1.000000e-07  1.000000e-05    1.0    0.000002    0.7136   \n",
            "10  8  5  1.000000e-03  1.000000e-07    5.0    0.002004    0.6984   \n",
            "11  8  5  1.000000e-07  1.000000e-05    5.0    0.000002    0.6762   \n",
            "12  8  5  1.000000e-07  1.000000e-07    5.0    0.000055    0.5602   \n",
            "13  8  5  1.000000e-07  1.000000e-07    1.0    0.000022    0.5368   \n",
            "14  8  5  1.000000e-05  1.000000e-07    1.0    0.000156    0.5358   \n",
            "15  8  5  1.000000e-07  1.000000e-03    1.0    0.000008    0.5322   \n",
            "16  8  5  1.000000e-07  1.000000e-03    5.0    0.000008    0.5290   \n",
            "17  8  5  1.000000e-05  1.000000e-03    5.0    0.000166    0.5284   \n",
            "18  8  5  1.000000e-05  1.000000e-07    5.0    0.000161    0.5284   \n",
            "19  8  5  1.000000e-01  1.000000e-03    0.1    0.020400    0.5228   \n",
            "20  8  5  1.000000e-01  1.000000e-03    1.0    0.020926    0.5210   \n",
            "21  8  5  1.000000e-01  1.000000e-03    5.0    0.020944    0.5102   \n",
            "22  8  5  1.000000e-03  1.000000e-05    5.0    0.004135    0.4952   \n",
            "23  8  5  1.000000e-05  1.000000e-03    1.0    0.000167    0.4928   \n",
            "24  8  5  1.000000e-05  1.000000e-07    0.1    0.000149    0.4916   \n",
            "25  8  5  1.000000e-07  1.000000e-07    0.1    0.000014    0.4398   \n",
            "26  8  5  1.000000e-03  1.000000e-05    1.0    0.003741    0.4338   \n",
            "27  8  5  1.000000e-05  1.000000e-05    5.0    0.000161    0.4024   \n",
            "28  8  5  1.000000e-03  1.000000e-07    1.0    0.002258    0.3978   \n",
            "29  8  5  1.000000e-03  1.000000e-03    5.0    0.016019    0.3970   \n",
            "30  8  5  1.000000e-03  1.000000e-03    1.0    0.016019    0.3968   \n",
            "31  8  5  1.000000e-05  1.000000e-05    1.0    0.000161    0.3874   \n",
            "32  8  5  1.000000e-03  1.000000e-03    0.1    0.016019    0.3822   \n",
            "33  8  5  1.000000e-05  1.000000e-03    0.1    0.000176    0.3692   \n",
            "34  8  5  1.000000e-05  1.000000e-05    0.1    0.000160    0.3680   \n",
            "35  8  5  1.000000e-07  1.000000e-03    0.1    0.000018    0.3664   \n",
            "36  8  5  1.000000e-03  1.000000e-01    0.1    0.019094    0.3652   \n",
            "37  8  5  1.000000e-03  1.000000e-01    5.0    0.019006    0.3568   \n",
            "38  8  5  1.000000e-01  1.000000e-01    5.0    1.601807    0.3396   \n",
            "39  8  5  1.000000e-01  1.000000e-01    1.0    1.601806    0.3392   \n",
            "40  8  5  1.000000e-01  1.000000e-01    0.1    1.601875    0.3368   \n",
            "41  8  5  1.000000e-05  1.000000e-01    5.0    0.001966    0.3352   \n",
            "42  8  5  1.000000e-07  1.000000e-01    5.0    0.001807    0.3336   \n",
            "43  8  5  1.000000e-03  1.000000e-01    1.0    0.019043    0.3278   \n",
            "44  8  5  1.000000e-07  1.000000e-01    1.0    0.001798    0.3138   \n",
            "45  8  5  1.000000e-05  1.000000e-01    1.0    0.001956    0.3126   \n",
            "46  8  5  1.000000e-07  1.000000e-01    0.1    0.001862    0.3084   \n",
            "47  8  5  1.000000e-05  1.000000e-01    0.1    0.002020    0.3080   \n",
            "\n",
            "         foscttm  \n",
            "0   4.230320e-03  \n",
            "1   5.974396e-02  \n",
            "2   6.096432e-02  \n",
            "3   3.156000e-05  \n",
            "4   8.000000e-08  \n",
            "5   8.665920e-02  \n",
            "6   3.438470e-02  \n",
            "7   8.981906e-02  \n",
            "8   2.862778e-01  \n",
            "9   3.324302e-01  \n",
            "10  1.563793e-01  \n",
            "11  3.127241e-01  \n",
            "12  1.819590e-01  \n",
            "13  1.973158e-01  \n",
            "14  2.091974e-01  \n",
            "15  2.665813e-01  \n",
            "16  2.661593e-01  \n",
            "17  2.663012e-01  \n",
            "18  1.855068e-01  \n",
            "19  3.033865e-01  \n",
            "20  2.353282e-01  \n",
            "21  2.328357e-01  \n",
            "22  2.143143e-01  \n",
            "23  2.713245e-01  \n",
            "24  1.513941e-01  \n",
            "25  1.898761e-01  \n",
            "26  2.587915e-01  \n",
            "27  4.447222e-01  \n",
            "28  1.426939e-01  \n",
            "29  3.950044e-01  \n",
            "30  3.960092e-01  \n",
            "31  4.440523e-01  \n",
            "32  3.980030e-01  \n",
            "33  2.896595e-01  \n",
            "34  4.289328e-01  \n",
            "35  2.972939e-01  \n",
            "36  3.497662e-01  \n",
            "37  3.474802e-01  \n",
            "38  4.077379e-01  \n",
            "39  4.077489e-01  \n",
            "40  4.089647e-01  \n",
            "41  2.975718e-01  \n",
            "42  2.978697e-01  \n",
            "43  3.628017e-01  \n",
            "44  3.089503e-01  \n",
            "45  3.083399e-01  \n",
            "46  3.104821e-01  \n",
            "47  3.103745e-01  \n",
            "\n",
            "=== Ranked by final loss (asc) ===\n",
            "    p  k   lambda_topo    lambda_reg  reach  final_loss  accuracy  \\\n",
            "0   8  5  1.000000e-07  1.000000e-05    0.1    0.000002    0.8018   \n",
            "1   8  5  1.000000e-07  1.000000e-05    1.0    0.000002    0.7136   \n",
            "2   8  5  1.000000e-07  1.000000e-05    5.0    0.000002    0.6762   \n",
            "3   8  5  1.000000e-07  1.000000e-03    5.0    0.000008    0.5290   \n",
            "4   8  5  1.000000e-07  1.000000e-03    1.0    0.000008    0.5322   \n",
            "5   8  5  1.000000e-07  1.000000e-07    0.1    0.000014    0.4398   \n",
            "6   8  5  1.000000e-07  1.000000e-03    0.1    0.000018    0.3664   \n",
            "7   8  5  1.000000e-07  1.000000e-07    1.0    0.000022    0.5368   \n",
            "8   8  5  1.000000e-07  1.000000e-07    5.0    0.000055    0.5602   \n",
            "9   8  5  1.000000e-05  1.000000e-07    0.1    0.000149    0.4916   \n",
            "10  8  5  1.000000e-05  1.000000e-07    1.0    0.000156    0.5358   \n",
            "11  8  5  1.000000e-05  1.000000e-05    0.1    0.000160    0.3680   \n",
            "12  8  5  1.000000e-05  1.000000e-05    5.0    0.000161    0.4024   \n",
            "13  8  5  1.000000e-05  1.000000e-05    1.0    0.000161    0.3874   \n",
            "14  8  5  1.000000e-05  1.000000e-07    5.0    0.000161    0.5284   \n",
            "15  8  5  1.000000e-05  1.000000e-03    5.0    0.000166    0.5284   \n",
            "16  8  5  1.000000e-05  1.000000e-03    1.0    0.000167    0.4928   \n",
            "17  8  5  1.000000e-05  1.000000e-03    0.1    0.000176    0.3692   \n",
            "18  8  5  1.000000e-03  1.000000e-07    0.1    0.000291    0.9960   \n",
            "19  8  5  1.000000e-01  1.000000e-07    1.0    0.000963    0.9968   \n",
            "20  8  5  1.000000e-07  1.000000e-01    1.0    0.001798    0.3138   \n",
            "21  8  5  1.000000e-07  1.000000e-01    5.0    0.001807    0.3336   \n",
            "22  8  5  1.000000e-07  1.000000e-01    0.1    0.001862    0.3084   \n",
            "23  8  5  1.000000e-05  1.000000e-01    1.0    0.001956    0.3126   \n",
            "24  8  5  1.000000e-05  1.000000e-01    5.0    0.001966    0.3352   \n",
            "25  8  5  1.000000e-03  1.000000e-07    5.0    0.002004    0.6984   \n",
            "26  8  5  1.000000e-05  1.000000e-01    0.1    0.002020    0.3080   \n",
            "27  8  5  1.000000e-03  1.000000e-07    1.0    0.002258    0.3978   \n",
            "28  8  5  1.000000e-01  1.000000e-07    5.0    0.003150    0.9974   \n",
            "29  8  5  1.000000e-03  1.000000e-05    0.1    0.003443    0.9936   \n",
            "30  8  5  1.000000e-01  1.000000e-07    0.1    0.003630    0.9882   \n",
            "31  8  5  1.000000e-03  1.000000e-05    1.0    0.003741    0.4338   \n",
            "32  8  5  1.000000e-03  1.000000e-05    5.0    0.004135    0.4952   \n",
            "33  8  5  1.000000e-01  1.000000e-05    0.1    0.006542    0.9958   \n",
            "34  8  5  1.000000e-01  1.000000e-05    1.0    0.009318    0.9970   \n",
            "35  8  5  1.000000e-01  1.000000e-05    5.0    0.009353    0.9968   \n",
            "36  8  5  1.000000e-03  1.000000e-03    1.0    0.016019    0.3968   \n",
            "37  8  5  1.000000e-03  1.000000e-03    0.1    0.016019    0.3822   \n",
            "38  8  5  1.000000e-03  1.000000e-03    5.0    0.016019    0.3970   \n",
            "39  8  5  1.000000e-03  1.000000e-01    5.0    0.019006    0.3568   \n",
            "40  8  5  1.000000e-03  1.000000e-01    1.0    0.019043    0.3278   \n",
            "41  8  5  1.000000e-03  1.000000e-01    0.1    0.019094    0.3652   \n",
            "42  8  5  1.000000e-01  1.000000e-03    0.1    0.020400    0.5228   \n",
            "43  8  5  1.000000e-01  1.000000e-03    1.0    0.020926    0.5210   \n",
            "44  8  5  1.000000e-01  1.000000e-03    5.0    0.020944    0.5102   \n",
            "45  8  5  1.000000e-01  1.000000e-01    1.0    1.601806    0.3392   \n",
            "46  8  5  1.000000e-01  1.000000e-01    5.0    1.601807    0.3396   \n",
            "47  8  5  1.000000e-01  1.000000e-01    0.1    1.601875    0.3368   \n",
            "\n",
            "         foscttm  \n",
            "0   2.862778e-01  \n",
            "1   3.324302e-01  \n",
            "2   3.127241e-01  \n",
            "3   2.661593e-01  \n",
            "4   2.665813e-01  \n",
            "5   1.898761e-01  \n",
            "6   2.972939e-01  \n",
            "7   1.973158e-01  \n",
            "8   1.819590e-01  \n",
            "9   1.513941e-01  \n",
            "10  2.091974e-01  \n",
            "11  4.289328e-01  \n",
            "12  4.447222e-01  \n",
            "13  4.440523e-01  \n",
            "14  1.855068e-01  \n",
            "15  2.663012e-01  \n",
            "16  2.713245e-01  \n",
            "17  2.896595e-01  \n",
            "18  8.000000e-08  \n",
            "19  3.156000e-05  \n",
            "20  3.089503e-01  \n",
            "21  2.978697e-01  \n",
            "22  3.104821e-01  \n",
            "23  3.083399e-01  \n",
            "24  2.975718e-01  \n",
            "25  1.563793e-01  \n",
            "26  3.103745e-01  \n",
            "27  1.426939e-01  \n",
            "28  4.230320e-03  \n",
            "29  3.438470e-02  \n",
            "30  8.981906e-02  \n",
            "31  2.587915e-01  \n",
            "32  2.143143e-01  \n",
            "33  8.665920e-02  \n",
            "34  5.974396e-02  \n",
            "35  6.096432e-02  \n",
            "36  3.960092e-01  \n",
            "37  3.980030e-01  \n",
            "38  3.950044e-01  \n",
            "39  3.474802e-01  \n",
            "40  3.628017e-01  \n",
            "41  3.497662e-01  \n",
            "42  3.033865e-01  \n",
            "43  2.353282e-01  \n",
            "44  2.328357e-01  \n",
            "45  4.077489e-01  \n",
            "46  4.077379e-01  \n",
            "47  4.089647e-01  \n",
            "\n",
            "=== Ranked by FOSCTTM (asc) ===\n",
            "    p  k   lambda_topo    lambda_reg  reach  final_loss  accuracy  \\\n",
            "0   8  5  1.000000e-03  1.000000e-07    0.1    0.000291    0.9960   \n",
            "1   8  5  1.000000e-01  1.000000e-07    1.0    0.000963    0.9968   \n",
            "2   8  5  1.000000e-01  1.000000e-07    5.0    0.003150    0.9974   \n",
            "3   8  5  1.000000e-03  1.000000e-05    0.1    0.003443    0.9936   \n",
            "4   8  5  1.000000e-01  1.000000e-05    1.0    0.009318    0.9970   \n",
            "5   8  5  1.000000e-01  1.000000e-05    5.0    0.009353    0.9968   \n",
            "6   8  5  1.000000e-01  1.000000e-05    0.1    0.006542    0.9958   \n",
            "7   8  5  1.000000e-01  1.000000e-07    0.1    0.003630    0.9882   \n",
            "8   8  5  1.000000e-03  1.000000e-07    1.0    0.002258    0.3978   \n",
            "9   8  5  1.000000e-05  1.000000e-07    0.1    0.000149    0.4916   \n",
            "10  8  5  1.000000e-03  1.000000e-07    5.0    0.002004    0.6984   \n",
            "11  8  5  1.000000e-07  1.000000e-07    5.0    0.000055    0.5602   \n",
            "12  8  5  1.000000e-05  1.000000e-07    5.0    0.000161    0.5284   \n",
            "13  8  5  1.000000e-07  1.000000e-07    0.1    0.000014    0.4398   \n",
            "14  8  5  1.000000e-07  1.000000e-07    1.0    0.000022    0.5368   \n",
            "15  8  5  1.000000e-05  1.000000e-07    1.0    0.000156    0.5358   \n",
            "16  8  5  1.000000e-03  1.000000e-05    5.0    0.004135    0.4952   \n",
            "17  8  5  1.000000e-01  1.000000e-03    5.0    0.020944    0.5102   \n",
            "18  8  5  1.000000e-01  1.000000e-03    1.0    0.020926    0.5210   \n",
            "19  8  5  1.000000e-03  1.000000e-05    1.0    0.003741    0.4338   \n",
            "20  8  5  1.000000e-07  1.000000e-03    5.0    0.000008    0.5290   \n",
            "21  8  5  1.000000e-05  1.000000e-03    5.0    0.000166    0.5284   \n",
            "22  8  5  1.000000e-07  1.000000e-03    1.0    0.000008    0.5322   \n",
            "23  8  5  1.000000e-05  1.000000e-03    1.0    0.000167    0.4928   \n",
            "24  8  5  1.000000e-07  1.000000e-05    0.1    0.000002    0.8018   \n",
            "25  8  5  1.000000e-05  1.000000e-03    0.1    0.000176    0.3692   \n",
            "26  8  5  1.000000e-07  1.000000e-03    0.1    0.000018    0.3664   \n",
            "27  8  5  1.000000e-05  1.000000e-01    5.0    0.001966    0.3352   \n",
            "28  8  5  1.000000e-07  1.000000e-01    5.0    0.001807    0.3336   \n",
            "29  8  5  1.000000e-01  1.000000e-03    0.1    0.020400    0.5228   \n",
            "30  8  5  1.000000e-05  1.000000e-01    1.0    0.001956    0.3126   \n",
            "31  8  5  1.000000e-07  1.000000e-01    1.0    0.001798    0.3138   \n",
            "32  8  5  1.000000e-05  1.000000e-01    0.1    0.002020    0.3080   \n",
            "33  8  5  1.000000e-07  1.000000e-01    0.1    0.001862    0.3084   \n",
            "34  8  5  1.000000e-07  1.000000e-05    5.0    0.000002    0.6762   \n",
            "35  8  5  1.000000e-07  1.000000e-05    1.0    0.000002    0.7136   \n",
            "36  8  5  1.000000e-03  1.000000e-01    5.0    0.019006    0.3568   \n",
            "37  8  5  1.000000e-03  1.000000e-01    0.1    0.019094    0.3652   \n",
            "38  8  5  1.000000e-03  1.000000e-01    1.0    0.019043    0.3278   \n",
            "39  8  5  1.000000e-03  1.000000e-03    5.0    0.016019    0.3970   \n",
            "40  8  5  1.000000e-03  1.000000e-03    1.0    0.016019    0.3968   \n",
            "41  8  5  1.000000e-03  1.000000e-03    0.1    0.016019    0.3822   \n",
            "42  8  5  1.000000e-01  1.000000e-01    5.0    1.601807    0.3396   \n",
            "43  8  5  1.000000e-01  1.000000e-01    1.0    1.601806    0.3392   \n",
            "44  8  5  1.000000e-01  1.000000e-01    0.1    1.601875    0.3368   \n",
            "45  8  5  1.000000e-05  1.000000e-05    0.1    0.000160    0.3680   \n",
            "46  8  5  1.000000e-05  1.000000e-05    1.0    0.000161    0.3874   \n",
            "47  8  5  1.000000e-05  1.000000e-05    5.0    0.000161    0.4024   \n",
            "\n",
            "         foscttm  \n",
            "0   8.000000e-08  \n",
            "1   3.156000e-05  \n",
            "2   4.230320e-03  \n",
            "3   3.438470e-02  \n",
            "4   5.974396e-02  \n",
            "5   6.096432e-02  \n",
            "6   8.665920e-02  \n",
            "7   8.981906e-02  \n",
            "8   1.426939e-01  \n",
            "9   1.513941e-01  \n",
            "10  1.563793e-01  \n",
            "11  1.819590e-01  \n",
            "12  1.855068e-01  \n",
            "13  1.898761e-01  \n",
            "14  1.973158e-01  \n",
            "15  2.091974e-01  \n",
            "16  2.143143e-01  \n",
            "17  2.328357e-01  \n",
            "18  2.353282e-01  \n",
            "19  2.587915e-01  \n",
            "20  2.661593e-01  \n",
            "21  2.663012e-01  \n",
            "22  2.665813e-01  \n",
            "23  2.713245e-01  \n",
            "24  2.862778e-01  \n",
            "25  2.896595e-01  \n",
            "26  2.972939e-01  \n",
            "27  2.975718e-01  \n",
            "28  2.978697e-01  \n",
            "29  3.033865e-01  \n",
            "30  3.083399e-01  \n",
            "31  3.089503e-01  \n",
            "32  3.103745e-01  \n",
            "33  3.104821e-01  \n",
            "34  3.127241e-01  \n",
            "35  3.324302e-01  \n",
            "36  3.474802e-01  \n",
            "37  3.497662e-01  \n",
            "38  3.628017e-01  \n",
            "39  3.950044e-01  \n",
            "40  3.960092e-01  \n",
            "41  3.980030e-01  \n",
            "42  4.077379e-01  \n",
            "43  4.077489e-01  \n",
            "44  4.089647e-01  \n",
            "45  4.289328e-01  \n",
            "46  4.440523e-01  \n",
            "47  4.447222e-01  \n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "full_df, rank_by_acc, rank_by_loss, rank_by_foscttm = summarize_results(results)\n",
        "\n",
        "print(\"=== Ranked by accuracy (desc) ===\")\n",
        "print(rank_by_acc)\n",
        "\n",
        "print(\"\\n=== Ranked by final loss (asc) ===\")\n",
        "print(rank_by_loss)\n",
        "\n",
        "print(\"\\n=== Ranked by FOSCTTM (asc) ===\")\n",
        "print(rank_by_foscttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "fmbcmV-XZRWW",
      "metadata": {
        "id": "fmbcmV-XZRWW"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'k'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     71\u001b[39m     plt.show()\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Robustness over p (aggregate over λ and reach), fixing k=5\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mplot_param_box_pretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Robustness over reach\u001b[39;00m\n\u001b[32m     77\u001b[39m plot_param_box_pretty(results, param_col=\u001b[33m\"\u001b[39m\u001b[33mreach\u001b[39m\u001b[33m\"\u001b[39m, metric_name=\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m, k_filter=\u001b[32m5\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mplot_param_box_pretty\u001b[39m\u001b[34m(df, param_col, metric_name, k_filter, ylim)\u001b[39m\n\u001b[32m     21\u001b[39m sub = df.copy()\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     sub = sub[\u001b[43msub\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == k_filter]\n\u001b[32m     24\u001b[39m sub = sub[np.isfinite(sub[metric_name])]\n\u001b[32m     26\u001b[39m groups = \u001b[38;5;28msorted\u001b[39m(sub[param_col].unique())\n",
            "\u001b[31mKeyError\u001b[39m: 'k'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_param_box_pretty(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    ylim=(0.0, 1.0),\n",
        "):\n",
        "    \"\"\"\n",
        "    Pretty robustness boxplot:\n",
        "\n",
        "      - x: discrete values of param_col (e.g. 'p' or 'reach')\n",
        "      - y: metric_name (e.g. 'accuracy' or 'foscttm')\n",
        "      - one box per param value\n",
        "      - no dots / outliers\n",
        "\n",
        "    Optionally filter to a fixed k (e.g. k=5).\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "\n",
        "    positions = np.arange(1, len(groups) + 1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5.5, 4.0))\n",
        "\n",
        "    # Boxplot (no outlier dots)\n",
        "    box = ax.boxplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showfliers=False,\n",
        "        patch_artist=True,   # so we can color the boxes\n",
        "        widths=0.6,\n",
        "    )\n",
        "\n",
        "    # Color + style boxes\n",
        "    for patch in box[\"boxes\"]:\n",
        "        patch.set_facecolor(\"#a6cee3\")   # pale blue\n",
        "        patch.set_alpha(0.8)\n",
        "        patch.set_linewidth(0.8)\n",
        "\n",
        "    for element in [\"whiskers\", \"caps\", \"medians\"]:\n",
        "        for line in box[element]:\n",
        "            line.set_linewidth(0.8)\n",
        "\n",
        "    # X axis labels\n",
        "    ax.set_xticks(positions)\n",
        "    ax.set_xticklabels([str(g) for g in groups], fontsize=11)\n",
        "    ax.set_xlabel(param_col, fontsize=12)\n",
        "    ax.set_ylabel(metric_name, fontsize=12)\n",
        "    ax.set_title(f\"{metric_name} across {param_col}\", fontsize=13)\n",
        "\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(ylim)\n",
        "\n",
        "    # Light horizontal grid\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.yaxis.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.4)\n",
        "\n",
        "    # Remove top/right spines\n",
        "    for spine in [\"top\", \"right\"]:\n",
        "        ax.spines[spine].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Robustness over p (aggregate over λ and reach), fixing k=5\n",
        "plot_param_box_pretty(results, param_col=\"p\", metric_name=\"accuracy\", k_filter=5)\n",
        "\n",
        "# Robustness over reach\n",
        "plot_param_box_pretty(results, param_col=\"reach\", metric_name=\"accuracy\", k_filter=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b7f874b5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{(8,\n",
              "  5,\n",
              "  1,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 0.44916751, -0.17579775,  0.01710016, ...,  0.07764716,\n",
              "           0.03773541, -0.01927316],\n",
              "         [-0.25998782,  0.26051028, -0.24093678, ..., -0.12824009,\n",
              "           0.04096042, -0.00856509],\n",
              "         [-0.08622245,  0.48258176, -0.23463979, ..., -0.07417583,\n",
              "           0.03057318,  0.03486404],\n",
              "         ...,\n",
              "         [-0.09815228,  0.34523271, -0.13503189, ...,  0.14684538,\n",
              "           0.00529904, -0.16545479],\n",
              "         [-0.3189362 , -0.12868701, -0.00065395, ..., -0.04786453,\n",
              "           0.03522305,  0.0641283 ],\n",
              "         [-0.26786635, -0.07687235,  0.01685982, ..., -0.0146406 ,\n",
              "          -0.02616994, -0.03807175]]), 'mapped_Y': array([[ 0.53409127, -0.10725799, -0.01985043, ...,  0.04375425,\n",
              "           0.02283597, -0.07434571],\n",
              "         [-0.42901335, -0.26227161, -0.07959843, ...,  0.04591436,\n",
              "          -0.0082818 , -0.04910707],\n",
              "         [ 0.03087475,  0.16930478,  0.02369686, ..., -0.12799068,\n",
              "          -0.01939926,  0.12247898],\n",
              "         ...,\n",
              "         [-0.11959769,  0.44573316, -0.26167589, ...,  0.05091334,\n",
              "           0.0142087 , -0.03912676],\n",
              "         [-0.36424636, -0.1927672 , -0.05251403, ...,  0.2856953 ,\n",
              "           0.06247917,  0.06090656],\n",
              "         [-0.3603886 , -0.20570436, -0.06074534, ..., -0.12507362,\n",
              "          -0.03537898, -0.009538  ]]), 'alpha': tensor([[ 4.1883e-03,  6.4974e-03, -3.8693e-04,  ...,  1.0992e-02,\n",
              "            4.1905e-03,  1.5743e-03],\n",
              "          [ 6.6853e-03,  2.1939e-03, -2.3954e-03,  ..., -2.8739e-02,\n",
              "            2.7840e-03, -1.0191e-02],\n",
              "          [ 9.4860e-05,  7.8103e-03, -1.8402e-02,  ..., -7.4960e-04,\n",
              "            4.1667e-03,  1.1303e-03],\n",
              "          ...,\n",
              "          [ 3.5418e-03,  5.9598e-03,  1.2601e-02,  ...,  1.9824e-02,\n",
              "            3.1687e-05, -1.4123e-02],\n",
              "          [-1.0448e-03,  4.9441e-03,  2.6940e-02,  ..., -1.3672e-02,\n",
              "            1.2566e-02,  5.9177e-03],\n",
              "          [ 8.9555e-04, -1.4225e-02,  1.5389e-02,  ..., -1.3780e-02,\n",
              "           -1.3062e-03, -1.2801e-02]], dtype=torch.float64), 'beta': tensor([[ 3.0895e-03, -5.8552e-05, -2.6414e-05,  ...,  1.3011e-02,\n",
              "            6.2734e-03, -7.4973e-03],\n",
              "          [-1.6186e-03, -3.4265e-03,  4.5747e-03,  ..., -2.7354e-03,\n",
              "           -1.2590e-03, -7.9727e-03],\n",
              "          [ 1.1677e-04,  9.0009e-04,  1.6578e-02,  ..., -1.3282e-02,\n",
              "           -1.9498e-03,  1.7581e-02],\n",
              "          ...,\n",
              "          [-5.4426e-03,  8.5751e-03, -1.4732e-02,  ...,  9.6456e-03,\n",
              "            6.4670e-03, -7.0449e-03],\n",
              "          [-3.0864e-03,  9.5345e-03, -7.0475e-03,  ...,  3.4548e-02,\n",
              "            1.6981e-02,  1.0486e-02],\n",
              "          [-2.9166e-03, -1.6465e-02,  8.0925e-04,  ..., -2.2197e-03,\n",
              "           -9.7936e-03, -6.6942e-03]], dtype=torch.float64), 'final_loss': 0.08329752267119764, 'loss_breakdown': {'ot': 0.00870889318655124,\n",
              "   'ortho': 0.00014675730303000676,\n",
              "   'graph': 74.44187218161639}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.1494313584362106}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[ 4.42079284e-01, -1.91689340e-01, -1.69867758e-02, ...,\n",
              "           1.46826878e-01,  9.04452448e-02,  6.47156640e-02],\n",
              "         [-2.42997623e-01,  2.42904406e-01, -2.56529975e-01, ...,\n",
              "          -1.44756044e-01, -3.20408007e-02, -9.47171767e-02],\n",
              "         [-5.69717066e-02,  4.06492726e-01, -2.54286724e-01, ...,\n",
              "          -9.82355941e-02, -6.17368035e-02, -4.92214772e-02],\n",
              "         ...,\n",
              "         [-7.46081104e-02,  2.83442262e-01, -1.42438523e-01, ...,\n",
              "           1.66692396e-04, -4.93427946e-02, -9.11549755e-02],\n",
              "         [-3.29909380e-01, -5.00138366e-02, -4.65582741e-02, ...,\n",
              "          -9.76043947e-02,  1.12257076e-01,  2.24221622e-04],\n",
              "         [-2.68850970e-01, -2.59243151e-02, -7.08012017e-03, ...,\n",
              "          -1.03184088e-01, -1.01259557e-02, -1.99775807e-02]]), 'mapped_Y': array([[ 0.50279793, -0.14047757,  0.00501755, ...,  0.10247757,\n",
              "           0.07481954,  0.0036934 ],\n",
              "         [-0.44082605, -0.18367304, -0.02366752, ..., -0.04522098,\n",
              "           0.04763542,  0.03759469],\n",
              "         [ 0.03863665,  0.16188317, -0.01706967, ..., -0.09905576,\n",
              "           0.01249232,  0.06780925],\n",
              "         ...,\n",
              "         [-0.09138161,  0.38702862, -0.28108605, ..., -0.03280754,\n",
              "          -0.06452994, -0.12878898],\n",
              "         [-0.38421951, -0.09064052, -0.01956559, ...,  0.20902004,\n",
              "           0.10564217,  0.1088576 ],\n",
              "         [-0.37705464, -0.16609327, -0.01299528, ..., -0.10616125,\n",
              "           0.02255027, -0.03171033]]), 'alpha': tensor([[ 0.0097,  0.0174, -0.0149,  ...,  0.0142,  0.0131, -0.0003],\n",
              "          [ 0.0112,  0.0076, -0.0121,  ..., -0.0433, -0.0156, -0.0213],\n",
              "          [-0.0010,  0.0060, -0.0189,  ...,  0.0104, -0.0020, -0.0039],\n",
              "          ...,\n",
              "          [ 0.0120,  0.0115, -0.0009,  ..., -0.0118,  0.0199,  0.0038],\n",
              "          [ 0.0004,  0.0203, -0.0013,  ..., -0.0372,  0.0542, -0.0091],\n",
              "          [ 0.0042,  0.0010, -0.0034,  ..., -0.0509,  0.0377, -0.0052]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0021,  0.0002,  0.0042,  ...,  0.0065,  0.0104, -0.0146],\n",
              "          [ 0.0008,  0.0007,  0.0085,  ..., -0.0139,  0.0064,  0.0038],\n",
              "          [ 0.0070,  0.0150,  0.0142,  ..., -0.0191,  0.0155,  0.0212],\n",
              "          ...,\n",
              "          [-0.0024,  0.0047, -0.0136,  ...,  0.0102,  0.0046, -0.0363],\n",
              "          [ 0.0009,  0.0409, -0.0077,  ...,  0.0438,  0.0335,  0.0026],\n",
              "          [-0.0046, -0.0172,  0.0058,  ..., -0.0060, -0.0123,  0.0023]],\n",
              "         dtype=torch.float64), 'final_loss': 0.06665802587241434, 'loss_breakdown': {'ot': 0.009829771655984951,\n",
              "   'ortho': 0.0001654387607119984,\n",
              "   'graph': 56.66281545571739}, 'best_iter': 3828, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9608404966571156,\n",
              "   'accuracy_raw': 0.9608404966571156,\n",
              "   'foscttm': 0.14554615041474753}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[ 0.43361359, -0.19556428,  0.02108467, ...,  0.15259823,\n",
              "           0.07662026,  0.0671226 ],\n",
              "         [-0.20519635,  0.23893237, -0.26620847, ..., -0.13524696,\n",
              "          -0.03654164, -0.08912093],\n",
              "         [-0.01995864,  0.39987435, -0.25527436, ..., -0.09567002,\n",
              "          -0.06806903, -0.04410381],\n",
              "         ...,\n",
              "         [-0.03966857,  0.27586086, -0.14338564, ..., -0.02856872,\n",
              "          -0.04727839, -0.04116277],\n",
              "         [-0.3338581 , -0.05250484, -0.0712105 , ..., -0.07690167,\n",
              "           0.1340264 , -0.03145731],\n",
              "         [-0.26742656, -0.03290965, -0.03296121, ..., -0.09660038,\n",
              "          -0.00543151, -0.02101494]]), 'mapped_Y': array([[ 0.49723745, -0.14827141,  0.06099979, ...,  0.11881811,\n",
              "           0.05314235,  0.01276605],\n",
              "         [-0.44166466, -0.16566265, -0.04397807, ..., -0.06605451,\n",
              "           0.07453178,  0.03151287],\n",
              "         [ 0.0369498 ,  0.15637306, -0.01604438, ..., -0.08169804,\n",
              "           0.01644159,  0.07055081],\n",
              "         ...,\n",
              "         [-0.05211415,  0.3872281 , -0.29277742, ..., -0.03953027,\n",
              "          -0.07626243, -0.12887081],\n",
              "         [-0.38713744, -0.08656215, -0.04539331, ...,  0.16426254,\n",
              "           0.13586591,  0.10462809],\n",
              "         [-0.38055331, -0.15082985, -0.03073413, ..., -0.08155278,\n",
              "           0.02488021, -0.034779  ]]), 'alpha': tensor([[ 0.0109,  0.0182, -0.0159,  ...,  0.0136,  0.0145, -0.0021],\n",
              "          [ 0.0132,  0.0082, -0.0126,  ..., -0.0406, -0.0147, -0.0223],\n",
              "          [-0.0001,  0.0066, -0.0205,  ...,  0.0090, -0.0031, -0.0037],\n",
              "          ...,\n",
              "          [ 0.0161,  0.0118, -0.0008,  ..., -0.0167,  0.0238,  0.0078],\n",
              "          [ 0.0010,  0.0171, -0.0043,  ..., -0.0330,  0.0528, -0.0198],\n",
              "          [ 0.0062, -0.0025, -0.0063,  ..., -0.0466,  0.0308, -0.0076]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0021,  0.0009,  0.0057,  ...,  0.0069,  0.0092, -0.0142],\n",
              "          [ 0.0006,  0.0021,  0.0102,  ..., -0.0166,  0.0105,  0.0027],\n",
              "          [ 0.0046,  0.0170,  0.0190,  ..., -0.0163,  0.0200,  0.0222],\n",
              "          ...,\n",
              "          [-0.0005,  0.0044, -0.0146,  ...,  0.0107,  0.0038, -0.0415],\n",
              "          [ 0.0015,  0.0442, -0.0097,  ...,  0.0438,  0.0387,  0.0066],\n",
              "          [-0.0049, -0.0164,  0.0070,  ..., -0.0038, -0.0144,  0.0004]],\n",
              "         dtype=torch.float64), 'final_loss': 0.06348042054783729, 'loss_breakdown': {'ot': 0.009041395189666224,\n",
              "   'ortho': 0.00011186285711164906,\n",
              "   'graph': 54.32716250105941}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.14607661495207575}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 2.1304e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5955e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4841e-03, -7.1046e-03,  ..., -1.2457e-02,\n",
              "            5.0021e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8313e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6872e-03, -3.2819e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5337e-03,\n",
              "            6.6289e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5819e-05,  ..., -7.8933e-03,\n",
              "           -2.8828e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5337e-04,\n",
              "            3.3084e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5453e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.5165e-02],\n",
              "          [-4.3881e-04,  1.5218e-03,  1.3888e-03,  ..., -8.5209e-03,\n",
              "           -3.0654e-03,  9.5026e-03],\n",
              "          ...,\n",
              "          [-1.2333e-03,  5.5055e-03, -8.6818e-03,  ...,  5.3526e-03,\n",
              "            2.5763e-03, -7.7908e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7910e-04,  ...,  3.1974e-02,\n",
              "            6.7755e-03, -3.2531e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3695e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.022963324343481292, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.40682737, -0.3165658 , -0.09090918, ..., -0.01114761,\n",
              "           0.0298235 , -0.01078256],\n",
              "         [-0.25338186,  0.35465251, -0.22912647, ..., -0.07631054,\n",
              "           0.0178064 , -0.03414748],\n",
              "         [-0.04075069,  0.51551405, -0.2392966 , ...,  0.00511837,\n",
              "           0.01411449, -0.00222815],\n",
              "         ...,\n",
              "         [-0.06863136,  0.37010033, -0.14356569, ...,  0.21132909,\n",
              "          -0.03733966, -0.23258463],\n",
              "         [-0.36581416, -0.08094738, -0.01278633, ..., -0.10030975,\n",
              "           0.0362571 ,  0.04258773],\n",
              "         [-0.29180828, -0.01055144,  0.03544098, ..., -0.16631658,\n",
              "          -0.06978126, -0.07653587]]), 'mapped_Y': array([[ 0.48537983, -0.23851336, -0.10616545, ..., -0.01311577,\n",
              "           0.03564153, -0.00064413],\n",
              "         [-0.49410195, -0.15924297,  0.0153101 , ...,  0.10166302,\n",
              "          -0.00245592, -0.11552766],\n",
              "         [ 0.09796447,  0.19315084, -0.04168134, ..., -0.08893309,\n",
              "          -0.0532922 ,  0.1504747 ],\n",
              "         ...,\n",
              "         [-0.07672796,  0.49821845, -0.23255937, ...,  0.08923664,\n",
              "           0.03357394, -0.13070253],\n",
              "         [-0.42045932, -0.20238384,  0.10868678, ...,  0.31053751,\n",
              "          -0.00666386,  0.02957889],\n",
              "         [-0.40840136, -0.08640204, -0.01787896, ..., -0.18206616,\n",
              "           0.01068925, -0.00327095]]), 'alpha': tensor([[ 0.0017,  0.0012, -0.0024,  ..., -0.0005,  0.0022, -0.0010],\n",
              "          [ 0.0014,  0.0036, -0.0061,  ..., -0.0157,  0.0032, -0.0010],\n",
              "          [-0.0005,  0.0084, -0.0073,  ..., -0.0034,  0.0050,  0.0033],\n",
              "          ...,\n",
              "          [-0.0003,  0.0014, -0.0022,  ...,  0.0241, -0.0045, -0.0335],\n",
              "          [-0.0038,  0.0030, -0.0047,  ..., -0.0204,  0.0101,  0.0008],\n",
              "          [-0.0026, -0.0041, -0.0070,  ..., -0.0549, -0.0044, -0.0214]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0024, -0.0042,  0.0002,  ...,  0.0011,  0.0023,  0.0013],\n",
              "          [-0.0024, -0.0006, -0.0001,  ...,  0.0064, -0.0013, -0.0134],\n",
              "          [ 0.0043,  0.0112, -0.0022,  ..., -0.0123, -0.0073,  0.0174],\n",
              "          ...,\n",
              "          [-0.0025,  0.0042, -0.0082,  ...,  0.0047,  0.0018, -0.0098],\n",
              "          [ 0.0008,  0.0045,  0.0044,  ...,  0.0359,  0.0046, -0.0005],\n",
              "          [-0.0043, -0.0050, -0.0024,  ..., -0.0190,  0.0025, -0.0007]],\n",
              "         dtype=torch.float64), 'final_loss': 0.032394473886182634, 'loss_breakdown': {'ot': 0.021226854814010206,\n",
              "   'ortho': 3.273443571010245e-05,\n",
              "   'graph': 111.34884636462326}, 'best_iter': 2921, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452722,\n",
              "   'accuracy_raw': 0.9656160458452722,\n",
              "   'foscttm': 0.15160384561703105}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 0.44062329, -0.28400735, -0.05354682, ..., -0.00569028,\n",
              "           0.03520458, -0.01238925],\n",
              "         [-0.26404437,  0.33021863, -0.25156113, ..., -0.07865221,\n",
              "           0.02706911, -0.03990362],\n",
              "         [-0.06912594,  0.50924356, -0.25012146, ...,  0.00330471,\n",
              "           0.0257661 , -0.00826301],\n",
              "         ...,\n",
              "         [-0.09394996,  0.35898998, -0.14690422, ...,  0.22114844,\n",
              "          -0.03444754, -0.23015117],\n",
              "         [-0.35895117, -0.1105307 , -0.04127112, ..., -0.09053447,\n",
              "           0.02724558,  0.0378102 ],\n",
              "         [-0.29667344, -0.03322044,  0.02206282, ..., -0.13952966,\n",
              "          -0.08552553, -0.07824574]]), 'mapped_Y': array([[ 0.51284102, -0.19755596, -0.06378719, ...,  0.00992562,\n",
              "           0.03892736, -0.00372128],\n",
              "         [-0.47856478, -0.20030317, -0.01715029, ...,  0.08620594,\n",
              "          -0.01045686, -0.11299723],\n",
              "         [ 0.09066121,  0.19856009, -0.04004247, ..., -0.07377821,\n",
              "          -0.07052019,  0.15535033],\n",
              "         ...,\n",
              "         [-0.1123649 ,  0.48942343, -0.24596793, ...,  0.07137989,\n",
              "           0.06589217, -0.13944805],\n",
              "         [-0.40371058, -0.24249373,  0.07766084, ...,  0.28956583,\n",
              "          -0.0311181 ,  0.02789033],\n",
              "         [-0.39534062, -0.11534095, -0.04184069, ..., -0.17876635,\n",
              "           0.01279202,  0.00117684]]), 'alpha': tensor([[ 0.0016,  0.0011, -0.0019,  ...,  0.0007,  0.0023, -0.0009],\n",
              "          [ 0.0014,  0.0036, -0.0059,  ..., -0.0160,  0.0031, -0.0013],\n",
              "          [-0.0007,  0.0084, -0.0075,  ..., -0.0012,  0.0053,  0.0031],\n",
              "          ...,\n",
              "          [-0.0008,  0.0004, -0.0013,  ...,  0.0258, -0.0052, -0.0328],\n",
              "          [-0.0036,  0.0020, -0.0051,  ..., -0.0119,  0.0095, -0.0005],\n",
              "          [-0.0022, -0.0044, -0.0051,  ..., -0.0239, -0.0057, -0.0222]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6866e-03, -3.5683e-03,  7.0086e-04,  ...,  4.1515e-03,\n",
              "            3.5311e-03,  1.4332e-03],\n",
              "          [-2.4488e-03, -8.0130e-04, -2.5713e-04,  ...,  4.5676e-03,\n",
              "           -2.6341e-03, -1.3442e-02],\n",
              "          [ 6.9322e-03,  1.2873e-02, -2.5862e-03,  ..., -7.1262e-03,\n",
              "           -1.1279e-02,  1.9074e-02],\n",
              "          ...,\n",
              "          [-2.9987e-03,  3.5298e-03, -8.3279e-03,  ...,  3.0145e-03,\n",
              "            2.4348e-03, -1.0119e-02],\n",
              "          [ 1.9419e-05,  5.0451e-03,  4.5083e-03,  ...,  3.5998e-02,\n",
              "            3.7776e-03, -6.4703e-04],\n",
              "          [-3.8431e-03, -4.6202e-03, -2.4012e-03,  ..., -1.8825e-02,\n",
              "            2.0285e-03, -8.6501e-04]], dtype=torch.float64), 'final_loss': 0.032328476176943115, 'loss_breakdown': {'ot': 0.021177230351997752,\n",
              "   'ortho': 2.8754457927897465e-05,\n",
              "   'graph': 111.22491367017464}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9670487106017192,\n",
              "   'accuracy_raw': 0.9670487106017192,\n",
              "   'foscttm': 0.15095524667285162}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 2.1325e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4842e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0022e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5821e-05,  ..., -9.8922e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5201e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5215e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  9.5043e-03],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3529e-03,\n",
              "            2.5763e-03, -9.6741e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3681e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.012603659323351942, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[ 0.44934628, -0.27651103, -0.02612143, ..., -0.01771472,\n",
              "           0.02345851, -0.00678979],\n",
              "         [-0.2622041 ,  0.31480836, -0.27533135, ..., -0.07485498,\n",
              "           0.02881775, -0.03625084],\n",
              "         [-0.06836455,  0.49912993, -0.26878353, ...,  0.00658945,\n",
              "           0.02518306, -0.00586929],\n",
              "         ...,\n",
              "         [-0.09153192,  0.35585883, -0.17551315, ...,  0.20996844,\n",
              "          -0.03216965, -0.23903532],\n",
              "         [-0.35188344, -0.12606709, -0.04620898, ..., -0.09736362,\n",
              "           0.03116828,  0.04457811],\n",
              "         [-0.30022753, -0.02977012, -0.00317946, ..., -0.16986181,\n",
              "          -0.07481256, -0.07922804]]), 'mapped_Y': array([[ 0.518099  , -0.18920633, -0.03978221, ..., -0.01644933,\n",
              "           0.03529828,  0.00889645],\n",
              "         [-0.47056215, -0.21285087, -0.03386668, ...,  0.10254617,\n",
              "          -0.00589046, -0.11840615],\n",
              "         [ 0.08137589,  0.20791925, -0.02948989, ..., -0.0929088 ,\n",
              "          -0.05303206,  0.14912271],\n",
              "         ...,\n",
              "         [-0.10148253,  0.47646036, -0.27155061, ...,  0.09135988,\n",
              "           0.03889934, -0.13662126],\n",
              "         [-0.40103195, -0.25349762,  0.0704455 , ...,  0.30905452,\n",
              "          -0.00297697,  0.03677685],\n",
              "         [-0.3928889 , -0.12854917, -0.05916484, ..., -0.1786186 ,\n",
              "           0.0028619 , -0.00642924]]), 'alpha': tensor([[ 0.0015, -0.0002, -0.0015,  ..., -0.0013,  0.0018, -0.0009],\n",
              "          [ 0.0011,  0.0036, -0.0065,  ..., -0.0146,  0.0040, -0.0007],\n",
              "          [-0.0005,  0.0078, -0.0072,  ..., -0.0033,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0010, -0.0035,  ...,  0.0242, -0.0045, -0.0338],\n",
              "          [-0.0035,  0.0009, -0.0054,  ..., -0.0206,  0.0087,  0.0006],\n",
              "          [-0.0026, -0.0032, -0.0093,  ..., -0.0649, -0.0080, -0.0217]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0026, -0.0036,  0.0001,  ...,  0.0014,  0.0024,  0.0002],\n",
              "          [-0.0024, -0.0002, -0.0003,  ...,  0.0056, -0.0018, -0.0139],\n",
              "          [ 0.0036,  0.0107, -0.0018,  ..., -0.0126, -0.0083,  0.0164],\n",
              "          ...,\n",
              "          [-0.0024,  0.0018, -0.0085,  ...,  0.0046,  0.0013, -0.0097],\n",
              "          [ 0.0002,  0.0054,  0.0049,  ...,  0.0358,  0.0028,  0.0003],\n",
              "          [-0.0040, -0.0041, -0.0030,  ..., -0.0206,  0.0034, -0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.02295015864255374, 'loss_breakdown': {'ot': 0.021797927656383817,\n",
              "   'ortho': 2.0467180776737993e-05,\n",
              "   'graph': 113.1763805393187}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15194502143295668}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.44866595, -0.27760688, -0.04128264, ..., -0.02336191,\n",
              "           0.02636059, -0.00425162],\n",
              "         [-0.28074093,  0.30304812, -0.270202  , ..., -0.06754164,\n",
              "           0.02780877, -0.04096341],\n",
              "         [-0.08973226,  0.48561178, -0.28780778, ...,  0.02202539,\n",
              "           0.02806762, -0.01250478],\n",
              "         ...,\n",
              "         [-0.10565754,  0.33609421, -0.1837918 , ...,  0.21899964,\n",
              "          -0.03205358, -0.2423617 ],\n",
              "         [-0.35401435, -0.12231927, -0.01846866, ..., -0.11174727,\n",
              "           0.02872299,  0.03722996],\n",
              "         [-0.29601729, -0.02475819,  0.02761264, ..., -0.17473672,\n",
              "          -0.07861233, -0.083202  ]]), 'mapped_Y': array([[ 0.51604571, -0.18723647, -0.06355566, ..., -0.00512066,\n",
              "           0.03817112,  0.00980729],\n",
              "         [-0.47109945, -0.21720186,  0.01499258, ...,  0.09126264,\n",
              "          -0.01701203, -0.11705721],\n",
              "         [ 0.08235482,  0.21034683, -0.05259305, ..., -0.07177481,\n",
              "          -0.06507895,  0.14641036],\n",
              "         ...,\n",
              "         [-0.12699577,  0.45564413, -0.28449239, ...,  0.09426283,\n",
              "           0.05441354, -0.14570136],\n",
              "         [-0.39737715, -0.26806736,  0.10951866, ...,  0.28944646,\n",
              "          -0.02135569,  0.0344148 ],\n",
              "         [-0.39246775, -0.11869342, -0.02221701, ..., -0.18302786,\n",
              "           0.00494836, -0.00386487]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0016,  ..., -0.0009,  0.0018, -0.0008],\n",
              "          [ 0.0009,  0.0037, -0.0064,  ..., -0.0136,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0075,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0003, -0.0017, -0.0029,  ...,  0.0232, -0.0048, -0.0336],\n",
              "          [-0.0036,  0.0013, -0.0051,  ..., -0.0229,  0.0087, -0.0013],\n",
              "          [-0.0024, -0.0026, -0.0064,  ..., -0.0522, -0.0079, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7590e-03, -3.2607e-03,  3.1551e-04,  ...,  3.0454e-03,\n",
              "            3.0126e-03,  5.3556e-04],\n",
              "          [-2.3071e-03, -3.2202e-04,  6.1196e-04,  ...,  5.9430e-03,\n",
              "           -3.2559e-03, -1.3639e-02],\n",
              "          [ 4.8931e-03,  9.7670e-03, -2.7539e-03,  ..., -6.9770e-03,\n",
              "           -1.1701e-02,  1.6507e-02],\n",
              "          ...,\n",
              "          [-3.0179e-03, -2.7999e-04, -8.5313e-03,  ...,  3.0589e-03,\n",
              "            2.2181e-03, -9.9754e-03],\n",
              "          [-7.0419e-05,  3.4373e-03,  5.1385e-03,  ...,  3.5834e-02,\n",
              "            1.7305e-03, -2.5815e-04],\n",
              "          [-3.7618e-03, -3.1639e-03, -1.8382e-03,  ..., -2.0082e-02,\n",
              "            2.7728e-03, -1.0686e-03]], dtype=torch.float64), 'final_loss': 0.022839207437031304, 'loss_breakdown': {'ot': 0.02168905732396601,\n",
              "   'ortho': 2.1819755612675134e-05,\n",
              "   'graph': 112.83303574526151}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.15143553829607312}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 4.1302e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4844e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0023e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5822e-05,  ..., -9.8928e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5117e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5216e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  1.1481e-02],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3530e-03,\n",
              "            2.5763e-03, -9.7894e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3679e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.011567692821339006, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.45623646, -0.26713212, -0.01775362, ..., -0.0168603 ,\n",
              "           0.02325861, -0.0070635 ],\n",
              "         [-0.26473789,  0.30795836, -0.28038785, ..., -0.07650139,\n",
              "           0.02931083, -0.03586998],\n",
              "         [-0.07527952,  0.49708557, -0.27150666, ...,  0.00430422,\n",
              "           0.0263963 , -0.00640449],\n",
              "         ...,\n",
              "         [-0.09741532,  0.35382605, -0.17784027, ...,  0.20971647,\n",
              "          -0.03072183, -0.23892929],\n",
              "         [-0.34839079, -0.13397149, -0.05234588, ..., -0.09536098,\n",
              "           0.03018952,  0.04480457],\n",
              "         [-0.30013581, -0.03642445, -0.00844652, ..., -0.16719354,\n",
              "          -0.07498915, -0.07935764]]), 'mapped_Y': array([[ 5.23040158e-01, -1.78489559e-01, -3.06737748e-02, ...,\n",
              "          -1.68624068e-02,  3.50187606e-02,  8.31956680e-03],\n",
              "         [-4.64838726e-01, -2.21902786e-01, -4.15800356e-02, ...,\n",
              "           1.03710039e-01, -5.68943978e-03, -1.17600282e-01],\n",
              "         [ 7.74080563e-02,  2.10196384e-01, -2.60215047e-02, ...,\n",
              "          -9.46018644e-02, -5.45309017e-02,  1.48323749e-01],\n",
              "         ...,\n",
              "         [-1.08214254e-01,  4.72907034e-01, -2.76356668e-01, ...,\n",
              "           9.00258352e-02,  4.12410454e-02, -1.36937465e-01],\n",
              "         [-3.94779596e-01, -2.62003757e-01,  6.45730880e-02, ...,\n",
              "           3.10416107e-01, -1.11899642e-03,  3.94652334e-02],\n",
              "         [-3.89190018e-01, -1.36982521e-01, -6.53426255e-02, ...,\n",
              "          -1.78813647e-01,  9.67513619e-06, -6.44953750e-03]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0014,  ..., -0.0014,  0.0017, -0.0009],\n",
              "          [ 0.0010,  0.0036, -0.0065,  ..., -0.0145,  0.0041, -0.0006],\n",
              "          [-0.0006,  0.0077, -0.0071,  ..., -0.0034,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0009, -0.0036,  ...,  0.0244, -0.0044, -0.0337],\n",
              "          [-0.0035,  0.0008, -0.0056,  ..., -0.0197,  0.0085,  0.0003],\n",
              "          [-0.0026, -0.0033, -0.0094,  ..., -0.0633, -0.0081, -0.0218]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6616e-03, -3.5415e-03,  1.5091e-04,  ...,  1.1958e-03,\n",
              "            2.3460e-03,  8.5193e-05],\n",
              "          [-2.4134e-03,  1.6518e-05, -2.8851e-04,  ...,  5.6403e-03,\n",
              "           -1.6873e-03, -1.4090e-02],\n",
              "          [ 3.6682e-03,  1.0130e-02, -1.6752e-03,  ..., -1.2702e-02,\n",
              "           -8.5709e-03,  1.6225e-02],\n",
              "          ...,\n",
              "          [-2.4348e-03,  1.2859e-03, -8.5312e-03,  ...,  4.6950e-03,\n",
              "            1.3529e-03, -9.7317e-03],\n",
              "          [ 1.1649e-04,  5.4134e-03,  4.9854e-03,  ...,  3.5974e-02,\n",
              "            2.8509e-03,  4.6260e-04],\n",
              "          [-3.9797e-03, -4.1669e-03, -3.0046e-03,  ..., -2.0793e-02,\n",
              "            3.1225e-03, -1.3760e-03]], dtype=torch.float64), 'final_loss': 0.021989337146263985, 'loss_breakdown': {'ot': 0.021856234610300545,\n",
              "   'ortho': 1.9795436407280467e-05,\n",
              "   'graph': 113.30709955615993}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15196782730300518}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.4505758 , -0.27521515, -0.0398706 , ..., -0.02432067,\n",
              "           0.02658821, -0.0060944 ],\n",
              "         [-0.28378532,  0.29904848, -0.27177766, ..., -0.06822371,\n",
              "           0.02703751, -0.03958535],\n",
              "         [-0.09361845,  0.48310993, -0.29131738, ...,  0.02158354,\n",
              "           0.02684226, -0.01105906],\n",
              "         ...,\n",
              "         [-0.10916482,  0.3338745 , -0.18757315, ...,  0.21873053,\n",
              "          -0.03362663, -0.2405884 ],\n",
              "         [-0.35244735, -0.12368436, -0.01598552, ..., -0.1125398 ,\n",
              "           0.02906869,  0.03745973],\n",
              "         [-0.2952116 , -0.02478029,  0.03016883, ..., -0.17567123,\n",
              "          -0.07790118, -0.08185218]]), 'mapped_Y': array([[ 0.51727359, -0.18394674, -0.06345396, ..., -0.00262515,\n",
              "           0.03832247,  0.0082302 ],\n",
              "         [-0.46996866, -0.22033555,  0.01690478, ...,  0.08701522,\n",
              "          -0.0163923 , -0.1188799 ],\n",
              "         [ 0.08080654,  0.20957705, -0.05315305, ..., -0.06830086,\n",
              "          -0.06833589,  0.14533449],\n",
              "         ...,\n",
              "         [-0.13072436,  0.45363498, -0.28869542, ...,  0.091509  ,\n",
              "           0.05255035, -0.14401419],\n",
              "         [-0.39587818, -0.27320764,  0.10922787, ...,  0.28415356,\n",
              "          -0.02007329,  0.0332718 ],\n",
              "         [-0.39130172, -0.12004521, -0.01836885, ..., -0.18165041,\n",
              "           0.00382527, -0.00270028]]), 'alpha': tensor([[ 0.0015, -0.0004, -0.0015,  ..., -0.0010,  0.0018, -0.0008],\n",
              "          [ 0.0008,  0.0037, -0.0064,  ..., -0.0133,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0074,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0004, -0.0018, -0.0030,  ...,  0.0230, -0.0049, -0.0334],\n",
              "          [-0.0035,  0.0014, -0.0051,  ..., -0.0236,  0.0086, -0.0013],\n",
              "          [-0.0024, -0.0024, -0.0062,  ..., -0.0520, -0.0080, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7885e-03, -3.1983e-03,  3.0808e-04,  ...,  3.6234e-03,\n",
              "            2.8640e-03,  4.3346e-04],\n",
              "          [-2.3315e-03, -3.6203e-04,  5.7311e-04,  ...,  5.5508e-03,\n",
              "           -3.2684e-03, -1.4026e-02],\n",
              "          [ 4.9259e-03,  9.2545e-03, -2.7952e-03,  ..., -6.3937e-03,\n",
              "           -1.2076e-02,  1.6332e-02],\n",
              "          ...,\n",
              "          [-3.0792e-03, -5.3974e-04, -8.5378e-03,  ...,  2.7738e-03,\n",
              "            2.3166e-03, -9.9703e-03],\n",
              "          [-7.4717e-05,  2.9472e-03,  4.9189e-03,  ...,  3.5469e-02,\n",
              "            1.4843e-03, -2.5153e-04],\n",
              "          [-3.7419e-03, -3.0790e-03, -1.5356e-03,  ..., -1.9926e-02,\n",
              "            2.7856e-03, -9.9450e-04]], dtype=torch.float64), 'final_loss': 0.02182549750719424, 'loss_breakdown': {'ot': 0.021691372764482953,\n",
              "   'ortho': 2.1231509878038317e-05,\n",
              "   'graph': 112.89323283324744}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.15142732818285565}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 4.1302e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4844e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0023e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5822e-05,  ..., -9.8928e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5107e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5216e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  1.1493e-02],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3530e-03,\n",
              "            2.5763e-03, -9.7895e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3678e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.011464096171137713, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.4571143 , -0.26575638, -0.01733357, ..., -0.01657534,\n",
              "           0.02306865, -0.00708779],\n",
              "         [-0.26497805,  0.30774931, -0.28034554, ..., -0.07630425,\n",
              "           0.02918566, -0.03594088],\n",
              "         [-0.07611997,  0.49747427, -0.27057487, ...,  0.00404016,\n",
              "           0.02647528, -0.00635527],\n",
              "         ...,\n",
              "         [-0.09807281,  0.35395936, -0.17731334, ...,  0.20968969,\n",
              "          -0.03043114, -0.23862196],\n",
              "         [-0.34799463, -0.13494363, -0.05339687, ..., -0.09320618,\n",
              "           0.03014091,  0.04490067],\n",
              "         [-0.30014737, -0.03709003, -0.0095811 , ..., -0.16583226,\n",
              "          -0.07506941, -0.07934665]]), 'mapped_Y': array([[ 5.23672052e-01, -1.76910129e-01, -2.98470668e-02, ...,\n",
              "          -1.69493587e-02,  3.51033348e-02,  8.37674106e-03],\n",
              "         [-4.63950089e-01, -2.22928987e-01, -4.31949866e-02, ...,\n",
              "           1.04551559e-01, -5.71174200e-03, -1.17456832e-01],\n",
              "         [ 7.67117985e-02,  2.10285211e-01, -2.52963539e-02, ...,\n",
              "          -9.58846506e-02, -5.39676805e-02,  1.48064502e-01],\n",
              "         ...,\n",
              "         [-1.09053019e-01,  4.73222141e-01, -2.75588998e-01, ...,\n",
              "           9.08358885e-02,  4.09681011e-02, -1.36560728e-01],\n",
              "         [-3.93703600e-01, -2.62749685e-01,  6.31975492e-02, ...,\n",
              "           3.10047011e-01, -6.43042380e-04,  4.00499925e-02],\n",
              "         [-3.88765128e-01, -1.38241916e-01, -6.65950247e-02, ...,\n",
              "          -1.78334617e-01, -2.57563856e-04, -6.78878459e-03]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0014,  ..., -0.0015,  0.0017, -0.0009],\n",
              "          [ 0.0010,  0.0036, -0.0065,  ..., -0.0146,  0.0040, -0.0006],\n",
              "          [-0.0006,  0.0077, -0.0071,  ..., -0.0034,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0009, -0.0036,  ...,  0.0244, -0.0044, -0.0336],\n",
              "          [-0.0035,  0.0007, -0.0056,  ..., -0.0187,  0.0084,  0.0003],\n",
              "          [-0.0026, -0.0033, -0.0095,  ..., -0.0618, -0.0082, -0.0218]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6631e-03, -3.5472e-03,  1.5186e-04,  ...,  1.2211e-03,\n",
              "            2.3418e-03,  9.3135e-05],\n",
              "          [-2.4105e-03,  4.3088e-05, -3.0964e-04,  ...,  5.7187e-03,\n",
              "           -1.6653e-03, -1.4083e-02],\n",
              "          [ 3.6502e-03,  1.0029e-02, -1.6495e-03,  ..., -1.2799e-02,\n",
              "           -8.5191e-03,  1.6151e-02],\n",
              "          ...,\n",
              "          [-2.4354e-03,  1.2903e-03, -8.5261e-03,  ...,  4.7600e-03,\n",
              "            1.3520e-03, -9.7023e-03],\n",
              "          [ 1.2906e-04,  5.4160e-03,  5.0022e-03,  ...,  3.5847e-02,\n",
              "            2.9406e-03,  5.2141e-04],\n",
              "          [-3.9831e-03, -4.1730e-03, -3.0431e-03,  ..., -2.0722e-02,\n",
              "            3.0515e-03, -1.4186e-03]], dtype=torch.float64), 'final_loss': 0.021919344614518516, 'loss_breakdown': {'ot': 0.021888248960522633,\n",
              "   'ortho': 1.9759404276883053e-05,\n",
              "   'graph': 113.36249718999812}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15199610658186533}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[ 0.45052781, -0.27539442, -0.03959662, ..., -0.02421996,\n",
              "           0.02648991, -0.00642587],\n",
              "         [-0.28344474,  0.29926156, -0.27181381, ..., -0.06850882,\n",
              "           0.02708461, -0.0394025 ],\n",
              "         [-0.09318893,  0.48340441, -0.29109121, ...,  0.02127276,\n",
              "           0.02690496, -0.01087424],\n",
              "         ...,\n",
              "         [-0.10901716,  0.33434382, -0.18752504, ...,  0.21835218,\n",
              "          -0.03365181, -0.24036328],\n",
              "         [-0.35243716, -0.12362116, -0.01642589, ..., -0.1124646 ,\n",
              "           0.02905878,  0.03760857],\n",
              "         [-0.29537263, -0.0244755 ,  0.02970424, ..., -0.17616194,\n",
              "          -0.07789116, -0.08152916]]), 'mapped_Y': array([[ 0.51727444, -0.18409876, -0.06317101, ..., -0.00286851,\n",
              "           0.03838821,  0.00783078],\n",
              "         [-0.47013855, -0.22006519,  0.01631937, ...,  0.08732   ,\n",
              "          -0.01653939, -0.11885669],\n",
              "         [ 0.08099701,  0.20941403, -0.05275718, ..., -0.06845435,\n",
              "          -0.06832474,  0.14522969],\n",
              "         ...,\n",
              "         [-0.13035234,  0.45411745, -0.28851624, ...,  0.09136192,\n",
              "           0.0523776 , -0.14372534],\n",
              "         [-0.39607829, -0.27317299,  0.10861317, ...,  0.28467867,\n",
              "          -0.02028736,  0.03320928],\n",
              "         [-0.391328  , -0.11995175, -0.01878548, ..., -0.18174615,\n",
              "           0.00366785, -0.00244941]]), 'alpha': tensor([[ 0.0015, -0.0004, -0.0015,  ..., -0.0010,  0.0018, -0.0008],\n",
              "          [ 0.0008,  0.0037, -0.0064,  ..., -0.0133,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0074,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0005, -0.0018, -0.0031,  ...,  0.0230, -0.0049, -0.0334],\n",
              "          [-0.0035,  0.0014, -0.0051,  ..., -0.0237,  0.0086, -0.0012],\n",
              "          [-0.0024, -0.0024, -0.0062,  ..., -0.0539, -0.0080, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7877e-03, -3.2013e-03,  3.0605e-04,  ...,  3.5724e-03,\n",
              "            2.8634e-03,  4.1755e-04],\n",
              "          [-2.3394e-03, -3.4586e-04,  5.6782e-04,  ...,  5.5862e-03,\n",
              "           -3.3102e-03, -1.4050e-02],\n",
              "          [ 4.9002e-03,  9.1734e-03, -2.7777e-03,  ..., -6.3997e-03,\n",
              "           -1.2108e-02,  1.6310e-02],\n",
              "          ...,\n",
              "          [-3.0729e-03, -5.1903e-04, -8.5332e-03,  ...,  2.7807e-03,\n",
              "            2.3009e-03, -9.9624e-03],\n",
              "          [-7.7511e-05,  2.9454e-03,  4.9263e-03,  ...,  3.5498e-02,\n",
              "            1.3785e-03, -2.5866e-04],\n",
              "          [-3.7431e-03, -3.0729e-03, -1.5434e-03,  ..., -1.9957e-02,\n",
              "            2.8275e-03, -9.7872e-04]], dtype=torch.float64), 'final_loss': 0.021728892178650684, 'loss_breakdown': {'ot': 0.021696404656399968,\n",
              "   'ortho': 2.11968031627531e-05,\n",
              "   'graph': 112.90719087964948}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.1514296087698605}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[ 4.49191413e-01, -2.89332130e-01, -5.39696125e-02, ...,\n",
              "          -3.00421111e-04,  4.60370929e-03, -2.84703531e-03],\n",
              "         [-2.73104237e-01,  3.38212119e-01, -2.41436192e-01, ...,\n",
              "          -1.00136316e-01,  3.84101324e-02, -2.96949428e-03],\n",
              "         [-7.32048610e-02,  5.25926459e-01, -2.30630032e-01, ...,\n",
              "          -3.76841928e-02,  2.80088163e-02,  2.28796264e-02],\n",
              "         ...,\n",
              "         [-9.66247127e-02,  3.95882483e-01, -1.52320319e-01, ...,\n",
              "           2.02949973e-01, -2.35976510e-02, -2.06521463e-01],\n",
              "         [-3.39959875e-01, -1.30480170e-01, -3.19514079e-02, ...,\n",
              "          -3.37359585e-02,  4.88103568e-02,  1.48032565e-02],\n",
              "         [-2.92406782e-01, -1.40936244e-02,  4.17569086e-02, ...,\n",
              "          -6.61781268e-02, -2.48471207e-02, -1.13097343e-01]]), 'mapped_Y': array([[ 0.49899085, -0.25094159, -0.00794346, ..., -0.01665716,\n",
              "           0.02332564, -0.0060863 ],\n",
              "         [-0.49390872, -0.17477361, -0.03638126, ...,  0.12608627,\n",
              "           0.02181698, -0.13902228],\n",
              "         [ 0.0875751 ,  0.18617134,  0.01466864, ..., -0.1021096 ,\n",
              "          -0.04107422,  0.09032276],\n",
              "         ...,\n",
              "         [-0.03640231,  0.48028194, -0.36523833, ...,  0.04668641,\n",
              "           0.01592784, -0.07560113],\n",
              "         [-0.44393548, -0.26882202,  0.05202451, ...,  0.35364461,\n",
              "           0.07856104,  0.005802  ],\n",
              "         [-0.39988894, -0.08052617, -0.03645151, ..., -0.19926339,\n",
              "          -0.02872175, -0.01296074]]), 'alpha': tensor([[ 4.1302e-03, -4.8360e-03, -3.6460e-04,  ...,  9.5953e-04,\n",
              "            1.7188e-03, -1.4662e-03],\n",
              "          [-9.0325e-04,  3.4844e-03, -7.1046e-03,  ..., -1.4457e-02,\n",
              "            5.0023e-03,  5.1368e-04],\n",
              "          [ 4.8984e-04,  5.9729e-03, -6.8314e-03,  ..., -6.0641e-03,\n",
              "            3.3768e-03,  4.7466e-03],\n",
              "          ...,\n",
              "          [ 3.2662e-04,  4.2487e-03, -4.8513e-03,  ...,  2.6273e-02,\n",
              "           -4.6873e-03, -3.2820e-02],\n",
              "          [-3.3691e-03, -7.2995e-04, -1.8078e-03,  ..., -3.5338e-03,\n",
              "            8.6271e-03,  3.4241e-03],\n",
              "          [-3.0377e-03,  8.1313e-04,  5.5822e-05,  ..., -9.8928e-03,\n",
              "           -2.8829e-03, -1.7521e-02]], dtype=torch.float64), 'beta': tensor([[ 2.1976e-03, -2.3990e-03, -1.2106e-03,  ..., -5.5339e-04,\n",
              "            3.3085e-03,  2.9227e-04],\n",
              "          [-2.1650e-03, -3.3673e-03,  3.5105e-05,  ...,  1.0757e-02,\n",
              "            1.1594e-03, -1.7165e-02],\n",
              "          [-4.3880e-04,  3.5216e-03,  1.3888e-03,  ..., -8.5210e-03,\n",
              "           -3.0654e-03,  1.1494e-02],\n",
              "          ...,\n",
              "          [-1.2333e-03,  7.5054e-03, -8.6818e-03,  ...,  5.3530e-03,\n",
              "            2.5763e-03, -9.7895e-03],\n",
              "          [-1.8448e-03, -4.6412e-03,  3.7911e-04,  ...,  3.1974e-02,\n",
              "            6.7756e-03, -3.2530e-04],\n",
              "          [-1.5625e-03, -2.0907e-03,  3.3678e-05,  ..., -1.7580e-02,\n",
              "           -3.8426e-03, -2.5070e-03]], dtype=torch.float64), 'final_loss': 0.011453736506117584, 'loss_breakdown': {'ot': 0.011452585432226459,\n",
              "   'ortho': 5.144895456478322e-29,\n",
              "   'graph': 115.1073891125483}, 'best_iter': 1, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1522615669092299}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.45713125, -0.26573401, -0.01730553, ..., -0.01658666,\n",
              "           0.02306238, -0.00708587],\n",
              "         [-0.26497279,  0.30774592, -0.28035551, ..., -0.0762933 ,\n",
              "           0.0291928 , -0.03593726],\n",
              "         [-0.07612367,  0.49748134, -0.27056165, ...,  0.00404929,\n",
              "           0.02647697, -0.00635153],\n",
              "         ...,\n",
              "         [-0.09807421,  0.35396103, -0.17731102, ...,  0.20969164,\n",
              "          -0.03043135, -0.23862141],\n",
              "         [-0.34798557, -0.13496059, -0.05343217, ..., -0.09320067,\n",
              "           0.0301478 ,  0.04489568],\n",
              "         [-0.30014984, -0.03709722, -0.00961658, ..., -0.16584001,\n",
              "          -0.07506382, -0.07934852]]), 'mapped_Y': array([[ 5.23684973e-01, -1.76881010e-01, -2.98114686e-02, ...,\n",
              "          -1.69694766e-02,  3.51012861e-02,  8.37985632e-03],\n",
              "         [-4.63929774e-01, -2.22955004e-01, -4.32457744e-02, ...,\n",
              "           1.04551337e-01, -5.69595865e-03, -1.17460658e-01],\n",
              "         [ 7.66957166e-02,  2.10287973e-01, -2.52855045e-02, ...,\n",
              "          -9.58954751e-02, -5.39609572e-02,  1.48067541e-01],\n",
              "         ...,\n",
              "         [-1.09054291e-01,  4.73228466e-01, -2.75577108e-01, ...,\n",
              "           9.08553444e-02,  4.09653459e-02, -1.36559441e-01],\n",
              "         [-3.93680603e-01, -2.62778970e-01,  6.31578568e-02, ...,\n",
              "           3.10050133e-01, -6.33912154e-04,  4.00498018e-02],\n",
              "         [-3.88757312e-01, -1.38258168e-01, -6.66362929e-02, ...,\n",
              "          -1.78334876e-01, -2.43595490e-04, -6.79102671e-03]]), 'alpha': tensor([[ 0.0015, -0.0003, -0.0014,  ..., -0.0015,  0.0017, -0.0009],\n",
              "          [ 0.0010,  0.0036, -0.0065,  ..., -0.0146,  0.0040, -0.0006],\n",
              "          [-0.0006,  0.0077, -0.0071,  ..., -0.0034,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0002,  0.0009, -0.0036,  ...,  0.0244, -0.0044, -0.0336],\n",
              "          [-0.0035,  0.0007, -0.0056,  ..., -0.0188,  0.0084,  0.0003],\n",
              "          [-0.0026, -0.0033, -0.0095,  ..., -0.0618, -0.0082, -0.0218]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.6631e-03, -3.5475e-03,  1.5165e-04,  ...,  1.2197e-03,\n",
              "            2.3419e-03,  9.3385e-05],\n",
              "          [-2.4104e-03,  4.3070e-05, -3.1058e-04,  ...,  5.7169e-03,\n",
              "           -1.6640e-03, -1.4083e-02],\n",
              "          [ 3.6494e-03,  1.0031e-02, -1.6500e-03,  ..., -1.2802e-02,\n",
              "           -8.5165e-03,  1.6150e-02],\n",
              "          ...,\n",
              "          [-2.4349e-03,  1.2912e-03, -8.5256e-03,  ...,  4.7618e-03,\n",
              "            1.3493e-03, -9.7018e-03],\n",
              "          [ 1.2983e-04,  5.4161e-03,  5.0022e-03,  ...,  3.5846e-02,\n",
              "            2.9397e-03,  5.2155e-04],\n",
              "          [-3.9833e-03, -4.1720e-03, -3.0441e-03,  ..., -2.0724e-02,\n",
              "            3.0560e-03, -1.4189e-03]], dtype=torch.float64), 'final_loss': 0.021909168769622903, 'loss_breakdown': {'ot': 0.021888280919326056,\n",
              "   'ortho': 1.975421944222744e-05,\n",
              "   'graph': 113.36308546197554}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15199565046446434}},\n",
              " (8,\n",
              "  5,\n",
              "  1,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.4505207 , -0.27540944, -0.03959522, ..., -0.02422116,\n",
              "           0.02648632, -0.00642506],\n",
              "         [-0.28343253,  0.29927654, -0.27181079, ..., -0.06851023,\n",
              "           0.02708719, -0.03940201],\n",
              "         [-0.09317089,  0.48341476, -0.29108154, ...,  0.02126745,\n",
              "           0.02690956, -0.01087007],\n",
              "         ...,\n",
              "         [-0.10900352,  0.33435389, -0.18752049, ...,  0.21835413,\n",
              "          -0.03364638, -0.24035815],\n",
              "         [-0.35244174, -0.12361261, -0.01643605, ..., -0.11244294,\n",
              "           0.02905679,  0.03760112],\n",
              "         [-0.2953768 , -0.02446112,  0.02969462, ..., -0.17615164,\n",
              "          -0.07789188, -0.08153433]]), 'mapped_Y': array([[ 0.51726983, -0.18411317, -0.06316899, ..., -0.0028797 ,\n",
              "           0.03838862,  0.00783481],\n",
              "         [-0.47014557, -0.22005216,  0.01630544, ...,  0.08733454,\n",
              "          -0.01654229, -0.11886318],\n",
              "         [ 0.08100397,  0.20941189, -0.05274798, ..., -0.06846007,\n",
              "          -0.06832099,  0.14523185],\n",
              "         ...,\n",
              "         [-0.13033373,  0.45413042, -0.2885086 , ...,  0.09136884,\n",
              "           0.05237353, -0.14372176],\n",
              "         [-0.39608863, -0.27316777,  0.10860165, ...,  0.28468098,\n",
              "          -0.02028552,  0.03320316],\n",
              "         [-0.39133225, -0.11994076, -0.01879467, ..., -0.18175049,\n",
              "           0.00366259, -0.00245189]]), 'alpha': tensor([[ 0.0015, -0.0004, -0.0015,  ..., -0.0010,  0.0018, -0.0008],\n",
              "          [ 0.0008,  0.0037, -0.0064,  ..., -0.0133,  0.0039, -0.0026],\n",
              "          [-0.0011,  0.0077, -0.0074,  ..., -0.0030,  0.0052,  0.0034],\n",
              "          ...,\n",
              "          [-0.0005, -0.0018, -0.0031,  ...,  0.0230, -0.0049, -0.0334],\n",
              "          [-0.0035,  0.0014, -0.0051,  ..., -0.0237,  0.0086, -0.0012],\n",
              "          [-0.0024, -0.0024, -0.0062,  ..., -0.0539, -0.0080, -0.0231]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.7877e-03, -3.2016e-03,  3.0579e-04,  ...,  3.5707e-03,\n",
              "            2.8628e-03,  4.1804e-04],\n",
              "          [-2.3395e-03, -3.4586e-04,  5.6744e-04,  ...,  5.5889e-03,\n",
              "           -3.3105e-03, -1.4050e-02],\n",
              "          [ 4.9003e-03,  9.1726e-03, -2.7777e-03,  ..., -6.4002e-03,\n",
              "           -1.2109e-02,  1.6310e-02],\n",
              "          ...,\n",
              "          [-3.0725e-03, -5.1853e-04, -8.5329e-03,  ...,  2.7807e-03,\n",
              "            2.3005e-03, -9.9620e-03],\n",
              "          [-7.7623e-05,  2.9445e-03,  4.9267e-03,  ...,  3.5497e-02,\n",
              "            1.3772e-03, -2.5872e-04],\n",
              "          [-3.7431e-03, -3.0720e-03, -1.5436e-03,  ..., -1.9958e-02,\n",
              "            2.8280e-03, -9.7874e-04]], dtype=torch.float64), 'final_loss': 0.021719251844675297, 'loss_breakdown': {'ot': 0.02169693067928813,\n",
              "   'ortho': 2.119207752708022e-05,\n",
              "   'graph': 112.90878600849769}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9665711556829035,\n",
              "   'accuracy_raw': 0.9665711556829035,\n",
              "   'foscttm': 0.15142869653505858}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 1.03651683e-01,  1.11209706e-01, -1.84105350e-02, ...,\n",
              "          -2.93382762e-03,  4.58605023e-02, -1.07756081e-02],\n",
              "         [ 2.55487200e-02,  6.54471793e-02, -1.78565632e-02, ...,\n",
              "          -2.12124096e-02,  2.25949763e-02, -1.84572856e-02],\n",
              "         [-3.85178928e-02,  1.13826682e-01, -8.15998571e-02, ...,\n",
              "           2.47021548e-02,  2.22420306e-02,  1.48625714e-02],\n",
              "         ...,\n",
              "         [-1.35639252e-02,  9.55461831e-02,  2.11668639e-02, ...,\n",
              "          -1.70505893e-02, -4.22183074e-02,  7.55415132e-04],\n",
              "         [-5.12321489e-02, -6.51616022e-02,  3.75571893e-02, ...,\n",
              "          -1.71246774e-02,  3.74635717e-02,  1.04188442e-05],\n",
              "         [-1.41586612e-02, -2.22600746e-02,  4.84511756e-02, ...,\n",
              "          -3.13918799e-02, -3.35072976e-03, -1.10973115e-02]]), 'mapped_Y': array([[ 1.07011403e-01,  5.38386170e-02, -2.38239099e-02, ...,\n",
              "          -2.12703440e-02,  2.49504184e-02, -1.42521768e-02],\n",
              "         [-3.88977393e-02, -6.53481068e-02,  6.43798500e-03, ...,\n",
              "           4.83146842e-03, -2.00359233e-02, -3.28281512e-04],\n",
              "         [ 2.46518213e-02,  4.55931737e-02,  3.87767533e-02, ...,\n",
              "           2.65239261e-02, -5.63069419e-03,  2.10929755e-02],\n",
              "         ...,\n",
              "         [-1.49563529e-01,  1.17142657e-01, -8.94491906e-02, ...,\n",
              "           2.60144441e-02,  2.76989566e-02, -4.32189083e-02],\n",
              "         [-4.87522143e-02, -3.53205197e-02, -4.20164431e-02, ...,\n",
              "           8.49233158e-02, -1.26801916e-03,  3.95898944e-02],\n",
              "         [-5.47794295e-02, -9.21412866e-02, -4.77726073e-05, ...,\n",
              "           2.41414996e-02, -1.78537491e-02,  1.60480150e-02]]), 'alpha': tensor([[ 0.0092,  0.0529, -0.0045,  ..., -0.0021, -0.0023, -0.0031],\n",
              "          [ 0.0419,  0.0254,  0.0548,  ..., -0.0126,  0.0028, -0.0050],\n",
              "          [ 0.0110,  0.0047, -0.0532,  ...,  0.0212, -0.0043,  0.0056],\n",
              "          ...,\n",
              "          [ 0.0305,  0.0220,  0.0887,  ..., -0.0626, -0.1526,  0.0385],\n",
              "          [-0.0098, -0.0156,  0.0168,  ..., -0.0148,  0.0532, -0.0061],\n",
              "          [ 0.0031,  0.0502,  0.0376,  ..., -0.0563, -0.0102, -0.0278]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0008,  0.0447, -0.0047,  ...,  0.0062, -0.0033,  0.0111],\n",
              "          [ 0.0106,  0.0201,  0.0137,  ...,  0.0016, -0.0013, -0.0094],\n",
              "          [-0.0328, -0.0178,  0.0376,  ...,  0.1749,  0.0475,  0.0544],\n",
              "          ...,\n",
              "          [-0.0456,  0.0081, -0.0134,  ...,  0.0061,  0.0049, -0.0301],\n",
              "          [ 0.0108,  0.0086, -0.0306,  ...,  0.1144,  0.0179,  0.0334],\n",
              "          [-0.0137, -0.0366, -0.0043,  ...,  0.0351, -0.0111,  0.0213]],\n",
              "         dtype=torch.float64), 'final_loss': 0.016700805984667125, 'loss_breakdown': {'ot': 0.0017831612022955726,\n",
              "   'ortho': 0.0005140300204805091,\n",
              "   'graph': 14.866241780323502}, 'best_iter': 2249, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9140401146131805,\n",
              "   'accuracy_raw': 0.9140401146131805,\n",
              "   'foscttm': 0.23228873326163169}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[ 0.18198085,  0.01241892, -0.05521487, ..., -0.00728813,\n",
              "           0.03303289, -0.01549646],\n",
              "         [ 0.0286781 ,  0.07833217, -0.06277039, ...,  0.00925781,\n",
              "          -0.00474958, -0.00082885],\n",
              "         [-0.05019246,  0.11135643, -0.12309915, ...,  0.0532202 ,\n",
              "           0.06296541, -0.00155023],\n",
              "         ...,\n",
              "         [-0.02866489,  0.1113097 , -0.02913302, ..., -0.00387556,\n",
              "           0.00149385, -0.01060091],\n",
              "         [-0.07718538, -0.00299592,  0.05140044, ..., -0.02982554,\n",
              "           0.08115389, -0.01113562],\n",
              "         [-0.03264689, -0.00608067,  0.04398757, ..., -0.03267536,\n",
              "          -0.00809924, -0.0109475 ]]), 'mapped_Y': array([[ 0.13076031, -0.04191924, -0.04216054, ..., -0.02222821,\n",
              "           0.01449442, -0.02844858],\n",
              "         [-0.05165797, -0.03023923,  0.05256777, ...,  0.01675627,\n",
              "          -0.0194894 ,  0.0105071 ],\n",
              "         [ 0.06158309,  0.05331902,  0.02349233, ...,  0.000433  ,\n",
              "           0.0090966 ,  0.02461331],\n",
              "         ...,\n",
              "         [-0.10056563,  0.12724617, -0.13681074, ...,  0.08914067,\n",
              "           0.0579615 , -0.04556172],\n",
              "         [-0.08325187,  0.03466722,  0.05996793, ...,  0.01102948,\n",
              "           0.03582326, -0.00938127],\n",
              "         [-0.09901036, -0.04515213,  0.02785364, ...,  0.00979859,\n",
              "          -0.03998946,  0.00325972]]), 'alpha': tensor([[ 0.0779,  0.0409, -0.0222,  ...,  0.0034,  0.0058,  0.0004],\n",
              "          [ 0.1111,  0.0229,  0.0249,  ..., -0.0166, -0.0340,  0.0170],\n",
              "          [-0.0009, -0.0022, -0.0295,  ...,  0.0366,  0.0141,  0.0082],\n",
              "          ...,\n",
              "          [-0.0008,  0.0554,  0.0234,  ..., -0.1081, -0.0677,  0.0331],\n",
              "          [-0.0170,  0.0007,  0.0061,  ..., -0.0202,  0.0862, -0.0104],\n",
              "          [ 0.0221, -0.0028,  0.0080,  ..., -0.0361, -0.0122, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0025,  0.0388, -0.0027,  ..., -0.0053, -0.0057, -0.0108],\n",
              "          [ 0.0228, -0.0031,  0.0168,  ...,  0.0043,  0.0063, -0.0014],\n",
              "          [ 0.0054,  0.0275,  0.0772,  ...,  0.0296,  0.0504, -0.0012],\n",
              "          ...,\n",
              "          [-0.0212,  0.0048, -0.0516,  ...,  0.0461, -0.0028, -0.0260],\n",
              "          [ 0.0029,  0.0495,  0.0453,  ...,  0.0119,  0.0440, -0.0128],\n",
              "          [-0.0232, -0.0138,  0.0152,  ...,  0.0031, -0.0247,  0.0067]],\n",
              "         dtype=torch.float64), 'final_loss': 0.01702765525307524, 'loss_breakdown': {'ot': 0.0018854237719168555,\n",
              "   'ortho': 0.0005340547060996303,\n",
              "   'graph': 15.088826010548422}, 'best_iter': 2751, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.893505253104107,\n",
              "   'accuracy_raw': 0.893505253104107,\n",
              "   'foscttm': 0.22474546368438864}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[ 0.18181075,  0.03942655, -0.03008099, ...,  0.0051249 ,\n",
              "           0.02585563, -0.01614375],\n",
              "         [ 0.0260092 ,  0.08455763, -0.06845369, ...,  0.01911589,\n",
              "           0.00350098, -0.00284337],\n",
              "         [-0.0495549 ,  0.09574931, -0.14206614, ...,  0.0730881 ,\n",
              "           0.08154083,  0.01534522],\n",
              "         ...,\n",
              "         [-0.03763228,  0.10919169, -0.035688  , ...,  0.0185789 ,\n",
              "           0.01387999, -0.00990931],\n",
              "         [-0.07177027, -0.0254615 ,  0.03252559, ..., -0.05292368,\n",
              "           0.05686183, -0.01527464],\n",
              "         [-0.02862806, -0.01475428,  0.04079225, ..., -0.03493182,\n",
              "           0.00164178, -0.01369572]]), 'mapped_Y': array([[ 0.14802694, -0.02361864, -0.03577785, ..., -0.01285785,\n",
              "           0.00394921, -0.02342211],\n",
              "         [-0.06182915, -0.04664739,  0.04469097, ..., -0.00519768,\n",
              "          -0.02294096,  0.00062741],\n",
              "         [ 0.04593729,  0.07753036,  0.03919087, ...,  0.00129934,\n",
              "           0.00524207,  0.01045026],\n",
              "         ...,\n",
              "         [-0.09363357,  0.10598964, -0.15930356, ...,  0.11990637,\n",
              "           0.07778109, -0.02211168],\n",
              "         [-0.0750097 , -0.01240468,  0.03137369, ..., -0.00688302,\n",
              "           0.04373245, -0.01538295],\n",
              "         [-0.11126377, -0.05984833,  0.01526437, ..., -0.00242865,\n",
              "          -0.03894849,  0.00371931]]), 'alpha': tensor([[ 0.0633,  0.0422, -0.0188,  ...,  0.0068,  0.0065, -0.0029],\n",
              "          [ 0.1039,  0.0363,  0.0334,  ..., -0.0118, -0.0304,  0.0095],\n",
              "          [ 0.0003, -0.0045, -0.0323,  ...,  0.0364,  0.0198,  0.0156],\n",
              "          ...,\n",
              "          [-0.0107,  0.0662,  0.0371,  ..., -0.0735, -0.0591,  0.0321],\n",
              "          [-0.0023, -0.0040, -0.0018,  ..., -0.0335,  0.0600, -0.0100],\n",
              "          [ 0.0377,  0.0054,  0.0221,  ..., -0.0348, -0.0171, -0.0251]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0055,  0.0238, -0.0198,  ..., -0.0021, -0.0014, -0.0052],\n",
              "          [ 0.0198,  0.0039,  0.0230,  ...,  0.0041,  0.0017, -0.0027],\n",
              "          [ 0.0007,  0.0336,  0.0944,  ...,  0.0414,  0.0570, -0.0126],\n",
              "          ...,\n",
              "          [-0.0172,  0.0083, -0.0445,  ...,  0.0598, -0.0076, -0.0193],\n",
              "          [-0.0015,  0.0346,  0.0235,  ...,  0.0109,  0.0459, -0.0092],\n",
              "          [-0.0291, -0.0179,  0.0118,  ..., -0.0026, -0.0233,  0.0053]],\n",
              "         dtype=torch.float64), 'final_loss': 0.016761661073106185, 'loss_breakdown': {'ot': 0.0017002008192278976,\n",
              "   'ortho': 0.0005205243585209047,\n",
              "   'graph': 15.009407818026197}, 'best_iter': 2776, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9097421203438396,\n",
              "   'accuracy_raw': 0.9097421203438396,\n",
              "   'foscttm': 0.21446457746652325}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 3.13428105e-01, -1.37598909e-01, -7.79359440e-02, ...,\n",
              "           1.77373214e-02,  1.81050986e-01,  5.34241751e-02],\n",
              "         [-1.10140132e-01,  2.46286013e-01, -1.27827663e-01, ...,\n",
              "          -1.61851166e-01, -1.72569949e-01, -8.96924105e-02],\n",
              "         [ 1.17045916e-01,  3.25404829e-01, -1.10599380e-01, ...,\n",
              "          -2.02771253e-02, -1.55179448e-01, -6.42182158e-02],\n",
              "         ...,\n",
              "         [ 3.52650276e-02,  2.32253352e-01, -6.26125865e-02, ...,\n",
              "           6.19248127e-02, -1.34672086e-01, -2.18696611e-01],\n",
              "         [-3.26407997e-01,  4.79742239e-02, -3.68696929e-02, ...,\n",
              "          -1.85000387e-01,  5.59870470e-03,  8.50486015e-02],\n",
              "         [-3.01023880e-01, -2.18564652e-02, -1.36713066e-04, ...,\n",
              "          -1.02098264e-01, -1.17942234e-02, -5.57545639e-02]]), 'mapped_Y': array([[ 0.37284964, -0.14765815, -0.060977  , ..., -0.01605146,\n",
              "           0.16995512,  0.03613869],\n",
              "         [-0.43350231, -0.01440383, -0.05273131, ..., -0.08421818,\n",
              "          -0.0580925 ,  0.05359114],\n",
              "         [ 0.13408416,  0.10988757,  0.04744167, ..., -0.05456968,\n",
              "          -0.04290526,  0.09918356],\n",
              "         ...,\n",
              "         [ 0.05953521,  0.34272496, -0.17521479, ..., -0.02795522,\n",
              "          -0.20539043, -0.21694412],\n",
              "         [-0.35317732,  0.0236546 , -0.05996943, ...,  0.0582864 ,\n",
              "           0.05416703,  0.07021289],\n",
              "         [-0.37928313, -0.01915598, -0.06051121, ..., -0.09403323,\n",
              "          -0.05261811,  0.04601853]]), 'alpha': tensor([[ 0.0116,  0.0369, -0.0046,  ..., -0.0046,  0.0199, -0.0030],\n",
              "          [ 0.0146, -0.0102,  0.0128,  ..., -0.0514, -0.0155, -0.0113],\n",
              "          [ 0.0053,  0.0110, -0.0190,  ...,  0.0117,  0.0103, -0.0047],\n",
              "          ...,\n",
              "          [ 0.0035,  0.0142, -0.0051,  ..., -0.0102,  0.0037, -0.0173],\n",
              "          [-0.0042,  0.0311, -0.0005,  ..., -0.0782,  0.0218,  0.0005],\n",
              "          [-0.0118,  0.0094, -0.0124,  ..., -0.0957,  0.0080, -0.0271]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0020,  0.0054, -0.0017,  ..., -0.0039,  0.0133, -0.0039],\n",
              "          [ 0.0039,  0.0056,  0.0155,  ..., -0.0135, -0.0039,  0.0041],\n",
              "          [ 0.0094,  0.0228,  0.0263,  ..., -0.0138,  0.0014,  0.0282],\n",
              "          ...,\n",
              "          [-0.0065, -0.0008, -0.0209,  ..., -0.0111,  0.0015, -0.0402],\n",
              "          [ 0.0202,  0.0289, -0.0102,  ...,  0.0193,  0.0289,  0.0126],\n",
              "          [-0.0129, -0.0078, -0.0015,  ...,  0.0026, -0.0167, -0.0029]],\n",
              "         dtype=torch.float64), 'final_loss': 0.010055181810349022, 'loss_breakdown': {'ot': 0.004073461345692896,\n",
              "   'ortho': 0.00026495448067697394,\n",
              "   'graph': 59.55225016588429}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9641833810888252,\n",
              "   'accuracy_raw': 0.9641833810888252,\n",
              "   'foscttm': 0.14932827590359138}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.41298459, -0.12186621, -0.04126788, ...,  0.06281958,\n",
              "           0.05283706, -0.07345341],\n",
              "         [-0.15324665,  0.3125831 , -0.10533071, ..., -0.15828474,\n",
              "          -0.031899  ,  0.0338134 ],\n",
              "         [ 0.01512793,  0.42096262, -0.04238972, ..., -0.07220389,\n",
              "           0.01872665, -0.01811808],\n",
              "         ...,\n",
              "         [-0.05181581,  0.30809525, -0.00997699, ..., -0.01656339,\n",
              "          -0.00092069, -0.14092272],\n",
              "         [-0.33378606, -0.03354724, -0.1413909 , ..., -0.07052344,\n",
              "           0.06968183,  0.12857662],\n",
              "         [-0.29713227, -0.02725229, -0.05970838, ..., -0.10194547,\n",
              "           0.03734593,  0.06348242]]), 'mapped_Y': array([[ 0.46322231, -0.13109298, -0.01520073, ...,  0.03307947,\n",
              "           0.10498787, -0.11969483],\n",
              "         [-0.42658019, -0.09091626, -0.08758033, ..., -0.04698286,\n",
              "          -0.04745635,  0.12363353],\n",
              "         [ 0.07982671,  0.18373717,  0.06352868, ..., -0.04179336,\n",
              "          -0.018268  ,  0.00483562],\n",
              "         ...,\n",
              "         [-0.05879871,  0.39033076, -0.06513107, ..., -0.01806648,\n",
              "           0.04031785, -0.02745692],\n",
              "         [-0.38406744, -0.11428798,  0.02970206, ...,  0.16461817,\n",
              "          -0.06714018,  0.13144337],\n",
              "         [-0.29357823, -0.04298766, -0.12328921, ..., -0.10519443,\n",
              "           0.05768751,  0.1817275 ]]), 'alpha': tensor([[ 0.0044,  0.0291,  0.0145,  ..., -0.0006,  0.0074, -0.0051],\n",
              "          [ 0.0112,  0.0057,  0.0144,  ..., -0.0512, -0.0106, -0.0020],\n",
              "          [-0.0007,  0.0131, -0.0077,  ...,  0.0107,  0.0028, -0.0060],\n",
              "          ...,\n",
              "          [ 0.0029,  0.0233,  0.0010,  ...,  0.0101,  0.0025, -0.0186],\n",
              "          [-0.0127,  0.0028, -0.0130,  ..., -0.0577,  0.0578, -0.0005],\n",
              "          [-0.0132, -0.0036, -0.0226,  ..., -0.0799,  0.0567, -0.0185]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0001,  0.0027,  0.0033,  ...,  0.0029,  0.0244, -0.0051],\n",
              "          [-0.0037,  0.0046,  0.0117,  ..., -0.0076, -0.0070, -0.0060],\n",
              "          [ 0.0121,  0.0267,  0.0200,  ...,  0.0014, -0.0125, -0.0014],\n",
              "          ...,\n",
              "          [-0.0097, -0.0009, -0.0069,  ...,  0.0252,  0.0057,  0.0088],\n",
              "          [-0.0010,  0.0191,  0.0168,  ...,  0.0418,  0.0075, -0.0088],\n",
              "          [-0.0014, -0.0065, -0.0354,  ..., -0.0262,  0.0429,  0.0107]],\n",
              "         dtype=torch.float64), 'final_loss': 0.012173315885574396, 'loss_breakdown': {'ot': 0.0055687774059445735,\n",
              "   'ortho': 0.00041309293395638916,\n",
              "   'graph': 65.63229186234182}, 'best_iter': 2176, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.1491631614044402}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 4.55292095e-01, -1.09173089e-01,  7.09081830e-02, ...,\n",
              "           2.37450420e-02,  6.68289975e-02, -2.84796433e-02],\n",
              "         [-2.03000893e-01,  3.16771968e-01, -1.50668988e-01, ...,\n",
              "          -1.24159707e-01, -5.17260174e-02, -3.33291385e-02],\n",
              "         [-9.31279969e-02,  4.38968729e-01, -9.65926883e-06, ...,\n",
              "          -1.20246859e-01, -1.52463195e-02, -9.88376761e-02],\n",
              "         ...,\n",
              "         [-1.11212558e-01,  3.50870783e-01,  1.14323904e-02, ...,\n",
              "           5.47578764e-03,  9.62190998e-03, -2.05377240e-01],\n",
              "         [-2.57857615e-01, -3.43128765e-02, -2.16397950e-01, ...,\n",
              "          -3.63082219e-02,  5.34514932e-02,  1.07064934e-01],\n",
              "         [-2.62416904e-01, -4.71237221e-03, -1.91872525e-01, ...,\n",
              "          -6.19295946e-02,  3.20080736e-02,  1.25009781e-02]]), 'mapped_Y': array([[ 0.461907  , -0.12342557,  0.12686685, ..., -0.02016597,\n",
              "           0.10112678, -0.06062113],\n",
              "         [-0.312591  , -0.08352261, -0.23102981, ...,  0.17117016,\n",
              "          -0.04892941,  0.10527289],\n",
              "         [ 0.01113668,  0.15056485,  0.11793917, ..., -0.1137166 ,\n",
              "          -0.03263215,  0.05553335],\n",
              "         ...,\n",
              "         [-0.1486836 ,  0.43339905, -0.06727019, ..., -0.06072143,\n",
              "           0.00406985, -0.17731573],\n",
              "         [-0.25179479, -0.10652781, -0.1232977 , ...,  0.39417581,\n",
              "          -0.05572552,  0.15212104],\n",
              "         [-0.2507035 , -0.04197664, -0.20536974, ..., -0.06852555,\n",
              "           0.08491924,  0.13613691]]), 'alpha': tensor([[ 0.0016,  0.0236,  0.0138,  ..., -0.0021,  0.0074, -0.0032],\n",
              "          [ 0.0061,  0.0026,  0.0056,  ..., -0.0424, -0.0111, -0.0049],\n",
              "          [-0.0023,  0.0132, -0.0039,  ...,  0.0101,  0.0040, -0.0093],\n",
              "          ...,\n",
              "          [ 0.0043,  0.0251, -0.0011,  ...,  0.0011,  0.0062, -0.0163],\n",
              "          [-0.0113, -0.0002, -0.0201,  ..., -0.0636,  0.0352,  0.0002],\n",
              "          [-0.0096, -0.0005, -0.0454,  ..., -0.0778,  0.0397, -0.0179]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0016,  0.0009,  0.0059,  ...,  0.0018,  0.0197, -0.0016],\n",
              "          [-0.0043,  0.0036,  0.0118,  ...,  0.0021, -0.0114, -0.0039],\n",
              "          [ 0.0047,  0.0167,  0.0271,  ..., -0.0043, -0.0147,  0.0052],\n",
              "          ...,\n",
              "          [-0.0083, -0.0019, -0.0161,  ...,  0.0062,  0.0042, -0.0053],\n",
              "          [ 0.0012,  0.0197,  0.0188,  ...,  0.0633,  0.0119, -0.0062],\n",
              "          [-0.0040, -0.0052, -0.0235,  ..., -0.0332,  0.0430,  0.0044]],\n",
              "         dtype=torch.float64), 'final_loss': 0.012899038346348679, 'loss_breakdown': {'ot': 0.005924604929475512,\n",
              "   'ortho': 0.0005357569706564845,\n",
              "   'graph': 69.20857719807518}, 'best_iter': 2166, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9641833810888252,\n",
              "   'accuracy_raw': 0.9641833810888252,\n",
              "   'foscttm': 0.15042158931371666}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[ 4.03108397e-01, -2.48860587e-01, -1.45344392e-02, ...,\n",
              "          -4.48877052e-04,  5.32152459e-02, -1.05249115e-01],\n",
              "         [-1.31812645e-01,  3.38404074e-01, -1.80000954e-01, ...,\n",
              "          -1.28206465e-01,  1.20839836e-02,  6.09699483e-02],\n",
              "         [ 4.22082062e-02,  4.70465008e-01, -7.28972598e-02, ...,\n",
              "          -5.44724570e-02,  3.08356751e-02,  1.00710787e-01],\n",
              "         ...,\n",
              "         [-2.73241737e-02,  3.86866491e-01, -1.90511023e-02, ...,\n",
              "           1.46176455e-01, -3.13772040e-03, -1.84750819e-01],\n",
              "         [-3.32635163e-01, -1.04495444e-02, -1.84573971e-01, ...,\n",
              "          -5.71228237e-02, -4.89873880e-02,  6.86484150e-02],\n",
              "         [-3.26117580e-01, -2.96752671e-02, -6.15661076e-02, ...,\n",
              "          -1.53253622e-01, -1.39494054e-01, -7.09638956e-02]]), 'mapped_Y': array([[ 0.44331169, -0.20188916,  0.02367685, ..., -0.02438182,\n",
              "           0.02631806, -0.08034338],\n",
              "         [-0.39139875, -0.09979583, -0.21257443, ...,  0.10541274,\n",
              "          -0.03476285, -0.07129809],\n",
              "         [ 0.10361429,  0.1393885 ,  0.0554125 , ..., -0.16416367,\n",
              "          -0.02381328,  0.17705629],\n",
              "         ...,\n",
              "         [-0.01148333,  0.52255434, -0.10854634, ...,  0.06745781,\n",
              "           0.02757403, -0.05243914],\n",
              "         [-0.31131531, -0.15020317, -0.12858255, ...,  0.39363703,\n",
              "          -0.04710066,  0.06137313],\n",
              "         [-0.3594838 , -0.04220961, -0.17484526, ..., -0.19737704,\n",
              "          -0.03821031, -0.00391474]]), 'alpha': tensor([[ 0.0018,  0.0085, -0.0009,  ..., -0.0003,  0.0043, -0.0017],\n",
              "          [ 0.0040, -0.0042,  0.0035,  ..., -0.0198,  0.0017,  0.0020],\n",
              "          [ 0.0016,  0.0078, -0.0086,  ..., -0.0027,  0.0061,  0.0042],\n",
              "          ...,\n",
              "          [-0.0018,  0.0139, -0.0020,  ...,  0.0217, -0.0017, -0.0358],\n",
              "          [-0.0034,  0.0112, -0.0090,  ..., -0.0201,  0.0090,  0.0020],\n",
              "          [-0.0052, -0.0055, -0.0111,  ..., -0.0650, -0.0055, -0.0246]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-5.9063e-04,  7.6581e-05, -6.6126e-04,  ..., -1.4462e-03,\n",
              "           -5.6709e-04, -9.4621e-04],\n",
              "          [ 2.5673e-03, -9.8596e-04, -7.5067e-04,  ...,  5.9060e-04,\n",
              "            2.4130e-03, -8.7189e-03],\n",
              "          [ 6.5857e-03,  6.6667e-03,  6.4351e-03,  ..., -2.5021e-02,\n",
              "           -5.5976e-03,  1.8973e-02],\n",
              "          ...,\n",
              "          [-2.8111e-03,  6.5046e-03, -8.9583e-03,  ...,  9.3525e-03,\n",
              "            2.2264e-03, -1.4625e-02],\n",
              "          [ 7.7975e-03,  6.4120e-03,  3.6495e-03,  ...,  3.9288e-02,\n",
              "            1.1184e-02,  1.0514e-02],\n",
              "          [-1.0621e-02, -1.2398e-03, -2.9415e-03,  ..., -2.2126e-02,\n",
              "           -2.7604e-03, -6.3272e-03]], dtype=torch.float64), 'final_loss': 0.008852531632137355, 'loss_breakdown': {'ot': 0.007793378137720305,\n",
              "   'ortho': 7.712657426278367e-05,\n",
              "   'graph': 105.14408369907716}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.1542196789115944}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[ 4.00091961e-01, -1.67302630e-01, -6.14447370e-02, ...,\n",
              "           3.70331186e-02,  4.57844418e-02,  6.99632420e-02],\n",
              "         [-1.96921630e-01,  3.10330594e-01, -1.25294628e-01, ...,\n",
              "          -1.47262152e-01, -3.79142339e-02, -3.26913817e-02],\n",
              "         [-1.67224148e-04,  4.62988682e-01, -1.03428191e-01, ...,\n",
              "          -6.88577000e-02,  8.65849213e-03, -2.07712049e-02],\n",
              "         ...,\n",
              "         [-1.18768535e-03,  3.52702501e-01, -4.31777328e-02, ...,\n",
              "           8.50326478e-02, -3.29943462e-02, -2.00710483e-01],\n",
              "         [-3.64501668e-01, -7.53007749e-02, -1.01101071e-01, ...,\n",
              "          -5.36661652e-02,  9.63231398e-02, -2.51760711e-02],\n",
              "         [-2.82635631e-01,  1.61189395e-02, -3.71374087e-02, ...,\n",
              "          -1.44595443e-01, -2.86198074e-02, -9.55387882e-02]]), 'mapped_Y': array([[ 0.44336918, -0.15834665, -0.04061779, ...,  0.00840655,\n",
              "           0.08841198,  0.08193664],\n",
              "         [-0.45107714, -0.12065817, -0.0248481 , ...,  0.09832478,\n",
              "          -0.08854352, -0.10682798],\n",
              "         [ 0.07106133,  0.16717763,  0.03288149, ..., -0.07444215,\n",
              "          -0.01820832,  0.06909221],\n",
              "         ...,\n",
              "         [-0.04088803,  0.45218573, -0.12439934, ...,  0.01342313,\n",
              "          -0.01903507, -0.08836057],\n",
              "         [-0.40971391, -0.13832896,  0.10531932, ...,  0.26526167,\n",
              "          -0.11959988, -0.0029968 ],\n",
              "         [-0.37744983, -0.07025439, -0.07062286, ..., -0.08482601,\n",
              "           0.07087444, -0.02457877]]), 'alpha': tensor([[ 2.7325e-03,  2.1883e-02,  8.0525e-03,  ..., -6.7718e-05,\n",
              "            1.0800e-02,  3.7868e-03],\n",
              "          [ 7.4704e-03,  2.4094e-03, -1.8868e-03,  ..., -4.6869e-02,\n",
              "           -8.6106e-03,  8.2988e-03],\n",
              "          [-1.5246e-03,  1.6543e-02, -3.8456e-03,  ...,  5.7498e-03,\n",
              "            9.8250e-03, -2.5877e-03],\n",
              "          ...,\n",
              "          [ 9.2835e-03,  1.7851e-02, -6.4772e-03,  ...,  1.7214e-02,\n",
              "           -1.2258e-02, -2.1016e-02],\n",
              "          [-7.7703e-03,  4.9437e-03, -1.6273e-02,  ..., -5.1422e-02,\n",
              "            5.9420e-02, -9.4444e-03],\n",
              "          [-4.6853e-03,  2.4631e-03, -2.6266e-02,  ..., -8.4300e-02,\n",
              "            2.6732e-02, -3.0350e-02]], dtype=torch.float64), 'beta': tensor([[-0.0015,  0.0007,  0.0016,  ...,  0.0055,  0.0158,  0.0048],\n",
              "          [-0.0018,  0.0029,  0.0076,  ...,  0.0047, -0.0139, -0.0094],\n",
              "          [ 0.0062,  0.0118,  0.0099,  ..., -0.0049, -0.0092, -0.0006],\n",
              "          ...,\n",
              "          [-0.0041, -0.0005, -0.0070,  ...,  0.0137, -0.0071,  0.0049],\n",
              "          [ 0.0034,  0.0173,  0.0191,  ...,  0.0450, -0.0072, -0.0082],\n",
              "          [-0.0078, -0.0074, -0.0169,  ..., -0.0222,  0.0420, -0.0071]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00751295471857496, 'loss_breakdown': {'ot': 0.006695307670638678,\n",
              "   'ortho': 0.00026584743397392206,\n",
              "   'graph': 79.10623045388897}, 'best_iter': 2144, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076409,\n",
              "   'accuracy_raw': 0.9646609360076409,\n",
              "   'foscttm': 0.15417999669771001}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.39968743, -0.19152064,  0.0173504 , ...,  0.00078452,\n",
              "           0.01760464,  0.07473511],\n",
              "         [-0.15509502,  0.30499803, -0.15609328, ..., -0.09281004,\n",
              "          -0.02273375, -0.00913687],\n",
              "         [ 0.04392821,  0.4579213 , -0.10129326, ..., -0.02488936,\n",
              "           0.03018684, -0.02355869],\n",
              "         ...,\n",
              "         [ 0.01394499,  0.33653342, -0.02889766, ...,  0.0628317 ,\n",
              "           0.01764604, -0.16665172],\n",
              "         [-0.32079148, -0.04618707, -0.17743271, ..., -0.07446535,\n",
              "           0.08049315, -0.0481606 ],\n",
              "         [-0.28898359,  0.02225951, -0.05307401, ..., -0.15777752,\n",
              "          -0.0164521 , -0.03010444]]), 'mapped_Y': array([[ 0.43404849, -0.17929134,  0.05821316, ..., -0.022305  ,\n",
              "           0.04660368,  0.07218718],\n",
              "         [-0.42676001, -0.10136016, -0.16601184, ...,  0.07258889,\n",
              "          -0.08901373, -0.10254988],\n",
              "         [ 0.08220929,  0.15444724,  0.04469956, ..., -0.05123872,\n",
              "          -0.04410374,  0.07937982],\n",
              "         ...,\n",
              "         [ 0.00078742,  0.4442202 , -0.13757254, ...,  0.01643942,\n",
              "           0.03100141, -0.09400224],\n",
              "         [-0.42340605, -0.12129248, -0.02666789, ...,  0.30117537,\n",
              "          -0.07975514, -0.04116398],\n",
              "         [-0.34038822, -0.0538557 , -0.14073732, ..., -0.09775748,\n",
              "           0.05949143,  0.02375859]]), 'alpha': tensor([[ 0.0037,  0.0221,  0.0059,  ..., -0.0023,  0.0093,  0.0079],\n",
              "          [ 0.0081,  0.0011,  0.0070,  ..., -0.0332, -0.0137,  0.0101],\n",
              "          [ 0.0002,  0.0178, -0.0064,  ...,  0.0090,  0.0117, -0.0041],\n",
              "          ...,\n",
              "          [ 0.0088,  0.0166, -0.0019,  ..., -0.0012, -0.0061, -0.0166],\n",
              "          [-0.0054,  0.0055, -0.0163,  ..., -0.0781,  0.0416, -0.0058],\n",
              "          [-0.0062,  0.0014, -0.0227,  ..., -0.1166,  0.0167, -0.0048]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0018,  0.0009,  0.0016,  ...,  0.0021,  0.0119,  0.0084],\n",
              "          [-0.0012,  0.0033,  0.0009,  ..., -0.0022, -0.0191, -0.0113],\n",
              "          [ 0.0096,  0.0081,  0.0081,  ..., -0.0068, -0.0303,  0.0004],\n",
              "          ...,\n",
              "          [-0.0050,  0.0012, -0.0101,  ...,  0.0066, -0.0012,  0.0034],\n",
              "          [ 0.0026,  0.0138,  0.0162,  ...,  0.0503, -0.0031, -0.0135],\n",
              "          [-0.0062, -0.0072, -0.0109,  ..., -0.0274,  0.0348,  0.0021]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007457687783924975, 'loss_breakdown': {'ot': 0.006628237613178076,\n",
              "   'ortho': 0.00040860022620895246,\n",
              "   'graph': 78.85901481260032}, 'best_iter': 2239, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.1541070179135548}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[ 0.3893139 , -0.26940013, -0.06097192, ..., -0.00240933,\n",
              "           0.03587313, -0.10356863],\n",
              "         [-0.13177991,  0.3526478 , -0.15483416, ..., -0.12279145,\n",
              "           0.02798435,  0.06036887],\n",
              "         [ 0.05899285,  0.47281593, -0.05599806, ..., -0.04506784,\n",
              "           0.04297753,  0.10016871],\n",
              "         ...,\n",
              "         [-0.01090133,  0.3922942 , -0.00132309, ...,  0.14529566,\n",
              "           0.00859921, -0.18813633],\n",
              "         [-0.35068354,  0.00734091, -0.15514688, ..., -0.05469242,\n",
              "          -0.04002386,  0.06730491],\n",
              "         [-0.32967989, -0.00685723, -0.03521372, ..., -0.16479109,\n",
              "          -0.1287823 , -0.07477948]]), 'mapped_Y': array([[ 0.43606741, -0.22340495, -0.02595766, ..., -0.02237715,\n",
              "           0.00752182, -0.07746994],\n",
              "         [-0.4175347 , -0.07613883, -0.17631949, ...,  0.10648048,\n",
              "          -0.02470728, -0.07573972],\n",
              "         [ 0.11446174,  0.13767612,  0.04760518, ..., -0.16367004,\n",
              "          -0.02618397,  0.17542093],\n",
              "         ...,\n",
              "         [ 0.00314226,  0.52634913, -0.08565716, ...,  0.07512706,\n",
              "           0.04274862, -0.05155288],\n",
              "         [-0.3388038 , -0.13961988, -0.10496971, ...,  0.38793981,\n",
              "          -0.04683515,  0.0565664 ],\n",
              "         [-0.37513872, -0.01937463, -0.14192666, ..., -0.2008868 ,\n",
              "          -0.02398672, -0.00501696]]), 'alpha': tensor([[ 0.0037,  0.0070, -0.0012,  ..., -0.0006,  0.0040, -0.0017],\n",
              "          [ 0.0038, -0.0033,  0.0023,  ..., -0.0184,  0.0019,  0.0023],\n",
              "          [ 0.0016,  0.0073, -0.0076,  ..., -0.0027,  0.0061,  0.0044],\n",
              "          ...,\n",
              "          [-0.0009,  0.0147, -0.0017,  ...,  0.0211, -0.0004, -0.0365],\n",
              "          [-0.0036,  0.0113, -0.0082,  ..., -0.0198,  0.0088,  0.0023],\n",
              "          [-0.0053, -0.0041, -0.0108,  ..., -0.0532, -0.0058, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0008, -0.0006, -0.0011,  ..., -0.0015, -0.0010, -0.0007],\n",
              "          [ 0.0024, -0.0008, -0.0006,  ...,  0.0015,  0.0023, -0.0090],\n",
              "          [ 0.0069,  0.0066,  0.0049,  ..., -0.0240, -0.0056,  0.0199],\n",
              "          ...,\n",
              "          [-0.0030,  0.0067, -0.0080,  ...,  0.0093,  0.0021, -0.0139],\n",
              "          [ 0.0070,  0.0048,  0.0035,  ...,  0.0389,  0.0100,  0.0099],\n",
              "          [-0.0108, -0.0004, -0.0019,  ..., -0.0226, -0.0020, -0.0060]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007998882094159396, 'loss_breakdown': {'ot': 0.007886214016709563,\n",
              "   'ortho': 6.196777317430332e-05,\n",
              "   'graph': 106.47130013240233}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.15435788248408835}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.37816272, -0.17229253, -0.07565505, ...,  0.04648673,\n",
              "           0.04791399,  0.09708982],\n",
              "         [-0.18773551,  0.30266079, -0.120343  , ..., -0.15746917,\n",
              "          -0.03531433, -0.04763794],\n",
              "         [ 0.01976812,  0.45064546, -0.08777132, ..., -0.10096737,\n",
              "           0.00145232, -0.03643835],\n",
              "         ...,\n",
              "         [ 0.02473806,  0.35383438, -0.03351434, ...,  0.07939733,\n",
              "          -0.03745475, -0.20279985],\n",
              "         [-0.3713113 , -0.05491075, -0.09788897, ..., -0.04912868,\n",
              "           0.09081965, -0.02028568],\n",
              "         [-0.28362169,  0.0263522 , -0.02896068, ..., -0.14272917,\n",
              "          -0.01835876, -0.09243558]]), 'mapped_Y': array([[ 0.41945873, -0.17364541, -0.05862407, ...,  0.01532848,\n",
              "           0.09151672,  0.09490923],\n",
              "         [-0.45344915, -0.09685088, -0.01560408, ...,  0.14220189,\n",
              "          -0.08514443, -0.0914494 ],\n",
              "         [ 0.06971329,  0.16973681,  0.02555468, ..., -0.09528623,\n",
              "          -0.01332589,  0.04367161],\n",
              "         ...,\n",
              "         [-0.01439887,  0.44290187, -0.1018126 , ..., -0.01503458,\n",
              "          -0.03192282, -0.09507641],\n",
              "         [-0.40947443, -0.11808688,  0.11528102, ...,  0.2840979 ,\n",
              "          -0.13150849,  0.0302092 ],\n",
              "         [-0.38507741, -0.05466163, -0.07052768, ..., -0.06511258,\n",
              "           0.08074278, -0.02798734]]), 'alpha': tensor([[ 0.0026,  0.0223,  0.0098,  ..., -0.0026,  0.0097,  0.0041],\n",
              "          [ 0.0069,  0.0010, -0.0024,  ..., -0.0457, -0.0062,  0.0076],\n",
              "          [-0.0015,  0.0170, -0.0027,  ...,  0.0035,  0.0083, -0.0019],\n",
              "          ...,\n",
              "          [ 0.0112,  0.0174, -0.0069,  ...,  0.0215, -0.0119, -0.0215],\n",
              "          [-0.0088,  0.0041, -0.0224,  ..., -0.0462,  0.0617, -0.0110],\n",
              "          [-0.0059,  0.0017, -0.0316,  ..., -0.0730,  0.0321, -0.0305]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0025,  0.0009,  0.0006,  ...,  0.0059,  0.0162,  0.0044],\n",
              "          [-0.0023,  0.0037,  0.0078,  ...,  0.0063, -0.0118, -0.0097],\n",
              "          [ 0.0051,  0.0136,  0.0108,  ..., -0.0095, -0.0062, -0.0067],\n",
              "          ...,\n",
              "          [-0.0037, -0.0006, -0.0073,  ...,  0.0079, -0.0090,  0.0063],\n",
              "          [ 0.0039,  0.0204,  0.0204,  ...,  0.0429, -0.0079, -0.0047],\n",
              "          [-0.0087, -0.0088, -0.0204,  ..., -0.0201,  0.0447, -0.0079]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006573553555535974, 'loss_breakdown': {'ot': 0.006478244786346401,\n",
              "   'ortho': 0.00016736792586094542,\n",
              "   'graph': 78.57197660347812}, 'best_iter': 2294, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076409,\n",
              "   'accuracy_raw': 0.9646609360076409,\n",
              "   'foscttm': 0.15420143421555563}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.38481909, -0.20429378,  0.05584875, ...,  0.00161789,\n",
              "           0.01707513,  0.03689579],\n",
              "         [-0.10900457,  0.33001425, -0.16035579, ..., -0.08615176,\n",
              "          -0.02046848, -0.00464813],\n",
              "         [ 0.08058447,  0.45956617, -0.04123384, ..., -0.02908328,\n",
              "           0.04204424, -0.03187419],\n",
              "         ...,\n",
              "         [ 0.0271718 ,  0.33518577, -0.00748388, ...,  0.08228128,\n",
              "           0.02267564, -0.20259983],\n",
              "         [-0.28437797, -0.024409  , -0.24239057, ..., -0.09134341,\n",
              "           0.0706177 ,  0.00066033],\n",
              "         [-0.25854683,  0.03389383, -0.10007795, ..., -0.16500521,\n",
              "          -0.0495409 , -0.0176306 ]]), 'mapped_Y': array([[ 0.41426533, -0.19560703,  0.11249125, ..., -0.01729947,\n",
              "           0.0478276 ,  0.03470128],\n",
              "         [-0.39240769, -0.07003641, -0.2456764 , ...,  0.08254449,\n",
              "          -0.08782902, -0.07470767],\n",
              "         [ 0.07741801,  0.16054216,  0.06104103, ..., -0.05536745,\n",
              "          -0.03691349,  0.07131489],\n",
              "         ...,\n",
              "         [ 0.04973981,  0.44328124, -0.08076981, ...,  0.01012945,\n",
              "           0.03661407, -0.10670474],\n",
              "         [-0.41518994, -0.09517355, -0.11381915, ...,  0.31109088,\n",
              "          -0.08886995,  0.02116975],\n",
              "         [-0.29289435, -0.02818219, -0.20623875, ..., -0.1006173 ,\n",
              "           0.05608803,  0.0544347 ]]), 'alpha': tensor([[ 0.0032,  0.0208,  0.0064,  ..., -0.0034,  0.0086,  0.0055],\n",
              "          [ 0.0070,  0.0021,  0.0073,  ..., -0.0280, -0.0139,  0.0061],\n",
              "          [ 0.0010,  0.0162, -0.0052,  ...,  0.0059,  0.0122, -0.0015],\n",
              "          ...,\n",
              "          [ 0.0074,  0.0137, -0.0012,  ...,  0.0027, -0.0077, -0.0231],\n",
              "          [-0.0041,  0.0069, -0.0185,  ..., -0.0769,  0.0418, -0.0048],\n",
              "          [-0.0031,  0.0021, -0.0221,  ..., -0.1170,  0.0102, -0.0157]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0016,  0.0005,  0.0015,  ...,  0.0032,  0.0118,  0.0074],\n",
              "          [-0.0024,  0.0035,  0.0012,  ..., -0.0017, -0.0180, -0.0148],\n",
              "          [ 0.0102,  0.0088,  0.0076,  ..., -0.0088, -0.0285, -0.0005],\n",
              "          ...,\n",
              "          [-0.0023,  0.0012, -0.0092,  ...,  0.0025, -0.0032,  0.0072],\n",
              "          [ 0.0005,  0.0135,  0.0144,  ...,  0.0474, -0.0043, -0.0101],\n",
              "          [-0.0051, -0.0063, -0.0103,  ..., -0.0253,  0.0322,  0.0021]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00752270650333117, 'loss_breakdown': {'ot': 0.007409927647808364,\n",
              "   'ortho': 0.0003008846814356423,\n",
              "   'graph': 82.69038737924139}, 'best_iter': 2114, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076408,\n",
              "   'accuracy_raw': 0.9646609360076408,\n",
              "   'foscttm': 0.1543574263666874}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[ 3.86415720e-01, -2.72859555e-01, -6.26827317e-02, ...,\n",
              "          -1.62598585e-03,  3.64280631e-02, -1.03143145e-01],\n",
              "         [-1.28273862e-01,  3.54091362e-01, -1.52467244e-01, ...,\n",
              "          -1.24336193e-01,  2.75517410e-02,  5.95268762e-02],\n",
              "         [ 6.34940944e-02,  4.71940900e-01, -5.32045513e-02, ...,\n",
              "          -4.74522521e-02,  4.17079406e-02,  9.83870438e-02],\n",
              "         ...,\n",
              "         [-7.20882168e-03,  3.92151773e-01,  3.37872417e-04, ...,\n",
              "           1.43806497e-01,  7.44213183e-03, -1.89285903e-01],\n",
              "         [-3.50877677e-01,  1.12706934e-02, -1.55279330e-01, ...,\n",
              "          -5.45086870e-02, -3.97406472e-02,  6.83665540e-02],\n",
              "         [-3.30188853e-01, -5.24221319e-03, -3.60189859e-02, ...,\n",
              "          -1.64358045e-01, -1.29109140e-01, -7.43637584e-02]]), 'mapped_Y': array([[ 0.43365656, -0.22743115, -0.0277192 , ..., -0.02199337,\n",
              "           0.00775048, -0.07762717],\n",
              "         [-0.41885319, -0.07063175, -0.17694132, ...,  0.10662659,\n",
              "          -0.02294376, -0.07495167],\n",
              "         [ 0.11590485,  0.1365024 ,  0.04932817, ..., -0.16523563,\n",
              "          -0.02625177,  0.17431893],\n",
              "         ...,\n",
              "         [ 0.00817634,  0.52639744, -0.08319113, ...,  0.07322163,\n",
              "           0.04128455, -0.05318419],\n",
              "         [-0.33971266, -0.13372319, -0.10573389, ...,  0.38832177,\n",
              "          -0.04566144,  0.05811334],\n",
              "         [-0.37552715, -0.0158646 , -0.14167472, ..., -0.20060984,\n",
              "          -0.02315475, -0.00401442]]), 'alpha': tensor([[ 0.0037,  0.0069, -0.0011,  ..., -0.0007,  0.0039, -0.0017],\n",
              "          [ 0.0038, -0.0034,  0.0022,  ..., -0.0182,  0.0020,  0.0023],\n",
              "          [ 0.0016,  0.0073, -0.0074,  ..., -0.0027,  0.0060,  0.0043],\n",
              "          ...,\n",
              "          [-0.0007,  0.0146, -0.0016,  ...,  0.0211, -0.0005, -0.0365],\n",
              "          [-0.0035,  0.0113, -0.0081,  ..., -0.0197,  0.0087,  0.0024],\n",
              "          [-0.0054, -0.0043, -0.0109,  ..., -0.0527, -0.0059, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0008, -0.0006, -0.0011,  ..., -0.0015, -0.0011, -0.0007],\n",
              "          [ 0.0022, -0.0007, -0.0006,  ...,  0.0015,  0.0024, -0.0092],\n",
              "          [ 0.0070,  0.0065,  0.0051,  ..., -0.0240, -0.0055,  0.0196],\n",
              "          ...,\n",
              "          [-0.0029,  0.0068, -0.0079,  ...,  0.0093,  0.0020, -0.0138],\n",
              "          [ 0.0070,  0.0048,  0.0035,  ...,  0.0387,  0.0100,  0.0100],\n",
              "          [-0.0109, -0.0004, -0.0019,  ..., -0.0227, -0.0020, -0.0060]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007900440214632227, 'loss_breakdown': {'ot': 0.007883735829703208,\n",
              "   'ortho': 6.0511400878951945e-05,\n",
              "   'graph': 106.53244841124291}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.1543601630710932}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.38851221, -0.16520584, -0.07529317, ...,  0.05541937,\n",
              "           0.04405229,  0.0787194 ],\n",
              "         [-0.19805966,  0.30645764, -0.11927083, ..., -0.1573685 ,\n",
              "          -0.0342426 , -0.03307142],\n",
              "         [ 0.00469961,  0.4516895 , -0.09329705, ..., -0.09576362,\n",
              "           0.00796445, -0.02078996],\n",
              "         ...,\n",
              "         [ 0.00735644,  0.35204413, -0.03380488, ...,  0.08286409,\n",
              "          -0.03038919, -0.19329998],\n",
              "         [-0.36970273, -0.06792925, -0.09986375, ..., -0.05489029,\n",
              "           0.08946714, -0.0185552 ],\n",
              "         [-0.28240876,  0.01342522, -0.03818504, ..., -0.14092663,\n",
              "          -0.02364683, -0.08666668]]), 'mapped_Y': array([[ 0.42843874, -0.16470996, -0.05803779, ...,  0.02333425,\n",
              "           0.08611627,  0.08133318],\n",
              "         [-0.45387974, -0.10442775, -0.0071366 , ...,  0.13480898,\n",
              "          -0.08650631, -0.09296636],\n",
              "         [ 0.07328331,  0.1746736 ,  0.02627605, ..., -0.09517415,\n",
              "          -0.01495976,  0.04855423],\n",
              "         ...,\n",
              "         [-0.03654152,  0.44043488, -0.10932378, ..., -0.01258544,\n",
              "          -0.02244845, -0.07907373],\n",
              "         [-0.4061693 , -0.1190501 ,  0.12693597, ...,  0.28055696,\n",
              "          -0.13690555,  0.02747007],\n",
              "         [-0.38310293, -0.06606691, -0.06812271, ..., -0.06833008,\n",
              "           0.08218666, -0.02160965]]), 'alpha': tensor([[ 0.0029,  0.0221,  0.0091,  ..., -0.0015,  0.0100,  0.0036],\n",
              "          [ 0.0070,  0.0010, -0.0037,  ..., -0.0447, -0.0073,  0.0075],\n",
              "          [-0.0016,  0.0169, -0.0029,  ...,  0.0046,  0.0091, -0.0018],\n",
              "          ...,\n",
              "          [ 0.0104,  0.0163, -0.0070,  ...,  0.0206, -0.0115, -0.0218],\n",
              "          [-0.0086,  0.0039, -0.0230,  ..., -0.0478,  0.0604, -0.0104],\n",
              "          [-0.0058,  0.0012, -0.0334,  ..., -0.0745,  0.0297, -0.0304]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-2.1127e-03,  8.4870e-04,  1.0804e-03,  ...,  5.7593e-03,\n",
              "            1.5693e-02,  4.7527e-03],\n",
              "          [-2.2016e-03,  3.2493e-03,  7.5365e-03,  ...,  5.9611e-03,\n",
              "           -1.2419e-02, -1.0123e-02],\n",
              "          [ 6.0229e-03,  1.2793e-02,  1.0249e-02,  ..., -8.8761e-03,\n",
              "           -7.5023e-03, -5.4794e-03],\n",
              "          ...,\n",
              "          [-4.4663e-03,  9.7183e-05, -7.2789e-03,  ...,  7.4951e-03,\n",
              "           -8.0801e-03,  6.4443e-03],\n",
              "          [ 3.8915e-03,  1.9550e-02,  2.0376e-02,  ...,  4.2791e-02,\n",
              "           -9.6878e-03, -4.3872e-03],\n",
              "          [-8.6891e-03, -9.1057e-03, -2.0045e-02,  ..., -1.9523e-02,\n",
              "            4.4760e-02, -6.9527e-03]], dtype=torch.float64), 'final_loss': 0.006658301938330267, 'loss_breakdown': {'ot': 0.006634716106676823,\n",
              "   'ortho': 0.00015666028275497767,\n",
              "   'graph': 79.1980337794579}, 'best_iter': 2244, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.1541996097459517}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[ 0.38299794, -0.19549059,  0.07757556, ..., -0.00733391,\n",
              "           0.02077709,  0.04233613],\n",
              "         [-0.10871915,  0.3109606 , -0.17410429, ..., -0.08355409,\n",
              "          -0.03584922, -0.00750163],\n",
              "         [ 0.08316286,  0.44848563, -0.08487913, ..., -0.01943675,\n",
              "           0.02847085, -0.03162774],\n",
              "         ...,\n",
              "         [ 0.03065145,  0.33101296, -0.02789995, ...,  0.07210807,\n",
              "           0.0123141 , -0.18447594],\n",
              "         [-0.29085304, -0.04104197, -0.23347204, ..., -0.07489434,\n",
              "           0.08435209, -0.0098657 ],\n",
              "         [-0.26259052,  0.03766699, -0.09313527, ..., -0.15874744,\n",
              "          -0.02364167, -0.00962052]]), 'mapped_Y': array([[ 0.41363422, -0.1882549 ,  0.12384375, ..., -0.02622705,\n",
              "           0.04853617,  0.03622629],\n",
              "         [-0.40199382, -0.08098815, -0.2273606 , ...,  0.07462406,\n",
              "          -0.07807507, -0.07630312],\n",
              "         [ 0.08298548,  0.16133888,  0.05700999, ..., -0.05438841,\n",
              "          -0.04138399,  0.07192989],\n",
              "         ...,\n",
              "         [ 0.04397911,  0.4346902 , -0.12678425, ...,  0.02119004,\n",
              "           0.03143948, -0.09558793],\n",
              "         [-0.4144794 , -0.10531163, -0.09177057, ...,  0.2973583 ,\n",
              "          -0.07126109,  0.00979117],\n",
              "         [-0.30780121, -0.03898202, -0.19580903, ..., -0.09127239,\n",
              "           0.06108939,  0.05817176]]), 'alpha': tensor([[ 0.0037,  0.0224,  0.0077,  ..., -0.0035,  0.0087,  0.0062],\n",
              "          [ 0.0077,  0.0026,  0.0102,  ..., -0.0307, -0.0172,  0.0061],\n",
              "          [ 0.0012,  0.0172, -0.0060,  ...,  0.0076,  0.0119, -0.0025],\n",
              "          ...,\n",
              "          [ 0.0084,  0.0160, -0.0014,  ..., -0.0005, -0.0080, -0.0197],\n",
              "          [-0.0049,  0.0058, -0.0191,  ..., -0.0772,  0.0458, -0.0035],\n",
              "          [-0.0037,  0.0038, -0.0221,  ..., -0.1173,  0.0140, -0.0115]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0021,  0.0012,  0.0018,  ...,  0.0028,  0.0125,  0.0074],\n",
              "          [-0.0025,  0.0047,  0.0020,  ..., -0.0032, -0.0167, -0.0140],\n",
              "          [ 0.0104,  0.0098,  0.0088,  ..., -0.0094, -0.0307, -0.0013],\n",
              "          ...,\n",
              "          [-0.0026,  0.0021, -0.0101,  ...,  0.0057, -0.0016,  0.0096],\n",
              "          [ 0.0006,  0.0153,  0.0155,  ...,  0.0458,  0.0002, -0.0101],\n",
              "          [-0.0057, -0.0073, -0.0122,  ..., -0.0252,  0.0350,  0.0043]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006627303909794436, 'loss_breakdown': {'ot': 0.006593943859537494,\n",
              "   'ortho': 0.0002543979193698486,\n",
              "   'graph': 79.20258319957401}, 'best_iter': 2293, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.15486052385995736}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[ 0.38491379, -0.27455988, -0.06354162, ..., -0.0010183 ,\n",
              "           0.03710309, -0.10256499],\n",
              "         [-0.1261279 ,  0.35498613, -0.15082024, ..., -0.12531956,\n",
              "           0.02694141,  0.05914713],\n",
              "         [ 0.0659041 ,  0.47161921, -0.05114842, ..., -0.04830337,\n",
              "           0.04094075,  0.09774955],\n",
              "         ...,\n",
              "         [-0.00529303,  0.39201309,  0.00126538, ...,  0.1432185 ,\n",
              "           0.00696377, -0.18987539],\n",
              "         [-0.35062463,  0.01348426, -0.15540214, ..., -0.05512471,\n",
              "          -0.04003144,  0.06870432],\n",
              "         [-0.3302543 , -0.00409733, -0.03620717, ..., -0.1645494 ,\n",
              "          -0.12898013, -0.07446886]]), 'mapped_Y': array([[ 0.43237167, -0.22948332, -0.02835544, ..., -0.02130423,\n",
              "           0.00825059, -0.07723911],\n",
              "         [-0.41923338, -0.06781691, -0.17787816, ...,  0.1057001 ,\n",
              "          -0.02279477, -0.07488242],\n",
              "         [ 0.11665994,  0.13582116,  0.0505366 , ..., -0.16551091,\n",
              "          -0.02622867,  0.17399151],\n",
              "         ...,\n",
              "         [ 0.01091307,  0.52646444, -0.08151796, ...,  0.07227651,\n",
              "           0.04028035, -0.05384834],\n",
              "         [-0.3404406 , -0.13091544, -0.10710658, ...,  0.38771096,\n",
              "          -0.04531135,  0.05827983],\n",
              "         [-0.37528826, -0.01376664, -0.14168262, ..., -0.20112292,\n",
              "          -0.0232616 , -0.00379766]]), 'alpha': tensor([[ 0.0037,  0.0068, -0.0010,  ..., -0.0007,  0.0039, -0.0017],\n",
              "          [ 0.0038, -0.0034,  0.0023,  ..., -0.0182,  0.0020,  0.0023],\n",
              "          [ 0.0017,  0.0074, -0.0074,  ..., -0.0028,  0.0060,  0.0043],\n",
              "          ...,\n",
              "          [-0.0007,  0.0146, -0.0016,  ...,  0.0210, -0.0004, -0.0365],\n",
              "          [-0.0035,  0.0114, -0.0080,  ..., -0.0198,  0.0086,  0.0024],\n",
              "          [-0.0054, -0.0043, -0.0109,  ..., -0.0526, -0.0059, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0008, -0.0006, -0.0011,  ..., -0.0015, -0.0010, -0.0007],\n",
              "          [ 0.0021, -0.0007, -0.0006,  ...,  0.0014,  0.0025, -0.0092],\n",
              "          [ 0.0070,  0.0064,  0.0052,  ..., -0.0240, -0.0055,  0.0196],\n",
              "          ...,\n",
              "          [-0.0029,  0.0069, -0.0079,  ...,  0.0093,  0.0020, -0.0138],\n",
              "          [ 0.0070,  0.0048,  0.0035,  ...,  0.0387,  0.0100,  0.0100],\n",
              "          [-0.0109, -0.0004, -0.0019,  ..., -0.0227, -0.0019, -0.0061]],\n",
              "         dtype=torch.float64), 'final_loss': 0.007888257250492912, 'loss_breakdown': {'ot': 0.00788115221406727,\n",
              "   'ortho': 6.039804737855732e-05,\n",
              "   'graph': 106.52316877876099}, 'best_iter': 4000, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.15437612718012717}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.38553507, -0.16622241, -0.0793837 , ...,  0.05695866,\n",
              "           0.04537759,  0.08227922],\n",
              "         [-0.19550588,  0.30706044, -0.11674107, ..., -0.15837408,\n",
              "          -0.03484334, -0.03565624],\n",
              "         [ 0.00833802,  0.45092825, -0.0922556 , ..., -0.09573745,\n",
              "           0.00656823, -0.02361725],\n",
              "         ...,\n",
              "         [ 0.01068626,  0.35094527, -0.03344912, ...,  0.08135619,\n",
              "          -0.0306501 , -0.1953438 ],\n",
              "         [-0.3708862 , -0.06516527, -0.09625968, ..., -0.05594927,\n",
              "           0.08991177, -0.01853892],\n",
              "         [-0.28121118,  0.01611807, -0.03450485, ..., -0.14164152,\n",
              "          -0.02183544, -0.08669763]]), 'mapped_Y': array([[ 0.42612142, -0.16627339, -0.06283366, ...,  0.02499819,\n",
              "           0.08779715,  0.08445911],\n",
              "         [-0.45456686, -0.10218737, -0.00324262, ...,  0.13281793,\n",
              "          -0.08584939, -0.09318935],\n",
              "         [ 0.07302174,  0.17445617,  0.02573967, ..., -0.09455803,\n",
              "          -0.01521396,  0.04732152],\n",
              "         ...,\n",
              "         [-0.03328561,  0.43956275, -0.10741218, ..., -0.0128386 ,\n",
              "          -0.02323373, -0.08132919],\n",
              "         [-0.40562451, -0.11761493,  0.12961958, ...,  0.27800257,\n",
              "          -0.13602845,  0.02682843],\n",
              "         [-0.38475244, -0.06355869, -0.06501739, ..., -0.06942704,\n",
              "           0.08202435, -0.02192622]]), 'alpha': tensor([[ 0.0030,  0.0222,  0.0091,  ..., -0.0015,  0.0100,  0.0037],\n",
              "          [ 0.0071,  0.0011, -0.0036,  ..., -0.0451, -0.0073,  0.0076],\n",
              "          [-0.0016,  0.0170, -0.0029,  ...,  0.0046,  0.0089, -0.0019],\n",
              "          ...,\n",
              "          [ 0.0106,  0.0163, -0.0072,  ...,  0.0206, -0.0113, -0.0217],\n",
              "          [-0.0087,  0.0039, -0.0230,  ..., -0.0481,  0.0611, -0.0100],\n",
              "          [-0.0057,  0.0013, -0.0332,  ..., -0.0748,  0.0302, -0.0301]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0022,  0.0009,  0.0009,  ...,  0.0058,  0.0158,  0.0048],\n",
              "          [-0.0022,  0.0033,  0.0076,  ...,  0.0059, -0.0122, -0.0100],\n",
              "          [ 0.0060,  0.0130,  0.0103,  ..., -0.0089, -0.0075, -0.0057],\n",
              "          ...,\n",
              "          [-0.0045,  0.0002, -0.0072,  ...,  0.0077, -0.0080,  0.0065],\n",
              "          [ 0.0041,  0.0196,  0.0204,  ...,  0.0426, -0.0093, -0.0045],\n",
              "          [-0.0088, -0.0092, -0.0201,  ..., -0.0195,  0.0450, -0.0068]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006578775353811989, 'loss_breakdown': {'ot': 0.006561659899255983,\n",
              "   'ortho': 0.00016326828155060783,\n",
              "   'graph': 78.86264009452579}, 'best_iter': 2265, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9641833810888252,\n",
              "   'accuracy_raw': 0.9641833810888252,\n",
              "   'foscttm': 0.15422652067260897}},\n",
              " (8,\n",
              "  5,\n",
              "  0.1,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.38512238, -0.19418099,  0.07687728, ..., -0.00779309,\n",
              "           0.01968246,  0.04254   ],\n",
              "         [-0.11029782,  0.31227096, -0.17307592, ..., -0.0829489 ,\n",
              "          -0.03463715, -0.00672472],\n",
              "         [ 0.07976234,  0.45012814, -0.08076431, ..., -0.01932218,\n",
              "           0.03029713, -0.03061048],\n",
              "         ...,\n",
              "         [ 0.02902774,  0.33171264, -0.02546405, ...,  0.07427057,\n",
              "           0.01248928, -0.18494056],\n",
              "         [-0.28912398, -0.04033789, -0.23514941, ..., -0.07607464,\n",
              "           0.0836381 , -0.01054267],\n",
              "         [-0.26153877,  0.03663073, -0.09377861, ..., -0.15785575,\n",
              "          -0.02615249, -0.0118952 ]]), 'mapped_Y': array([[ 0.41435028, -0.18648827,  0.12430693, ..., -0.02663038,\n",
              "           0.04826627,  0.03682622],\n",
              "         [-0.39880436, -0.0811814 , -0.23132837, ...,  0.07538169,\n",
              "          -0.07949576, -0.07664026],\n",
              "         [ 0.08144662,  0.16122686,  0.05828284, ..., -0.05472207,\n",
              "          -0.04037908,  0.07203642],\n",
              "         ...,\n",
              "         [ 0.04169924,  0.43650068, -0.12262207, ...,  0.02109365,\n",
              "           0.03238122, -0.09509761],\n",
              "         [-0.41251815, -0.1063129 , -0.09616608, ...,  0.29839652,\n",
              "          -0.07375804,  0.00998211],\n",
              "         [-0.30555763, -0.03937576, -0.19765993, ..., -0.09141961,\n",
              "           0.0609715 ,  0.05718237]]), 'alpha': tensor([[ 3.6408e-03,  2.2323e-02,  7.6158e-03,  ..., -3.4859e-03,\n",
              "            8.6142e-03,  6.1756e-03],\n",
              "          [ 7.6548e-03,  2.5631e-03,  1.0114e-02,  ..., -3.0540e-02,\n",
              "           -1.7098e-02,  5.9853e-03],\n",
              "          [ 1.1033e-03,  1.7152e-02, -5.9026e-03,  ...,  7.5305e-03,\n",
              "            1.1928e-02, -2.4336e-03],\n",
              "          ...,\n",
              "          [ 8.4097e-03,  1.5932e-02, -1.2936e-03,  ..., -1.1210e-04,\n",
              "           -8.1763e-03, -1.9918e-02],\n",
              "          [-4.8468e-03,  5.9468e-03, -1.8979e-02,  ..., -7.7150e-02,\n",
              "            4.5571e-02, -3.8194e-03],\n",
              "          [-3.6198e-03,  3.7435e-03, -2.2029e-02,  ..., -1.1690e-01,\n",
              "            1.3496e-02, -1.2107e-02]], dtype=torch.float64), 'beta': tensor([[-0.0021,  0.0012,  0.0018,  ...,  0.0029,  0.0124,  0.0074],\n",
              "          [-0.0024,  0.0046,  0.0018,  ..., -0.0032, -0.0167, -0.0140],\n",
              "          [ 0.0104,  0.0098,  0.0089,  ..., -0.0094, -0.0305, -0.0013],\n",
              "          ...,\n",
              "          [-0.0025,  0.0021, -0.0101,  ...,  0.0055, -0.0017,  0.0096],\n",
              "          [ 0.0006,  0.0152,  0.0155,  ...,  0.0458, -0.0002, -0.0101],\n",
              "          [-0.0056, -0.0073, -0.0122,  ..., -0.0253,  0.0349,  0.0042]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006676959019140021, 'loss_breakdown': {'ot': 0.006647514765728472,\n",
              "   'ortho': 0.00028649752663242574,\n",
              "   'graph': 79.4500748306029}, 'best_iter': 2281, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.1,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9651384909264565,\n",
              "   'accuracy_raw': 0.9651384909264565,\n",
              "   'foscttm': 0.1547396527487003}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 0.10260591,  0.11534476, -0.02115489, ..., -0.00141052,\n",
              "           0.02107278, -0.0335997 ],\n",
              "         [ 0.03544818,  0.0808323 , -0.02417903, ..., -0.01548103,\n",
              "          -0.0001315 , -0.01888213],\n",
              "         [-0.03368331,  0.10375662, -0.08201993, ...,  0.03460288,\n",
              "           0.0107769 ,  0.02296324],\n",
              "         ...,\n",
              "         [-0.02993269,  0.09280697,  0.01541533, ...,  0.00967281,\n",
              "          -0.03590849,  0.00880392],\n",
              "         [-0.04122785, -0.05853474,  0.02899599, ..., -0.01509054,\n",
              "           0.10924559,  0.01335118],\n",
              "         [-0.01171442, -0.02877517,  0.04229777, ..., -0.03122296,\n",
              "           0.01249254,  0.00858972]]), 'mapped_Y': array([[ 0.11998867,  0.01317396, -0.03639536, ..., -0.00714075,\n",
              "          -0.01002729, -0.05218   ],\n",
              "         [-0.03986441, -0.08640409,  0.0209756 , ..., -0.01216654,\n",
              "          -0.03420021, -0.00742193],\n",
              "         [ 0.01433921,  0.03544743,  0.06145865, ..., -0.00552315,\n",
              "          -0.0135029 ,  0.01843835],\n",
              "         ...,\n",
              "         [-0.10263605,  0.10993354, -0.09837878, ...,  0.04655535,\n",
              "          -0.0013929 , -0.02348552],\n",
              "         [-0.07437603,  0.03462116,  0.02184102, ...,  0.01855495,\n",
              "           0.03973114,  0.05623363],\n",
              "         [-0.05271966, -0.09908023, -0.0129132 , ...,  0.00177649,\n",
              "          -0.04207364,  0.00583254]]), 'alpha': tensor([[ 8.9066e-03,  7.7248e-02, -6.4290e-03,  ...,  1.1119e-03,\n",
              "            1.2943e-02, -5.7688e-03],\n",
              "          [ 4.3340e-02,  5.2620e-02,  3.9356e-02,  ..., -2.8826e-02,\n",
              "           -2.6995e-02, -2.7113e-02],\n",
              "          [ 7.1967e-03,  6.8297e-03, -5.0824e-02,  ...,  2.4626e-02,\n",
              "           -9.9916e-03,  9.3212e-03],\n",
              "          ...,\n",
              "          [ 5.2460e-03,  3.8979e-02,  8.7320e-02,  ..., -3.4817e-02,\n",
              "           -1.0433e-01,  3.2341e-02],\n",
              "          [ 3.3309e-06, -9.2227e-03,  1.1190e-02,  ..., -7.9737e-03,\n",
              "            1.0146e-01, -9.4556e-03],\n",
              "          [ 1.2896e-02,  1.3548e-02,  3.4180e-02,  ..., -4.0937e-02,\n",
              "           -1.3384e-03, -1.4826e-02]], dtype=torch.float64), 'beta': tensor([[ 0.0097,  0.0145, -0.0050,  ..., -0.0045, -0.0037,  0.0036],\n",
              "          [ 0.0128,  0.0006,  0.0122,  ...,  0.0045, -0.0159, -0.0151],\n",
              "          [-0.0308, -0.0142,  0.0490,  ...,  0.0551,  0.0427, -0.0065],\n",
              "          ...,\n",
              "          [-0.0245,  0.0118, -0.0293,  ..., -0.0131, -0.0071, -0.0185],\n",
              "          [-0.0065,  0.0464,  0.0129,  ...,  0.0267,  0.0185,  0.0188],\n",
              "          [-0.0071, -0.0220, -0.0143,  ...,  0.0157, -0.0246,  0.0047]],\n",
              "         dtype=torch.float64), 'final_loss': 0.019131423511841692, 'loss_breakdown': {'ot': 0.0020501235327894415,\n",
              "   'ortho': 0.07537734699949561,\n",
              "   'graph': 16.327526509057293}, 'best_iter': 399, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.8810888252148997,\n",
              "   'accuracy_raw': 0.8810888252148997,\n",
              "   'foscttm': 0.2425235516219991}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[-0.02989091, -0.06810103, -0.04303009, ..., -0.01370794,\n",
              "           0.02887652, -0.00154708],\n",
              "         [ 0.0519554 , -0.04080461, -0.01884525, ..., -0.05219643,\n",
              "           0.0316447 , -0.01019225],\n",
              "         [-0.00732741,  0.01197961, -0.08188218, ..., -0.00896563,\n",
              "           0.00355431,  0.02445523],\n",
              "         ...,\n",
              "         [-0.05335286,  0.01888023, -0.0099866 , ..., -0.01185122,\n",
              "           0.0007975 ,  0.01184405],\n",
              "         [ 0.11366305,  0.01725917,  0.03682959, ..., -0.00814572,\n",
              "           0.00137785,  0.03676126],\n",
              "         [ 0.04332575, -0.00155062,  0.03858097, ..., -0.01895095,\n",
              "          -0.00228002,  0.00303209]]), 'mapped_Y': array([[ 0.05328385,  0.02718242,  0.00442176, ..., -0.00107409,\n",
              "          -0.03981582, -0.01487038],\n",
              "         [-0.00589337, -0.06910801, -0.00475604, ..., -0.00030439,\n",
              "           0.01925808, -0.00881903],\n",
              "         [ 0.01976046,  0.05819609,  0.0422435 , ..., -0.01973898,\n",
              "           0.04207477,  0.03411308],\n",
              "         ...,\n",
              "         [-0.06910487, -0.02718739, -0.10507695, ...,  0.06974805,\n",
              "           0.01178125,  0.0133876 ],\n",
              "         [-0.02018793,  0.0436918 , -0.079965  , ...,  0.01669661,\n",
              "           0.02031723, -0.0051538 ],\n",
              "         [ 0.00342419, -0.12094974, -0.01406979, ..., -0.00646565,\n",
              "          -0.00193245, -0.01464156]]), 'alpha': tensor([[-0.0101,  0.0003, -0.0101,  ..., -0.0042,  0.0098, -0.0027],\n",
              "          [ 0.0066, -0.0275,  0.0364,  ..., -0.0296,  0.0537, -0.0078],\n",
              "          [ 0.0181, -0.0066, -0.0363,  ...,  0.0035, -0.0042, -0.0012],\n",
              "          ...,\n",
              "          [-0.0830,  0.0019,  0.0352,  ..., -0.0471, -0.0085, -0.0132],\n",
              "          [ 0.0575, -0.0075,  0.0225,  ..., -0.0101,  0.0216,  0.0324],\n",
              "          [ 0.0145, -0.0166,  0.0303,  ..., -0.0352, -0.0040, -0.0261]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0034,  0.0052, -0.0055,  ..., -0.0048, -0.0103, -0.0026],\n",
              "          [ 0.0053,  0.0093,  0.0152,  ...,  0.0034,  0.0022, -0.0011],\n",
              "          [-0.0060,  0.0127,  0.0282,  ...,  0.0476,  0.0602,  0.0082],\n",
              "          ...,\n",
              "          [ 0.0036, -0.0315, -0.0385,  ...,  0.0267, -0.0200, -0.0088],\n",
              "          [-0.0058,  0.0559, -0.0163,  ...,  0.0143,  0.0094,  0.0072],\n",
              "          [ 0.0067, -0.0352, -0.0011,  ..., -0.0043, -0.0080, -0.0023]],\n",
              "         dtype=torch.float64), 'final_loss': 0.019587027837700083, 'loss_breakdown': {'ot': 0.002135398159244065,\n",
              "   'ortho': 0.08535479703280291,\n",
              "   'graph': 16.59808170812799}, 'best_iter': 671, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.20487106017191978,\n",
              "   'accuracy_raw': 0.20487106017191978,\n",
              "   'foscttm': 0.5610736638724916}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[ 0.12483233, -0.03000143, -0.02476031, ..., -0.00603041,\n",
              "           0.0303138 , -0.03909476],\n",
              "         [ 0.07936076,  0.00781851, -0.06402075, ...,  0.00058108,\n",
              "           0.06681164, -0.02967091],\n",
              "         [ 0.03740755,  0.0612012 , -0.12388114, ...,  0.02845631,\n",
              "           0.02431829,  0.02230984],\n",
              "         ...,\n",
              "         [ 0.02155738,  0.07707694, -0.05776607, ..., -0.03336138,\n",
              "          -0.01334056,  0.01042393],\n",
              "         [-0.04598323,  0.00159637,  0.03145397, ...,  0.0132368 ,\n",
              "           0.00736862,  0.04275775],\n",
              "         [-0.04757807,  0.00719007,  0.0221133 , ..., -0.00428933,\n",
              "           0.00173298,  0.0352356 ]]), 'mapped_Y': array([[-8.26777797e-02,  2.64319769e-04, -4.15824357e-03, ...,\n",
              "           8.46116340e-03, -1.63181301e-02, -6.08096298e-03],\n",
              "         [ 5.17569504e-02, -6.87715316e-02,  1.26920900e-02, ...,\n",
              "          -1.14822383e-02,  2.20738616e-02, -1.45616150e-02],\n",
              "         [-3.17174106e-02,  6.73361653e-02, -1.06551607e-02, ...,\n",
              "           3.23107119e-02,  2.59401110e-02, -5.28638543e-03],\n",
              "         ...,\n",
              "         [ 6.42160874e-02,  8.01381162e-02, -1.06213375e-01, ...,\n",
              "           4.41083719e-02,  4.76731056e-02,  4.33891160e-02],\n",
              "         [ 7.85085255e-03, -2.61546056e-02, -1.12925976e-02, ...,\n",
              "           3.35797773e-02,  3.40237286e-03, -1.16278997e-03],\n",
              "         [ 8.31539950e-02, -7.86082803e-02, -6.07072689e-03, ...,\n",
              "          -3.27063476e-02, -4.39800707e-05, -6.30384936e-03]]), 'alpha': tensor([[ 0.0440,  0.0194, -0.0190,  ..., -0.0070,  0.0197, -0.0175],\n",
              "          [ 0.0813, -0.0080,  0.0433,  ..., -0.0099,  0.0727, -0.0427],\n",
              "          [ 0.0052, -0.0073, -0.0306,  ...,  0.0285,  0.0079,  0.0005],\n",
              "          ...,\n",
              "          [-0.0094,  0.0296, -0.0075,  ..., -0.0907, -0.0360,  0.0208],\n",
              "          [ 0.0076, -0.0055,  0.0243,  ...,  0.0184,  0.0154,  0.0302],\n",
              "          [-0.0115, -0.0044,  0.0022,  ..., -0.0194, -0.0183,  0.0126]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0019,  0.0040, -0.0125,  ...,  0.0023, -0.0069,  0.0060],\n",
              "          [-0.0100,  0.0076,  0.0105,  ...,  0.0090,  0.0067, -0.0078],\n",
              "          [-0.0191,  0.0166,  0.0321,  ...,  0.0742,  0.0597, -0.0227],\n",
              "          ...,\n",
              "          [ 0.0062, -0.0055, -0.0307,  ...,  0.0258,  0.0058,  0.0188],\n",
              "          [-0.0175,  0.0230, -0.0047,  ...,  0.0373,  0.0042,  0.0041],\n",
              "          [ 0.0155, -0.0179, -0.0032,  ..., -0.0110, -0.0097,  0.0037]],\n",
              "         dtype=torch.float64), 'final_loss': 0.019388765822687837, 'loss_breakdown': {'ot': 0.0021827905509761276,\n",
              "   'ortho': 0.07587308169773195,\n",
              "   'graph': 16.44724445473439}, 'best_iter': 677, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.31852913085004775,\n",
              "   'accuracy_raw': 0.31852913085004775,\n",
              "   'foscttm': 0.5007421030113783}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 0.41384121, -0.01002607, -0.08795606, ...,  0.01745137,\n",
              "           0.02392837,  0.00276837],\n",
              "         [-0.24675842,  0.13806963, -0.12745634, ..., -0.1236863 ,\n",
              "          -0.01531404, -0.06364705],\n",
              "         [-0.09500709,  0.2659466 , -0.11978112, ..., -0.01423602,\n",
              "          -0.05472282, -0.03098076],\n",
              "         ...,\n",
              "         [-0.0922918 ,  0.20137013, -0.04804347, ..., -0.02273908,\n",
              "          -0.02539857, -0.06460199],\n",
              "         [-0.28511565, -0.05806404, -0.03710649, ..., -0.08454301,\n",
              "           0.11103326,  0.06020068],\n",
              "         [-0.21641456, -0.03958053,  0.00126977, ..., -0.06065756,\n",
              "           0.05228288,  0.00992185]]), 'mapped_Y': array([[ 0.43659231, -0.04699945, -0.05433822, ..., -0.02775977,\n",
              "           0.01972514, -0.01081871],\n",
              "         [-0.37750313, -0.11732048, -0.06008006, ..., -0.08811618,\n",
              "           0.0392882 ,  0.0359678 ],\n",
              "         [ 0.05967555,  0.12881683, -0.00669427, ..., -0.06384829,\n",
              "          -0.02283632,  0.094947  ],\n",
              "         ...,\n",
              "         [-0.16919019,  0.26062509, -0.1341338 , ..., -0.02895805,\n",
              "          -0.04057565, -0.14759904],\n",
              "         [-0.28456814, -0.03445057, -0.04025735, ...,  0.02009079,\n",
              "           0.10123787,  0.04666557],\n",
              "         [-0.33492267, -0.11827152, -0.06859341, ..., -0.03626567,\n",
              "           0.00865925,  0.0254939 ]]), 'alpha': tensor([[ 1.4120e-02,  4.7756e-02, -1.0477e-02,  ..., -3.8960e-05,\n",
              "            1.4779e-02, -4.6520e-03],\n",
              "          [ 2.4745e-02, -5.2073e-04,  2.3171e-02,  ..., -4.8309e-02,\n",
              "           -5.6363e-03, -1.3544e-02],\n",
              "          [ 4.1209e-03,  6.0917e-03, -1.9040e-02,  ...,  1.6523e-02,\n",
              "           -3.6150e-03, -7.2249e-03],\n",
              "          ...,\n",
              "          [ 4.6799e-03,  2.8784e-02, -7.8444e-03,  ..., -2.6540e-02,\n",
              "            2.3550e-02,  1.6491e-02],\n",
              "          [-9.7809e-03,  2.2900e-02, -6.9181e-03,  ..., -6.2198e-02,\n",
              "            4.4687e-02,  4.8960e-03],\n",
              "          [-9.6543e-03,  1.1559e-02, -2.1027e-02,  ..., -9.6190e-02,\n",
              "            3.1215e-02, -2.0319e-02]], dtype=torch.float64), 'beta': tensor([[-2.6028e-04,  7.9509e-03, -1.5888e-03,  ..., -3.6976e-03,\n",
              "            1.3484e-02, -7.9457e-03],\n",
              "          [ 3.0331e-03,  8.0453e-03,  6.7373e-03,  ..., -1.8459e-02,\n",
              "            2.9963e-04,  3.6815e-03],\n",
              "          [ 1.4225e-02,  3.1692e-02,  6.5277e-03,  ..., -2.2012e-02,\n",
              "            1.3239e-02,  3.0537e-02],\n",
              "          ...,\n",
              "          [-6.3467e-03, -2.3076e-03, -1.4604e-02,  ..., -1.0218e-02,\n",
              "            6.4408e-03, -4.1524e-02],\n",
              "          [ 1.1111e-02,  5.5278e-02, -5.6567e-03,  ...,  1.5755e-02,\n",
              "            3.1226e-02,  1.2075e-02],\n",
              "          [-1.2726e-02, -1.8960e-02, -4.8621e-05,  ...,  1.0015e-02,\n",
              "           -2.1242e-02, -4.0853e-03]], dtype=torch.float64), 'final_loss': 0.007060483097766743, 'loss_breakdown': {'ot': 0.002751012195681888,\n",
              "   'ortho': 0.015073557022380491,\n",
              "   'graph': 41.587353318610496}, 'best_iter': 884, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.15029205197184112}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.26119607, -0.05434652,  0.03562691, ...,  0.0081415 ,\n",
              "           0.05384102, -0.04228252],\n",
              "         [ 0.00157884,  0.17427062, -0.05329301, ..., -0.02025951,\n",
              "           0.03128617, -0.01354059],\n",
              "         [ 0.08343558,  0.14630231,  0.01806458, ...,  0.07505959,\n",
              "          -0.03640862, -0.02528699],\n",
              "         ...,\n",
              "         [ 0.1126512 ,  0.14139815,  0.0254624 , ...,  0.06523673,\n",
              "          -0.03985494, -0.02017736],\n",
              "         [-0.27239187,  0.1051357 , -0.11854628, ..., -0.06617756,\n",
              "           0.09853125,  0.08342661],\n",
              "         [-0.19815918,  0.09216043, -0.09557969, ..., -0.05882819,\n",
              "           0.08460736,  0.08709362]]), 'mapped_Y': array([[ 2.82829535e-01, -1.48944347e-01,  5.86468759e-02, ...,\n",
              "          -2.93157028e-02,  5.11028325e-02, -6.62963596e-02],\n",
              "         [-3.43716971e-01,  6.38468253e-02, -1.04273886e-01, ...,\n",
              "          -3.61529872e-02,  3.22218320e-02,  6.23778075e-02],\n",
              "         [ 7.75946734e-02,  8.93706114e-02,  7.27964096e-02, ...,\n",
              "           1.78556161e-02, -3.16897338e-02,  1.55729428e-02],\n",
              "         ...,\n",
              "         [ 5.18942791e-02,  1.39390532e-01, -2.80933958e-04, ...,\n",
              "           7.62323909e-02, -3.47308053e-03,  1.51883792e-02],\n",
              "         [-2.39240210e-01,  9.84791628e-02, -9.43836810e-02, ...,\n",
              "           2.76735228e-02,  6.11467604e-02,  1.03896261e-01],\n",
              "         [-2.99301935e-01,  4.43189572e-02, -1.48223780e-01, ...,\n",
              "          -3.10100819e-02,  4.50308711e-02,  5.73512056e-02]]), 'alpha': tensor([[ 0.0069,  0.0266,  0.0149,  ...,  0.0041,  0.0116, -0.0122],\n",
              "          [ 0.0499,  0.0054,  0.0266,  ..., -0.0449,  0.0067, -0.0038],\n",
              "          [-0.0085,  0.0128, -0.0097,  ...,  0.0352,  0.0056, -0.0110],\n",
              "          ...,\n",
              "          [ 0.0251,  0.0506, -0.0067,  ...,  0.0263,  0.0325,  0.0183],\n",
              "          [-0.0118,  0.0173,  0.0008,  ..., -0.0413,  0.0315, -0.0045],\n",
              "          [-0.0015,  0.0350, -0.0098,  ..., -0.0618,  0.0320, -0.0248]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0039,  0.0014,  0.0052,  ..., -0.0016,  0.0143, -0.0058],\n",
              "          [-0.0021,  0.0041,  0.0155,  ..., -0.0036, -0.0061, -0.0017],\n",
              "          [ 0.0086, -0.0030,  0.0380,  ...,  0.0256,  0.0092,  0.0264],\n",
              "          ...,\n",
              "          [-0.0127,  0.0012, -0.0140,  ...,  0.0186,  0.0148, -0.0006],\n",
              "          [ 0.0263,  0.0331,  0.0021,  ...,  0.0030,  0.0251,  0.0213],\n",
              "          [-0.0139, -0.0153, -0.0145,  ..., -0.0003, -0.0024, -0.0087]],\n",
              "         dtype=torch.float64), 'final_loss': 0.005416502418174256, 'loss_breakdown': {'ot': 0.0022351741934886573,\n",
              "   'ortho': 0.006679281831511557,\n",
              "   'graph': 31.145354063704826}, 'best_iter': 1833, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.1546634811427383}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 0.1895026 ,  0.08942193, -0.19682242, ..., -0.05692716,\n",
              "           0.15325328,  0.03608999],\n",
              "         [-0.04634017,  0.11392103,  0.01617181, ...,  0.05377212,\n",
              "          -0.08002038, -0.11279586],\n",
              "         [ 0.06930898,  0.11370955, -0.01242709, ...,  0.12837302,\n",
              "          -0.09854093, -0.12393224],\n",
              "         ...,\n",
              "         [ 0.08227783,  0.05514049,  0.02941383, ...,  0.10346936,\n",
              "          -0.0789587 , -0.06228115],\n",
              "         [-0.25945483,  0.0692413 ,  0.11235946, ..., -0.06204242,\n",
              "           0.01477924,  0.00093593],\n",
              "         [-0.16214701,  0.05225219,  0.11079476, ..., -0.05736436,\n",
              "           0.04166233,  0.02403245]]), 'mapped_Y': array([[ 0.23504389,  0.00396858, -0.22121991, ..., -0.08005366,\n",
              "           0.1688431 ,  0.0420129 ],\n",
              "         [-0.36108099,  0.02490376,  0.12117733, ..., -0.01806526,\n",
              "           0.02031389,  0.04381497],\n",
              "         [ 0.08142171,  0.08359641,  0.04593722, ...,  0.01260564,\n",
              "          -0.03221233, -0.01638058],\n",
              "         ...,\n",
              "         [ 0.03873691,  0.03722892,  0.01764747, ...,  0.17821075,\n",
              "          -0.12016252, -0.13139604],\n",
              "         [-0.29602821,  0.06193028,  0.10889485, ...,  0.05952345,\n",
              "           0.0695815 ,  0.0778914 ],\n",
              "         [-0.29007285,  0.0018953 ,  0.05931654, ..., -0.01487503,\n",
              "           0.03632796,  0.04968431]]), 'alpha': tensor([[ 0.0065,  0.0298,  0.0127,  ...,  0.0007,  0.0093, -0.0257],\n",
              "          [ 0.0505,  0.0142,  0.0070,  ..., -0.0381, -0.0100, -0.0113],\n",
              "          [-0.0110,  0.0254, -0.0127,  ...,  0.0346,  0.0136, -0.0242],\n",
              "          ...,\n",
              "          [ 0.0356,  0.0336,  0.0159,  ...,  0.0026,  0.0037,  0.0582],\n",
              "          [-0.0021,  0.0218,  0.0109,  ..., -0.0374,  0.0135, -0.0239],\n",
              "          [ 0.0082,  0.0189,  0.0056,  ..., -0.0588,  0.0079, -0.0142]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0032,  0.0020, -0.0003,  ...,  0.0031,  0.0192, -0.0080],\n",
              "          [ 0.0019,  0.0093,  0.0148,  ..., -0.0048, -0.0005, -0.0021],\n",
              "          [ 0.0130, -0.0075,  0.0468,  ...,  0.0312, -0.0023, -0.0037],\n",
              "          ...,\n",
              "          [-0.0198, -0.0188, -0.0039,  ...,  0.0569,  0.0188, -0.0064],\n",
              "          [ 0.0174,  0.0317,  0.0083,  ...,  0.0089,  0.0172, -0.0019],\n",
              "          [-0.0064, -0.0105, -0.0192,  ...,  0.0031,  0.0134,  0.0175]],\n",
              "         dtype=torch.float64), 'final_loss': 0.006167081885117918, 'loss_breakdown': {'ot': 0.0025671419772376972,\n",
              "   'ortho': 0.00933002620113353,\n",
              "   'graph': 35.06639645868884}, 'best_iter': 1588, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.1525936203771361}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[ 0.3874703 , -0.08038856, -0.07243101, ...,  0.048181  ,\n",
              "           0.14366095, -0.0179895 ],\n",
              "         [-0.13197535,  0.1799317 , -0.07906091, ..., -0.13605139,\n",
              "          -0.12682304, -0.01644663],\n",
              "         [ 0.04948953,  0.27872698, -0.00342382, ..., -0.0349231 ,\n",
              "          -0.06787946, -0.0573802 ],\n",
              "         ...,\n",
              "         [-0.03032207,  0.2463012 ,  0.05956052, ...,  0.05756913,\n",
              "          -0.09483515, -0.25375446],\n",
              "         [-0.31283581,  0.00483465, -0.12519443, ..., -0.15348981,\n",
              "          -0.03188685,  0.03602584],\n",
              "         [-0.31958267, -0.0241411 , -0.04182832, ..., -0.18771172,\n",
              "          -0.0467403 , -0.09715989]]), 'mapped_Y': array([[ 0.44122776, -0.12836901, -0.01902101, ...,  0.01089878,\n",
              "           0.11426454, -0.00752942],\n",
              "         [-0.40836205, -0.01872729, -0.17248712, ...,  0.02642502,\n",
              "          -0.13150438,  0.02335223],\n",
              "         [ 0.09773144,  0.13819055,  0.03414265, ..., -0.07652419,\n",
              "           0.01403635,  0.10399069],\n",
              "         ...,\n",
              "         [-0.00973905,  0.26439579,  0.00289023, ...,  0.01554638,\n",
              "          -0.12803517, -0.1703926 ],\n",
              "         [-0.32609151,  0.04206678, -0.11993977, ...,  0.2594956 ,\n",
              "          -0.10860598,  0.07897696],\n",
              "         [-0.35025875, -0.0403749 , -0.15884153, ..., -0.18231182,\n",
              "          -0.04011998,  0.0431742 ]]), 'alpha': tensor([[ 0.0061,  0.0386, -0.0003,  ..., -0.0045,  0.0130, -0.0014],\n",
              "          [ 0.0121, -0.0190,  0.0287,  ..., -0.0359, -0.0092,  0.0086],\n",
              "          [ 0.0018,  0.0091, -0.0151,  ...,  0.0093,  0.0178, -0.0073],\n",
              "          ...,\n",
              "          [ 0.0057,  0.0303, -0.0007,  ...,  0.0042, -0.0193, -0.0248],\n",
              "          [-0.0016,  0.0177, -0.0036,  ..., -0.0681,  0.0174, -0.0099],\n",
              "          [-0.0048,  0.0094, -0.0182,  ..., -0.1192,  0.0003, -0.0381]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0014,  0.0042, -0.0008,  ..., -0.0070,  0.0066,  0.0030],\n",
              "          [ 0.0008,  0.0074,  0.0023,  ..., -0.0033, -0.0002,  0.0004],\n",
              "          [ 0.0190,  0.0202,  0.0128,  ..., -0.0342,  0.0052,  0.0136],\n",
              "          ...,\n",
              "          [-0.0087, -0.0139, -0.0158,  ...,  0.0062,  0.0016, -0.0090],\n",
              "          [ 0.0068,  0.0382,  0.0093,  ...,  0.0523,  0.0155,  0.0050],\n",
              "          [-0.0071, -0.0126, -0.0116,  ..., -0.0296, -0.0056, -0.0053]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004920154618248535, 'loss_breakdown': {'ot': 0.0041329806397392786,\n",
              "   'ortho': 0.0052075332066982925,\n",
              "   'graph': 73.50986464422739}, 'best_iter': 1338, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9646609360076409,\n",
              "   'accuracy_raw': 0.9646609360076409,\n",
              "   'foscttm': 0.15513236983093553}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[ 0.24067478, -0.13762797,  0.01439955, ...,  0.10106249,\n",
              "           0.00683973, -0.12622696],\n",
              "         [-0.02755026,  0.22265284, -0.15904172, ..., -0.13853272,\n",
              "           0.06840324,  0.05528907],\n",
              "         [ 0.16997188,  0.25938426, -0.11132459, ..., -0.04152298,\n",
              "           0.06732905,  0.02598961],\n",
              "         ...,\n",
              "         [ 0.0870851 ,  0.15986979, -0.01713814, ...,  0.00322293,\n",
              "           0.04569071, -0.02366576],\n",
              "         [-0.28600393,  0.10443394, -0.12433066, ..., -0.08165025,\n",
              "           0.05554891,  0.03034958],\n",
              "         [-0.20273348,  0.0299664 , -0.05719677, ..., -0.12643436,\n",
              "           0.06520039,  0.04153283]]), 'mapped_Y': array([[ 0.2867433 , -0.18426493,  0.03667252, ...,  0.07242787,\n",
              "           0.01403453, -0.14865472],\n",
              "         [-0.46273404,  0.01164517, -0.06713518, ..., -0.01598468,\n",
              "          -0.05116718,  0.02217928],\n",
              "         [ 0.10965028,  0.15425317,  0.04686286, ..., -0.07422069,\n",
              "          -0.03151123,  0.04325118],\n",
              "         ...,\n",
              "         [ 0.1309607 ,  0.25034567, -0.14408288, ...,  0.01911685,\n",
              "           0.10616442,  0.03364795],\n",
              "         [-0.44095718, -0.01323187,  0.04647224, ...,  0.11273062,\n",
              "          -0.07274717,  0.09143962],\n",
              "         [-0.32038735,  0.0430528 , -0.11997705, ..., -0.12260527,\n",
              "           0.03695816,  0.09410725]]), 'alpha': tensor([[ 0.0036,  0.0229,  0.0142,  ..., -0.0009,  0.0089, -0.0120],\n",
              "          [ 0.0284,  0.0011,  0.0042,  ..., -0.0549,  0.0006,  0.0055],\n",
              "          [-0.0048,  0.0151, -0.0057,  ...,  0.0258,  0.0062, -0.0107],\n",
              "          ...,\n",
              "          [ 0.0154,  0.0195, -0.0014,  ..., -0.0093,  0.0058,  0.0246],\n",
              "          [-0.0004,  0.0159, -0.0026,  ..., -0.0394,  0.0297, -0.0152],\n",
              "          [ 0.0025,  0.0183, -0.0134,  ..., -0.0734,  0.0398, -0.0351]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0048,  0.0017,  0.0054,  ..., -0.0003,  0.0122, -0.0062],\n",
              "          [-0.0051,  0.0049,  0.0098,  ...,  0.0001, -0.0124, -0.0104],\n",
              "          [ 0.0069,  0.0014,  0.0167,  ...,  0.0076, -0.0291, -0.0158],\n",
              "          ...,\n",
              "          [-0.0117,  0.0195, -0.0106,  ...,  0.0182,  0.0059,  0.0121],\n",
              "          [ 0.0020,  0.0201,  0.0234,  ...,  0.0220, -0.0002, -0.0047],\n",
              "          [-0.0026, -0.0088, -0.0148,  ..., -0.0128,  0.0153,  0.0063]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00453323671723355, 'loss_breakdown': {'ot': 0.0038804924323803665,\n",
              "   'ortho': 0.005237201345970055,\n",
              "   'graph': 60.03722713934821}, 'best_iter': 1351, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9584527220630372,\n",
              "   'accuracy_raw': 0.9584527220630372,\n",
              "   'foscttm': 0.1513178600066228}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.15299889, -0.01355182, -0.05181193, ..., -0.10870453,\n",
              "           0.1622605 , -0.00624464],\n",
              "         [-0.00435663,  0.23282758, -0.01222562, ..., -0.00969051,\n",
              "          -0.02660235, -0.00258557],\n",
              "         [ 0.12129414,  0.26043119, -0.03066189, ...,  0.03429971,\n",
              "          -0.01569463,  0.00303221],\n",
              "         ...,\n",
              "         [ 0.11889911,  0.1299913 ,  0.03070488, ...,  0.09026626,\n",
              "          -0.03327838,  0.03521325],\n",
              "         [-0.22415569,  0.06354227, -0.03270841, ...,  0.0063054 ,\n",
              "          -0.04541687,  0.00573463],\n",
              "         [-0.15542369,  0.04998232,  0.1055485 , ..., -0.03147841,\n",
              "          -0.09009418, -0.03213918]]), 'mapped_Y': array([[ 1.82618585e-01, -6.58442093e-02, -6.32803900e-02, ...,\n",
              "          -1.41661186e-01,  1.89781187e-01, -2.51120645e-02],\n",
              "         [-3.88318063e-01, -1.77681245e-02,  3.68814988e-02, ...,\n",
              "           1.57462592e-02, -7.54166874e-02,  1.95031777e-02],\n",
              "         [ 8.95858730e-02,  9.37376509e-02,  6.46471111e-02, ...,\n",
              "          -5.12517712e-04, -4.89712433e-02,  1.16821989e-02],\n",
              "         ...,\n",
              "         [ 1.15378038e-01,  2.36475931e-01, -5.96773010e-02, ...,\n",
              "           1.03103040e-01,  1.19001992e-02,  2.61477297e-02],\n",
              "         [-3.45782275e-01,  1.76549229e-04,  1.48343656e-01, ...,\n",
              "           3.51909941e-02,  3.90318465e-02,  7.91283092e-02],\n",
              "         [-2.91120837e-01, -3.48518500e-03, -5.71129157e-02, ...,\n",
              "           4.60147899e-02, -5.91509709e-02,  2.72820181e-02]]), 'alpha': tensor([[ 0.0055,  0.0320,  0.0156,  ...,  0.0024,  0.0102, -0.0070],\n",
              "          [ 0.0361,  0.0137,  0.0232,  ..., -0.0408, -0.0036, -0.0216],\n",
              "          [-0.0089,  0.0295, -0.0086,  ..., -0.0122, -0.0076, -0.0054],\n",
              "          ...,\n",
              "          [ 0.0046,  0.0331,  0.0175,  ...,  0.0514,  0.0541,  0.0480],\n",
              "          [ 0.0059,  0.0143, -0.0133,  ..., -0.0225, -0.0028, -0.0289],\n",
              "          [ 0.0020,  0.0331,  0.0245,  ..., -0.0310,  0.0198, -0.0383]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-4.5172e-03,  4.2877e-03,  4.2800e-03,  ...,  5.1676e-03,\n",
              "            1.7562e-02, -4.5476e-03],\n",
              "          [-7.8489e-03,  4.0168e-03,  2.0111e-02,  ..., -6.2584e-03,\n",
              "           -7.5944e-03, -5.8401e-03],\n",
              "          [ 9.6355e-05, -8.5623e-03,  4.9850e-02,  ...,  1.8409e-02,\n",
              "           -2.7244e-02, -2.3650e-02],\n",
              "          ...,\n",
              "          [-1.5080e-02,  4.4502e-03, -1.7816e-03,  ...,  5.3514e-02,\n",
              "            3.0896e-02,  1.6101e-02],\n",
              "          [ 7.1461e-03,  3.0137e-02,  3.7994e-02,  ..., -5.7476e-04,\n",
              "            3.2952e-02,  1.0460e-02],\n",
              "          [-5.7667e-03, -1.3356e-02, -2.9079e-02,  ...,  4.2544e-03,\n",
              "           -1.0138e-03,  2.3984e-03]], dtype=torch.float64), 'final_loss': 0.00265985716785953, 'loss_breakdown': {'ot': 0.0022203354906340945,\n",
              "   'ortho': 0.0017786493489056856,\n",
              "   'graph': 42.17351837363786}, 'best_iter': 3134, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.15306524576973918}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[ 0.41743848, -0.06718089, -0.02466989, ...,  0.04629329,\n",
              "           0.09477247, -0.05751697],\n",
              "         [-0.14031953,  0.10642931, -0.09533496, ..., -0.11250293,\n",
              "          -0.01324269,  0.00056977],\n",
              "         [-0.02976122,  0.18753722, -0.02580948, ..., -0.04379949,\n",
              "           0.06897472, -0.07113489],\n",
              "         ...,\n",
              "         [-0.09098775,  0.1778785 ,  0.07329628, ...,  0.01705117,\n",
              "           0.01636392, -0.22182167],\n",
              "         [-0.29510281,  0.00749732, -0.15444756, ..., -0.12577533,\n",
              "          -0.0433251 ,  0.0749597 ],\n",
              "         [-0.35585423, -0.00804636, -0.06536277, ..., -0.13362689,\n",
              "          -0.03609498, -0.09450111]]), 'mapped_Y': array([[ 0.44691176, -0.1373563 ,  0.0158942 , ...,  0.00385219,\n",
              "           0.07463061, -0.0419812 ],\n",
              "         [-0.29842352,  0.05851146, -0.17499536, ...,  0.06319777,\n",
              "          -0.19157528,  0.09369729],\n",
              "         [ 0.07272905,  0.1099683 ,  0.04724569, ..., -0.05498101,\n",
              "           0.01386991,  0.07346748],\n",
              "         ...,\n",
              "         [-0.08474245,  0.17795042, -0.02983331, ..., -0.01443502,\n",
              "           0.05066187, -0.13201509],\n",
              "         [-0.19657555,  0.11062633, -0.12366189, ...,  0.19991458,\n",
              "          -0.1354345 ,  0.17837721],\n",
              "         [-0.33649574, -0.01901209, -0.16974459, ..., -0.11029651,\n",
              "          -0.09902014,  0.05331803]]), 'alpha': tensor([[ 1.2663e-02,  4.0212e-02,  4.7244e-05,  ..., -7.1448e-03,\n",
              "            1.9762e-02, -3.2669e-03],\n",
              "          [ 1.7250e-02, -2.8802e-02,  2.8600e-02,  ..., -3.3523e-02,\n",
              "            8.4215e-03,  1.8715e-02],\n",
              "          [ 6.6089e-04,  3.8992e-03, -1.4193e-02,  ...,  1.2164e-02,\n",
              "            1.8110e-02, -1.3158e-02],\n",
              "          ...,\n",
              "          [ 9.2444e-03,  4.0336e-02, -3.9632e-03,  ..., -2.9121e-03,\n",
              "           -2.2056e-02, -1.9387e-02],\n",
              "          [-4.7386e-03,  1.1792e-02, -8.3382e-03,  ..., -7.4337e-02,\n",
              "            1.1943e-02, -5.2877e-03],\n",
              "          [-1.1257e-02,  1.6060e-03, -2.7910e-02,  ..., -1.0625e-01,\n",
              "           -6.3250e-03, -3.3639e-02]], dtype=torch.float64), 'beta': tensor([[ 0.0042,  0.0036, -0.0044,  ..., -0.0077,  0.0075,  0.0061],\n",
              "          [ 0.0108,  0.0137,  0.0053,  ..., -0.0001, -0.0061,  0.0058],\n",
              "          [ 0.0226,  0.0254,  0.0174,  ..., -0.0246, -0.0004,  0.0189],\n",
              "          ...,\n",
              "          [-0.0047, -0.0094, -0.0255,  ...,  0.0027,  0.0057,  0.0072],\n",
              "          [ 0.0177,  0.0450,  0.0126,  ...,  0.0443,  0.0121,  0.0166],\n",
              "          [-0.0109, -0.0182, -0.0135,  ..., -0.0264, -0.0166, -0.0079]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003130564729998714, 'loss_breakdown': {'ot': 0.0030433671587924843,\n",
              "   'ortho': 0.002228887138812262,\n",
              "   'graph': 64.90869981810692}, 'best_iter': 1838, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9594078319006686,\n",
              "   'accuracy_raw': 0.9594078319006686,\n",
              "   'foscttm': 0.16021853496915278}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.41319133, -0.05479018, -0.0071554 , ...,  0.09328461,\n",
              "           0.08848415, -0.10633554],\n",
              "         [-0.20894304,  0.22906198, -0.07664707, ..., -0.18151793,\n",
              "          -0.00875913,  0.0579003 ],\n",
              "         [-0.04432785,  0.28688348,  0.00688983, ..., -0.13319394,\n",
              "           0.01281165,  0.04554772],\n",
              "         ...,\n",
              "         [-0.09959934,  0.18253321,  0.07629009, ..., -0.03073387,\n",
              "          -0.00696484, -0.0686403 ],\n",
              "         [-0.30313052,  0.02735437, -0.19977168, ..., -0.03334684,\n",
              "           0.04007281,  0.04948416],\n",
              "         [-0.30168655, -0.07734528, -0.01763133, ..., -0.13523899,\n",
              "           0.0050032 ,  0.07893622]]), 'mapped_Y': array([[ 0.43690202, -0.08677497,  0.02044428, ...,  0.04388588,\n",
              "           0.11076359, -0.13962839],\n",
              "         [-0.40270728, -0.05525683, -0.12907938, ...,  0.10792177,\n",
              "          -0.08392908,  0.005848  ],\n",
              "         [ 0.07379469,  0.14086052,  0.07590552, ..., -0.10239541,\n",
              "          -0.01669292,  0.05837247],\n",
              "         ...,\n",
              "         [-0.11921747,  0.30312802, -0.02206014, ..., -0.07150492,\n",
              "           0.01339797,  0.02015216],\n",
              "         [-0.31497525, -0.04963147, -0.0327121 , ...,  0.26908995,\n",
              "          -0.12488792,  0.07297912],\n",
              "         [-0.34100608, -0.04923036, -0.15654593, ..., -0.09815731,\n",
              "           0.01213774,  0.1010462 ]]), 'alpha': tensor([[ 0.0030,  0.0202,  0.0152,  ...,  0.0004,  0.0133, -0.0010],\n",
              "          [ 0.0130,  0.0023,  0.0058,  ..., -0.0486, -0.0012,  0.0006],\n",
              "          [-0.0059,  0.0118,  0.0010,  ...,  0.0192,  0.0035, -0.0050],\n",
              "          ...,\n",
              "          [ 0.0028,  0.0240, -0.0031,  ..., -0.0084,  0.0014,  0.0086],\n",
              "          [-0.0085,  0.0120, -0.0130,  ..., -0.0426,  0.0435, -0.0119],\n",
              "          [-0.0093,  0.0153, -0.0147,  ..., -0.0725,  0.0460, -0.0247]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0037,  0.0017,  0.0047,  ...,  0.0021,  0.0165, -0.0046],\n",
              "          [-0.0025,  0.0024,  0.0095,  ...,  0.0040, -0.0109, -0.0110],\n",
              "          [ 0.0072,  0.0014,  0.0205,  ...,  0.0095, -0.0221, -0.0110],\n",
              "          ...,\n",
              "          [-0.0080,  0.0354, -0.0069,  ...,  0.0102, -0.0013,  0.0072],\n",
              "          [ 0.0055,  0.0198,  0.0247,  ...,  0.0329, -0.0069, -0.0037],\n",
              "          [-0.0058, -0.0098, -0.0163,  ..., -0.0239,  0.0204,  0.0020]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004596046255826277, 'loss_breakdown': {'ot': 0.00447185734488361,\n",
              "   'ortho': 0.005797066757339252,\n",
              "   'graph': 66.21824336927489}, 'best_iter': 1197, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9617956064947468,\n",
              "   'accuracy_raw': 0.9617956064947468,\n",
              "   'foscttm': 0.15293707678006657}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.26611059, -0.04175348, -0.04671782, ..., -0.02967666,\n",
              "           0.21831183,  0.06007523],\n",
              "         [-0.10809485,  0.23443593, -0.05168513, ..., -0.08189833,\n",
              "          -0.11393315,  0.01616001],\n",
              "         [ 0.043981  ,  0.32790155, -0.00453834, ..., -0.01095861,\n",
              "          -0.0771028 ,  0.01592267],\n",
              "         ...,\n",
              "         [ 0.07578124,  0.13474472,  0.09140016, ...,  0.08358343,\n",
              "          -0.10825784, -0.03063501],\n",
              "         [-0.27250535,  0.04447394, -0.11531279, ..., -0.00964819,\n",
              "          -0.01636927, -0.06510549],\n",
              "         [-0.20234296, -0.00829306,  0.0484424 , ..., -0.14521241,\n",
              "          -0.13707128, -0.02526842]]), 'mapped_Y': array([[ 0.28500538, -0.06862644, -0.04734766, ..., -0.0635179 ,\n",
              "           0.22460212,  0.04254775],\n",
              "         [-0.36085409, -0.10692329, -0.07988843, ...,  0.06614606,\n",
              "          -0.09486073, -0.09463893],\n",
              "         [ 0.07172212,  0.13679849,  0.07164528, ..., -0.06220001,\n",
              "          -0.07747336,  0.03525826],\n",
              "         ...,\n",
              "         [ 0.0391904 ,  0.28727289, -0.01855905, ...,  0.07680573,\n",
              "          -0.08341922,  0.00464827],\n",
              "         [-0.35778146, -0.11964489,  0.07158391, ...,  0.15427306,\n",
              "          -0.01618001, -0.00147172],\n",
              "         [-0.32097074, -0.02606085, -0.10594825, ..., -0.04788574,\n",
              "          -0.04928448, -0.01205119]]), 'alpha': tensor([[ 0.0023,  0.0248,  0.0215,  ...,  0.0015,  0.0135, -0.0080],\n",
              "          [ 0.0242,  0.0082,  0.0137,  ..., -0.0465, -0.0145, -0.0120],\n",
              "          [-0.0065,  0.0278, -0.0025,  ...,  0.0231,  0.0113, -0.0133],\n",
              "          ...,\n",
              "          [ 0.0138,  0.0097,  0.0111,  ...,  0.0161, -0.0029,  0.0247],\n",
              "          [ 0.0026,  0.0162, -0.0108,  ..., -0.0298, -0.0013, -0.0244],\n",
              "          [-0.0001,  0.0222,  0.0061,  ..., -0.0569,  0.0051, -0.0419]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0044,  0.0017,  0.0024,  ..., -0.0009,  0.0147, -0.0067],\n",
              "          [-0.0014,  0.0001,  0.0095,  ...,  0.0021, -0.0133, -0.0140],\n",
              "          [ 0.0003, -0.0059,  0.0182,  ...,  0.0076, -0.0332, -0.0292],\n",
              "          ...,\n",
              "          [-0.0113,  0.0117, -0.0005,  ...,  0.0290,  0.0083,  0.0117],\n",
              "          [ 0.0027,  0.0192,  0.0359,  ...,  0.0199,  0.0113, -0.0048],\n",
              "          [-0.0047, -0.0087, -0.0212,  ..., -0.0103, -0.0016,  0.0062]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0042754565889782424, 'loss_breakdown': {'ot': 0.004167305688327747,\n",
              "   'ortho': 0.004554190741641801,\n",
              "   'graph': 62.608993234077744}, 'best_iter': 1387, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9656160458452723,\n",
              "   'accuracy_raw': 0.9656160458452723,\n",
              "   'foscttm': 0.15291381479261712}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[ 0.36474287, -0.0965209 , -0.1734355 , ...,  0.07005282,\n",
              "           0.05230488,  0.01535436],\n",
              "         [-0.17738957,  0.16151381, -0.0442366 , ..., -0.18862245,\n",
              "           0.00503206,  0.03606605],\n",
              "         [ 0.02455828,  0.26221588, -0.02716489, ..., -0.10428765,\n",
              "           0.06062082,  0.02030679],\n",
              "         ...,\n",
              "         [ 0.00778351,  0.24499458,  0.04149434, ...,  0.0181127 ,\n",
              "           0.02255736, -0.21385799],\n",
              "         [-0.35815123, -0.0068414 , -0.01846423, ..., -0.13913773,\n",
              "          -0.03899971, -0.01776641],\n",
              "         [-0.31224997, -0.03075067,  0.07153226, ..., -0.1813409 ,\n",
              "          -0.01922172, -0.15855131]]), 'mapped_Y': array([[ 0.41611118, -0.14702293, -0.14488032, ...,  0.02608966,\n",
              "           0.02569064,  0.04133286],\n",
              "         [-0.42620128,  0.02400081, -0.04883452, ...,  0.09560326,\n",
              "          -0.17883689, -0.03915916],\n",
              "         [ 0.09683491,  0.13408936,  0.00785444, ..., -0.09208832,\n",
              "           0.01296819,  0.15320785],\n",
              "         ...,\n",
              "         [-0.01497831,  0.25979523, -0.02381272, ..., -0.06043389,\n",
              "           0.02294906, -0.07517434],\n",
              "         [-0.35297317,  0.04035753,  0.01779459, ...,  0.28367484,\n",
              "          -0.07495116, -0.00076521],\n",
              "         [-0.39205941, -0.02452515, -0.04934257, ..., -0.15808476,\n",
              "          -0.05826184,  0.01165408]]), 'alpha': tensor([[ 0.0099,  0.0361, -0.0010,  ..., -0.0064,  0.0148, -0.0008],\n",
              "          [ 0.0133, -0.0273,  0.0218,  ..., -0.0393, -0.0012,  0.0130],\n",
              "          [-0.0007,  0.0086, -0.0131,  ...,  0.0071,  0.0170, -0.0072],\n",
              "          ...,\n",
              "          [ 0.0154,  0.0330, -0.0038,  ...,  0.0062, -0.0085, -0.0252],\n",
              "          [-0.0014,  0.0100, -0.0063,  ..., -0.0672,  0.0143, -0.0095],\n",
              "          [-0.0028, -0.0012, -0.0208,  ..., -0.0996,  0.0035, -0.0395]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 2.0431e-03,  3.1406e-03, -2.8559e-03,  ..., -7.2523e-03,\n",
              "            2.7289e-03,  4.0891e-03],\n",
              "          [ 5.0783e-03,  1.2226e-02,  1.3599e-05,  ...,  4.0903e-03,\n",
              "           -1.2303e-02,  2.9155e-03],\n",
              "          [ 1.6741e-02,  2.0761e-02,  7.3277e-03,  ..., -2.7015e-02,\n",
              "           -4.6348e-03,  1.8958e-02],\n",
              "          ...,\n",
              "          [-1.0614e-02, -8.0331e-03, -1.6657e-02,  ...,  4.1463e-03,\n",
              "            2.3734e-03,  2.6200e-03],\n",
              "          [ 1.0634e-02,  3.4704e-02,  1.4175e-02,  ...,  4.6840e-02,\n",
              "            1.7369e-02,  9.3781e-03],\n",
              "          [-8.5921e-03, -1.2578e-02, -1.1793e-02,  ..., -3.0867e-02,\n",
              "           -1.4449e-02, -8.1653e-05]], dtype=torch.float64), 'final_loss': 0.004122044949812211, 'loss_breakdown': {'ot': 0.004080968367052204,\n",
              "   'ortho': 0.003348155230062078,\n",
              "   'graph': 75.95030459385717}, 'best_iter': 1451, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.15720496730094352}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.38115265, -0.0308977 , -0.07257841, ...,  0.12160429,\n",
              "           0.10934346, -0.02589723],\n",
              "         [-0.19451181,  0.23758634, -0.06580833, ..., -0.19071504,\n",
              "          -0.02929657, -0.01453326],\n",
              "         [-0.02877319,  0.31283256, -0.0096105 , ..., -0.11482084,\n",
              "           0.00677656, -0.00528897],\n",
              "         ...,\n",
              "         [-0.08776098,  0.19534814,  0.02558753, ..., -0.00854576,\n",
              "          -0.00622754, -0.11507589],\n",
              "         [-0.31967499,  0.00964195, -0.12399036, ..., -0.07995213,\n",
              "           0.02175874,  0.0239827 ],\n",
              "         [-0.30712602, -0.05006342, -0.01736314, ..., -0.17115634,\n",
              "           0.00445893,  0.06187037]]), 'mapped_Y': array([[ 0.41817977, -0.06028068, -0.05715864, ...,  0.08646756,\n",
              "           0.13688036, -0.0410274 ],\n",
              "         [-0.41669541, -0.08148984, -0.06339875, ...,  0.06327411,\n",
              "          -0.10940667, -0.03705633],\n",
              "         [ 0.08955217,  0.14807337,  0.08112295, ..., -0.11032267,\n",
              "          -0.01949148,  0.04822817],\n",
              "         ...,\n",
              "         [-0.09773045,  0.31247842, -0.04490489, ..., -0.04563385,\n",
              "           0.00469501, -0.04450577],\n",
              "         [-0.34653769, -0.06642544,  0.02342728, ...,  0.2395652 ,\n",
              "          -0.1471374 ,  0.04120139],\n",
              "         [-0.3512882 , -0.06164028, -0.09778013, ..., -0.14833116,\n",
              "          -0.00089188,  0.06477074]]), 'alpha': tensor([[ 7.3487e-04,  2.1658e-02,  1.5523e-02,  ...,  1.8019e-04,\n",
              "            1.2963e-02, -3.2797e-03],\n",
              "          [ 1.4118e-02,  2.2462e-03,  3.2353e-03,  ..., -4.8220e-02,\n",
              "           -3.9484e-03, -4.9722e-03],\n",
              "          [-6.6655e-03,  1.5211e-02,  1.5258e-03,  ...,  1.8409e-02,\n",
              "            2.8363e-03, -5.9721e-03],\n",
              "          ...,\n",
              "          [ 6.1011e-05,  2.7412e-02, -1.0426e-02,  ..., -8.3826e-03,\n",
              "            7.7973e-04,  5.6544e-03],\n",
              "          [-7.3138e-03,  1.3360e-02, -9.8224e-03,  ..., -4.3536e-02,\n",
              "            4.7004e-02, -1.0260e-02],\n",
              "          [-9.2202e-03,  1.6664e-02, -2.0199e-02,  ..., -7.2475e-02,\n",
              "            4.9163e-02, -2.4632e-02]], dtype=torch.float64), 'beta': tensor([[-0.0032,  0.0014,  0.0044,  ...,  0.0031,  0.0154, -0.0025],\n",
              "          [-0.0015,  0.0031,  0.0091,  ...,  0.0037, -0.0111, -0.0106],\n",
              "          [ 0.0072,  0.0037,  0.0213,  ...,  0.0050, -0.0218, -0.0115],\n",
              "          ...,\n",
              "          [-0.0063,  0.0280, -0.0070,  ...,  0.0110, -0.0006,  0.0070],\n",
              "          [ 0.0041,  0.0216,  0.0241,  ...,  0.0338, -0.0086, -0.0038],\n",
              "          [-0.0048, -0.0106, -0.0171,  ..., -0.0253,  0.0247,  0.0047]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00453931032568706, 'loss_breakdown': {'ot': 0.004479151013132293,\n",
              "   'ortho': 0.00534988712001718,\n",
              "   'graph': 66.60441354595605}, 'best_iter': 1201, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.1540354074816025}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[ 2.41223125e-01, -1.03359165e-01, -3.20320684e-02, ...,\n",
              "          -9.94481882e-06,  1.69433514e-01,  2.36195004e-02],\n",
              "         [-7.33607724e-02,  2.73906542e-01, -2.65342270e-02, ...,\n",
              "          -9.21004765e-02, -9.56099539e-02,  4.14835915e-02],\n",
              "         [ 7.92614613e-02,  3.49748878e-01,  7.83706880e-03, ...,\n",
              "          -4.07665948e-02, -3.87177081e-02,  3.49487437e-02],\n",
              "         ...,\n",
              "         [ 8.12623180e-02,  1.87984384e-01,  7.38948918e-02, ...,\n",
              "           7.73730627e-02, -4.28720477e-02, -4.62385647e-02],\n",
              "         [-2.91321506e-01,  6.17002305e-02, -1.43798171e-01, ...,\n",
              "          -3.37551480e-02, -7.77649980e-03, -1.71195058e-02],\n",
              "         [-2.42029674e-01, -2.75688213e-03,  9.73434519e-02, ...,\n",
              "          -1.29790053e-01, -1.33209126e-01, -1.97214254e-02]]), 'mapped_Y': array([[ 0.27051637, -0.12930829, -0.04669868, ..., -0.03926309,\n",
              "           0.18718693,  0.00152572],\n",
              "         [-0.37503092, -0.07420433, -0.07402541, ...,  0.07383264,\n",
              "          -0.11510986, -0.04819167],\n",
              "         [ 0.07885684,  0.13627574,  0.08593893, ..., -0.06734708,\n",
              "          -0.06255584,  0.04305829],\n",
              "         ...,\n",
              "         [ 0.07058222,  0.3407094 , -0.0161181 , ...,  0.04172155,\n",
              "          -0.02597562,  0.02150074],\n",
              "         [-0.32976344, -0.08191843,  0.07407067, ...,  0.16411649,\n",
              "          -0.0380396 ,  0.046957  ],\n",
              "         [-0.33371792, -0.00170987, -0.09814094, ..., -0.05750808,\n",
              "          -0.05946519,  0.02531596]]), 'alpha': tensor([[ 0.0027,  0.0240,  0.0237,  ..., -0.0004,  0.0128, -0.0083],\n",
              "          [ 0.0235,  0.0079,  0.0152,  ..., -0.0446, -0.0089, -0.0103],\n",
              "          [-0.0066,  0.0270, -0.0013,  ...,  0.0161,  0.0073, -0.0130],\n",
              "          ...,\n",
              "          [ 0.0102,  0.0187,  0.0076,  ...,  0.0417,  0.0214,  0.0285],\n",
              "          [ 0.0022,  0.0164, -0.0237,  ..., -0.0353,  0.0014, -0.0206],\n",
              "          [-0.0028,  0.0214,  0.0118,  ..., -0.0561,  0.0098, -0.0350]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0044,  0.0020,  0.0020,  ..., -0.0010,  0.0149, -0.0043],\n",
              "          [-0.0031, -0.0022,  0.0114,  ...,  0.0022, -0.0140, -0.0134],\n",
              "          [-0.0055, -0.0040,  0.0249,  ...,  0.0096, -0.0332, -0.0265],\n",
              "          ...,\n",
              "          [-0.0095,  0.0234,  0.0013,  ...,  0.0225,  0.0138,  0.0130],\n",
              "          [ 0.0095,  0.0206,  0.0366,  ...,  0.0166,  0.0175,  0.0025],\n",
              "          [-0.0048, -0.0098, -0.0211,  ..., -0.0084, -0.0026,  0.0068]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003918619088752267, 'loss_breakdown': {'ot': 0.003877231555061904,\n",
              "   'ortho': 0.003523994193558363,\n",
              "   'graph': 61.47591754779758}, 'best_iter': 1551, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.15303377366907223}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[ 0.38113047, -0.08296633, -0.15674622, ...,  0.07413147,\n",
              "           0.03821323,  0.00590741],\n",
              "         [-0.18649465,  0.14124351, -0.05822695, ..., -0.17341674,\n",
              "           0.0129565 ,  0.01723889],\n",
              "         [ 0.01192657,  0.24173402, -0.03725612, ..., -0.09709241,\n",
              "           0.08372275,  0.01546698],\n",
              "         ...,\n",
              "         [ 0.01257996,  0.22368227,  0.06390244, ...,  0.00373265,\n",
              "           0.04634429, -0.23098228],\n",
              "         [-0.35304641, -0.00932811, -0.04075635, ..., -0.11953203,\n",
              "          -0.0289393 , -0.0111474 ],\n",
              "         [-0.30377351, -0.03431705,  0.05035178, ..., -0.16221886,\n",
              "           0.00353562, -0.17068942]]), 'mapped_Y': array([[ 0.43202538, -0.13477127, -0.132769  , ...,  0.02599039,\n",
              "           0.0144707 ,  0.04435765],\n",
              "         [-0.41059323,  0.02797825, -0.04537012, ...,  0.10959282,\n",
              "          -0.16922306, -0.07406889],\n",
              "         [ 0.08096295,  0.13007698,  0.0049031 , ..., -0.08328393,\n",
              "           0.0124048 ,  0.15315658],\n",
              "         ...,\n",
              "         [-0.0226876 ,  0.24444336, -0.0294279 , ..., -0.06269767,\n",
              "           0.05099458, -0.07939151],\n",
              "         [-0.32781792,  0.04979623,  0.01637986, ...,  0.28019367,\n",
              "          -0.07414332, -0.03156818],\n",
              "         [-0.39123632, -0.02899597, -0.05689972, ..., -0.13287958,\n",
              "          -0.07315582, -0.01166537]]), 'alpha': tensor([[ 0.0109,  0.0372, -0.0020,  ..., -0.0069,  0.0155, -0.0001],\n",
              "          [ 0.0135, -0.0297,  0.0199,  ..., -0.0376, -0.0011,  0.0146],\n",
              "          [-0.0008,  0.0077, -0.0133,  ...,  0.0088,  0.0181, -0.0065],\n",
              "          ...,\n",
              "          [ 0.0201,  0.0338, -0.0031,  ...,  0.0020, -0.0098, -0.0273],\n",
              "          [-0.0022,  0.0106, -0.0087,  ..., -0.0661,  0.0151, -0.0064],\n",
              "          [-0.0031, -0.0005, -0.0269,  ..., -0.1040,  0.0018, -0.0422]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0024,  0.0038, -0.0041,  ..., -0.0075,  0.0040,  0.0052],\n",
              "          [ 0.0059,  0.0133,  0.0014,  ...,  0.0053, -0.0100,  0.0021],\n",
              "          [ 0.0173,  0.0229,  0.0085,  ..., -0.0235, -0.0047,  0.0191],\n",
              "          ...,\n",
              "          [-0.0126, -0.0055, -0.0209,  ...,  0.0033,  0.0026,  0.0034],\n",
              "          [ 0.0134,  0.0367,  0.0153,  ...,  0.0490,  0.0197,  0.0066],\n",
              "          [-0.0100, -0.0141, -0.0120,  ..., -0.0280, -0.0177, -0.0033]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0037543048050595698, 'loss_breakdown': {'ot': 0.0037268716741743054,\n",
              "   'ortho': 0.002670343949261255,\n",
              "   'graph': 72.9691392651748}, 'best_iter': 1570, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9637058261700095,\n",
              "   'accuracy_raw': 0.9637058261700095,\n",
              "   'foscttm': 0.1573915193179403}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.38415143, -0.00715777, -0.071156  , ...,  0.10755308,\n",
              "           0.10822918, -0.04256894],\n",
              "         [-0.19616954,  0.20671122, -0.0656073 , ..., -0.18054198,\n",
              "          -0.01815969,  0.0064078 ],\n",
              "         [-0.03178037,  0.27946223,  0.00047036, ..., -0.09709138,\n",
              "           0.01261201,  0.00771277],\n",
              "         ...,\n",
              "         [-0.08528415,  0.17992307,  0.01418679, ..., -0.00193443,\n",
              "           0.00750953, -0.08452341],\n",
              "         [-0.32049224,  0.0117184 , -0.11861621, ..., -0.0842783 ,\n",
              "           0.01558204,  0.02717532],\n",
              "         [-0.29789745, -0.04519554, -0.01964794, ..., -0.16722694,\n",
              "           0.00654881,  0.07657154]]), 'mapped_Y': array([[ 0.42076311, -0.04672831, -0.05190159, ...,  0.08181022,\n",
              "           0.14209664, -0.06370028],\n",
              "         [-0.4159877 , -0.07282845, -0.08855689, ...,  0.05040308,\n",
              "          -0.10671772, -0.01901284],\n",
              "         [ 0.08099016,  0.13471749,  0.09534399, ..., -0.10069629,\n",
              "          -0.02041911,  0.04988265],\n",
              "         ...,\n",
              "         [-0.1020575 ,  0.28219416, -0.04479854, ..., -0.03144159,\n",
              "           0.01555587, -0.0251903 ],\n",
              "         [-0.34548278, -0.05051893, -0.01279092, ...,  0.21557846,\n",
              "          -0.13977608,  0.03966484],\n",
              "         [-0.34913148, -0.06281401, -0.10096633, ..., -0.14976247,\n",
              "          -0.00686446,  0.08511538]]), 'alpha': tensor([[ 0.0004,  0.0233,  0.0147,  ..., -0.0013,  0.0127, -0.0042],\n",
              "          [ 0.0164,  0.0002,  0.0044,  ..., -0.0495, -0.0015, -0.0047],\n",
              "          [-0.0075,  0.0150,  0.0017,  ...,  0.0179,  0.0009, -0.0071],\n",
              "          ...,\n",
              "          [ 0.0030,  0.0330, -0.0139,  ..., -0.0063,  0.0045,  0.0129],\n",
              "          [-0.0082,  0.0141, -0.0087,  ..., -0.0455,  0.0468, -0.0100],\n",
              "          [-0.0087,  0.0200, -0.0205,  ..., -0.0745,  0.0502, -0.0225]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0035,  0.0016,  0.0040,  ...,  0.0030,  0.0147, -0.0034],\n",
              "          [-0.0015,  0.0032,  0.0086,  ...,  0.0033, -0.0102, -0.0096],\n",
              "          [ 0.0072,  0.0034,  0.0258,  ...,  0.0075, -0.0237, -0.0137],\n",
              "          ...,\n",
              "          [-0.0077,  0.0304, -0.0066,  ...,  0.0098, -0.0007,  0.0060],\n",
              "          [ 0.0052,  0.0225,  0.0220,  ...,  0.0315, -0.0045, -0.0058],\n",
              "          [-0.0050, -0.0112, -0.0177,  ..., -0.0254,  0.0248,  0.0077]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0041195525235278845, 'loss_breakdown': {'ot': 0.004077343006565635,\n",
              "   'ortho': 0.004157256465297991,\n",
              "   'graph': 63.69523092697355}, 'best_iter': 1328, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9613180515759312,\n",
              "   'accuracy_raw': 0.9613180515759312,\n",
              "   'foscttm': 0.1546146765808345}},\n",
              " (8,\n",
              "  5,\n",
              "  0.01,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.24416483, -0.09130391, -0.04040269, ..., -0.00226556,\n",
              "           0.17566631,  0.03254906],\n",
              "         [-0.07930892,  0.2673709 , -0.02320284, ..., -0.08970919,\n",
              "          -0.10162456,  0.03825022],\n",
              "         [ 0.07269183,  0.3475463 ,  0.01297589, ..., -0.0404966 ,\n",
              "          -0.04741259,  0.03313801],\n",
              "         ...,\n",
              "         [ 0.07838322,  0.18670804,  0.07639223, ...,  0.07539666,\n",
              "          -0.04622491, -0.05034731],\n",
              "         [-0.29478354,  0.05729625, -0.13699192, ..., -0.02940985,\n",
              "          -0.00718279, -0.02486201],\n",
              "         [-0.24470582, -0.0067935 ,  0.09732947, ..., -0.12966764,\n",
              "          -0.1317964 , -0.02221951]]), 'mapped_Y': array([[ 0.27330654, -0.11673669, -0.0548772 , ..., -0.04251874,\n",
              "           0.19189096,  0.01116861],\n",
              "         [-0.37540587, -0.08174004, -0.07268897, ...,  0.07678869,\n",
              "          -0.1105735 , -0.05532667],\n",
              "         [ 0.07675418,  0.13502001,  0.08737879, ..., -0.06733847,\n",
              "          -0.06634778,  0.04274326],\n",
              "         ...,\n",
              "         [ 0.0654425 ,  0.33667365, -0.01045945, ...,  0.04298893,\n",
              "          -0.03415506,  0.01902184],\n",
              "         [-0.33030317, -0.0865055 ,  0.07245347, ...,  0.16617031,\n",
              "          -0.0311722 ,  0.04005354],\n",
              "         [-0.3357009 , -0.00815749, -0.0933637 , ..., -0.05426752,\n",
              "          -0.06142503,  0.01935813]]), 'alpha': tensor([[ 0.0029,  0.0242,  0.0238,  ..., -0.0005,  0.0126, -0.0083],\n",
              "          [ 0.0235,  0.0082,  0.0145,  ..., -0.0447, -0.0091, -0.0099],\n",
              "          [-0.0065,  0.0271, -0.0011,  ...,  0.0158,  0.0069, -0.0130],\n",
              "          ...,\n",
              "          [ 0.0100,  0.0197,  0.0076,  ...,  0.0414,  0.0215,  0.0280],\n",
              "          [ 0.0020,  0.0165, -0.0231,  ..., -0.0351,  0.0015, -0.0208],\n",
              "          [-0.0029,  0.0215,  0.0112,  ..., -0.0560,  0.0097, -0.0350]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0042,  0.0021,  0.0020,  ..., -0.0011,  0.0148, -0.0041],\n",
              "          [-0.0029, -0.0024,  0.0111,  ...,  0.0021, -0.0137, -0.0133],\n",
              "          [-0.0051, -0.0043,  0.0249,  ...,  0.0101, -0.0333, -0.0269],\n",
              "          ...,\n",
              "          [-0.0096,  0.0233,  0.0010,  ...,  0.0230,  0.0138,  0.0133],\n",
              "          [ 0.0094,  0.0208,  0.0363,  ...,  0.0166,  0.0178,  0.0023],\n",
              "          [-0.0048, -0.0099, -0.0209,  ..., -0.0086, -0.0029,  0.0070]],\n",
              "         dtype=torch.float64), 'final_loss': 0.00391545868184422, 'loss_breakdown': {'ot': 0.0038802001507189667,\n",
              "   'ortho': 0.0034644006263963517,\n",
              "   'graph': 61.45248612902982}, 'best_iter': 1549, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.01,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9627507163323783,\n",
              "   'accuracy_raw': 0.9627507163323783,\n",
              "   'foscttm': 0.15322032568606897}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.1): {'mapped_X': array([[ 1.64226932e-03,  4.09708336e-03,  1.17700326e-03, ...,\n",
              "           3.26476999e-03, -4.33736145e-04, -1.40919349e-03],\n",
              "         [ 4.91901191e-04,  6.67295935e-04,  1.99843284e-03, ...,\n",
              "           7.60628460e-05,  2.51436197e-03,  5.91306653e-03],\n",
              "         [ 7.40621305e-04,  1.84995248e-03,  4.55434871e-03, ...,\n",
              "          -1.71042581e-03,  3.34391269e-03,  1.67299089e-03],\n",
              "         ...,\n",
              "         [-5.59224643e-04, -2.86627218e-04,  2.10936279e-03, ...,\n",
              "          -3.18744450e-03,  3.52134576e-03,  1.31135768e-02],\n",
              "         [ 2.56821127e-04, -9.42126337e-04, -1.24033108e-03, ...,\n",
              "           2.66757294e-03, -9.19377866e-04, -3.52708579e-03],\n",
              "         [-2.78127447e-05, -7.54128439e-04, -3.24544139e-03, ...,\n",
              "           2.72787439e-03, -7.48955787e-04, -1.11017061e-03]]), 'mapped_Y': array([[-7.49225750e-04, -1.53861865e-03,  6.85699769e-04, ...,\n",
              "           3.20731873e-03, -2.22478906e-03, -2.80163254e-04],\n",
              "         [ 6.11555957e-04,  8.91185267e-04,  1.28281903e-04, ...,\n",
              "          -1.45377856e-03,  4.29747121e-04, -3.29466506e-03],\n",
              "         [-1.61038364e-03, -2.37132879e-03,  3.02488830e-03, ...,\n",
              "           8.02433285e-03,  5.34011213e-03, -3.90238588e-03],\n",
              "         ...,\n",
              "         [ 2.55346402e-04,  2.06211691e-03, -5.87676896e-03, ...,\n",
              "          -2.42671401e-03, -5.11568677e-03,  4.67272453e-03],\n",
              "         [ 4.00599214e-04,  3.98458719e-03, -3.85369059e-03, ...,\n",
              "           8.53468963e-03,  9.40991303e-04, -3.58016455e-03],\n",
              "         [ 1.77839504e-03,  8.90518565e-04,  1.94156549e-05, ...,\n",
              "          -6.07924156e-03, -1.17916805e-03,  1.43756912e-03]]), 'alpha': tensor([[ 1.9284e-04,  8.2589e-04,  2.1737e-03,  ...,  1.4352e-03,\n",
              "            2.9960e-04, -9.1048e-04],\n",
              "          [ 2.2909e-06, -9.3711e-04,  1.0128e-03,  ...,  3.9877e-03,\n",
              "           -1.1974e-02, -1.6836e-03],\n",
              "          [ 8.5812e-04,  2.4297e-03,  1.8891e-03,  ...,  9.2630e-03,\n",
              "           -7.1911e-03, -1.0698e-02],\n",
              "          ...,\n",
              "          [-1.0446e-04,  9.7417e-05,  2.2610e-03,  ...,  7.1394e-03,\n",
              "            6.5819e-03, -4.1232e-03],\n",
              "          [ 1.2342e-03,  2.0411e-03,  1.9008e-03,  ...,  3.7331e-03,\n",
              "           -1.1859e-03, -2.3430e-03],\n",
              "          [ 1.2355e-03,  1.7515e-03, -1.7582e-03,  ...,  5.8998e-03,\n",
              "            7.8404e-04,  8.8520e-04]], dtype=torch.float64), 'beta': tensor([[-2.3186e-04,  8.7286e-04, -7.8339e-04,  ...,  8.9071e-04,\n",
              "           -1.8726e-03,  2.2192e-03],\n",
              "          [-5.5091e-04, -5.9897e-04,  4.5028e-04,  ..., -4.7780e-04,\n",
              "            2.5675e-04, -3.0183e-03],\n",
              "          [-1.0639e-03, -1.2466e-03, -4.6940e-03,  ...,  1.0243e-02,\n",
              "            5.4247e-03, -8.9751e-03],\n",
              "          ...,\n",
              "          [ 8.1399e-05,  1.9621e-03, -3.3996e-03,  ..., -5.4970e-03,\n",
              "           -3.1234e-03,  7.3990e-03],\n",
              "          [-1.9746e-06, -1.1297e-04, -9.2124e-04,  ...,  1.4985e-02,\n",
              "            2.1911e-03, -3.6076e-03],\n",
              "          [ 2.9246e-04, -4.2443e-04,  4.5345e-04,  ..., -9.3254e-04,\n",
              "            3.6333e-04,  3.1449e-03]], dtype=torch.float64), 'final_loss': 0.015893395661103826, 'loss_breakdown': {'ot': 4.310033354048703e-06,\n",
              "   'ortho': 15.792292661716116,\n",
              "   'graph': 0.09679296603366136}, 'best_iter': 177, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.08930276981852914,\n",
              "   'accuracy_raw': 0.08930276981852914,\n",
              "   'foscttm': 0.6178707709934876}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  1.0): {'mapped_X': array([[ 2.41062806e-04,  1.97937471e-03, -4.15382497e-03, ...,\n",
              "          -1.18343461e-02, -2.48600714e-03,  4.23056610e-03],\n",
              "         [ 1.10354546e-03,  1.90878672e-03,  1.95418763e-03, ...,\n",
              "          -4.63517867e-03,  2.50872968e-03,  1.10362411e-02],\n",
              "         [-6.97695753e-04,  7.17396533e-04,  3.01058360e-03, ...,\n",
              "           4.67377526e-03, -9.85120431e-06,  5.52998593e-03],\n",
              "         ...,\n",
              "         [-6.77080987e-04,  8.57212224e-04,  2.01638080e-03, ...,\n",
              "          -7.73247883e-03,  4.74900299e-03,  2.23525653e-02],\n",
              "         [ 6.63874924e-04, -2.93580138e-05, -8.30277270e-04, ...,\n",
              "           5.35399178e-04,  2.07182609e-03, -4.51372383e-03],\n",
              "         [ 1.05049416e-03, -6.88632849e-04, -1.67463344e-03, ...,\n",
              "           4.20854528e-03,  7.19489021e-04, -8.60896637e-03]]), 'mapped_Y': array([[ 1.50873569e-04, -8.40501177e-04, -1.58776161e-03, ...,\n",
              "          -1.02760186e-02, -1.22718785e-03,  1.60036423e-03],\n",
              "         [-3.08587897e-05, -6.47907514e-04,  1.99283103e-03, ...,\n",
              "           5.65480682e-03,  2.12121725e-03, -6.07064682e-03],\n",
              "         [-1.17457783e-03, -6.26689178e-04,  8.92542351e-04, ...,\n",
              "           2.88029176e-02,  4.69699388e-03, -8.27890512e-03],\n",
              "         ...,\n",
              "         [ 1.04763217e-03, -1.38864032e-04, -5.30723698e-03, ...,\n",
              "          -2.12355125e-02, -2.67320169e-03,  6.09394514e-03],\n",
              "         [-3.96697487e-04, -4.61153773e-04, -9.04921117e-04, ...,\n",
              "           2.06332054e-02,  3.44400900e-03, -8.19406211e-03],\n",
              "         [ 9.33049824e-04,  1.22662579e-04,  1.99086179e-03, ...,\n",
              "          -7.96536472e-03, -1.05823865e-03,  2.64764987e-03]]), 'alpha': tensor([[-1.4716e-04,  3.8237e-04, -3.7016e-04,  ...,  1.0702e-03,\n",
              "            1.4063e-04, -1.0619e-04],\n",
              "          [ 7.7765e-04,  7.8990e-04,  2.3321e-04,  ...,  5.5155e-03,\n",
              "           -2.2314e-03,  9.5326e-04],\n",
              "          [-2.8780e-05, -2.8478e-04, -5.9058e-04,  ...,  1.1798e-02,\n",
              "           -1.0548e-02, -7.0886e-03],\n",
              "          ...,\n",
              "          [-2.7777e-05, -1.3763e-03,  1.0942e-03,  ...,  9.1525e-05,\n",
              "            4.5502e-03,  4.1159e-03],\n",
              "          [ 1.0234e-03, -6.5282e-04,  8.4180e-05,  ..., -6.1985e-04,\n",
              "            3.3983e-03, -7.6087e-04],\n",
              "          [ 1.6581e-03, -4.9808e-04, -2.7035e-03,  ...,  2.7942e-03,\n",
              "           -9.3543e-04, -8.1248e-03]], dtype=torch.float64), 'beta': tensor([[-1.3498e-04, -2.0496e-03, -8.7655e-04,  ...,  1.2982e-04,\n",
              "           -9.7079e-04,  3.4835e-03],\n",
              "          [-4.5518e-04, -1.9146e-03,  4.7678e-04,  ...,  6.1086e-03,\n",
              "            6.8545e-04, -5.8363e-03],\n",
              "          [-5.2610e-04, -3.1974e-03, -7.8852e-04,  ...,  2.5878e-02,\n",
              "            6.6182e-03, -1.1375e-02],\n",
              "          ...,\n",
              "          [ 1.9780e-05, -1.0578e-03, -3.2610e-03,  ..., -1.6015e-02,\n",
              "           -1.1102e-03,  8.2888e-03],\n",
              "          [-9.3944e-05, -1.0778e-03, -2.7469e-04,  ...,  1.7657e-02,\n",
              "            4.0308e-03, -5.3993e-03],\n",
              "          [ 3.1118e-04, -8.3331e-04,  6.9319e-04,  ..., -3.5966e-03,\n",
              "           -1.0347e-03,  6.5258e-03]], dtype=torch.float64), 'final_loss': 0.015210292109196567, 'loss_breakdown': {'ot': 9.701259246737545e-05,\n",
              "   'ortho': 14.313575791623887,\n",
              "   'graph': 0.7997037251053045}, 'best_iter': 459, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.4140401146131805,\n",
              "   'accuracy_raw': 0.4140401146131805,\n",
              "   'foscttm': 0.42452762201368544}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  5.0): {'mapped_X': array([[-8.36036924e-05, -2.36679546e-05, -1.98083074e-03, ...,\n",
              "           4.84839679e-03,  1.29087166e-03, -4.53100147e-03],\n",
              "         [ 9.55524001e-04,  3.50507702e-03,  7.48501917e-04, ...,\n",
              "          -7.78108327e-03, -2.17812441e-03,  5.91918533e-03],\n",
              "         [-1.03850637e-03,  2.43222053e-03, -1.47074219e-05, ...,\n",
              "          -2.29891945e-02, -3.31249615e-03,  7.33362729e-03],\n",
              "         ...,\n",
              "         [-7.21708715e-04,  2.32385823e-03, -3.66010146e-04, ...,\n",
              "          -3.26816740e-02,  1.80994283e-03,  2.25423199e-02],\n",
              "         [ 7.82528359e-04,  6.69813500e-04, -5.90797024e-05, ...,\n",
              "           1.08985418e-02, -4.19791428e-04, -3.47790461e-03],\n",
              "         [ 1.14938516e-03, -1.13819375e-04, -1.37861351e-03, ...,\n",
              "           1.09501560e-02, -1.52763264e-03, -7.81435134e-03]]), 'mapped_Y': array([[ 7.21495437e-04, -2.36762350e-03,  7.35719875e-04, ...,\n",
              "          -1.59528583e-03,  1.76694089e-03, -7.88495245e-03],\n",
              "         [ 6.41218398e-05,  4.26939477e-04,  7.90139205e-04, ...,\n",
              "           1.74644963e-02, -3.03527900e-03, -5.15591522e-03],\n",
              "         [-1.13571854e-03, -7.98069381e-04,  3.60770400e-04, ...,\n",
              "           2.20771477e-02,  6.54411417e-03, -4.61653358e-03],\n",
              "         ...,\n",
              "         [-6.91982474e-04,  6.98771207e-04, -4.68111078e-03, ...,\n",
              "          -2.84823605e-02, -1.90323816e-03,  1.49999201e-02],\n",
              "         [-6.68987806e-04,  5.61670190e-04, -1.25726929e-03, ...,\n",
              "           3.58364765e-02, -1.20906584e-03, -1.08124838e-02],\n",
              "         [ 1.03625402e-03,  7.99822962e-04,  1.11135600e-03, ...,\n",
              "           1.88960495e-03, -4.53062411e-03,  3.07931468e-03]]), 'alpha': tensor([[-2.9668e-04,  2.8604e-04, -4.5946e-04,  ...,  1.8191e-03,\n",
              "            4.0914e-04, -5.9924e-04],\n",
              "          [ 7.0136e-04,  7.2359e-04,  4.0622e-04,  ...,  9.2153e-03,\n",
              "           -3.1287e-03, -1.2101e-03],\n",
              "          [-2.4251e-04, -2.4252e-04, -5.4075e-04,  ...,  1.8040e-02,\n",
              "           -1.1174e-02, -8.2026e-03],\n",
              "          ...,\n",
              "          [ 1.0559e-05, -1.4467e-03,  9.3034e-04,  ..., -3.8362e-03,\n",
              "            5.4962e-03,  4.2027e-03],\n",
              "          [ 1.0123e-03, -6.3800e-04,  3.7543e-06,  ..., -1.7598e-03,\n",
              "            3.3285e-03, -1.4610e-03],\n",
              "          [ 1.6269e-03, -4.9181e-04, -2.6288e-03,  ..., -3.0105e-04,\n",
              "           -1.1100e-03, -8.7560e-03]], dtype=torch.float64), 'beta': tensor([[-0.0002, -0.0021, -0.0008,  ...,  0.0003, -0.0010,  0.0032],\n",
              "          [-0.0004, -0.0019,  0.0003,  ...,  0.0060,  0.0004, -0.0055],\n",
              "          [-0.0005, -0.0032, -0.0010,  ...,  0.0258,  0.0073, -0.0116],\n",
              "          ...,\n",
              "          [-0.0003, -0.0011, -0.0030,  ..., -0.0138, -0.0013,  0.0056],\n",
              "          [-0.0002, -0.0011, -0.0002,  ...,  0.0183,  0.0039, -0.0061],\n",
              "          [ 0.0003, -0.0007,  0.0005,  ..., -0.0039, -0.0011,  0.0069]],\n",
              "         dtype=torch.float64), 'final_loss': 0.015368976210562317, 'loss_breakdown': {'ot': 0.00013529706632578638,\n",
              "   'ortho': 14.485157830867884,\n",
              "   'graph': 0.7485213133686466}, 'best_iter': 453, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.5415472779369628,\n",
              "   'accuracy_raw': 0.5415472779369628,\n",
              "   'foscttm': 0.36539200097791574}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.0001,\n",
              "  0.1): {'mapped_X': array([[ 0.07290468,  0.00913756, -0.02741372, ..., -0.16568545,\n",
              "          -0.14964641, -0.25988526],\n",
              "         [-0.04729957, -0.07450585, -0.10127616, ...,  0.09951518,\n",
              "           0.16910646,  0.14883194],\n",
              "         [-0.03474224, -0.05889328, -0.08615874, ...,  0.02169828,\n",
              "           0.08234362,  0.14636306],\n",
              "         ...,\n",
              "         [-0.02446684, -0.0060269 , -0.01284015, ...,  0.11773975,\n",
              "           0.02924389,  0.04539186],\n",
              "         [-0.04182637, -0.06828958, -0.10816554, ...,  0.09810502,\n",
              "           0.08506559,  0.131125  ],\n",
              "         [-0.03876226, -0.02420862,  0.00448474, ...,  0.003583  ,\n",
              "           0.15445675,  0.07172539]]), 'mapped_Y': array([[-0.03853662, -0.02480446, -0.03991469, ...,  0.14672042,\n",
              "           0.15048522,  0.14453487],\n",
              "         [ 0.07760353, -0.00225067, -0.03358196, ..., -0.14687479,\n",
              "          -0.1255962 , -0.32249912],\n",
              "         [-0.0217424 ,  0.00378703,  0.0136209 , ...,  0.0027669 ,\n",
              "           0.02381012,  0.17609717],\n",
              "         ...,\n",
              "         [-0.04219093, -0.05558715, -0.10255119, ...,  0.13858994,\n",
              "           0.08025194,  0.10039079],\n",
              "         [ 0.07321777,  0.01277249, -0.01067202, ..., -0.13819573,\n",
              "          -0.07338607, -0.28716575],\n",
              "         [ 0.05435685, -0.01292464, -0.03827228, ..., -0.14966802,\n",
              "          -0.12443483, -0.18781482]]), 'alpha': tensor([[-2.0857e-03,  1.1715e-04, -1.3605e-03,  ..., -5.7819e-03,\n",
              "           -3.7930e-03,  1.8118e-03],\n",
              "          [-8.5747e-04, -4.2612e-03, -4.8028e-05,  ..., -1.8050e-03,\n",
              "            1.5764e-02, -1.3739e-02],\n",
              "          [-2.2168e-03, -2.4769e-03, -8.0540e-03,  ..., -8.7639e-03,\n",
              "            4.6256e-03,  3.4176e-03],\n",
              "          ...,\n",
              "          [ 2.3888e-04,  3.4071e-04,  2.4935e-04,  ...,  2.3578e-02,\n",
              "           -6.2281e-03, -9.5579e-03],\n",
              "          [-2.0967e-03, -3.2296e-03, -4.3621e-03,  ..., -4.9110e-03,\n",
              "           -2.1141e-03,  9.6383e-04],\n",
              "          [-1.1351e-03, -3.1126e-03, -5.0035e-03,  ..., -7.6527e-03,\n",
              "            9.6649e-03, -1.6768e-02]], dtype=torch.float64), 'beta': tensor([[-1.3043e-03, -1.5401e-03,  9.1135e-04,  ...,  5.7126e-03,\n",
              "            7.5259e-03,  6.4793e-04],\n",
              "          [ 4.9194e-05,  4.0606e-04,  4.9880e-03,  ..., -2.0027e-04,\n",
              "            2.9059e-03, -6.6383e-03],\n",
              "          [-1.9660e-03, -4.1928e-03,  1.1708e-03,  ..., -1.8864e-03,\n",
              "            1.0717e-02,  9.1833e-03],\n",
              "          ...,\n",
              "          [-2.4990e-03, -2.1064e-03, -1.0053e-02,  ...,  1.2490e-02,\n",
              "           -8.8225e-04, -1.8411e-03],\n",
              "          [-1.4908e-03, -2.9818e-03, -1.9352e-03,  ...,  2.6072e-03,\n",
              "            7.5298e-03, -1.1917e-03],\n",
              "          [ 1.0398e-03,  1.3180e-04,  1.4605e-03,  ...,  3.1670e-03,\n",
              "           -4.5790e-03, -8.5198e-04]], dtype=torch.float64), 'final_loss': 0.012243261657900847, 'loss_breakdown': {'ot': 0.0018517228163622348,\n",
              "   'ortho': 7.475738025268635,\n",
              "   'graph': 29.158008162699772}, 'best_iter': 224, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.26599808978032474,\n",
              "   'accuracy_raw': 0.26599808978032474,\n",
              "   'foscttm': 0.5906236858117384}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.0001,\n",
              "  1.0): {'mapped_X': array([[ 0.16943958,  0.02403396,  0.26611709, ...,  0.12204789,\n",
              "           0.03663011, -0.19080616],\n",
              "         [-0.08388161,  0.00770291, -0.13976479, ..., -0.23182228,\n",
              "          -0.09181233, -0.019223  ],\n",
              "         [-0.07239435, -0.02922134, -0.06411156, ..., -0.1681128 ,\n",
              "          -0.21464761,  0.0039582 ],\n",
              "         ...,\n",
              "         [-0.06089889, -0.019983  , -0.06795781, ..., -0.10579313,\n",
              "          -0.19741848, -0.03381223],\n",
              "         [-0.06078446,  0.01797533, -0.06962488, ..., -0.08903709,\n",
              "           0.10641156,  0.15294943],\n",
              "         [-0.08350277,  0.02303821, -0.08230868, ..., -0.17615297,\n",
              "           0.00085411,  0.05156803]]), 'mapped_Y': array([[ 0.18414776, -0.02841719,  0.26526873, ...,  0.1578718 ,\n",
              "           0.04159578, -0.20979976],\n",
              "         [-0.09142393,  0.02218382, -0.15696878, ...,  0.00164538,\n",
              "           0.05325625,  0.10454052],\n",
              "         [-0.02106791, -0.00819566,  0.02333893, ...,  0.00266327,\n",
              "          -0.09212973,  0.03388108],\n",
              "         ...,\n",
              "         [-0.08932457, -0.04664129, -0.09295711, ..., -0.19785356,\n",
              "          -0.22447385, -0.01128878],\n",
              "         [-0.08077528, -0.01212493, -0.1008595 , ...,  0.05604948,\n",
              "           0.07217883,  0.19595772],\n",
              "         [-0.08066768,  0.02416398, -0.14928559, ..., -0.07773467,\n",
              "           0.03844399,  0.07369708]]), 'alpha': tensor([[-0.0012,  0.0043,  0.0066,  ..., -0.0126,  0.0004, -0.0066],\n",
              "          [ 0.0088,  0.0215, -0.0004,  ..., -0.0455,  0.0310, -0.0304],\n",
              "          [ 0.0018,  0.0050,  0.0019,  ..., -0.0062, -0.0041, -0.0068],\n",
              "          ...,\n",
              "          [ 0.0019,  0.0133, -0.0070,  ..., -0.0095, -0.0084,  0.0024],\n",
              "          [ 0.0005,  0.0079,  0.0006,  ..., -0.0178,  0.0169,  0.0012],\n",
              "          [-0.0011, -0.0011, -0.0067,  ..., -0.0258,  0.0141, -0.0304]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 1.8597e-03, -8.2800e-03, -1.2971e-03,  ...,  1.3248e-03,\n",
              "            2.4709e-03, -1.7440e-03],\n",
              "          [-1.8773e-03, -1.7282e-03,  9.7364e-04,  ...,  1.3990e-02,\n",
              "           -3.9480e-03, -4.0151e-03],\n",
              "          [-4.5669e-03, -1.8381e-03,  8.8327e-03,  ...,  1.6353e-02,\n",
              "           -1.7770e-03,  1.8024e-02],\n",
              "          ...,\n",
              "          [-4.2013e-03, -3.9446e-02, -5.6402e-03,  ..., -2.3341e-02,\n",
              "           -7.9231e-03, -1.1263e-02],\n",
              "          [-2.7607e-03, -1.3130e-02,  1.6115e-02,  ...,  1.0270e-02,\n",
              "           -1.5026e-02,  1.6497e-02],\n",
              "          [ 5.4543e-04,  7.5761e-03, -9.7711e-03,  ...,  1.6605e-03,\n",
              "            5.3600e-03, -5.9753e-05]], dtype=torch.float64), 'final_loss': 0.008508342118745675, 'loss_breakdown': {'ot': 0.0019450775743573565,\n",
              "   'ortho': 3.9009354974687125,\n",
              "   'graph': 26.62329046919605}, 'best_iter': 880, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.828080229226361,\n",
              "   'accuracy_raw': 0.828080229226361,\n",
              "   'foscttm': 0.19275430141514985}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  0.0001,\n",
              "  5.0): {'mapped_X': array([[ 0.20144948, -0.02378857, -0.04863276, ...,  0.02360538,\n",
              "           0.11557676, -0.09881091],\n",
              "         [-0.11741668,  0.08526179,  0.08962548, ..., -0.00191056,\n",
              "           0.03156329,  0.10308366],\n",
              "         [ 0.01556335,  0.00306338,  0.08851313, ...,  0.00406962,\n",
              "          -0.04684586,  0.18006523],\n",
              "         ...,\n",
              "         [ 0.00355327,  0.02437702,  0.04637601, ...,  0.00486812,\n",
              "          -0.07065571,  0.05498048],\n",
              "         [-0.1943119 ,  0.04106491,  0.05465909, ..., -0.06031389,\n",
              "           0.03315375,  0.10101284],\n",
              "         [-0.17022974,  0.06552574,  0.04565143, ..., -0.06200931,\n",
              "           0.02405298,  0.02240893]]), 'mapped_Y': array([[ 0.22371933, -0.05166176, -0.06810865, ...,  0.04015278,\n",
              "           0.12376535, -0.1411798 ],\n",
              "         [-0.2941718 ,  0.08387818,  0.00533658, ..., -0.01913603,\n",
              "           0.02409908, -0.01079007],\n",
              "         [ 0.03076962,  0.02155916,  0.03634528, ...,  0.07477908,\n",
              "          -0.08218039,  0.0138039 ],\n",
              "         ...,\n",
              "         [ 0.0106043 , -0.0151441 ,  0.08830331, ..., -0.10274508,\n",
              "          -0.03674389,  0.21622674],\n",
              "         [-0.2533519 ,  0.04618128,  0.03901708, ..., -0.0414514 ,\n",
              "           0.01922822,  0.02469128],\n",
              "         [-0.23686796,  0.0914836 ,  0.01814489, ..., -0.01882481,\n",
              "           0.0249708 ,  0.04712186]]), 'alpha': tensor([[ 0.0052, -0.0002,  0.0164,  ..., -0.0078, -0.0088,  0.0036],\n",
              "          [ 0.0138,  0.0113,  0.0120,  ..., -0.0149,  0.0135, -0.0190],\n",
              "          [ 0.0038, -0.0064,  0.0068,  ..., -0.0117,  0.0010,  0.0112],\n",
              "          ...,\n",
              "          [ 0.0118,  0.0168, -0.0006,  ..., -0.0183, -0.0003, -0.0037],\n",
              "          [ 0.0022,  0.0011,  0.0069,  ..., -0.0068,  0.0072,  0.0030],\n",
              "          [ 0.0016,  0.0038,  0.0056,  ..., -0.0044,  0.0183, -0.0213]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0009, -0.0054,  0.0025,  ..., -0.0027, -0.0035,  0.0007],\n",
              "          [-0.0040,  0.0006, -0.0024,  ...,  0.0077, -0.0062, -0.0158],\n",
              "          [-0.0021,  0.0048,  0.0078,  ...,  0.0119, -0.0051,  0.0043],\n",
              "          ...,\n",
              "          [-0.0020, -0.0180,  0.0018,  ..., -0.0571,  0.0006,  0.0179],\n",
              "          [ 0.0044, -0.0099,  0.0153,  ...,  0.0074, -0.0042,  0.0063],\n",
              "          [-0.0051,  0.0052, -0.0062,  ...,  0.0005,  0.0025, -0.0009]],\n",
              "         dtype=torch.float64), 'final_loss': 0.009048966159274772, 'loss_breakdown': {'ot': 0.0017462449489529807,\n",
              "   'ortho': 4.713956381319267,\n",
              "   'graph': 25.88764829002524}, 'best_iter': 705, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 0.0001,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9555873925501432,\n",
              "   'accuracy_raw': 0.9555873925501432,\n",
              "   'foscttm': 0.1506218248527425}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-05,\n",
              "  0.1): {'mapped_X': array([[-0.20866582,  0.16343142,  0.32246205, ...,  0.00417728,\n",
              "          -0.04732432, -0.19412133],\n",
              "         [ 0.12389843,  0.03034395, -0.30006258, ..., -0.05806108,\n",
              "          -0.01303448,  0.05548043],\n",
              "         [ 0.05028971, -0.03552046, -0.24258963, ...,  0.03832265,\n",
              "          -0.03470315,  0.10957211],\n",
              "         ...,\n",
              "         [ 0.18897799,  0.11823917, -0.09747738, ...,  0.1250357 ,\n",
              "          -0.00639392,  0.1096732 ],\n",
              "         [-0.00212729, -0.12359089, -0.18533453, ...,  0.04622721,\n",
              "           0.00569611,  0.00343389],\n",
              "         [ 0.0646727 , -0.02355445, -0.15720655, ..., -0.14535209,\n",
              "           0.13038902, -0.03135404]]), 'mapped_Y': array([[ 0.0778452 ,  0.05904291, -0.19838537, ..., -0.09036864,\n",
              "          -0.03372383,  0.11464443],\n",
              "         [-0.20047488,  0.12939818,  0.30915618, ...,  0.06940086,\n",
              "          -0.06716129, -0.20302985],\n",
              "         [ 0.06083932,  0.0416418 , -0.0923673 , ..., -0.06625283,\n",
              "          -0.05518232,  0.11441023],\n",
              "         ...,\n",
              "         [ 0.07865328, -0.02635766, -0.23796819, ...,  0.02347141,\n",
              "           0.0830346 ,  0.10348976],\n",
              "         [-0.12806185,  0.14052713,  0.29161924, ...,  0.19234557,\n",
              "          -0.03522666, -0.13980427],\n",
              "         [-0.22829636,  0.06442679,  0.18387353, ..., -0.05798719,\n",
              "           0.0008879 , -0.14120731]]), 'alpha': tensor([[ 0.0018,  0.0002,  0.0090,  ..., -0.0041, -0.0085, -0.0047],\n",
              "          [ 0.0087, -0.0101,  0.0083,  ..., -0.0133,  0.0041, -0.0246],\n",
              "          [ 0.0007,  0.0046, -0.0088,  ..., -0.0015,  0.0057,  0.0010],\n",
              "          ...,\n",
              "          [ 0.0179,  0.0074,  0.0015,  ...,  0.0046, -0.0204, -0.0247],\n",
              "          [-0.0042, -0.0193, -0.0042,  ...,  0.0165, -0.0012,  0.0061],\n",
              "          [ 0.0154, -0.0047, -0.0201,  ..., -0.0073,  0.0155, -0.0258]],\n",
              "         dtype=torch.float64), 'beta': tensor([[-0.0033,  0.0003, -0.0032,  ..., -0.0133, -0.0023,  0.0058],\n",
              "          [-0.0008,  0.0031,  0.0071,  ...,  0.0022, -0.0125, -0.0016],\n",
              "          [-0.0024,  0.0101, -0.0085,  ..., -0.0021, -0.0198,  0.0096],\n",
              "          ...,\n",
              "          [ 0.0001,  0.0086, -0.0056,  ...,  0.0011,  0.0132,  0.0255],\n",
              "          [ 0.0136,  0.0159, -0.0012,  ...,  0.0328,  0.0008,  0.0102],\n",
              "          [-0.0125, -0.0036, -0.0018,  ..., -0.0144,  0.0053, -0.0011]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004890108478772638, 'loss_breakdown': {'ot': 0.0038648310483435076,\n",
              "   'ortho': 0.41838096030312066,\n",
              "   'graph': 60.68964701260096}, 'best_iter': 655, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.19866284622731614,\n",
              "   'accuracy_raw': 0.19866284622731614,\n",
              "   'foscttm': 0.5520895194255839}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-05,\n",
              "  1.0): {'mapped_X': array([[-0.15821302,  0.01316817,  0.15258428, ...,  0.09260005,\n",
              "           0.23282118, -0.21861018],\n",
              "         [ 0.10318421, -0.02274126, -0.07351736, ..., -0.200353  ,\n",
              "           0.01735187,  0.21733897],\n",
              "         [ 0.07189771, -0.05754219,  0.16794115, ..., -0.19029335,\n",
              "           0.04799433,  0.19720115],\n",
              "         ...,\n",
              "         [-0.02811956, -0.05133808,  0.07772835, ..., -0.13025609,\n",
              "          -0.03874637,  0.06128744],\n",
              "         [ 0.10539609,  0.03121051, -0.24624766, ...,  0.00160794,\n",
              "          -0.10465468,  0.15251915],\n",
              "         [ 0.20449223,  0.06833442, -0.1231519 , ..., -0.04827388,\n",
              "          -0.07501009,  0.14308316]]), 'mapped_Y': array([[-0.1422686 , -0.0232259 ,  0.18036822, ...,  0.07496109,\n",
              "           0.26250197, -0.27834647],\n",
              "         [ 0.06377264,  0.03171029, -0.32158334, ...,  0.10183205,\n",
              "          -0.25757744,  0.10481892],\n",
              "         [-0.03753616, -0.00543432,  0.0937573 , ..., -0.12985327,\n",
              "          -0.00177497,  0.04756688],\n",
              "         ...,\n",
              "         [ 0.09631323, -0.0864475 ,  0.16636713, ..., -0.14329819,\n",
              "           0.03639254,  0.20490607],\n",
              "         [ 0.05829344,  0.0495795 , -0.23751207, ...,  0.07294365,\n",
              "          -0.19852991,  0.12648362],\n",
              "         [ 0.10596343,  0.01182831, -0.29157536, ...,  0.04307959,\n",
              "          -0.17223488,  0.13756806]]), 'alpha': tensor([[ 0.0018, -0.0031,  0.0180,  ..., -0.0176,  0.0024,  0.0032],\n",
              "          [ 0.0125,  0.0197, -0.0074,  ..., -0.0421,  0.0408, -0.0075],\n",
              "          [ 0.0189, -0.0106,  0.0126,  ..., -0.0070, -0.0013,  0.0002],\n",
              "          ...,\n",
              "          [-0.0125,  0.0379, -0.0096,  ..., -0.0129,  0.0109,  0.0075],\n",
              "          [-0.0020,  0.0092, -0.0154,  ..., -0.0238,  0.0178,  0.0017],\n",
              "          [ 0.0121, -0.0095, -0.0257,  ..., -0.0418,  0.0348, -0.0154]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0021, -0.0083,  0.0015,  ..., -0.0018, -0.0018, -0.0087],\n",
              "          [ 0.0001,  0.0007,  0.0049,  ...,  0.0030, -0.0148, -0.0095],\n",
              "          [ 0.0181,  0.0099,  0.0206,  ...,  0.0140, -0.0086, -0.0009],\n",
              "          ...,\n",
              "          [ 0.0156, -0.0532,  0.0146,  ...,  0.0118,  0.0053,  0.0011],\n",
              "          [ 0.0018, -0.0055,  0.0243,  ..., -0.0062, -0.0015,  0.0035],\n",
              "          [-0.0018,  0.0025, -0.0101,  ...,  0.0064, -0.0103, -0.0015]],\n",
              "         dtype=torch.float64), 'final_loss': 0.004447857030225301, 'loss_breakdown': {'ot': 0.0031654165681884714,\n",
              "   'ortho': 0.7735283126642577,\n",
              "   'graph': 50.89121493725719}, 'best_iter': 924, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9579751671442216,\n",
              "   'accuracy_raw': 0.9579751671442216,\n",
              "   'foscttm': 0.15131649165441993}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-05,\n",
              "  5.0): {'mapped_X': array([[ 0.22847676, -0.0500847 ,  0.12754868, ...,  0.14015682,\n",
              "           0.13518358, -0.20397233],\n",
              "         [-0.06246445,  0.03054162, -0.05246559, ..., -0.26689918,\n",
              "           0.07980798,  0.16318274],\n",
              "         [ 0.13631355, -0.00507768,  0.08298501, ..., -0.26822997,\n",
              "          -0.0223042 ,  0.18434642],\n",
              "         ...,\n",
              "         [ 0.00207119, -0.01605112,  0.07886596, ..., -0.1664508 ,\n",
              "          -0.02226172,  0.03272646],\n",
              "         [-0.24328308,  0.0471755 , -0.16623946, ..., -0.0437783 ,\n",
              "          -0.00407476,  0.13541886],\n",
              "         [-0.11615373,  0.11546695, -0.14336431, ..., -0.0624912 ,\n",
              "          -0.03904928,  0.18580017]]), 'mapped_Y': array([[ 0.29557106, -0.07908146,  0.10600669, ...,  0.15864374,\n",
              "           0.11928426, -0.2375887 ],\n",
              "         [-0.39352831,  0.04271748, -0.18017146, ...,  0.07034707,\n",
              "          -0.06302393,  0.08507707],\n",
              "         [ 0.02740754,  0.01829474,  0.11017338, ..., -0.13816351,\n",
              "          -0.00621299, -0.00645851],\n",
              "         ...,\n",
              "         [ 0.12497809, -0.0392341 ,  0.07994199, ..., -0.21480582,\n",
              "          -0.04117782,  0.23220474],\n",
              "         [-0.37001245,  0.0553634 , -0.05371146, ...,  0.04985586,\n",
              "          -0.04130072,  0.09285823],\n",
              "         [-0.28228756,  0.03729956, -0.18887893, ...,  0.00634595,\n",
              "          -0.02065745,  0.14165462]]), 'alpha': tensor([[ 5.3236e-03, -1.6180e-03,  1.7649e-02,  ..., -2.0588e-02,\n",
              "           -1.6504e-03, -3.1727e-03],\n",
              "          [ 1.3478e-02,  2.1063e-02, -9.2085e-03,  ..., -3.5422e-02,\n",
              "            4.4415e-02, -1.8484e-02],\n",
              "          [ 1.9000e-02, -1.2957e-02, -2.4261e-03,  ..., -1.7087e-02,\n",
              "           -2.2226e-02,  6.2580e-03],\n",
              "          ...,\n",
              "          [-1.0588e-02,  4.8527e-02,  1.0471e-02,  ..., -2.4299e-02,\n",
              "            4.7865e-02, -1.3775e-02],\n",
              "          [ 6.8016e-05,  8.1747e-03, -1.9763e-02,  ..., -1.5073e-02,\n",
              "            1.1410e-02,  1.8565e-04],\n",
              "          [ 8.2524e-03, -5.9569e-03, -2.4152e-02,  ..., -2.9149e-02,\n",
              "            1.9301e-02, -1.3843e-02]], dtype=torch.float64), 'beta': tensor([[ 3.1706e-03, -9.2312e-03, -1.0701e-03,  ...,  4.9987e-05,\n",
              "           -7.4244e-03, -2.2450e-03],\n",
              "          [-4.6071e-03,  1.4806e-03,  2.6271e-03,  ...,  6.0423e-03,\n",
              "           -1.3149e-02, -1.0612e-02],\n",
              "          [ 6.4837e-03,  1.1250e-02,  1.6453e-02,  ...,  1.4482e-02,\n",
              "           -5.8263e-03,  9.2398e-03],\n",
              "          ...,\n",
              "          [ 2.8969e-03, -4.7751e-02,  1.7637e-02,  ...,  2.1405e-02,\n",
              "           -7.9301e-03,  1.6601e-02],\n",
              "          [-1.3073e-03, -6.9182e-03,  4.0851e-02,  ..., -2.3188e-03,\n",
              "           -1.0300e-02,  1.1945e-03],\n",
              "          [-5.3487e-03,  1.2812e-03, -1.4318e-02,  ...,  7.9347e-03,\n",
              "           -3.3838e-03,  5.9269e-03]], dtype=torch.float64), 'final_loss': 0.004423854637037205, 'loss_breakdown': {'ot': 0.0030360616553695803,\n",
              "   'ortho': 0.892000812088026,\n",
              "   'graph': 49.579216957959844}, 'best_iter': 955, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-05,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9555873925501432,\n",
              "   'accuracy_raw': 0.9555873925501432,\n",
              "   'foscttm': 0.1508913902367158}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-06,\n",
              "  0.1): {'mapped_X': array([[-0.09176252,  0.13417843,  0.02168085, ...,  0.03903911,\n",
              "           0.10350716,  0.01159994],\n",
              "         [-0.01226267,  0.116599  , -0.09368487, ..., -0.04927521,\n",
              "           0.00462847,  0.03365105],\n",
              "         [-0.03548835,  0.30936676, -0.0003346 , ...,  0.04196456,\n",
              "          -0.02307297,  0.04138872],\n",
              "         ...,\n",
              "         [-0.02731463,  0.17117823,  0.10032486, ...,  0.19126645,\n",
              "          -0.06592676, -0.15971401],\n",
              "         [ 0.15902601, -0.19745799, -0.20519162, ..., -0.03245779,\n",
              "          -0.06625183,  0.09274955],\n",
              "         [ 0.03280203, -0.13895979, -0.19361794, ..., -0.12042485,\n",
              "          -0.06736683, -0.01766509]]), 'mapped_Y': array([[-0.01909216,  0.22551494,  0.0450907 , ...,  0.03654679,\n",
              "           0.04087629, -0.01548602],\n",
              "         [ 0.17324436, -0.3643995 , -0.13479744, ...,  0.06828531,\n",
              "          -0.05286097,  0.00739882],\n",
              "         [-0.08988026,  0.12397156,  0.03966803, ..., -0.09215483,\n",
              "           0.02097956,  0.03788616],\n",
              "         ...,\n",
              "         [-0.02690521,  0.25915857, -0.0228463 , ...,  0.08438407,\n",
              "           0.04696469, -0.01024011],\n",
              "         [ 0.14147278, -0.34198267,  0.00897289, ...,  0.18377213,\n",
              "          -0.00309339,  0.03452342],\n",
              "         [ 0.07243428, -0.27435907, -0.23555907, ..., -0.1060237 ,\n",
              "          -0.04323265,  0.03344137]]), 'alpha': tensor([[-6.3818e-03,  4.7534e-03,  1.3247e-02,  ...,  5.7568e-04,\n",
              "            1.5899e-02,  1.7353e-02],\n",
              "          [ 2.2186e-02,  2.2872e-02,  2.1121e-02,  ..., -4.0575e-02,\n",
              "            2.9842e-02,  1.2662e-02],\n",
              "          [ 1.5316e-03,  2.7687e-03, -5.0154e-03,  ...,  1.1448e-03,\n",
              "            1.2066e-02,  3.8385e-03],\n",
              "          ...,\n",
              "          [-3.5097e-03,  9.2606e-03, -2.0002e-03,  ...,  2.4487e-02,\n",
              "           -1.1389e-02, -6.5868e-03],\n",
              "          [ 1.6264e-02,  1.0109e-02, -6.0397e-03,  ..., -1.5458e-02,\n",
              "           -8.7287e-05,  7.2508e-03],\n",
              "          [ 1.4053e-02,  1.9759e-02, -3.0037e-02,  ..., -4.1336e-02,\n",
              "           -1.8392e-02, -3.8044e-02]], dtype=torch.float64), 'beta': tensor([[ 8.2555e-03, -2.3777e-04, -1.0312e-03,  ..., -6.5514e-05,\n",
              "            8.2832e-03, -7.3495e-04],\n",
              "          [ 7.2631e-03,  1.3119e-03,  6.4146e-03,  ...,  8.9579e-04,\n",
              "           -9.0724e-03, -2.9318e-03],\n",
              "          [-1.0717e-02,  1.9644e-02, -1.1996e-03,  ..., -1.2691e-02,\n",
              "           -1.4580e-02,  2.0837e-03],\n",
              "          ...,\n",
              "          [-1.9280e-02, -2.5397e-03, -1.1128e-02,  ...,  2.0997e-02,\n",
              "            4.8128e-03,  5.4188e-03],\n",
              "          [ 9.1753e-03,  1.6617e-02,  1.6001e-02,  ...,  1.7192e-02,\n",
              "            9.6921e-03,  2.0834e-03],\n",
              "          [-7.1237e-04, -8.5072e-03, -1.3727e-02,  ..., -1.0202e-02,\n",
              "           -1.4179e-02, -8.2024e-03]], dtype=torch.float64), 'final_loss': 0.004801277576682456, 'loss_breakdown': {'ot': 0.004381184726572963,\n",
              "   'ortho': 0.3480400512612566,\n",
              "   'graph': 72.05279884823615}, 'best_iter': 584, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.718720152817574,\n",
              "   'accuracy_raw': 0.718720152817574,\n",
              "   'foscttm': 0.22083608144067415}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-06,\n",
              "  1.0): {'mapped_X': array([[ 0.01218003, -0.01288242,  0.16177622, ...,  0.10062004,\n",
              "           0.22443824, -0.25534355],\n",
              "         [ 0.00588026, -0.00337013, -0.10134778, ..., -0.18645729,\n",
              "           0.05719743,  0.22867147],\n",
              "         [ 0.06658811, -0.07635522,  0.13565622, ..., -0.1818008 ,\n",
              "           0.08705722,  0.23159173],\n",
              "         ...,\n",
              "         [-0.05360778, -0.03583017,  0.0913606 , ..., -0.11891368,\n",
              "           0.0162875 ,  0.07042495],\n",
              "         [-0.02792193,  0.05474361, -0.25175577, ..., -0.0219117 ,\n",
              "          -0.13299973,  0.16681166],\n",
              "         [ 0.10089123,  0.09122986, -0.14558093, ..., -0.05426322,\n",
              "          -0.10050104,  0.17778495]]), 'mapped_Y': array([[ 0.05198147, -0.06011232,  0.1789416 , ...,  0.09761292,\n",
              "           0.2344729 , -0.30658115],\n",
              "         [-0.0949066 ,  0.07397111, -0.30911541, ...,  0.05098154,\n",
              "          -0.27983834,  0.10368091],\n",
              "         [-0.03342089,  0.00495144,  0.10251112, ..., -0.11286248,\n",
              "           0.05086792,  0.05219237],\n",
              "         ...,\n",
              "         [ 0.08202822, -0.11035188,  0.13364224, ..., -0.13674636,\n",
              "           0.05911355,  0.25172272],\n",
              "         [-0.07286587,  0.09935871, -0.22186942, ...,  0.04474968,\n",
              "          -0.22226898,  0.13506464],\n",
              "         [-0.04973303,  0.04900832, -0.28062528, ...,  0.01277509,\n",
              "          -0.18437119,  0.15584131]]), 'alpha': tensor([[ 0.0038, -0.0019,  0.0174,  ..., -0.0210,  0.0058,  0.0020],\n",
              "          [ 0.0129,  0.0230, -0.0160,  ..., -0.0335,  0.0480, -0.0125],\n",
              "          [ 0.0196, -0.0241,  0.0096,  ..., -0.0173, -0.0068,  0.0042],\n",
              "          ...,\n",
              "          [-0.0093,  0.0584, -0.0077,  ..., -0.0050,  0.0251, -0.0118],\n",
              "          [-0.0008,  0.0100, -0.0176,  ..., -0.0219,  0.0180,  0.0013],\n",
              "          [ 0.0140, -0.0039, -0.0281,  ..., -0.0373,  0.0301, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0036, -0.0085,  0.0014,  ..., -0.0051, -0.0046, -0.0059],\n",
              "          [ 0.0016,  0.0010,  0.0040,  ...,  0.0007, -0.0144, -0.0097],\n",
              "          [ 0.0144,  0.0110,  0.0170,  ...,  0.0136, -0.0036,  0.0087],\n",
              "          ...,\n",
              "          [ 0.0132, -0.0500,  0.0151,  ...,  0.0092, -0.0038,  0.0082],\n",
              "          [ 0.0027, -0.0026,  0.0276,  ..., -0.0050,  0.0012,  0.0079],\n",
              "          [-0.0035,  0.0029, -0.0088,  ...,  0.0065, -0.0096,  0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003985990031385569, 'loss_breakdown': {'ot': 0.003266397022125316,\n",
              "   'ortho': 0.6665152880301284,\n",
              "   'graph': 53.07772123012346}, 'best_iter': 929, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065903,\n",
              "   'accuracy_raw': 0.9570200573065903,\n",
              "   'foscttm': 0.15203031538693806}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-06,\n",
              "  5.0): {'mapped_X': array([[ 0.21984703, -0.02841732,  0.03858052, ...,  0.07765432,\n",
              "           0.32668293, -0.08555402],\n",
              "         [-0.08505639,  0.00909836, -0.09402541, ..., -0.23953589,\n",
              "          -0.09800277,  0.14310221],\n",
              "         [ 0.1189141 , -0.01539879,  0.03000713, ..., -0.26585275,\n",
              "          -0.10395719,  0.21389242],\n",
              "         ...,\n",
              "         [-0.00899312, -0.03042679,  0.09048303, ..., -0.16504731,\n",
              "          -0.05033928,  0.04419085],\n",
              "         [-0.23652351,  0.04532768, -0.14632593, ...,  0.01527725,\n",
              "          -0.16074181,  0.04608834],\n",
              "         [-0.12345405,  0.08842364, -0.11181844, ...,  0.00172591,\n",
              "          -0.184701  ,  0.07755448]]), 'mapped_Y': array([[ 0.28374899, -0.06544634,  0.02091055, ...,  0.08144759,\n",
              "           0.32359413, -0.12020503],\n",
              "         [-0.37381977,  0.04470596, -0.12932263, ...,  0.15284589,\n",
              "          -0.19242879, -0.02459728],\n",
              "         [ 0.01221492,  0.00152211,  0.10785818, ..., -0.14044562,\n",
              "           0.01422007,  0.02097367],\n",
              "         ...,\n",
              "         [ 0.12391319, -0.04457461,  0.03065973, ..., -0.2149744 ,\n",
              "          -0.12449807,  0.25280228],\n",
              "         [-0.35346572,  0.0628981 , -0.0332414 , ...,  0.15805878,\n",
              "          -0.12355186,  0.02218385],\n",
              "         [-0.28181495,  0.03110399, -0.13608268, ...,  0.05011909,\n",
              "          -0.17932898,  0.02774614]]), 'alpha': tensor([[ 5.7986e-03, -2.3735e-03,  1.5155e-02,  ..., -2.1011e-02,\n",
              "            6.2397e-04,  2.7053e-05],\n",
              "          [ 1.0862e-02,  1.5342e-02, -1.1271e-02,  ..., -4.2090e-02,\n",
              "            2.5384e-02, -1.7048e-02],\n",
              "          [ 1.7761e-02, -6.2548e-03, -2.9939e-03,  ..., -1.4795e-02,\n",
              "           -1.9532e-02,  5.0175e-03],\n",
              "          ...,\n",
              "          [-1.0558e-02,  4.2583e-02,  1.0071e-02,  ..., -1.7134e-02,\n",
              "            3.9638e-02, -1.3366e-02],\n",
              "          [-8.4135e-04,  8.7690e-03, -2.1992e-02,  ..., -1.6003e-02,\n",
              "            3.7883e-03, -7.3270e-04],\n",
              "          [ 5.5034e-03, -8.1915e-03, -3.1966e-02,  ..., -2.9575e-02,\n",
              "            7.1662e-03, -1.8648e-02]], dtype=torch.float64), 'beta': tensor([[ 3.4969e-03, -9.6724e-03,  2.7034e-03,  ..., -9.0572e-05,\n",
              "           -2.9508e-03, -2.9463e-03],\n",
              "          [-3.1298e-03,  6.0664e-04,  6.1913e-03,  ...,  8.0310e-03,\n",
              "           -7.2590e-03, -1.2593e-02],\n",
              "          [ 3.1565e-03,  8.3314e-03,  2.2099e-02,  ...,  1.9272e-02,\n",
              "            4.0733e-04,  5.1796e-03],\n",
              "          ...,\n",
              "          [ 7.0803e-03, -5.3419e-02,  1.3523e-02,  ...,  1.6038e-02,\n",
              "            8.0279e-03,  1.6727e-02],\n",
              "          [-6.3596e-04, -5.8538e-03,  3.7703e-02,  ...,  3.7558e-03,\n",
              "            7.5782e-04,  8.8740e-03],\n",
              "          [-4.7784e-03,  1.0200e-03, -1.0483e-02,  ...,  4.9943e-03,\n",
              "           -8.4016e-03, -3.0268e-03]], dtype=torch.float64), 'final_loss': 0.004306103582639219, 'loss_breakdown': {'ot': 0.0033659146866381754,\n",
              "   'ortho': 0.8869742242008327,\n",
              "   'graph': 53.21467180021143}, 'best_iter': 947, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-06,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065902,\n",
              "   'accuracy_raw': 0.9570200573065902,\n",
              "   'foscttm': 0.15137624303394698}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-07,\n",
              "  0.1): {'mapped_X': array([[-0.14582654,  0.1391885 , -0.0720575 , ..., -0.02129762,\n",
              "           0.0876595 ,  0.0272386 ],\n",
              "         [ 0.02866534,  0.00774457, -0.12884177, ..., -0.11514699,\n",
              "          -0.01674113,  0.04922391],\n",
              "         [-0.10663809,  0.16993629, -0.13898879, ..., -0.08883319,\n",
              "           0.06386119,  0.0857945 ],\n",
              "         ...,\n",
              "         [-0.15058222,  0.1667532 ,  0.04832057, ...,  0.0455581 ,\n",
              "           0.05297123, -0.10759996],\n",
              "         [ 0.23588079, -0.2176923 , -0.04871325, ...,  0.0382682 ,\n",
              "          -0.13808761,  0.02136873],\n",
              "         [ 0.15428498, -0.21749942, -0.01225954, ..., -0.06021215,\n",
              "          -0.1313088 , -0.01820634]]), 'mapped_Y': array([[-0.16240875,  0.20924118, -0.10060054, ..., -0.08707393,\n",
              "           0.06483956, -0.00807786],\n",
              "         [ 0.30774452, -0.22450081,  0.03306977, ...,  0.1888554 ,\n",
              "          -0.10150466, -0.11202711],\n",
              "         [-0.09094221,  0.06337898, -0.0227864 , ..., -0.10105356,\n",
              "          -0.02670444,  0.078226  ],\n",
              "         ...,\n",
              "         [-0.11391403,  0.16826797, -0.13482412, ...,  0.02164842,\n",
              "           0.12881487,  0.05253273],\n",
              "         [ 0.26180021, -0.10114685,  0.12198364, ...,  0.33921481,\n",
              "          -0.04902667, -0.0527101 ],\n",
              "         [ 0.20835557, -0.29527862, -0.06101347, ...,  0.02460533,\n",
              "          -0.15098285, -0.04200004]]), 'alpha': tensor([[-0.0025,  0.0100,  0.0090,  ..., -0.0078,  0.0039,  0.0209],\n",
              "          [ 0.0256,  0.0143,  0.0163,  ..., -0.0469, -0.0088,  0.0316],\n",
              "          [ 0.0015,  0.0022, -0.0105,  ..., -0.0038,  0.0094, -0.0003],\n",
              "          ...,\n",
              "          [-0.0183,  0.0217, -0.0014,  ...,  0.0154,  0.0092, -0.0075],\n",
              "          [ 0.0130,  0.0063, -0.0029,  ..., -0.0137, -0.0132,  0.0079],\n",
              "          [ 0.0161,  0.0037, -0.0123,  ..., -0.0446, -0.0180, -0.0207]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 1.2177e-03,  5.4502e-03, -5.5597e-04,  ..., -3.9725e-03,\n",
              "            1.5749e-03,  6.8978e-04],\n",
              "          [ 7.9616e-03,  8.3681e-03,  5.7347e-03,  ...,  1.6433e-03,\n",
              "           -7.1096e-03, -6.3686e-03],\n",
              "          [-1.1821e-02,  1.0561e-02, -4.3014e-03,  ..., -2.2402e-03,\n",
              "           -1.7502e-02,  5.4994e-05],\n",
              "          ...,\n",
              "          [-1.5085e-02, -3.9616e-03, -9.5538e-03,  ...,  3.1236e-02,\n",
              "            7.3385e-03,  8.6030e-03],\n",
              "          [ 7.2272e-03,  2.7161e-02,  1.4868e-02,  ...,  3.0018e-02,\n",
              "            1.1080e-04,  1.5289e-02],\n",
              "          [-5.2693e-04, -1.5569e-02, -7.4629e-03,  ..., -8.2930e-03,\n",
              "           -1.8978e-02, -1.2606e-02]], dtype=torch.float64), 'final_loss': 0.004625350758739602, 'loss_breakdown': {'ot': 0.004270821900445233,\n",
              "   'ortho': 0.34708806851165375,\n",
              "   'graph': 74.40789782714802}, 'best_iter': 588, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.7874880611270296,\n",
              "   'accuracy_raw': 0.7874880611270296,\n",
              "   'foscttm': 0.20954398294485815}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-07,\n",
              "  1.0): {'mapped_X': array([[ 0.00534337, -0.01114434,  0.16188133, ...,  0.09907231,\n",
              "           0.22133992, -0.25908428],\n",
              "         [ 0.00879436, -0.00400449, -0.10152138, ..., -0.18558793,\n",
              "           0.05937577,  0.23000074],\n",
              "         [ 0.06494516, -0.07827163,  0.13603309, ..., -0.1828474 ,\n",
              "           0.08994986,  0.2314345 ],\n",
              "         ...,\n",
              "         [-0.05375514, -0.0348176 ,  0.08970452, ..., -0.11932022,\n",
              "           0.01665956,  0.07078206],\n",
              "         [-0.02153751,  0.05380624, -0.25116278, ..., -0.0189279 ,\n",
              "          -0.13113497,  0.16930497],\n",
              "         [ 0.10544146,  0.0902087 , -0.14362128, ..., -0.05291406,\n",
              "          -0.09763265,  0.18014534]]), 'mapped_Y': array([[ 0.04396651, -0.05819344,  0.17962012, ...,  0.09548421,\n",
              "           0.23432852, -0.31101005],\n",
              "         [-0.08591372,  0.0731698 , -0.30905771, ...,  0.05420324,\n",
              "          -0.28194714,  0.1083246 ],\n",
              "         [-0.03406442,  0.00511229,  0.10173387, ..., -0.11308359,\n",
              "           0.05149892,  0.05176868],\n",
              "         ...,\n",
              "         [ 0.08101204, -0.1128702 ,  0.13411561, ..., -0.13745421,\n",
              "           0.06222965,  0.25194302],\n",
              "         [-0.06550268,  0.09935679, -0.22089972, ...,  0.04727036,\n",
              "          -0.22350481,  0.1394964 ],\n",
              "         [-0.04259811,  0.04808145, -0.28033831, ...,  0.01520596,\n",
              "          -0.18575078,  0.15891648]]), 'alpha': tensor([[ 0.0038, -0.0019,  0.0176,  ..., -0.0209,  0.0058,  0.0020],\n",
              "          [ 0.0131,  0.0232, -0.0162,  ..., -0.0333,  0.0478, -0.0126],\n",
              "          [ 0.0195, -0.0255,  0.0099,  ..., -0.0176, -0.0067,  0.0042],\n",
              "          ...,\n",
              "          [-0.0090,  0.0606, -0.0083,  ..., -0.0045,  0.0250, -0.0120],\n",
              "          [-0.0007,  0.0103, -0.0178,  ..., -0.0217,  0.0179,  0.0012],\n",
              "          [ 0.0142, -0.0034, -0.0280,  ..., -0.0371,  0.0303, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0037, -0.0085,  0.0015,  ..., -0.0051, -0.0046, -0.0058],\n",
              "          [ 0.0018,  0.0010,  0.0041,  ...,  0.0008, -0.0144, -0.0095],\n",
              "          [ 0.0146,  0.0107,  0.0172,  ...,  0.0139, -0.0035,  0.0084],\n",
              "          ...,\n",
              "          [ 0.0134, -0.0504,  0.0155,  ...,  0.0093, -0.0036,  0.0082],\n",
              "          [ 0.0027, -0.0026,  0.0277,  ..., -0.0049,  0.0013,  0.0079],\n",
              "          [-0.0034,  0.0029, -0.0088,  ...,  0.0065, -0.0097,  0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003939969831868576, 'loss_breakdown': {'ot': 0.0032809458752675984,\n",
              "   'ortho': 0.6536969995839013,\n",
              "   'graph': 53.269570170763615}, 'best_iter': 932, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065903,\n",
              "   'accuracy_raw': 0.9570200573065903,\n",
              "   'foscttm': 0.15214297638497767}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-07,\n",
              "  5.0): {'mapped_X': array([[-0.08023488, -0.02574555,  0.10185766, ...,  0.07331466,\n",
              "           0.35592786, -0.10678085],\n",
              "         [ 0.06298459, -0.01740854, -0.12466853, ..., -0.26927691,\n",
              "          -0.105817  ,  0.1150663 ],\n",
              "         [ 0.09529184, -0.02519532,  0.08214664, ..., -0.3086844 ,\n",
              "           0.00067058,  0.15826809],\n",
              "         ...,\n",
              "         [-0.01762972, -0.03049303,  0.08115233, ..., -0.15110379,\n",
              "          -0.0585594 ,  0.00307048],\n",
              "         [ 0.01747373,  0.02766079, -0.2057337 , ...,  0.01670326,\n",
              "          -0.2269756 ,  0.08647254],\n",
              "         [ 0.10225711,  0.07066691, -0.16546975, ..., -0.00200048,\n",
              "          -0.18498374,  0.08962084]]), 'mapped_Y': array([[-0.05680747, -0.04895205,  0.12190812, ...,  0.07466961,\n",
              "           0.40636732, -0.15594232],\n",
              "         [-0.02848608,  0.01437455, -0.2649387 , ...,  0.16248261,\n",
              "          -0.34556755,  0.0390163 ],\n",
              "         [-0.04384248, -0.01085627,  0.1026278 , ..., -0.14074819,\n",
              "          -0.01048635, -0.00445986],\n",
              "         ...,\n",
              "         [ 0.12514297, -0.03764534,  0.08429145, ..., -0.261053  ,\n",
              "          -0.00793857,  0.19348995],\n",
              "         [-0.03009198,  0.02640466, -0.17295212, ...,  0.1782865 ,\n",
              "          -0.30871553,  0.09394532],\n",
              "         [ 0.00169907,  0.01008168, -0.23982763, ...,  0.05049521,\n",
              "          -0.26658694,  0.06943743]]), 'alpha': tensor([[ 0.0049, -0.0041,  0.0154,  ..., -0.0227, -0.0004, -0.0015],\n",
              "          [ 0.0138,  0.0141, -0.0132,  ..., -0.0439,  0.0227, -0.0223],\n",
              "          [ 0.0199, -0.0113,  0.0015,  ..., -0.0211, -0.0073,  0.0029],\n",
              "          ...,\n",
              "          [-0.0126,  0.0444,  0.0026,  ..., -0.0013,  0.0163, -0.0148],\n",
              "          [-0.0002,  0.0105, -0.0173,  ..., -0.0153,  0.0050, -0.0009],\n",
              "          [ 0.0103, -0.0072, -0.0314,  ..., -0.0291,  0.0094, -0.0199]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0035, -0.0094,  0.0031,  ..., -0.0005, -0.0012, -0.0047],\n",
              "          [ 0.0002, -0.0002,  0.0031,  ...,  0.0063, -0.0108, -0.0128],\n",
              "          [ 0.0076,  0.0068,  0.0164,  ...,  0.0127, -0.0044,  0.0026],\n",
              "          ...,\n",
              "          [ 0.0132, -0.0503,  0.0120,  ...,  0.0117,  0.0098,  0.0110],\n",
              "          [ 0.0022, -0.0070,  0.0344,  ...,  0.0046, -0.0096,  0.0096],\n",
              "          [-0.0034,  0.0014, -0.0118,  ...,  0.0050, -0.0059, -0.0029]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0041812513654202075, 'loss_breakdown': {'ot': 0.0033176769312503606,\n",
              "   'ortho': 0.8581889319592769,\n",
              "   'graph': 53.855022105704116}, 'best_iter': 941, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-07,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9584527220630372,\n",
              "   'accuracy_raw': 0.9584527220630372,\n",
              "   'foscttm': 0.15105559250106504}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-08,\n",
              "  0.1): {'mapped_X': array([[-0.16417657,  0.14218078, -0.01855154, ..., -0.02082507,\n",
              "           0.08275012, -0.00211923],\n",
              "         [ 0.00058363,  0.02381958, -0.13416458, ..., -0.10671171,\n",
              "          -0.00302414,  0.03691979],\n",
              "         [-0.14080952,  0.1846456 , -0.10557153, ..., -0.10202345,\n",
              "           0.06482828,  0.06959061],\n",
              "         ...,\n",
              "         [-0.14775166,  0.1435518 ,  0.09113591, ...,  0.04431002,\n",
              "           0.04266529, -0.12000286],\n",
              "         [ 0.24057867, -0.21021455, -0.12524155, ...,  0.0460538 ,\n",
              "          -0.12466786,  0.04779546],\n",
              "         [ 0.15976268, -0.22867302, -0.0722782 , ..., -0.06190279,\n",
              "          -0.0921932 , -0.01024161]]), 'mapped_Y': array([[-0.17804157,  0.21209684, -0.04115743, ..., -0.08702622,\n",
              "           0.05849435, -0.04585263],\n",
              "         [ 0.30919296, -0.21368048, -0.04154351, ...,  0.22766647,\n",
              "          -0.08686524, -0.07389907],\n",
              "         [-0.09459356,  0.055863  , -0.01095479, ..., -0.11032854,\n",
              "          -0.02220503,  0.06726557],\n",
              "         ...,\n",
              "         [-0.15927628,  0.18535188, -0.09333263, ...,  0.00769276,\n",
              "           0.12706326,  0.03238509],\n",
              "         [ 0.28239612, -0.09544707,  0.07121426, ...,  0.36960988,\n",
              "          -0.05081758, -0.01688011],\n",
              "         [ 0.20203891, -0.28352546, -0.13117319, ...,  0.03009503,\n",
              "          -0.12137653, -0.01711945]]), 'alpha': tensor([[-0.0017,  0.0093,  0.0094,  ..., -0.0069,  0.0010,  0.0199],\n",
              "          [ 0.0248,  0.0151,  0.0129,  ..., -0.0442, -0.0081,  0.0275],\n",
              "          [ 0.0009,  0.0038, -0.0092,  ..., -0.0039,  0.0093, -0.0002],\n",
              "          ...,\n",
              "          [-0.0151,  0.0151,  0.0035,  ...,  0.0128,  0.0037, -0.0120],\n",
              "          [ 0.0133,  0.0059, -0.0048,  ..., -0.0138, -0.0130,  0.0076],\n",
              "          [ 0.0153,  0.0017, -0.0163,  ..., -0.0430, -0.0152, -0.0245]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0017,  0.0055, -0.0002,  ..., -0.0037,  0.0015, -0.0002],\n",
              "          [ 0.0074,  0.0086,  0.0043,  ...,  0.0043, -0.0075, -0.0064],\n",
              "          [-0.0106,  0.0124, -0.0056,  ..., -0.0040, -0.0192,  0.0012],\n",
              "          ...,\n",
              "          [-0.0183, -0.0051, -0.0066,  ...,  0.0293,  0.0065,  0.0083],\n",
              "          [ 0.0100,  0.0300,  0.0143,  ...,  0.0318, -0.0021,  0.0151],\n",
              "          [-0.0030, -0.0166, -0.0091,  ..., -0.0085, -0.0176, -0.0132]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0047186547256221545, 'loss_breakdown': {'ot': 0.004350556247558694,\n",
              "   'ortho': 0.3673454118013586,\n",
              "   'graph': 75.30662621020038}, 'best_iter': 571, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 0.1,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.7788920725883477,\n",
              "   'accuracy_raw': 0.7788920725883477,\n",
              "   'foscttm': 0.21019440635864142}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-08,\n",
              "  1.0): {'mapped_X': array([[ 0.00216754, -0.00971746,  0.16094702, ...,  0.09937866,\n",
              "           0.22249102, -0.26014456],\n",
              "         [ 0.01024908, -0.00487838, -0.10076776, ..., -0.18575203,\n",
              "           0.05888276,  0.23059933],\n",
              "         [ 0.06451681, -0.07888663,  0.13689581, ..., -0.1832817 ,\n",
              "           0.09063728,  0.23105278],\n",
              "         ...,\n",
              "         [-0.05369672, -0.03510398,  0.08964553, ..., -0.11984538,\n",
              "           0.0162696 ,  0.07080284],\n",
              "         [-0.01868622,  0.05300878, -0.25069607, ..., -0.01848177,\n",
              "          -0.13241031,  0.1703165 ],\n",
              "         [ 0.1075587 ,  0.08944112, -0.14241592, ..., -0.05297758,\n",
              "          -0.09803363,  0.18086115]]), 'mapped_Y': array([[ 0.04027558, -0.05643732,  0.17866586, ...,  0.09601095,\n",
              "           0.23436479, -0.31234737],\n",
              "         [-0.08191258,  0.07223884, -0.30843785, ...,  0.05430418,\n",
              "          -0.28195447,  0.11026913],\n",
              "         [-0.03430957,  0.00494666,  0.10158368, ..., -0.11322264,\n",
              "           0.05147621,  0.0516049 ],\n",
              "         ...,\n",
              "         [ 0.08072401, -0.11406054,  0.13502355, ..., -0.13796919,\n",
              "           0.0630185 ,  0.25157336],\n",
              "         [-0.06205221,  0.09883265, -0.22021543, ...,  0.04735214,\n",
              "          -0.223221  ,  0.14146239],\n",
              "         [-0.03942214,  0.04714971, -0.27966723, ...,  0.01527599,\n",
              "          -0.18582833,  0.16017309]]), 'alpha': tensor([[ 0.0038, -0.0019,  0.0176,  ..., -0.0208,  0.0058,  0.0019],\n",
              "          [ 0.0132,  0.0232, -0.0162,  ..., -0.0333,  0.0478, -0.0126],\n",
              "          [ 0.0195, -0.0256,  0.0100,  ..., -0.0176, -0.0066,  0.0042],\n",
              "          ...,\n",
              "          [-0.0090,  0.0608, -0.0085,  ..., -0.0045,  0.0248, -0.0120],\n",
              "          [-0.0007,  0.0103, -0.0178,  ..., -0.0217,  0.0178,  0.0012],\n",
              "          [ 0.0142, -0.0034, -0.0279,  ..., -0.0371,  0.0303, -0.0175]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0037, -0.0085,  0.0015,  ..., -0.0051, -0.0046, -0.0058],\n",
              "          [ 0.0019,  0.0010,  0.0041,  ...,  0.0008, -0.0143, -0.0095],\n",
              "          [ 0.0146,  0.0107,  0.0172,  ...,  0.0139, -0.0033,  0.0084],\n",
              "          ...,\n",
              "          [ 0.0135, -0.0504,  0.0155,  ...,  0.0093, -0.0035,  0.0082],\n",
              "          [ 0.0027, -0.0026,  0.0277,  ..., -0.0049,  0.0014,  0.0079],\n",
              "          [-0.0034,  0.0029, -0.0087,  ...,  0.0066, -0.0098,  0.0014]],\n",
              "         dtype=torch.float64), 'final_loss': 0.003934803149900844, 'loss_breakdown': {'ot': 0.003280798694890467,\n",
              "   'ortho': 0.6534715129674039,\n",
              "   'graph': 53.294204297341984}, 'best_iter': 932, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 1.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9570200573065903,\n",
              "   'accuracy_raw': 0.9570200573065903,\n",
              "   'foscttm': 0.1521105920495088}},\n",
              " (8,\n",
              "  5,\n",
              "  0.001,\n",
              "  1e-08,\n",
              "  5.0): {'mapped_X': array([[ 0.07134933, -0.03142097, -0.12450511, ...,  0.02159739,\n",
              "           0.13215612, -0.10413529],\n",
              "         [-0.02791859,  0.01299618, -0.02637497, ..., -0.20612598,\n",
              "           0.04206703,  0.14127951],\n",
              "         [ 0.07915154,  0.05840755,  0.02887138, ..., -0.24063567,\n",
              "           0.06028877,  0.20745533],\n",
              "         ...,\n",
              "         [-0.01360092, -0.01329102,  0.09378947, ..., -0.13485624,\n",
              "           0.06270578,  0.06001437],\n",
              "         [-0.0907309 , -0.01577685, -0.01688269, ...,  0.02685944,\n",
              "          -0.0682515 ,  0.0449937 ],\n",
              "         [-0.03672468,  0.02311376, -0.03492318, ..., -0.0602708 ,\n",
              "          -0.06542615,  0.10927534]]), 'mapped_Y': array([[ 0.1087566 , -0.0158491 , -0.15042091, ...,  0.05315685,\n",
              "           0.12440481, -0.11849459],\n",
              "         [-0.1731945 , -0.08264042,  0.00458996, ...,  0.11586951,\n",
              "          -0.27359902,  0.02952711],\n",
              "         [-0.00734271,  0.01204538,  0.08055379, ..., -0.12209421,\n",
              "           0.02206344,  0.01846864],\n",
              "         ...,\n",
              "         [ 0.082341  ,  0.0363145 ,  0.04439574, ..., -0.20946889,\n",
              "           0.09029236,  0.23526945],\n",
              "         [-0.14341179, -0.07115163,  0.10190093, ...,  0.12925009,\n",
              "          -0.23275125,  0.02420856],\n",
              "         [-0.16261121, -0.04484086, -0.00395934, ...,  0.07906791,\n",
              "          -0.13419864,  0.04361122]]), 'alpha': tensor([[ 0.0080, -0.0081,  0.0171,  ..., -0.0328,  0.0047, -0.0027],\n",
              "          [ 0.0154,  0.0137, -0.0059,  ..., -0.0412,  0.0457, -0.0238],\n",
              "          [ 0.0234, -0.0064, -0.0039,  ..., -0.0210, -0.0258,  0.0147],\n",
              "          ...,\n",
              "          [-0.0158,  0.0318,  0.0100,  ..., -0.0054,  0.0335, -0.0153],\n",
              "          [-0.0030,  0.0039, -0.0376,  ..., -0.0193,  0.0125, -0.0092],\n",
              "          [ 0.0027, -0.0178, -0.0321,  ..., -0.0511,  0.0185, -0.0260]],\n",
              "         dtype=torch.float64), 'beta': tensor([[ 0.0043, -0.0082,  0.0079,  ..., -0.0016, -0.0023,  0.0003],\n",
              "          [ 0.0025, -0.0016,  0.0032,  ..., -0.0036, -0.0169, -0.0017],\n",
              "          [ 0.0197,  0.0048,  0.0342,  ...,  0.0176, -0.0199,  0.0184],\n",
              "          ...,\n",
              "          [ 0.0109, -0.0640,  0.0090,  ...,  0.0018,  0.0103,  0.0076],\n",
              "          [ 0.0056, -0.0064,  0.0401,  ..., -0.0067,  0.0012,  0.0066],\n",
              "          [-0.0075,  0.0007, -0.0088,  ...,  0.0175, -0.0059, -0.0047]],\n",
              "         dtype=torch.float64), 'final_loss': 0.0025451572757359707, 'loss_breakdown': {'ot': 0.0023576431224919077,\n",
              "   'ortho': 0.18705466704489487,\n",
              "   'graph': 45.948619916819816}, 'best_iter': 2049, 'config': {'p': 8,\n",
              "   'lambda_topo': 0.001,\n",
              "   'lambda_reg': 1e-08,\n",
              "   'iterations': 4000,\n",
              "   'lr': 0.001,\n",
              "   'reach': 5.0,\n",
              "   'scaling': 0.8,\n",
              "   'blur': 0.01,\n",
              "   'patience': 10,\n",
              "   'print_every': 500,\n",
              "   'dtype': torch.float64,\n",
              "   'seed': 50,\n",
              "   'stop_when_lr_below': 1e-06,\n",
              "   'init_K1': None,\n",
              "   'init_K2': None}, 'metrics': {'accuracy': 0.9603629417383,\n",
              "   'accuracy_raw': 0.9603629417383,\n",
              "   'foscttm': 0.15507353068621038}}}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "2654243c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_param_violin_pretty(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    ylim=(0.0, 1.0),\n",
        "):\n",
        "    \"\"\"\n",
        "    Pretty robustness violin plot:\n",
        "\n",
        "      - x: distinct values of param_col (e.g. 'p' or 'reach')\n",
        "      - y: metric_name (e.g. 'accuracy' or 'foscttm')\n",
        "      - one violin per param value\n",
        "      - shows mean & min/max, no scatter dots\n",
        "\n",
        "    If k_filter is not None, only keep rows with that k.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "\n",
        "    positions = np.arange(1, len(groups) + 1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5.5, 4.0))\n",
        "\n",
        "    # Violin plot\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,     # small horizontal line at mean\n",
        "        showextrema=True,   # min/max\n",
        "        showmedians=False,  # we don't need both mean & median\n",
        "        widths=0.7,\n",
        "    )\n",
        "\n",
        "    # Style violins\n",
        "    for body in parts[\"bodies\"]:\n",
        "        body.set_facecolor(\"#a6cee3\")   # soft blue\n",
        "        body.set_edgecolor(\"#1f78b4\")   # darker outline\n",
        "        body.set_alpha(0.8)\n",
        "        body.set_linewidth(0.8)\n",
        "\n",
        "    # Style means / extrema\n",
        "    for line in parts.get(\"cmeans\", []):\n",
        "        line.set_color(\"#1f78b4\")\n",
        "        line.set_linewidth(1.2)\n",
        "    for element in [\"cmins\", \"cmaxes\"]:\n",
        "        if element in parts:\n",
        "            for line in parts[element]:\n",
        "                line.set_color(\"#1f78b4\")\n",
        "                line.set_linewidth(0.8)\n",
        "\n",
        "    # Axis labels / ticks\n",
        "    ax.set_xticks(positions)\n",
        "    ax.set_xticklabels([str(g) for g in groups], fontsize=11)\n",
        "    ax.set_xlabel(param_col, fontsize=12)\n",
        "    ax.set_ylabel(metric_name, fontsize=12)\n",
        "    ax.set_title(f\"{metric_name} across {param_col}\", fontsize=13)\n",
        "\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(ylim)\n",
        "\n",
        "    # Light horizontal grid\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.yaxis.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.4)\n",
        "\n",
        "    # Remove top/right spines\n",
        "    for spine in [\"top\", \"right\"]:\n",
        "        ax.spines[spine].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "72dc6789",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHqCAYAAAD/IrHXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdX1JREFUeJzt3QWcVFX7B/DfdrJ0LSxd0t0hISkCAtIlHYIimLzUiyCgSAgujSCppFIKSAlKd3d3LbuwOf/Pc/zPvruzNTN7Z6d+Xz9Xdu7cuXNm7szc557znHNcdDqdDkREREQUy/V/fxIRERGRYIBEREREZIABEhEREZEBBkhEREREBhggERERERlggERERERkgAESERERkQEGSEREREQGGCARERERGWCARERERGSAAZIdWLRoEVxcXHDt2rUUtx09erTa1pG8fv0aHh4eyJAhg3p9zs7YY2xr79ukSZNQrFgxxMTEwBHe/0ePHlm7KHbNUd7H4OBg5MmTB+Hh4dYuCmmMAZKFXb16FYMGDUKRIkXg6+urluLFi2PgwIE4ceKEtYtnF6KiojBv3jzkzZsXY8eOxYMHD6xdJLtgS+/bixcvMHHiRHz66adwdU3bn52LFy+iffv2yJ07t/r+SZAm70dYWBhs0c6dO1XgkNjy999/W7t4dkOL91GCHvnMBgYGwsfHB1WqVMEff/wRb5vu3bsjIiICs2fPttArIWtxt9ozO4HffvsN7dq1g7u7Ozp16oQyZcqok8O5c+ewZs0a/PDDDyqAkhNYcrp06aJ+4L28vOCM/P390a1bN/U+du7cWQWWDRo0sHaxbJ4tvW8LFixQAVuHDh3S9Hlv3ryJypUrI3369OpCJVOmTNi/fz9GjRqFw4cPY/369bBVgwcPRqVKleKtK1SokNXKY69S8z5K8PPLL7/gww8/ROHChVVtftOmTfHnn3+iZs2aahtvb2/1PZsyZQo++OADh6vBd2YMkCzk8uXLKqiR4Gf79u3ImTNnvPvlanrWrFnJXk2HhobCz88Pbm5uanFU+teZkhIlSqh/z549ywDJBLbwvi1cuBDvvPOOOpmkpSVLluDZs2fYu3dv7PvQp08f1cy3ePFiPH36FBkzZoQtqlWrFtq0aWP17529M/d9PHDgAFasWIHJkydj2LBhal3Xrl1RsmRJfPLJJ9i3b1/stu+9955qQpbAqV69epqWn6yHTWwWIl8W+QGSE4NhcCTkql6ubIKCguK1x585cwYdO3ZUP9r6K5SkcpDkR1+ujOSkU7BgQZOreI8ePYomTZogICBA1TbUr18/XtWzXDnJ8+7atSvBY+W55L5Tp07Frrt9+zbef/99ZM+eXdV2yQlJag7iSu51GpNTI+Sxtub69esYMGAAihYtqqriM2fOjLZt2yY4ZvrXf+nSJXV1KvlBUrvRo0ePRJt8UnuMbeF9k1rSpGqv9O+H1KrKSUY+i/LeDRkyJLbcqW3aE/KZjEu+k3Jx4unpCa2Ov9RKyMnz/v370EpISIiqeUutlL53xnx3jf2M6/fXs2dP1TQl+8ufPz/69++vmqIMSQBrzHchrd9H+f2TC1MJqPXkeyivS2ohpXZSr0KFCqp20pZrJMl0rEGyYPOa/GBKm7Up5AdHqnLHjx8PnU6X5HYnT55Ew4YNkTVrVvXjJ19+aTYwPBEk5fTp0+rKSk5IcjUkybxy8n3zzTdVQCTlbtasmQqcVq1ahTp16sR7/MqVK9WPqJwQhJwUqlatqn6EpSlDyrV582b1YyInKamiNud1xvXxxx/H1oTYmoMHD6orSn2ui5w0pAlV3k85KUnuS1wSDMhJY8KECThy5IjKFcqWLZuqWdTqGNvK+6a/0i5fvnyS28j7kS9fPvV+SJA+ffp0VbsjtTwiMjISz58/N+r55ESlr5mV91/eU/kcjhkzRp3UpTxybOQCRYsaFKktlloDeV7JT8mSJUuqyqwngcLLly/VSVq+q1KTUbFixVSVNbHvnbHfXWM/43fu3FHNmhL4SHAhOV8SMEnAIYGPYVCa0nfBWu+jXEBK7qj8RsYlr00cO3Ys9gJX//n+66+/jCon2Qkdae758+fyy6Nr2bJlgvuePn2qe/jwYewSFham1o8aNUo9pkOHDgkes3DhQnXf1atXY9fJvr29vXXXr1+PXXfmzBmdm5ub2jYl8nhPT0/d5cuXY9fduXNHly5dOl3t2rVj10l5smXLpouKiopdd/fuXZ2rq6tu7Nixset69uypy5kzp+7Ro0fxnqd9+/a69OnTG/U6k7NkyRL1OCmLLLZG//ri2r9/vyrz4sWLY9fpX//7778fb9tWrVrpMmfOHG9dao+xrbxvI0aMUGUICQlJcJ/+/XjnnXfirR8wYIBaf/z4cXX7zz//VLeNWeJ+T8R///tfnY+PT7xtvvzyS7Nfj77M8v09e/asLjAwUFepUiXdkydP4m1nbpn/+usvXevWrXXz58/XrV+/XjdhwgT12ZDPwpEjR1JV5sS+d8Z+d439jHft2lX9Phw8eDDB9jExMSZ/F6z1PpYoUUJXr169BOtPnz6tnis4ODje+j59+qjPGTkO1iBZgL5aX2pfDMnV1vHjx2Nvx23fFv369Utx/9HR0di6dStatmypupfqvfHGG2jUqBE2bdqU4uN///139fgCBQrEa3aQ6ve5c+eq1yBXTpJkvnz5ctUjRJrghFwJSg6H3CfkSnT16tXqSlD+jtttV8oj7fhyZVijRg2TXqeeXP1JTxJpDpRaq2+++QZPnjxRV4u2Qpoc9OSKV94/qUGUZgN57ZJoH5fh65cr27Vr18a+76k9xrb0vj1+/Fg1KSf2fdCTXp1xSbKr5OjJ6yxdurTq4GDYeygpOXLkiHdbaqZq166N1q1bqxqkjRs3qhoU2U5qTMwlzcvyHZDjLDUuhjUN5pa5evXqatGT3C3JoZH34fPPP8eWLVvMLrPh586U764xn3H5XVi3bh2aN2+eaC1NYgnMKX0XrPU+vnr1KtGOMfo8Ork/Lmm2lHVSS2ZYY0z2iQGSBaRLly72BGVImrGkPVyqtaVnkSGpak7Jw4cP1RdRqsoNSX5ASidPebx8iWVbQ3IClh85aV+Xk2rjxo1VXoA0qekDJPm7bNmyqvpZvz+pTp8zZ45aEmPYxdyY16knJzP54Z42bZrKyRFSpR83h0JOgj/99JPR+Uxak+MhTQSScybNCXGbDRNrHogb9Ah9orA0K8lJIbXH2Nj3zVYYvk7Jt5KmEn1+i7w/5iSYywlemnkuXLigmoXEu+++qz7jEjxKrzoJmswhQYA0d0ogm1jwZ26ZEyOBSIsWLVTvVwmeze20Yfi9M+W7a8xnXPYngY2+6d0YKX0XrPU+SkCY2NhG+ty4uAGj0L8f7MXmOBggWYAEFFIbEzeBWU+fk5TUoI+GXzprkysoqcWQKzq5opfATtrZ5eSrpx/4TwI+6e6aGLlqM+d1Sn6HdJ+VPBo5icqPpj6fxpZO9FLjIScOydeoVq2a+gzID6XkayQ2MGJSP8zG5mNZ4n2THCep6dGaBCCyb7kw0F88pMTwJCPJvVL7ZQzJodG/v/KZLVeuXGxwFLc2QTo/SJ6JuSdfqZH68ccfsXTpUvTt2zfB/eaWOSmS7yL7lM4fhrVVxjL83pny3TX1M26slL4L1nof5TdcAkFDd+/eVf9KAnpc8h2TmiNb+w0n8zFAshBJcJZkQ+kqqk/q04r8CMiXUAbAM3T+/HmjHi9f5MS2ld5EcuUeN/lQmhHkRCDDFcgJVn649M1r+v3JiU+uyLTuRj506FC1/y+//DK2hsuwR1avXr1w48YNldAsZZdaOqnhkqp7SXSW2ghJ+o3bxCc/7LJOmjjlx1ICieHDh8cmsCf32MRIs6OcYL799tt4V5pydW6NY2zM+6Z/H2bMmKHKLUHEnj171HspPY4kWVqSZb/77jtVkyj++ecf9X5LjyZpjpXPQ+/evROtDdWTJF19bzbDQFlPXmfc2g3p5ScnXakZFJIcXLdu3RRft/559I+TgD6xbvzSRCRS00NMPjsSUErPLvn8y/sRl7llTsqVK1dU805yTZWmMuW7a8xnXPYnQUdiF4fmstb7KL8h0m1f39SnJ98B/f2Gz63/npFjYIBkIdIzbNmyZarrrAQWhj2PUlNTIFdIkh8gbf1yMtNXUcvJSqr7jXm8BBPSJVVqsuKeTKTMUsMQ9wdBfjglb0Wa1uQ5JOCLezKT/cnVtDxWfhgNq9el2l1+OE0lr2XDhg2qmUTf20h+zCV4i9sjSwLRbdu2xTaxScAjJ2W50t2xY4eqTpfmEKlViXuylJ6GUl7pdSM/wNILRfIfZNuUHpvYe2p4TCXwkBNPWh9jY983PcnvkLw46ckoQYm8XunBJJ8P6bkktS3yPkmuiTRPySjUMh6M5KrNnz9fBUjJkdoGcejQoSQDpJkzZ6rPZNz3Tkj+lDA3D0WagSXfTprY9E3CQvLqJJhOqjzGkOBSmqWkZkwCBznhynulZ26ZE/u+yPGRYyrvh5YjkZvy3TXmMy5lkxpn+S7K8TbMQ5LHm9oElRbvo6QcyPdMeiDqeyFKvpLk7ckx1ueJSpOb1KJJS0Dci0gheVgyIDA5EGtniTuydevWqV4N0hNEeuXMnj1b9Xz49NNPdUFBQaqnx/LlyxP0jDGmF5v07pHeGHny5NF9/fXXunHjxumyZ8+uK126tFE9nE6dOqXz8/PT5cqVS/fVV1/pJk6cqCtQoIDOy8tL9/fffyfYvlevXjp/f3+di4uL7ttvv01w/71793R58+bV+fr66oYMGaJeq/Qaadu2rS5jxoyx2yX3OuOKiIjQFStWTFe3bt0E9zVq1Ei97rjkuffs2aP+3r17t7odV9WqVXXLli2LvS1lkN4xetKrqXfv3kY9NjHSc0d6l+lfe/fu3XW5c+dWvWa6deuW4uvX6hib+r7Jfvbt2xevV1LhwoXjbSM9gaR88n7JZyQu+RxLT7mUlCxZMtEeVPr3o1SpUrrmzZvrZs6cqevcubNa17FjR11q7dq1Sx0X6cEnvS5l/02aNFH7l8+0IVlfp06dZPdpeAzlPW/atKn67mzfvj3VZZZjJ/uT4z1nzhzdhx9+qL5X8jsivRi1KLM5311jP+O3bt3S5ciRQ+1Pyi7bjh49WvUKk1685nwXLP0+6nvKSZnikvfA3d1dN3z4cPU6qlevrm7L5yquQ4cOqcdv27YtVWUm28IAycIuXbqk69+/v65QoULqZCcBk5zA+vXrpzt27FjsdqYGSEK+pBUqVFDd9eXEJcGXfj/GkK6uctKUwEd+OOQHJe7JMq4//vhD7VcCpJs3bya6zf3793UDBw5UJ00PDw/1I1m/fn3142TM64xrypQp6odIAjlDQ4cOVeWI2208boC0YsUKXc2aNeM9pl27drpvvvkm9raUQY6Nnrx3b7/9tlGPTYz88Pfo0UOXJUsW9X7K+3ru3DlVLnMDJHOOsanvm+znxo0bsbdXrlypHi8nEf0igfT48eNVMF+rVq0EwaMxAZKUS94Xw67i+tciJ6w2bdqoYSbkpDxo0CDdq1evdFr4559/VFAkn0f5XBYpUkRdFERGRsbbTt4XKYt0b09OYsdQXpcEKfIaE7vAMMW0adN0lStX1mXKlEkdC+mCL0HjxYsXE2ybmjKb+t019jMuZGgKCaiyZs2qAkf57Mr+w8PD0yxAMuV9TCpAks/gsGHD1Pshr0OGc9iyZUuCx8tFr1x8xB3GgOwfAyRyCPny5Uu2BqlatWpm1yAZPtaRyPsQN+Ddu3evqs1JTGpqkJ49e6ZOVPPmzYu33tiAOS1s3LhRBZAnTpzQ2Qt7LLOjef36tQqgpk6dau2ikMY41Qg5BEkm1vcM1PcU/P7771US7s8//6xyb/SJxnoyUq8kYErSs0yrIGPBGPtYRyWvX/KQZIRkyeWSRZ+4LblE0tVbcjDkvQkODo7t0ZMS6fEkeXmS2JyaHk+WJAm50iOrVKlSsBf2WGZHI98Hyd8zZWw3shNaR1xE1rB69WqVTyVNQkuXLlX5O5IvEBAQoCtXrpyqGYpLPvrTp09XNSCSnyI5F3opPdaRa5DEtWvXdC1atFBNKZJfIk0p+uYOaYKVXBJpCuvbt6+qXVu1apXZz29LNUhERHG5yP+sHaQRpTXpSSODYRqOj0PGk58Oef+kli3uiMWmkDnmZI406XGk7z1ERGQL2MRGREaTKWdkdG5pepMmSgk0UzOBqgRIEmgxOCIiW8NxkIjIaDJ4puRqSS6SDIon40QZzs5OROQI2MRGREREZIBNbEREREQGGCARERERGWAOkglk/BaZt0vmtTJ1PiEiIiIhmS0yh19gYKCmc+sZksmEpUOFVjw9PdVEv86CAZIJJDgynKCQiIjIHJYcakSCo/x5/XHvgXkTZic1GfDVq1edJkhigGQCqTnSf6jjznZPRERkLBnBXy629ecUS5CaIwmOrh7Oi4B0qa+lehESg/wVrqv9MkCiBPTNahIcMUAiIqLUSItUDQmOtAiQnBEDJCIiIgcVrYtBtE6b/TgbBkhEREQOKgY6tWixH2fDejciIiIiA6xBIiIiclAx6j9t9uNsGCARERE5qGidTi1a7MfZsImNiIiIyABrkIiIiBwUk7TNxwApjZ0+fRqXL19WfxcoUAAlS5a0dpHIAi5cuIDz58+r6Wny5MmDsmXLcnoaB3TlyhWcOXMGUVFRyJUrFypWrMjj7IBu3LiBkydPqkESZTTpKlWqWHSKEC1JYBPNAMksDJDSaN6dZcuWYdq06Th48EC8+8qXr4AhQwajc+fOdvOFo6SP85o1azB9xlTs3rU33n2lS5fEoEGD0aNHD7i782tn7zZt2oSp077DH79vi7e+WLFCGDBgMPr06QMvLy+rlY+08eeff2LKlG+wceNm9f3WK1AgD/r3/wADBgyAr6+vVctIlsMzsoXJlWXXrl1VAHT18A2URjXUwttqKYPquHnsDrp164aOHTsiMjLS2sUlM8mP5wcffIA2bdrg8asTGDotL+btK4EF/5TAiPkF4J3tFvr164sWLd/Bq1evrF1cSsVxHjFiBJo1a4YHD/Zi4nfpsedgNuw/mg0/rsiE/IVuY+jQD9G4cUM1nQTZr8mTJ6NevXq4eW0nfpicRU3ZcedkPvy5LhDVyj/Fl19+ijp1auLRo0ewhyY2LRZnY5MB0u7du9G8eXM107FUV69bty7V+9y7dy9q1KiBzJkzw8fHB8WKFcN3330HSxs6dCiWLV2GkqiCsrqayOaSC14u3mrJ6hKIMroaKIWq+HnVz+oES/Zp9OjRmDlzJvqOy42xywqgRrOMyJjNA+kze6BcnQB8GpwPX8zLj+3b/0D3Ht2sXVwy07Rp0/DVV1/h0y/TYdWGDGjVxhfZc7ghcxY3VKvhhWk/ZMCSVRlx+PA+tH2vdbxaB7IfixYtwieffILPh2TAwd9zoGenAOQOdEfWLG6oWcUHi2Zkw97fAnH92mm8804zm7641fdi02JxNjYZIIWGhqJMmTLqhKMVPz8/DBo0SAVfZ8+eVVeBssyZMweWcv36dcz8fiYK6kogh0tQkttld8mNQrpSmD17dmx+EtmPx48fY+LEr9F6QHY0bJ8lye3K1Q5An/8GYtXKn3HkyJE0LSNp87s0evR/0LGrL3r2808y16hCJU9MnpYOv2/dpppoyL5IsPPll5+hfSt/jPk0U5LHuVwpL6yalwX79x/Ahg0b0ryc5KQBUpMmTTBu3Di0atUq0fvDw8MxbNgwlRQpgY8kzO3cuTPZfZYrVw4dOnRAiRIlkC9fPtXk1ahRI+zZs8dCrwIq+HJ39UAuFExx21woAC83bwQHB1usPGQZCxcuVGmQb3fPmuK2tZpnRNZAH8yaNStNykbaWb58OV68eIle/fxS3LZuAy8ULuKNWbO+T5OykXYk2Llz5z6GDcyQYsK91CZVr+yHWbNmwFbFaLg4G5sMkFIiNUH79+/HihUrcOLECbRt2xaNGzfGxYsXjd7H0aNHsW/fPtSpU8di5Vy/dj0yR+eEu0vKSbluLm7IEh2IdWvXW6w8ZBkbfl2HcnX8EZDJiOPs7oJa76TDbxt5nO3Nb7/9hspVvZE7KOXjLCfWlm088NtvG9nMZofHuXQJX5QpYVySfZe2vtixYxfCwsIsXjZKW+722N1SrtjlX8lRElKbtGXLFrV+/PjxyT4+d+7cePjwoUqelryRXr16Jbmt1FTJomdq0uXTZ8/ghXRGb+8Fbzx7+sCk5yDre/r0KXKX9jB6e8lNevb0oUXLRNp79uwxsmYzfvts2V0RHh6B169fq7xHsg/Pnj1DYHbjt8+Z3S32cbbYoy1ao27+0U6YpG13AZKMRREdHY0iRYrEWy+BjCRgC39//9j10pQWt9lKmtRevnyJv//+G5999hkKFSqkmt4SM2HCBIwZM8bssvr7+yEMxifvRSICfv4pV9+TbUnnnw4vX9wxevuXz6Ph5297P6SUPH//ADx/bvxJ4vkzHdzcXOHt7W3RcpG25Pxx96bx2z99FpPgvGNLonX/Llrsx9nYXYAkwY2bmxsOHz6s/o1L/wE9duxY7LqAgIB42+TPn1/9W6pUKdy/f1/VIiUVIH3++eeqF1rcGqSgoKSTrQ01eKsBFl5dhJioMnB1Sb41M0YXg8fud9GxYeJlIdtVr14DfDftCF6FRsPHL/5n0pA0t+zbGIK6dRunWflIG3Xr1sMXX2zB40fRqtdaSjZuiMCbb9bmwJF25s0338TSpT/hyvVIFMibcs3wqvVhKF++TIJzDdk/u8tBkmRrqUF68OCBqv2Ju8gIpyLuumzZkq4Tl1GO4zahGZKB3uRDH3cxRf/+/fEqKgz3kPLlyAPcRlhUKAYOHGjSc5D1yaCAr8OiseOXJylue2xPCG5eCsXAATzO9qZ79+5wdXXHsiUp55ocPxqBo4dfY8AADt1hb+SCOSDAH9/Pe57itucuRmDLjpcYOHAwbBWTtB0sQJJaIqkF0tcEXb16Vf0teUfStNapUyc1+KKMWiz3HThwQDWHbdy4Mcl9ypABv/76q0rklmX+/Pn45ptvVBNcSuSxxYsXR6VKlUx6HTKNiPTEu+h2HM90SQ8m9lz3BBfcjqnB52RKCrIvMpWIjJD906R7OLYn6Ty16+df4fvht1GzVnV1lUr2RZrwZTT0WdNCsXVz0oN9Xr8ahSH9QlC2bCm88847aVpGSj3JI/rkk88xY95zLFqR9Pf51p0otO7xEAUL5kf79u1hq2LggmgNlhg4X02oi84Gu1hIl/26desmWC8jTssAXjJOhQwDsHjxYty+fRtZsmRB1apVVb6QNJ0lZsaMGWqcIQmoZKqHggULonfv3ujbt6/RU3xIE1v69Onx/Plzo2uTZOyUxo0aY//+v5EzJg9yoyD8XdKr+17qXuAWLuOe6w1UqFgef2z7A+nSGZ/UTbZDaiJbtWqJ3//4HXVaZkCTzllQoOS/eUZ3r4Xj9+WP8MeKZyhcqCh2bN8Zmy9H9kVqrzt16ohVq1aheUsfdOrmi7LlPVQz2p3b0VjxUyiW/xSB7NmCsGPHbjUUCdkfOS3KuWHu3Llo/bY/+vcIQO1q3uo4370fhflLX+CHRaHw9smK7dt3qtYKU5hzLjGV/jmOnMkO/3Sprwt5GRKD8sXvW7TMtsYmAyRbZe6HWnqxfP3115g1cxYePnoIDzdPFYtHREcgc6Ys6D+gH7744gv2dLFz0jNSaiVnzpqBWzfvwMfXHa5uLggNiUTGTOnR8/3eGDlyJINgOydN83LBNX36FFy5cgM+vm7wcHfBixdRCAjwQ7du72PUqFEMgu2cnBrnzZuHKVMm4dy5S/DxcYOXpyuev4iEj483OnXqoi7Kc+bMafK+0zJAOnRauwCpYgkGSGShD7XMBC2TXMoM4PqEcWlW8/T0tEBpyZqB0tatW3HhwgVV4yBNcDJ1DgNgxwuUtm/fjtOnT6tabaktkiY1W+3NROaRU+SuXbtw/Phx9Rsuua5ynOVcYK60DJD+OZ1DswCpSol7DJAoYQ6SLHKyk5OeM31AiIhIWwyQ7INNJmnbGulZdubMGRw8eNDaRSEiIjKaFgna0f+/OBu7GweJiIiIjBOjc1GLFvtxNqxBIiIiIjLAGiQTc5CIiIjshVbNY9FO2MTGGiQjMAeJiIjIubAGiYiIyEFFw1Utqd+P82GARERE5KB0GiVp65ikTURERESsQTICk7SJiMgeMUnbfKxBMgKTtImIyB5F61w1W0wlFQv58uWDt7c3qlSpggMHDiS5rUzXM3bsWDWRvGxfpkwZbNmyBdbEAImIiIg0tXLlSgwdOlRN3HzkyBEV8DRq1AgPHjxIdPsRI0Zg9uzZaiJoqZDo168fWrVqhaNHj8JaGCARERE5qBi4IAauGiwuJj3vlClT0Lt3b/To0QPFixdHcHAwfH19sWDBgkS3X7JkCb744gs0bdoUBQoUQP/+/dXf3377LayFARIREZGDssZcbBERETh8+DAaNGgQu87V1VXd3r9/f6KPCQ8PV01rcfn4+GDv3r2wFgZIRrajSgRcqVIlaxeFiIjIal68eBFvkcDG0KNHj1SnpuzZs8dbL7fv3buX6H6l+U1qnS5evIiYmBj88ccfWLNmDe7evQtrYYBkBCZpExGRPdI6STsoKAjp06ePXSZMmKBJOadNm4bChQujWLFi8PT0xKBBg1TznNQ8WQu7+RMRETl0DlLqu+jH/P8+bt68iYCAgNj1Xl5eCbbNkiUL3NzccP/+/Xjr5XaOHDkS3X/WrFmxbt06vH79Go8fP0ZgYCA+++wzlY9kLaxBIiIiIqMEBATEWxILkKQGqEKFCti+fXvsOmk2k9vVqlVLdv+Sh5QrVy5ERUVh9erVaNGiBayFNUhEREQOKkajudhioDNpe+ni361bN1SsWBGVK1fG1KlTERoaqprNRNeuXVUgpG+i++eff3D79m2ULVtW/Tt69GgVVH3yySewFgZIREREDsrcQR4NRetMC5DatWuHhw8fYuTIkSoxWwIfGfhRn7h948aNePlF0rQmYyFduXIF/v7+qou/dP3PkCEDrMVFpzPxVTsxydiXpLTnz5/Ha4MlIiKypXOJ/jlWHCsO33Ruqd5fWEg02pc941TnP9YgGYFzsRERkT3SD/SY+v3o4GyYpG0EdvMnIiJyLqxBIiIiclDROhe1aLEfZ8MAiYiIyEFFa9SLLZpNbERERETEGiQiIiIHFaNzVUvq96ODs2GARERE5KDYxGY+NrERERERGWANEhERkYOK0agHWgycDwMkI3CgSCIicu6BIl3hbJzvFZuBA0USERE5F9YgEREROSjtJqt1hbNhgEREROSgYuCiFi3242ycLyQkIiIiSgFrkIiIiBwUm9jM53yvmIiIiCgFrEEiIiJyUNqNpO0KZ8MAiYiIyEHF6FzUosV+nI3zhYREREREKWANEhERkYOSEbC1aB6LccL6FAZIREREDipG56oWLfbjbJzvFRMRERGlgDVIRuBktUREZI+i4aIWLfbjbFiDZAROVktERPbcxKbF4myc7xUTERERpYBNbERERA5KEkO0aWJzPgyQiIiIHBR7sZnP+V4xERERUQpYg0REROSgonWuatFiP87G+V4xERERUQpYg0REROSgdHBBjAZJ2jonHAeJARIREZGDYhOb+ZzvFRMRERGlgDVIREREDipG56IWLfbjbBggEREROahouKpFi/04G+d7xUREREQpYA1SGgsNDcXdu3fV3zlz5oSfn5+1i0QW8OrVK9y5cwcxMTHIkSMH0qVLZ+0ikQWEh4fj9u3biIqKQvbs2ZE+fXprF4ksICIiQh1n+TdbtmzImDEj7AWb2MzHGqQ0cvjwYfTo0QNZsmRC4cKF1ZI5c0Z0794dBw8etHbxSCOnTp1C//79kS1bFhQqVAhFihRB5syZ0KFDe+zdu9faxSONXLhwAR9++CGyZ8+CggULomjRouo4v/tuS2zbtg06nc7aRSQNXLt2DZ9++ikCA7OjQIECKFasGDJnzoxmzZpg48aN6gLI1sXAVbPF2TjfK05j8kM5YcIEVKxYEdv+WI6PB3tjw6osavl0qA/+3L4ClStXxujRo/mjaudmzZqFMmXKYN2aBfiwjxe2rsqJbasD8dUX6XH4wHrUqlULQ4cOtYsfVUrakiVLUKJEcSz96Qf07uyGjSty4PfVOfDNmIw4f+Z3vPXWW+jVq5eqVSL7tW7dOrzxRlHMmf0durQGNi8PxJ9rcmPm11lx9+ZuvP3222jfvh1ev35t7aKSMzWx7d69G5MnT1a1LtIctXbtWrRs2VKz/f/111+oU6cOSpYsiWPHjsGSpk2bhi+++AKffJQOn3wUADe3/1VT1qrhjcH9dfju+xCMGTMGvr6++OSTTyxaHrKMRYsWYeDAgfigV3pMHJkZHh7/O851qvtgSJ/0mLngOT4e+R28vb0xfvx4q5aXzCO/Rd26dUPXdv6YNj4TvL3/d41Zu5oP+vVIhyWrXqL/sIXw8PBAcHCwVctL5tm+fTvatm2DFo19sXBaNvj5xj/OfboEYPXGl+g6aC26d++G5ctXwMXFNpugonUuatFiP87GRWeD1RabN29WQUyFChXw7rvvahogPXv2TO1Xmj/u379vUoD04sULlWPw/PlzBAQEpLj948ePkStXIHp09sSEsRmS3XbkuGcInvcaN2/eUrkMZD/CwsKQK1cONG8IzJ+aNdkfyonTn2LEhCe4dOmSapoh+yE1QvnyBaF8yRCsnJ8Vrq5JH+c5P77A4M8fq4u88uXLp2k5KXXklPjGG4URmOUetqzICXf3pI/zinUh6NT/ngqo6tWrZ7FziTn0z9F3d2t4+Xuken/hLyMxu/Zqi5bZ1thkE1uTJk0wbtw4tGrVKsnEyGHDhiFXrlwqyblKlSrYuXOnUfvu168fOnbsiGrVqsHSFi5cCJ0uCh8PSTlBd+igALi76zB//nyLl4u0tXz5cjx/HoKRwzKmeBU5uHd6ZMzggdmzZ6dZ+Ugb69evx+3b9/CfYemTDY7E+53SIXegl2p2Jfvy559/4vz5y/jP0AzJBkeiXQt/FC/qg1mzvk+z8pGTB0gpGTRoEPbv348VK1bgxIkTaNu2LRo3boyLFy+mGLBcuXIFo0aNSpNyrly5FM0aeSNLZrcUt82QwRXvNPVSjyH7snLlcjSo7Yd8QSlfpfn4uKJTa18eZzu0cuVKVCzrg9IlvFLcVk6sXdv5YNWqFWlSNtL2OBcu4KOa0lIiF0S9Ovph3br1NpuLpNO5IkaDRcepRmzfjRs3VKDz888/q6RXaaaQ2qSaNWuq9UmR4Omzzz7DTz/9BHd341KvpKZKqinjLqZ4+PAB8udLOTjSy5/PHQ8ePDDpOcj6Hjy4i4L5jT/OBdRxfmTRMpH2Hj68hwL5jP/JLJjfHSEhoTZ74qTEPXz4EAXyuhqdU1Qgnweio2Pw9OlT2KJouGi2OBu7C5BOnjyJ6Oho1X3a398/dtm1axcuX76stom7XprUZHtpVpNEaHmcsaT3mbTh6pegoCCTyurl5YVXr4xP8Xr1Wgdv75SvTsm2eHl5I8yE4/yax9kueXn5mPR9ls+EnGQ9PT0tWi7S1r+/2zDpd1tI5wtyLDbZiy05L1++hJubm0p+lH/jkoBIxE28lmSykJAQHDp0CEePHlXNc0K6WksyntQm/f7774km2H3++eeqW7ae1CCZEiRVrFgVW7evwbhRuhRzFqQsW36PVI8h+1KpUjWs/vk0IiN18XqvJeXX38NRsWKVNCkbaadSpcqYNnUHXobGwN8v5WvLjb+/RvnyZeDqanfXoU5NhmT5Ys0qPHwUhaxZUj5F/ro1FAUL5kWGDMl3xLGWGJ02gzzG2Fx3Lsuzu29uuXLlVI2QNEVJT7S4i4xYLOKuk1FPJUiSmicJnPSL1CzJ4G7ytyR5J3UlIY+Nu5iif/8BuHI1HDt2hae47d594Th/8TUGDBho0nOQ9cln6d6DcKzZ+DLFbY+dCsf+g6Ho35/H2d707t0boWExWPZLysf58rVIbN0hx/nfCzKyHzJ4r4uLG+YtTTml4v7DKPzymxznD2y2mz85WIAktUT6QEZcvXpV/S35R9JE1qlTJ3Tt2hVr1qxR9x04cEA1h8nIpomRKzgZ8yjuIoGTVInK3ylN9zFz5kwUL14clSpVMul11KhRA1WrVsKQ4S9w42bSg8bduh2FQUNDUKFCWbz55psmPQdZn3yGmjRpiA9HPMPZCxFJbvfgURS6DHiMwoULoHnz5mlaRkq9PHnyoH379/DlV89x5ETSFz3PnkejS7/HCAzMgfbt26dpGSn1ZKTs99/vhXFTn2H3/qTb2iRY7tD3Afz906mgylZpkaAd8/+Ls7HJVyzNYVJTJIuQZi75e+TIkeq2JGNLgPTxxx+rWiAZI0mm65AfMEuQAQDPnDlj8pQgckWxevU6+PjmxFvNn2DOwpd4EfK/UZRDXsZg/o8v1X0ublmxbt2vvAqxUz/9tBw5chZEnRb38F3wMzx5Gh17X1hYDBYuf4Eaze7jWYg/fvttsxpEkOzP7NlzUbxEWTRs/QATpz/Dg0f/O87h4TosX/MStZs/wNWbHuo4c65F+zRlyhTUqFELjTvcxejJj3H77v8ucKUp/ZffQlDrnTs4fFKHDRs2qqDKVsXARbPF2djkQJG2ytzBvaQ58IMPBmH16tXw9nJF0SKekDjo/IUIhL2KQcuW72DmzB9imwjJPskgpEOGDFbDT7i6xqBEMW+4uQLnL0XgRUgUmjZtrI5z3rx5rV1USuWE03LRtnjxIkRHR6HUGz6QePfilQg8eRqJBg3qYcaMmWreLrJf0otZ8lDnzp2tJp8uXdwX0rfi8vUoPHgYjpo1q2HGjFkoW7asyftOy4Eiu/zZAZ7+qe8oEPEyAkvqLneqgSIZIKXhh1pmg168eHFsb7v8+fOraQty585tgdKStUhALMf5/PnzKl9OajalxlMmuyTH8eTJEzUv2+nTkqAfqQau7dKli6rVJsf63V+6dKlK84iIiFAXsh06dEDp0qVTtc+0CpA67uioWYC0rN4yBkiUMAdJFjnZySzezvQBISIibaVlgNR+e2fNAqQV9X8yqcxy3pR5Ve/du6cm8p4xY4aanD0pU6dOxQ8//KDyjbNkyYI2bdqo/GJrDaFgkzlItsbcHCQiIiJnHZF86NChauaKI0eOqACpUaNGSQ6GvGzZMjWYs2x/9uxZNe2W7EMme7cWBkhEREQOSiVY6zRY4GJyorsMjdGjRw/VCzw4OBi+vr5YsGBBotvv27dP9fyWQZ3z5cuHhg0bqqZM6aVuLQyQiIiIHJROox5suv8PkAyn35JkdkOSqyWDOTdo0CDecDtyW+ZRTUz16tXVY/QBkcybumnTJjRt2hTWwgDJCOaOg0RERORIgoKC4k3BJTlChh49eqRydrNnzx5vvdyWfKTESM3R2LFj1byqMgyKzLMq4wJas4nN7qYasVYOkiz6pDciIiJ7oG8i02I/4ubNm/GStGXGCS3s3LkT48ePx6xZs9TsFpcuXcKQIUPw3//+F//5z39gDQyQiIiIHJRWo2DH/P8+jJl2S3qgyVyp9+/fj7debic13p8EQTJMRq9evdTtUqVKqTHH+vTpgy+//NIqcxqyiY2IiIg04+npiQoVKmD79u2x62SCeLldrVq1RB8TFhaWIAjST0hvrdGIWINERETkoLRuYjOWdPGXgZArVqyoxj6SMY6kRkh6tQkZPFcGV9XnMMn8lNLzTaYV0zexSa2SrNcHSmmNAZKJA0USERFR8tq1a4eHDx+qOVQlMVumZNmyZUts4rYMBhm3xmjEiBFqLlL5V2adyJo1qwqOvvrqK1gLR9K2sdFPiYjIsaXlSNrNf+8JD7/Uj6QdGRqBXxvOd6rzH2uQiIiIHJS1mtgcAZO0iYiIiAywBomIiMhBsQbJfAyQjMAkbSIiskcMkMzHJjYjyCjaZ86cwcGDB61dFCIiIkoDrEEiIiJyUKxBMh8DJCIiIgcl4/jEIPXBjQ7Oh01sRERERAZYg0REROSg2MRmPgZIREREDooBkvnYxGYE6eJfvHhxVKpUydpFISIiojTAAMkI7OZPRET2XIOkxeJs2MRGRETkoNjEZj7WIBEREREZYA0SERGRg9LpXNSixX6cDWuQiIiIiAywBomIiMhBySjaWoykHaPBPuwNAyQiIiIHxSRt87GJjYiIiMgAa5CMHChSlujoaGsXhYiIyGhM0jYfa5CMwIEiiYjIHnGgSPMxQCIiIiIywCY2IiIiB8UmNvMxQCIiInJQOo2ax3ROGCCxiY2IiIjIAGuQiIiIHJRO1f5osx9nwwCJiIjIQckI2PKfFvtxNmxiIyIiIjLAGiQiIiIHxV5s5mMNEhEREZEB1iARERE5KOni78LJas3CAImIiMhBSQ82TXqx6eB02MRmBJmotnjx4qhUqZK1i0JERERpgAGSEThZLRER2XOSthaLs2ETGxERkYNiLzbzsQaJiIiIyABrkIiIiBwUe7GZjwESERGRg2IvNvOxiY2IiIjIAGuQiIiIHLoGSYskbTgdBkhEREQOir3YzMcmNiIiIiIDrEEiIiJyUNIypkXrmA7OhwESERGRg2ITm/nYxEZERERkgDVIREREjoptbGZjDZIV6HQ6tZBj43F2DjzOzoPH2bkwQEojjx8/xjfffINixQrB09NDLUWLFsTEiRPx8OFDaxePNPL8+XPMmDEDpUq9AS8vT3h4uKNAgTwYO3Ys7t69a+3ikUZevnyJOXPmoEKFsvD29oK7uzvy5AnEl19+iRs3bli7eKSRV69eYdGiRahatVLscQ4MzIZhw4bh0qVLsAv/n4OU2gVOmIPkomNIbLQXL14gffr06iQYEBBg9ONWr16Nrl07IyoqAu++7YuqFbzg4gIcOBqOXzaEwcXFAwsWLESHDh0sWn6yrK1bt+K999ogLCwMLZv4oXZVb7i6AUdPhGP5ulBERrpg5sxZ6N27t7WLSqmwd+9etGr1Dp48eYZmb/mhQS0fuLkDp89FYOnqMLwMjcakSZMwdOhQuMgXnezSkSNH0Lx5U9y5cx+N6vqjcV1veHq64PylSCz5JRTPnkdhxIgRGDNmjMnH2dxziTnPkX/hl3D19U71/mLCXuNqj68sWmZbY5M5SLt378bkyZNx+PBhddW9du1atGzZMlX73LlzJ+rWrZtgvew/R44csJR169ahbdu2aNPcD1O+yoasmd1i7+vbHZg0KhrDRj1Fx44d1dWJbEv2Z/v27Wje/G28VccbsyfnRWCO+F+tSSOj8cX4x+jTp4/6Me3Vq5fVykrmO3DgABo2bIAq5dyxYGpe5A3yiHf/1yNiMO67J6qGISYmBsOHD7daWcl8p0+fRr16dVAkfwx2/JwXhQt4xrt//BeZMSX4GUb+97+IiorC+PHjrVZWcrImttDQUJQpUwYzZ87UfN/nz59XQZF+yZYtGyxFahJ69OiGFk388OOsLPGCI73Mmdwwf1pmtG3hj549eyAkJMRi5SHLkB/Ibt06o3Y1b6xZkCNBcCQypHfDzK+zok+X9Bg4cADu379vlbKS+aSyvXv3zihT3A2//ZQjQXAk/P1c8fWILPh0UEZ8+umnuHz5slXKSqnTq1cPBOWMxu+rciQIjoSPjyu+/CgTvh6RGRMmTMDRo0dhq7RoXtOZOVSAnMPz5csHb29vVKlSRV1gJOXNN99UF4+GS7NmzWAtNhkgNWnSBOPGjUOrVq0SvT88PFxdoeXKlQt+fn7qjZcaImNIQCQ1RvrF1dVyb8Hy5cvx/PkLTBiZAa6uSX+45L7xIzIiNDQMP/30k8XKQ5axYcMG3L59D5NHZoKHR9LHWb7sX32eGa6uMViwYEGalpFS788//8TZsxfx1RcZ1QkyOSM+yoT0Ae6YPXt2mpWPtGta+/vvgxg9PAMC0iW8qI3ro74ZkTvQyyIX85rR5w9psZhg5cqVqpl51KhR6j2VSo9GjRrhwYMHiW6/Zs2aeJUXp06dgpubm1VbVWwyQErJoEGDsH//fqxYsQInTpxQb2Djxo1x8eLFFB9btmxZ5MyZE2+99Rb++usvi5bzxx8X4K03/ZA/T8IrTUNBudxVPoM8huzLjz8uRNUKfihTwivFbTNldEO7FnKc56dJ2Ug7P/74I4oV9kGdaj4pbuvr64pu7/H7bI8WL16MwBxeaN7QL8Vt3d1d0KuTH5Yt+wmRkZFpUj57MWXKFJVv2aNHDxQvXhzBwcHw9fVN8uIwU6ZM8Sov/vjjD7U9AyQTSA+RhQsX4ueff0atWrVQsGBBVZtUs2ZNtT4pEhTJAZKEaVmCgoJUlZ5EtkmRmipJdIu7mOLmzesoXcL4NK9Sxd1x8yZ7wNibGzeuoYwJx7lMcU/cvHnbomUi7anvc3E3oxNyy5T0woMHjxEREWHxspF2bt68iRJF3VXwY4zSxb3w6lU4njx5Alsk3bC0WoThOVHOk4bkMy85xA0aNIhdJ601clsqN4wxf/58tG/fXrUSWYtNJmkn5+TJk4iOjkaRIkXirZeDlDlzZvW3v79/7PrOnTurwKho0aJq0atevbrKD/juu++wZMmSRJ9L2palh4K5JOk6Jtr47aNjdHB3T75Kl2yPHOfoaOM7g0bHyGN4nO3zOBu/vf4zYclmfNKe+t2OMX57/WdCHucMA0UGBQXFWy1NaKNHj4637tGjR+o8nT179njr5fa5c+dSfCrJVZImNgmSrMlGj2jy449Iu6REp/JvXPrA6NixY7HrkuuOWLlyZdVlNymff/65akPVk2jZ8MORnGLFSmD3fuNyo8TufZEoWrS40duTbXjjjZLY9dd5xMToks0109u573W8YJ3sQ7FixfHzyr2IjNQlm2umt/Ov1yhUKJ/tnjgpUcWKFcPUzWvxMjRGJd2nZNf+MGTLlhkZMmSAs9SwBcQ5r3p5pZxaYCoJjEqVKqXO0dZkd5c25cqVU5GpJHoVKlQo3qLvrh93XXK91CSQkqa3pMiBlw9C3MUUffr0w6FjYTh0LGEVpKETp8Ox/2AY+vbtb9JzkPX16dMXF6+8wvY9YSlue+1mJDZte4m+fQekSdlIOzJEw70H4Vi7+WWK2z58FIWff5XjPDBNykbaef/999VYVktXp9yjWIKoxavC0KtX3wQX7I7aiy3A4JyYWICUJUsW9X4Y9taV2ykNqyO92CW/uGfPnrA2V1utJZLgRV8TdPXqVfW35B9J01qnTp3QtWtXlfUu90l1nDSHbdy4Mcl9Tp06FevXr1ejn0rV3YcffogdO3Zg4MCUf8Ckh4IkmVWqVMmk19G0aVMULJgPAz95ihchMcl+yQYMf4a8eXOjRYsWJj0HWV+NGjVQvnwZDP7yqToxJuX16xj0+ugRMmfOqNrWyb6ULFlSjY3zydinuHUn6YRcqWHqPewhPD29VYIq2Ze8efOiVasWGDX5GS5eSTp/TGqMB372EK/Dgb59+8Km6TRYTODp6YkKFSqo8eH0ZFwwuV2tWrVkHyv5xZIyI+kx1maTAdKhQ4dUTZEsQpq55O+RI0eq25KMLQHSxx9/rJoqZBDJgwcPIk+ePEnuU5LGZHuptqtTpw6OHz+Obdu2oX79+imWR4KoM2fOqOcwhUTQa9duwLWbbqjf6gF27HkVby4f+XvXvld4690HOH/ZRW3L6nj7I0m7K1f+gmchvqjV4i42bQ9VP55xj/P+Q6/QsN097D8cgTVr1ls18ZDMt3jxUri4ZUHNd+5i7aaXiIqKf+Y4cuI1mnW+i83bX2Hlyp9j8yLJvsyePReZMudB7ZZ3sWJdCCIi4h/nU+fC0fr9+6qW6ccfFyd77nFWQ4cOxdy5c1Xvz7Nnz6J///6qdkh/0SDncEljSax5Tc7ptvDd4VQjaTA8vNRYdejwHk6dOosihbxRubw7pLLy4NFonLv4Cm+8UQTLlq1UQxCQ/ZKk//bt2+LQoaPIn8cbNat4wM3NBUdPRuH46TBVm7hkybIUr6DItt26dQsdO7bDnj371Bg4b1b3VD2eTp+LwsFjYQgKCsSCBT/G68FD9kfmyOzSuSO2/r4N2bN6oX4tT3h5yVQj0dh3MBTZs2dBcPBcs2Z5SMupRoJmj4KrjwZTjbx6jZt9x5hU5u+//17NinHv3j11fps+fboat1BIL3IZRFLmuos7kLPkgP3+++9qKB5rY4CURh9qeZtlCpV58+biypV/x2vKn78QevbsFTuCKNk/Oc7//POPGiDw4sVziI6OQp48+dGjx/to2LAhezQ5EBkiRCasPX36BCIjI5ArVx507dpNjfzLmmDHmnZEekIfP34EEeHhyJEzFzp27KQCI2lKMoezBEjWGMw1sSnFzMUAyQiSgySLJIdfuHDBpj8gRERk29I0QArWMEDqZ9sBkiSM586dWzXjdevWzaRe54nh5awRzM1BIiIisi4XDRfbdvv2bTXTxi+//IICBQqoqU1WrVpl9mCtDJCIiIjI7mXJkgUfffSR6vUuqQ7S633AgAEIDAzE4MGDVecsUzBAIiIiclRadPHXaTQadxoqX7686iUnNUoydJDMASdDD8gUZZJXZgwGSEYwdxwkIiIiq3KyACkyMlI1sck4hDKm1datW1VvOhmkUsZBlHXGToDLrhZG5iDJok96IyIiItvywQcfYPny5ao3cZcuXTBp0iQ1wKuejD/3zTffqCY3YzBAIiIiclQyRcj/TxOS6v3YOOlMNWPGDLz77rtJzhEneUoyHIAxGCARERE5KBnIR4vBfHR20MQWd2qTpMgYZTKbhjGYg0RERER2b8KECSoZ25Csmzhxosn7Y4BkBCZpExGRXXKiJO3Zs2erqUoMlShRQo2GbioGSEbgQJFERGTXOUhaLDZO5nzLmTNngvVZs2bF3bt3Td4fAyQiIiKye0FBQfjrr78SrJd1xvZci4tJ2kRERA7KRffvosV+bF3v3r3x4YcfqrGQ6tWrF5u4/cknn+Djjz82eX8MkIiIiByVVvlDOti84cOH4/Hjx2p6Ef38a97e3vj000/VqNqmYoBEREREds/FxUX1VvvPf/6Ds2fPwsfHB4ULF05yTKSUMEAyshebLNHR0dYuChERkfGcaKBIPX9/f016nTNAMgKnGiEiIrJ9hw4dwqpVq3Djxo3YZja9NWvWmLQv9mIjIiJyVE40DtKKFStQvXp11by2du1alax9+vRp7Nixw6zKDU1qkDZt2pRgXUBAgBpcMVOmTFo8BREREZnKiZK0x48fj++++061+KRLlw7Tpk1D/vz50bdv30THR0qTAOn777/HP//8o7rVySy6O3fuRNmyZXHz5k18+eWX6Nq1qxZPQ0RERJSoy5cvo1mzZupvT09PhIaGqsTtjz76SMUnY8aMQZoHSNLOd+7cOTVapXj48CE6duyogqaaNWsyQCIiIrIGJ6pBypgxI0JCQtTfuXLlwqlTp1CqVCk8e/YMYWFhJu9PkwDp1q1b8ZrSpJBSe5QhQwZ4eHho8RRERERkKifqxVa7dm388ccfKihq27YthgwZovKPZF39+vWtEyBJQWrUqIFWrVqp2+vXr1frpHqraNGisHfs5k9ERGTbJN3n9evX6m9J75EKmn379qF169YYMWKEyftz0UnSkAZkIlcpiOxOssgrV64MR6Pv5v/8+XOVhE5ERGSL5xL9c+SZNA6uPt6p3l/Mq9e48ckImz3/RUVFYdmyZWjUqBGyZ8+uyT416+b/6NEjuLq6qnlQ8uTJo7rZERERkRU5STd/d3d39OvXL7YGyWYCpGHDhqnxB6QZSri5uaF79+5a7JqIiIgoRdJydezYMWhFkxwkmS336NGjKFeunLotvdm0jOKIiIiIkiOT1A4dOlR1EqtQoQL8/Pzi3V+6dGmkeYAkiVAxMTFqvAHx5MkT1dxGRERE1iNnZRcNmsdcYPvat2+v/h08eHDsOolLJDda/jW1o5UmAZIUpl27dioP6b///S9WrlypMsiJiIiI0sLVq1c13Z9m3fwrVqyomtqkJkkmipNpRoiIiMiKnGgcpLx589pWgCRVV5J7dObMGRQrVkybUhERERGZYPHixcneb+qsHqkOkKRdr0yZMmrG3BIlSsARcaBIIiKyS0401ciQIUPi3Y6MjFRTjMi8bL6+vmkfIAkJjqQWqUiRIqoQ+oSoAwcOwBHIzMCy6AfeIiIisgtOFCA9ffo0wbqLFy+if//+GD58uMn70yRA+vXXX7XYDREREZFmChcujK+//hqdO3fGuXPn0j5A0joxioiIiFJPuvhr0s1fB7slo2zfuXPH9Mel9oklL0eislOnTsUua9euTe1uiYiIKLWcqIltw4YN8W5Lus/du3fVJLY1atSwbIB05coVnDx5Ml4wJO17ERER8PLywhtvvIFSpUqZXAgiIiKi1GjZsmW825ILLTN71KtXD99++63lAiRpv1u+fLl6QknEDg0NRbNmzTBy5EgVFEk7n8zBRkRERDbCiWqQYmJiNN2f0fOB/PLLL5g+fTpevnyp2vIGDRqE33//HQcPHlQ5SAyOiIiIbDMHSYvF2RgdIH300UdqDAFvb2/4+/tj2rRp+Ouvv/Dnn3+q8Y+2bNli2ZISERERJaF169aYOHFigvWTJk1SM35YLECaMGEC0qVLF2+dzJYrYx3J4EwyF1vHjh3x8OFDkwtBREREFpxqRIvFxu3evRtNmzZNsL5JkybqPosFSEmRnCQJkGSqkfDwcE43QkREZGs5SFosNk5SgGTUbEMeHh5qoOc0D5D0cuXKhdWrV6c4FwoRERGR1qTD2MqVKxOsX7FiBYoXL27y/jQZKDIu6dnmaDgXGxER2SNnGijyP//5D959911cvnxZde0X27dvVz3wf/75Z+sHSI6Ic7EREZFdcqJu/s2bN8e6deswfvx41fPex8cHpUuXxrZt21CnTh2T98cAiYiIiBxCs2bNNGvJYoBERETkqLQaw0gHmyfjMspgkVWqVIm3/p9//lFjNVasWNE6SdpERERE1iKpMDdv3kyw/vbt2+o+U7EGiYiIyFE5UQ7SmTNnUL58+QTry5Urp+4zFWuQiIiIHJUTjYPk5eWF+/fvJ1h/9+5duLubXh/EAImIiIg0N3PmTOTLl09NUSZ5QTLzRnKePXummsJy5sypgp0iRYpg06ZNRj9fw4YN8fnnn+P58+fx9vnFF1/grbfeMrn8bGIjIiJyUNYaB2nlypUYOnQogoODVXA0depUNGrUCOfPn0e2bNkSbB8REaGCGLlPuujL4NPXr19HhgwZjH7Ob775BrVr10bevHlVs5o4duwYsmfPjiVLlpj2AhggERERkdamTJmC3r17o0ePHuq2BEobN27EggUL8NlnnyXYXtY/efIE+/btU1ODCKl9MoUEVSdOnMDSpUtx/PhxNQ6SPH+HDh1i92kKNrERERGRZiIiInD48GE0aNAgdp2rq6u6vX///kQfs2HDBlSrVk01sUmNT8mSJdWAj6bOYOHn54eaNWuqQSOlNklqoDZv3qz2byrWIBERETkqjXuxvTCY9FVyhWSJ69GjRyqwkUAnLrl97ty5RHd/5coV7NixA506dVJ5R5cuXcKAAQMQGRmJUaNGGVVE2UerVq1w8uRJuLi4QKfTqX/1TA22WINERETk4DlIWiwiKChITbmlXyZMmAAtyACPkn80Z84cVKhQAe3atcOXX36pmuaMNWTIEOTPnx8PHjyAr68vTp06hV27dqkBInfu3GlymViDREREREa5efMmAgICYm8b1h6JLFmyqJGrDbvcy+0cOXIkul/puSZ5QvI4vTfeeAP37t1TTXaenp4plk2a76QWSp5fmvRkX9LcJkHc4MGDcfToUZNeK2uQiIiIHJmGYyAFBATEWxILkCSYkVqg7du3x6shktuSZ5SYGjVqqGY12U7vwoULKnAyJjjSN6GlS5dO/S1B0p07d9Tf0qtNes+ZigFSGpEDJxn8777bEmXKFEeZ0sXRsuU7+PXXX01uFyXbJV9umTm6Xbv3ULZsCZQu9Qbefrup6rYqbenkGCS3Yc+ePejcuRPKlSuFUiWLoXHjhqr3THh4uLWLRxoeZxm7R3pClS9fCiVLFkWDBnVVj6uwsDDYBSsNFDl06FDMnTsXP/74I86ePYv+/fsjNDQ0tldb165d1ZhFenK/9GKTZjIJjOR8KUnapkwRIond0ntNyNACkyZNwl9//YWxY8eiQIECpr0ABkhpQ7L5ixYtiLfffhtXL/2OauVvoXrFW7h1fTveeecdFCqUX02mR/ZNhrIvVaq4Gsvj9InfUK3cLdSuchdPH+5C27ZtkS9fEP78809rF5NSSRJBK1Ysp3rIHPx7LaqWuYk3q95DxMv96Ny5M4KCAtWFD9k3qX2oXbuGOtHu3LEClUreQL2qD+AadQi9evVErlw5sHz5cmsX02a1a9dOjUs0cuRIlC1bVo1HtGXLltjE7Rs3bqgRrvUkt2nr1q1qwtnSpUurJjEJlhIbEiApI0aMiK2BkqDo6tWrqFWrlkr6nj59usmvwUUnITIZRbL3JSlNRumM2wabnEOHDuHNN2vjjSLAt+MyoGJZz3hZ9YePh2P4yOc4fioa27f/mWT1I9l+cFSzZjUEZo/E9xMyokYV73jH+eTZcAwf/RS794dj48ZNZo3qStZ37do1VKtWGf4+IZj5dWbUr+UT7zifvxSBT8c9xsY/wrBq1Sq0bt3aquUl80jeS/XqVRAZfh8zv86EJvX84Ob2v+N89UYk/vP1YyxfG4L58+fj/ffft/i5xFT65yj8yXi4eXmnen/R4a9xcdIXFi2zJUitVMaMGeN9T+22Bmn37t1q/ILAwED1gtatW6fJfqXaWzLipS1S2kxlACqpJrWkqKgotG7dEsWLApt/zopK5bwSHKQKZbywcUUWlCvlhjZtWqlkNLIvco3Rrl0bFRztXJcdNavGP2mKUm944defsqN+LW+8914bhISEWK28ZL4uXTrC1ysEu9fnRIPavgmOc9FCnlg9PwfaNPdHly6dVG8asj+9e/fE67D72L0uJ95+yz9ecCTy5/HAkpnZ0btzevTt20fVKpJtypQpk1nBkU0GSNJGWaZMGTWHi5bee+89lSAm0b4ka0nVaNGiRWFJMjDVjRu3Mf3rDPDzTfqt9vFxxfSJGXDnzn2sXbvWomUi7Un30VOnzmLaVxmRIf3/emAY8vBwwaxJmfHiRYjKVSH7Ij1g9u7dj0kjMyJ71qQ7AMvJ9PvxWaDTRanfG7Ivly9fxsaNmzH20/TIG5T06Mty0p0yJgv8/Vwxe/Zs2CwnmqxWazYXIDVp0gTjxo1Tgz0lVRM0bNgwNaS4jJip2odTGN9A2j1lLARph5SRPKX2SJqyJGvekubNm4PKFXxQpmTCLH9DxYt6olY1X8yZ84NFy0Tamzt3Dt4o4oPa1VKuxg7K5Y7mDf0wdy6Ps72ZN28ecuX0UscvJZkzuaFdCx5ne7Rw4UKkD3BH+xb/9oZKjq+vK7q388P8+XNstrON1uMgORObC5BSMmjQIDXWwYoVK9ScK5L82rhxY1y8eDHZmhwZKEoy2iWwkhmCJch69epVss8lwZi048ZdTHHhwlnUrGL8/C/Vq3jg4kXTuyKSdclxrlHZw+hq3BpVvHDx4iWLl4u0deHCOVSr6AF3d+OOc80q3rh69aZqaif7IT2oKpTxVMGPMWpW8cHjx8/w9OlTi5eN0pZdDRQpWe8S3cu/kqMkJNCRGiJZL10CEyPtw3v37oW3t7dqwpJh0GUI88ePH6vHJUUGlxozZozZ5ZVseldX49s+ZdOYGCcM0+2cHGdTmrhdXXmcneM4/7tx3HFdyPap320Tv8/6xznDVCPOxK5qkGR+FanGlBogf3//2EWaz6TdWMRd369fvzg/bC4q76Ny5cpo2rSpmmlYxmdIrhZJxmiQjH39IiOImiJv3vw4ctz4sW+OnoxC3rymzV5M1pcvXwEcOWF8LcGRExHImzfIomUi7cn3+ejJaKOD2yMnXiNnzmxGD3JHtkE68pw4E4XISGOPczj8/X1VTymbxBwk56hBevnypRo6XMYVijscuZCASMhYC3r6rogyEqc0rUmXx7hDmEvvo1u3bqFw4cKJPl9ik/CZokePXujWbQ8uXYlEoQLJN7VdvxmJrdtDMWdOL7Ofj6yjR4+eeOed9Th07DUqlk0+D+nR42j88msovvqqd5qVj7QhA9xJjfOOva9UD7bkvAyNwZKfwzDoA+MHuSPb0L17d3UBvW7LS7RtnnwekgRR85aGokuX99U0GeRY7KoGqVy5cqoGSbrOFipUKN6in98l7jqZ+E5IMrYM+iUBVtx2ZpmrJXfu3Ck+r/SoK168OCpVqmRyz7ksWTJi+KhniIpKOvyOjtZh+MhnSJ8+AB07djTpOcj6pEZSBoEcPuYZwsOTPs4SkA8f8xiurh6xo8mS/ZA5nUqXLoHPxj1VAVByx3nEhMcIDYtGnz590rSMlHqlSpVSA0SOnPgMT54mn3g9ftoT3HsQrlI2bBWTtB0oQJIgRmqB9DVBMhKm/C15R9K01qlTJzVE+Zo1a9R9Mgy85ArJsORJkaAjc+bM6qQkA/rJWEvDhw9Xg3v5+PikWCYZ6lweJyN8mkJynn76aTm27XyF9j0f4dbthM0wt+9GoXPfR9j0xyssWbJUzUBM9kVqM+U4HzoWiead7+PK9YTNqg8eRaHH4If46WcZWG6B+jySfZFm+h9//AmXrrmg4Xt3ce5iwjHL5IT6wRcPMWP+M0ybNl0115D9mTdvIR4/80a91vdw4kzCqWNehETj868eYey3T1Sva5niwmaxic1sNjeStnTZr1u3boL13bp1w6JFi9R8VvKBXLx4MW7fvq0mpKtatapKppbIPynnzp3DBx98oOZlkZOT1O7IfowJkFI7+unmzZvRoUM7hIS8RLOGvqhcXkbTBg4ejcBvW8NUULR06XI1QCbZLwm8ZWDQx4+folFdf9Sq6glpCT52KhKrfwuFu7sH5s1bwFpCOyej47ds2Ry3b99DvZr+qF/LS41xdepcBFZtCEVMjCumT5+Bvn37WruolApyUdy8eVNcuXIdNav4odGb3vD2dlGB8Yr1YXj9OgYTJnytOgqZOhBhWo6kXfRD7UbSPj/V/kbSdqgAyZal5kMtIydLkvi8ecG4fPnfUVcLFMiPnj37qvmbnOUD5+hkAsuVK1eq8aykGVeahPPkCUKPHr1VkC+jupL9kyFAVq9ejdmzZ+H06dPqwi1XrkB07fq+qpnWN++TfZPjKsPE/PDD9zh+/BgiIiKRPXs2dOrUDb169VK5reZI0wBpiIYB0jQGSJRIDpIscrKTk54zfUCIiEhbaRkgFRusXYB0brpzBUg2l4Nki8zNQSIiIiL7ZFfd/ImIiMgEHCjSbAyQiIiIHJRWXfRdnDBAYhObEcwdB4mIiIjsEwMkIzAHiYiI7BLHQTIbAyQiIiIiA8xBIiIiclRM0jYbAyQiIiIHJWN8u2i0H2fDJjYjMEmbiIjIuTBAMgKTtImIyC4xSdtsbGIjIiJyUBwHyXysQSIiIiIywBokIiIiR8VebGZjgEREROTInDC40QKb2IzAXmxERETOhQGSEdiLjYiI7DlJW4vF2bCJjYiIyFExB8lsrEEiIiIiMsAaJCIiIgfFcZDMxxokIiIiIgOsQSIiInJUzEEyG2uQjMBu/kREZI/Yi818DJCMwG7+REREzoVNbERERI6KTWxmY4BERETkqBggmY1NbEREREQGWINERETkoDgOkvkYIBERETkqNrGZjU1sRERERAZYg0REROSgXHQ6tWixH2fDGiQjcKBIIiKy6yY2LRYnwwDJCBwokoiIyLmwiY2IiMhBsReb+RggEREROSr2YjMbm9iIiIiIDLAGiYiIyEGxic18rEEiIiIiMsAaJCIiIkfFHCSzsQaJiIjIwZvYtFjMGUMwX7588Pb2RpUqVXDgwIEkt120aBFcXFziLfI4a2KARERERJpauXIlhg4dilGjRuHIkSMoU6YMGjVqhAcPHiT5mICAANy9ezd2uX79OqyJARIREZGjstJI2lOmTEHv3r3Ro0cPNRNFcHAwfH19sWDBgiQfI7VGOXLkiF2yZ88Oa2KARERE5MDSunktIiIChw8fRoMGDWLXubq6qtv79+9P8nEvX75E3rx5ERQUhBYtWuD06dOwJgZIRuBcbERERMCLFy/iLeHh4Qm2efToEaKjoxPUAMnte/fuJbrfokWLqtql9evX46effkJMTAyqV6+OW7duwVoYIBmBc7EREZFd0um0WwBVu5M+ffrYZcKECZoUs1q1aujatSvKli2LOnXqYM2aNciaNStmz54Na2E3fyIiIgel9UCRN2/eVMnUel5eXgm2zZIlC9zc3HD//v146+W25BYZw8PDA+XKlcOlS5dgLaxBIiIiIqMEBATEWxILkDw9PVGhQgVs3749dp00mcltqSkyhjTRnTx5Ejlz5oS1sAaJiIjIUVlpoMihQ4eiW7duqFixIipXroypU6ciNDRU9WoT0pyWK1eu2Ca6sWPHomrVqihUqBCePXuGyZMnq27+vXr1grUwQCIiInJQLjH/LlrsxxTt2rXDw4cPMXLkSJWYLblFW7ZsiU3cvnHjhurZpvf06VM1LIBsmzFjRlUDtW/fPtVBylpcdLr/z7yiFEnGviSlPX/+PF4bLBERkS2dS/TPUanVOLh7pH5E6qjI1zi4doRTnf9Yg0REROSoOBeb2ZikTURERGSANUhEREQOSutu/s6EARIREZGjijPIY6r342TYxEZERERkgDVIREREDopNbOZjgEREROSo2IvNbGxiIyIiIjLAGqQ0JJPuLVy4EJcvX1a3CxQogO7du6NIkSLWLhppSEaIXbBgAc6fP6/mH8qTJ48acr9kyZLWLhpp6O7du+o4nz59GlFRUWrahC5duqB8+fLWLhppSEaDXrRoEY4dO4aIiAg12WrHjh3VtBguLi6wdWxiMx9H0k6D0U9v376N3r17YvPmrciYwQNlSnqo9SdOR+LJ00g0bNgAc+fOVydSsu8f0n79+mDdug3w83VF+dJecHMDTp2LxIOHEahTpybmzJnPgNjOyfd/4MD+WLlyFTw9XVCpjBfcPYCzF6Jw5144qlSpqI5z6dKlrV1USoWwsDAMGTIEixf/CBeXGFQu5w0vT+DClWjcuPUaZcuWwg8/zFGBki2PpF216VjNRtL+e9NIjqRN2pHJ9mrWrAYX3RPM+S4L2r7jBx+ff1s2X7+OwerfQjFm8h5UrVoJe/fuV7VKZH/u37+PWrWq4/mzW5gxIRM6tk4Hf79/j3NEhA7rt4Ri9KRDqF69Cnbt2osSJUpYu8hkBplE8803a+H6tfOYPDIjur4XgAzp3dR9UVE6bNwWitGTT6NmzerYtm2HmqST7DM4euutejh27BDGfpIB73dIj8yZ/j3OMTE6bP0zDP+dchl169bBb79tQv369a1dZHKWHKTdu3ejefPmCAwMVFWY69atS/U+pSlL9mW4WPJEJZVz777bAu6uT7Hr12zo2i5dbHAkvL1d0alNOuz+NRt8vV+gZcu3VZMM2Z+OHdsh5Pkt7N6QA326po8NjoTUMrR9xx97fs2BwOzhePvtJqqqnuxPr17v48b189i1LicG984YGxwJd3cXtGjsjz0bAlGqGNC8eVOEhIRYtbxkng8++ADHjx/G9l8CMXxgptjgSLi6uqBJfT/sWJ0Ttat64t13W+LBgwew9SY2LRZnY5MBUmhoKMqUKYOZM2dqts9p06apnAH9cvPmTWTKlAlt27aFpezcuRNHjhzHD99kQGCOpCvrcmRzx5wpGXHy5Fls27bNYuUhyzh69Ch27NiFaV9lRMF8/zafJiZTRjcsnpkZ167dxNq1a9O0jJR6V65cwZo16zDxPxlRsphXkttJcLx0VlY8evQES5cuTdMyUupJsLNkyWKM+jiDalZLilzg/jQzGyIiXqlcNJvvxabF4mRsMkBq0qQJxo0bh1atWiV6f3h4OIYNG6aSIv38/FClShUVjCRH2mIluU6/HDp0CE+fPkWPHj0s9CqA4OAfULSwN96skXL7b/XKXihV3Ac//KBdUEhpY/bs2ciV0wvvNPZLcVs5sdau5ocffvg+TcpG2pkzZw7SB7ijQ8t0KW6bJ7cH3n7Ln8fZDklHGjc3Hbq3SznPRmqW2rXwQ3Dw96rFgByLTQZIKRk0aBD279+PFStW4MSJE6oWqHHjxrh48aLR+5g/fz4aNGiAvHnzJrmNBGKS6BZ3MYW0Xzeu52lUTwfZplE9Txw7dtik5yDrO3rkIN5601M1sRijSX0vHD9+3OLlIm0dO3YUb1b3hK+vcT+bTRv44OTJM4iOjrZ42Ug70lutannveM1qyWlS3xfXr99W+Wm2iE1sThQgSRdqifB//vln1KpVCwULFlS1STVr1lTrjXHnzh1s3rwZvXr1Sna7CRMmqJon/RIUFGRSWSXA8vIyvhuot5cLwsOZm2JvwiNew8vT+OMsnwkeZ/sTHv7a5O+z1CrIEABkP/793YZJx1n/OHIsdhcgnTx5Ul2RSVdpf3//2GXXrl2x4wvFXd+vX78E+/jxxx+RIUMGtGzZMtnn+vzzz1WXRv0ieUumyJEjJy5eNv7H8cLlKGTPnt2k5yDry5EjFy5cNr6W4MLlSGTPntWiZSLt5cgRiAuXje9Ecf5SBNKn94eXKWdbsjpJwbh4JVr1VjP2++zh4Y6MGTPCJsnr0GpxMnbXzf/ly5dwc3PD4cOH1b9xSUCkryLVMxyvQa7oJKFOBnTz9PRM9rnkhy01P24dOnTBsGFDce9BlErETs6jx9FYtykM48Z1Nfv5yDo6duyMbt3+wKWrkSiUP+kkbREaFoNlq8Mw6INBaVY+0kaHDh3QosUKHDr2GhXLJp9XGBmpw8IVYejY8f00Kx9pd5x/+OEH7Nj7Cg1q+ya7rQRRc38KRevWrW03EOZUI85Tg1SuXDlVgyQ9DQoVKhRvkchfxF2XLVu2eI+XmiYZ0bpnz54WL6uMnuzh4YFx3z5LMYFv/HfP4OLibtGkcbKM9957D5kypceoiU9TPM7fzHyGl6Ex6NOnT5qVj7TRrFkz5MmTCyMnPUF0dPLHeeaCZ7j3IBz9+/dPs/KRNiRdo2TJNzD226dqDLPkLP45BBevvMKAAQPTrHzk5AGS1BJJLZC+Jujq1avqb8k/kqa1Tp06oWvXrlizZo2678CBAypfaOPGjUYlZ0uvN1OmfZDhBooXL45KlSqZ9DqkGW/q1OmYtyQEn499gvDwhF82+QL+Z8ITzFrwAt988y2yZMli0nOQ9Xl7e2PWrNlYtT4E/Yc/wqtXCZthZBDBidOfYtyUpxg9enSynQPINkmNdXDwXGzb/QpdBj1QgW5iNQoSHA0f+xgfffQRSpUqZZWykvmkw4yMkH3wWCRa97yHp88SNp/LhdCPq16g3/CH6N69mwqqbJVkSGmSpA3nY5NTjUiX/bp16yZaIyNz4kRGRqphABYvXqym8ZCgQoZ7HzNmTLI/SJJHlDNnTjUmUu/evdNsePjp06fjww8/RJbMHujewQdVynupL+GBo6+xaNkr3H8YgcmTJ6tkc7Jf8tns3bsX0vm7ols7X9Sq6qOmGjl2Mhzzlobh1p1wjBgxAmPHjrWLOZwocatXr0bnzh3h4R6DLm39UL+WLzw8XHD6XDjmLAnF1RuvMXjwYEyZMiVBGgDZj61bt6JNm3cRExOBjq180aiuH7y9XXD+YgTmLg3F+Uuv0K1bV8ydO0+1FNjqVCM16o+Gu7sGU41EvcZf20c71VQjNhkg2arUfKjPnTun2rUXLZqPFy9C1bp06fzQtWt3VQ3PqSccZzDB4OBgzJ8/B0+ePFfrfHy8VJ7SwIEDVRMx2T/psCHjIs2dG4z79x+pdZ6eHmjXrp1qbjFnfi6yPffu3cO8efMQHDwTt2/fU+vc3d3w7rvvquNcu3Ztsy52GCDZBwZIRjaxySK5TxcuXEjVB0Rqvx4/fqz+zpw5s8lXHmQfpGu3HGf5zEgNZ0odAsg+yfGV4yzfa/k+S3MrOR6ZAkqOs0wRJDMw+Pj4pGp/aRkg1aynXYC0d4dzBUh214vNGuTKXxb9By41JCDSJ5OT43J3d+eQDU5AmtAMO4KQ43F1dUXWrHY6NAd7sTlWkjYRERGRNbEGiYiIyEG56HRq0WI/zoY1SBbs5k9ERGRVMRouToYBkhEk/+jMmTM4ePCgtYtCREREaYBNbERERA6KTWzmY4BERETkqNiLzWxsYiMiIiIywADJCEzSJiIiuyRNY1otToYBkhGYpE1ERORcmINERETkoFx0/y5a7MfZMEAiIiJyVFo1j+mcL0JiExsRERGRAdYgEREROSiXmH8XLfbjbFiDZAT2YiMiIrvEXmxmY4BkBPZiIyIici5sYiMiInJUHEnbbAyQiIiIHBTnYjMfm9iIiIiIDLAGiYiIyFFxHCSzMUAiIiJyVBLXaNFFXwenwyY2I7CbPxERkXNhgGQEdvMnIiJ7TtLWYnE2DJCIiIiIDDAHiYiIyKHHQdIiSRtOhwESERGRo2IvNrOxiY2IiIjIAGuQiIiIHJV08XfRaD9OhjVIREREDsqavdhmzpyJfPnywdvbG1WqVMGBAweMetyKFSvg4uKCli1bwpoYIBEREZGmVq5ciaFDh2LUqFE4cuQIypQpg0aNGuHBgwfJPu7atWsYNmwYatWqBWtjgGQEDhRJRER2naStxWKCKVOmoHfv3ujRo4c6fwYHB8PX1xcLFixI8jHR0dHo1KkTxowZgwIFCsDaGCAZgQNFEhGRXdI4QHrx4kW8JTw8PMFTRkRE4PDhw2jQoEHsOldXV3V7//79SRZ17NixyJYtG3r27AlbwACJiIiIjBIUFIT06dPHLhMmTEiwzaNHj1RtUPbs2eOtl9v37t1LdL979+7F/PnzMXfuXNgK9mIjIiJyVBqPg3Tz5k0EBATErvby8kr1rkNCQtClSxcVHGXJkgW2ggESERGRo9K4m39AQEC8ACkxEuS4ubnh/v378dbL7Rw5ciTY/vLlyyo5u3nz5v97uph/n9Dd3R3nz59HwYIFkdbYxEZERESa8fT0RIUKFbB9+/Z4AY/crlatWoLtixUrhpMnT+LYsWOxyzvvvIO6deuqv6VZzxpYg0REROSgzB3DyJCp+5Au/t26dUPFihVRuXJlTJ06FaGhoapXm+jatSty5cqlcphknKSSJUvGe3yGDBnUv4br0xIDJCIiIkdlpbnY2rVrh4cPH2LkyJEqMbts2bLYsmVLbOL2jRs3VM82W+ai0znhDHRmki6NkrX//PnzFNtgiYiIrHUu0T9Hg8Ifwd0t9YnUUdHh2HbxO6c6/7EGiYiIyFHF6KQqRJv9OBnbrt8iIiIisgLWIBERETkqK+UgOQIGSERERA5LowAJzhcgsYnNCJysloiIyLkwQDICJ6slIiK7pPFktc6ETWxERESOSvU+Yy82c7AGiYiIiMgAa5CIiIgclS7m30WL/TgZBkhERESOit38zcYmNiIiIiIDrEEiIiJyVEzSNhsDJCIiIkfFJjazsYmNiIiIyABrkIiIiByVamHTogYJToc1SEREREQGWINERETkqJiDZDYGSERERI4qRgZ4jNFoP86FAVIaCgsLw5o1a3D58mV1u0CBAnj33Xfh5+dn7aKRhl6/fo3169fj/PnziImJQZ48edCmTRsEBARYu2ikocjISPz22284deoUoqKikCtXLnWcM2XKZO2ikYaio6OxefNmHDt2DBEREciRIwdat26N7NmzW7toZGEuOp0T1puZ6cWLF0ifPj2eP39u0skuNDQUo0aNwvz5c/D8eQiyZ/WCiwtw70E4AgL80aNHL4wdOxbp0qWzaPnJssLDwzFu3DgEB8/Eo0dPkT2bF9xcXdRx9vHxRteu3dX9PIHaNwmGJk2ahO+/n4a7dx8gW1YvuLu54P7DcHh4eKB9+46YMGGCOpGS/ZKLm2nTpmHq1G9x48ZtZMnsCS9PVzx4FKHSd9u2bYvx4ycgb968aXYuMec5GmTtCXdXz1TvLyomAtsezrdomW0Nk7QtTD5M9erVQXDwNPTs6IrT+3Lj2rFAXD0aiLN/50afrm6YP+971KlTE0+fPrV2cSkVtYNNmjTE5MkT0KFlDE7uDsKt47lx/WguXDmUBx/398aK5fNQo0ZV3Lt3z9rFpVTUGr37bkuMHDkCzRu8xtHteXD3RB7cPBqEW8fyYeTQdNi0cRmqVauMa9euWbu4lIpao65dO+Pjj4eibrUQ/LM5CPdP5cWNI0G4czwfJnyRAbt3rkHVqpVw5swZ2EUOkhaLk7G5AGn37t1o3rw5AgMD4eLignXr1mmy36VLl6JMmTLw9fVFzpw58f777+Px48ewtE6dOuDC+RPYtjobvhqRCQXyesTely/IA//9PBN2rMuO69fOot17bSxeHrKMvn17459//sKWFdkx5b9ZUKzw/67YcuV0x38+zoS/NubAi2c30KLF2+rqlOzP0KFDsWXLZmxYnBM/TMqO0sW9Yu/LlsUdn36QCQc2B8IND9G0aSPVJEP2Z8yYMVi+fAWWBefAgqnZUbGsd+x9mTK64aN+GXFwayCyZgxVx/nly5dWLS85SYAkzVESyMycOVOzff7111/o2rUrevbsidOnT+Pnn3/GgQMH0Lt3b1iStFlv3LgZM77OgHKl//dDaqhUcU/88E1G/LFtBw4ePGjRMpH2rl69iqVLl2PyqIyoWdUnye0KF/DE4pmZceDAYWzbti1Ny0ip9+DBA8yZMxtjhmdE43pJ5w0G5fLAqrnZcPbsBaxduzZNy0ipJ8HO1KlT8HH/DHjvnaTTHiQgXrMwG27evK0uwG2WTBGi1eJkbC5AatKkicrTaNWqVZJ5HsOGDVMJkZLcXKVKFezcuTPZfe7fvx/58uXD4MGDkT9/ftSsWRN9+/ZVQZIl/fDDDwjM4YVWzVJOwn67oS/yBHlpGhhS2pg9ezbSB7ijc5uUc8hqV/NGqeK+mDXr+zQpG2lnwYIFcHWNQa9O6VPctmxJL9Su6odZs2akSdlIOxLshIaGYUD3lI+ztAi8/ZY/Zs6cDltN59XpYjRbnI3NBUgpGTRokAp4VqxYgRMnTqhEucaNG+PixYtJPqZatWq4efMmNm3apD7E9+/fxy+//IKmTZsm+1wSjEmiW9zFFHv27ECLJl5wd3dJcVs3Nxe0auqlHkP2ZffuHWhS3wu+vil/naTZuM3b3tizZ3ealI20I8esbg1vZM7kZtT2bZr7Yu/e/WxOtTN79uxB1Qq+yJP7f+kQKR3nkyfPmHx+INtnVwHSjRs3sHDhQtVEVqtWLRQsWFDVJkmNkKxPSo0aNdRVQbt27eDp6al6l0h2f0q1NdITRbbTL0FBQSY3FwYEpBwc6QWkc1VXLmRfQkNfIn2A8V+lgAA5zq8sWibSXmhoCNKb8H2Wz4QER3KhRfZD/W6b0KFY/92Xx9kknUbNazrbrCGzJLsKkE6ePKl6FxQpUgT+/v6xy65du2LHFoq7vl+/fmqd9DIYMmQIRo4cicOHD2PLli2qh4n+/qR8/vnnqheafpFaKFNkzJgJt+9GG729bMsu4PYnU6YsJh7nKGTKlHL1PdmWjBnlOBt/krh1Jwre3l7w9v5fgi/ZvowZM5p8nEWGDBlgk9iLzTkGipTkOTc3NxXkyL9xSUCkT4zW04/VIDVBUos0fPhwdbt06dIqf0lqoSTfSXq1JcbLy0st5mrZsg2++eYrTPlvjKodSk5oWAx+2fAKAwexJ5u9admyNYYP/wv3HkQhR7bkv1KRkTos/eUVWr7bIc3KR9po2bIlundfh0tXI1Aof/LjysTE6LBoZZh6jDSrkv2QYyYtEoeOvY7Xey0pP64MQ6NGb6ke0uRY7KoGqVy5cqoGSXqTFCpUKN6iH5Qt7rps2bLFjlHj6hr/peoDLEsm1kkvudevYzBz/vMUt5296AVCXkar5HGyL926dYO7uwem/PAsxW0XrwrB3fvh6N+/f5qUjbTz3nvvqZq/r2ekPF7Zmk0vcfHKKwwYMDBNykbaadasGfLkyYUJ05+meH7YtjsMB46GYsCAQbBZkgOn1eJkXG2xlkhqgfQ1QdKFWv6W/CNpWuvUqZPqsi9Tdsh90hNNaog2btyY5D5lXCXZXnqVXblyRXX7lx5tlStXVuMtpURylYoXL45KlSqZ9Fqkp92wYcMxdvIzLFwWkuR2S38JwYjxz/Dhhx+aNSorWZdUrY8aNQbfBT/Hd8HPkvxRXbfpJQZ/8Rjdu3dHqVKl0ryclDo+Pj6YMGESFi5/gdGTHyd5nP/YFYr3P3yEli3fUfmRZF/k4nnSpG+xbvNLfPSfR6o2MDH7Dr5Cuz4PULduHRVU2Sw2sTnOVCPSZb9u3bqJXqUvWrRIjWQrzWKLFy/G7du3kSVLFlStWlUN7JXcSWfGjBkIDg5WQZWc0OrVq4eJEyeqIMaSw8NLkuaAAQNUV/AqFXzRp5svqlbwBlyAA0fCMefHUOw/GIYePXpg7ty5CZoOyT7I1+iLL77A119/jbKlfNGvm5/q0i+9E4+eDMfsH1/iz72haNu2DX76aanqLED2SY6x5CeWKOqDft380aC2r+qpeupcOGYvDsHWP1+iceNG+OWXNWx2sWNyQS29pgvm80K/rn5q7CsvLxecuxiBuT+F4NffX6JGjWrYsGGjyflHaTnVSH3/jnB30WCqEV0Etr9c5lRTjdhcgGTLzP1Qy1u8YcMGfP/9dGzbFr8bv0xDMnDgYDXuE3MV7N/WrVsxY8Y0bNq0JV4Ng0wxMmDAB2jfvn2C5l6yP9IxZPr0qVi/fgOio//X9FChQln1fe7SpQvc3e0qxZMS8c8//2DatKlqWJjIyH+TsUWpUsXRv/8gNSODOXmqaRkg1fNtr1mAtCNsBQMkStjEJovkP124cCFVHxDpPSe1WEIGr5SBK8nx3Lp1C5cuXVKfmTx58qBw4cLWLhJZwN27d9VvgtRsS230G2+8Ye0ikQU8fPgQZ8+eVVPHSL5riRIlUnVBywDJPjBAsrEPNRERObY0DZB82mkXIL1a6VTnP9YBExEROSpJMnfRoB5E53x1KUyGICIiIjLAGiQiIiJHpWp+NBjDSOd8NUgMkExM0iYiIrIXuhgddBo0semcMEBiE5sRBg4cqOZzO3jwoLWLQkRERGmANUhERESOShejURNbDJwNAyQiIiIHxSY287GJzQjmzsVGRERE9ok1SEbmIMkiA2TJnDsyABcREZE59OeQtKiVidKFa9I8FoVIOBsGSCYICQlR/wYFBVm7KERE5ADnFBnt2hJkQmyZFmXvvU2a7TNHjhxONdE2pxoxQUxMDO7cuYN06dIlmIdHmt8S6+WW2Hq5epAg6+bNmzY1ZHtSr8Ga+zTl8cZum9J2yd3P4+zcxzmx+3icLfN4Rz7OctqV4CgwMNCik1e/fv1azR+nFU9PT3h7e8NZsAbJBPJBzp07d6L3ubm5JfqlSWq9kPW29IOaXFmttU9THm/stiltl9z9PM7OfZyTu4/HWdvHO/pxtlTNUVwSzDhTQKM1JmlrRHKUTFlviyxR1tTu05THG7ttStsldz+Ps3MfZ1Oe39p4nJ3jOJPlsInNQWdyJuvjcXYOPM7OgcfZ+bAGyQq8vLwwatQo9S85Lh5n58Dj7Bx4nJ0Pa5CIiIiIDLAGiYiIiMgAAyQiIiIiAwyQiIiIiAwwQCIiIiIywAAplXbv3o3mzZurEVFldO1169alep979+5FjRo1kDlzZvj4+KBYsWL47rvvNCkv2c5xXrNmDd566y1kzZpVdRuuVq0atm7dqkl5yXaO8927d9GxY0cUKVJEDTb74YcfalJWsp1jfuLECdSqVUsNyiijbU+aNMkiZaW0xQAplUJDQ1GmTBnMnDlTs336+flh0KBB6ot79uxZjBgxQi1z5szR7DnI+sdZjq8ESJs2bcLhw4dRt25d9UN99OhRzZ6DrH+cw8PDVRAs32HZNznWMZfxkRo2bIi8efOq7/HkyZMxevRo/l47AunmT9qQt3Pt2rXx1r1+/Vr38ccf6wIDA3W+vr66ypUr6/7880+T992qVStd586dNSwt2eJxLl68uG7MmDEalpZs6TjXqVNHN2TIEAuUlqx1zGfNmqXLmDGjLjw8PHbdp59+qitatGialp20xxokC5OaoP3792PFihWqGrZt27Zo3LgxLl68aPQ+pEZh3759qFOnjkXLStY9zjIZskxgmSlTJouWlax7nMmxjrncV7t27Xiz3Ddq1Ajnz5/H06dPrVhySjULBF1Oy/Dq4/r16zo3Nzfd7du3421Xv3593eeff57i/nLlyqXz9PTUubq66saOHWuRMpP1j7PexIkT1ZXo/fv3NS0v2c5xZg2S4x3zt956S9enT594958+fVrt68yZM2lUcrIE99SHWJSUkydPIjo6WiVnGuYkSAK28Pf3j13fuXNnBAcHx97es2cPXr58ib///hufffYZChUqhA4dOqThK6C0OM5i2bJlGDNmDNavX49s2bKlUckprY8zOd4xJ8fFAMmCJLhxc3NTiXvyb1z6H9Jjx47FrjOcADF//vzq31KlSuH+/fsq8Y8BkuMdZ6m679WrF37++Wc0aNAgjUpNaX2cyTGPeY4cOdTvc1z623If2S8GSBZUrlw5dfXx4MED1QU0MVIrZGx+ily1kGMd5+XLl+P9999XQVKzZs0sXFKyle8zOc4xl+E5vvzyS0RGRsLDw0Ot++OPP1C0aFFkzJgxjUtMWmKApMEVxqVLl2JvX716VV1FSqKtVMt26tQJXbt2xbfffqu+bA8fPsT27dtRunTpJE+I0t00T548avwjfXfwb775BoMHD06z10WWP87SrNatWzdMmzYNVapUwb1799R6Gfsqffr0afbayLLHOW7NkuxfHiO3Jam3ePHiafK6yHLHXMa4kubxnj174tNPP8WpU6fUd5pj1zkAi2Q2ORHp7ilvo+HSrVs3dX9ERIRu5MiRunz58uk8PDx0OXPmVF32T5w4keQ+p0+fritRooTqUhoQEKArV66c6koaHR2dhq+MLH2cJWE3uX2SYxxnkdg+8+bNm0aviix9zI8fP66rWbOmzsvLS3Wu+frrr634ikgrLvI/awdpRERERLaE4yARERERGWCARERERGSAARIRERGRAQZIRERERAYYIBEREREZYIBEREREZIABEhEREZEBBkhEREREBhggERERERlggERESfrss8/g5eWl5psiInImnGqEiJL0/PlzLFmyBB988AEuXrzI2eqJyGmwBomIkpQ+fXo1S7mrqytOnjxp7eIQEaUZBkhElKyoqCj4+vri1KlT1i4KEVGaYYBERMkaMWIEXr58yQCJiJwKAyQiStLhw4cRHByMZs2axQuQnj17hjlz5li1bERElsQkbSJKVExMDCpXrow6deqgSpUq6Ny5M0JDQ+Hh4YFr166hTZs2OHTokLWLSURkEaxBIqJEzZgxA48ePcLYsWNRqlQpREZG4ty5c+q+L7/8EmfOnEHZsmXV/WLixIkoWbKk2nbp0qVqnQRSpUuXxnvvvYc33ngD3bp1UzlNSW1PRGQrWINERAncvn1bBTTLly9XzWsS1Pj7+2PhwoXo0KFDghqkgwcPol+/fvjrr78QFhaGSpUqYc+ePYiIiECBAgVw4MABVKxYUY2n1LBhQ5QoUSLR7QMDA6390omIFNYgEVECgwcPRpMmTVRwJNzd3VXAlFSitgQ6rVu3hre3NzJlyoT69euroEnI2EkSHIn27dtj7969yW5PRGQL3K1dACKyLb/99ht27NiBs2fPxlsvTWHm9GRzcXGJ93fc20REtopNbERkssePH6N69eo4f/68ui1NbYk1mYWHh6smNrm/fPnyKtH7rbfeSrKJLWfOnNZ+aURECmuQiMhkmTNnVgGP1Cq1bdsWI0eOVP9WqFBB1RCNGTNGBTuSqySJ2JKQfeLECRUISR6S9IRLbHsiIlvBGiQishgOB0BE9opJ2kREREQGWINEREREZIA1SEREREQGGCARERERGWCARERERGSAARIRERGRAQZIRERERAYYIBEREREZYIBEREREZIABEhEREZEBBkhEREREBhggERERERlggERERERkgAESEREREeL7P/AJeR6TnDaPAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\", title=None):\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(metric_name)\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Grid over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Violin plots for robustness over p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_violin_by_param(df, param_col, metric_name=\"accuracy\", k_filter=None):\n",
        "    \"\"\"\n",
        "    Make a violin plot similar in style to the example figure:\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: metric_name (e.g. accuracy or foscttm)\n",
        "      - one violin per parameter value, with mean/extrema lines.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "\n",
        "    positions = np.arange(1, len(groups) + 1)  # positions for violins (1..N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,\n",
        "        showextrema=True,\n",
        "        showmedians=False\n",
        "    )\n",
        "\n",
        "    # Optional: make violins slightly transparent (not strictly necessary)\n",
        "    for body in parts['bodies']:\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    # Labeling\n",
        "    ax.set_xticks(positions)\n",
        "    xticklabels = [f\"{param_col}={g}\" for g in groups]\n",
        "    ax.set_xticklabels(xticklabels, rotation=25, ha=\"right\")\n",
        "    ax.set_ylabel(metric_name)\n",
        "    ax.set_title(f\"{metric_name} across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(bottom=0.0)  # if metric is in [0,1], keeps it tidy\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all three robustness plots\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # or \"foscttm\"\n",
        "    )\n",
        "    plot_lambda_grid(df_slice, metric_name=\"accuracy\")\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(df_all, param_col=\"p\", metric_name=\"accuracy\", k_filter=5)\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(df_all, param_col=\"reach\", metric_name=\"accuracy\", k_filter=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b26171",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\", title=None, out_file=\"lambda_grid.pdf\"):\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(metric_name)\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Grid over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Violin plots for robustness over p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_violin_by_param(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    out_file=\"violin.pdf\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Violin plot:\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: metric_name (e.g. accuracy or foscttm)\n",
        "      - one violin per parameter value, with mean/extrema lines.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    if len(groups) == 0:\n",
        "        raise ValueError(f\"No valid rows for param {param_col} after filtering.\")\n",
        "\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "    positions = np.arange(1, len(groups) + 1)  # positions for violins (1..N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,\n",
        "        showextrema=True,\n",
        "        showmedians=False\n",
        "    )\n",
        "\n",
        "    for body in parts['bodies']:\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    # Labeling\n",
        "    ax.set_xticks(positions)\n",
        "    # Shorter tick labels: \"0.1\", \"1.0\", etc.\n",
        "    xticklabels = [str(g) for g in groups]\n",
        "    ax.set_xticklabels(xticklabels, rotation=25, ha=\"right\")\n",
        "\n",
        "    ax.set_ylabel(metric_name)\n",
        "    ax.set_xlabel(param_col)\n",
        "    ax.set_title(f\"{metric_name} across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(0.0, 1.0)  # accuracy/FOSCTTM in [0,1]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all robustness plots and save as PDF\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # or \"foscttm\"\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "022cc53c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\", title=None, out_file=\"lambda_grid.pdf\"):\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(metric_name)\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Grid over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Violin plots for robustness over p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_violin_by_param(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    out_file=\"violin.pdf\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Violin plot:\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: metric_name (e.g. accuracy or foscttm)\n",
        "      - one violin per parameter value, with mean/extrema lines.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    if len(groups) == 0:\n",
        "        raise ValueError(f\"No valid rows for param {param_col} after filtering.\")\n",
        "\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "    positions = np.arange(1, len(groups) + 1)  # positions for violins (1..N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,\n",
        "        showextrema=True,\n",
        "        showmedians=False\n",
        "    )\n",
        "\n",
        "    for body in parts['bodies']:\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    # Labeling\n",
        "    ax.set_xticks(positions)\n",
        "    # Shorter tick labels: \"0.1\", \"1.0\", etc.\n",
        "    xticklabels = [str(g) for g in groups]\n",
        "    ax.set_xticklabels(xticklabels, rotation=25, ha=\"right\")\n",
        "\n",
        "    ax.set_ylabel(metric_name)\n",
        "    ax.set_xlabel(param_col)\n",
        "    ax.set_title(f\"{metric_name} across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(0.0, 1.0)  # accuracy/FOSCTTM in [0,1]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all robustness plots and save as PDF\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # or \"foscttm\"\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "52376380",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 550x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 550x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\", title=None):\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(metric_name)\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Grid over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Bar + error + jitter for p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_param_bar_with_jitter(df, param_col, metric_name=\"accuracy\", k_filter=None):\n",
        "    \"\"\"\n",
        "    Bar chart robustness plot:\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: mean of metric_name\n",
        "      - error bars: std of metric_name\n",
        "      - jittered points: all individual runs for that setting\n",
        "\n",
        "    Optionally filter to a fixed k (e.g. k=5).\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    stats = (\n",
        "        sub.groupby(param_col)[metric_name]\n",
        "        .agg([\"mean\", \"std\"])\n",
        "        .reset_index()\n",
        "        .sort_values(param_col)\n",
        "    )\n",
        "\n",
        "    # For jittered points, collect list of arrays per group\n",
        "    values_per_group = [\n",
        "        sub.loc[sub[param_col] == g, metric_name].values for g in groups\n",
        "    ]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5.5, 4))\n",
        "\n",
        "    x = np.arange(len(groups))\n",
        "    means = stats[\"mean\"].values\n",
        "    stds = stats[\"std\"].values\n",
        "\n",
        "    # Bars with error bars\n",
        "    ax.bar(x, means, yerr=stds, capsize=4, alpha=0.8)\n",
        "\n",
        "    # Add jittered individual points\n",
        "    for xi, vals in zip(x, values_per_group):\n",
        "        jitter = (np.random.rand(len(vals)) - 0.5) * 0.2  # width of jitter\n",
        "        ax.scatter(\n",
        "            np.full_like(vals, xi, dtype=float) + jitter,\n",
        "            vals,\n",
        "            s=18,\n",
        "            alpha=0.7,\n",
        "            color=\"black\"\n",
        "        )\n",
        "\n",
        "    # Labels\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([str(g) for g in groups])\n",
        "    ax.set_xlabel(param_col)\n",
        "    ax.set_ylabel(metric_name)\n",
        "    ax.set_title(f\"{metric_name} across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(bottom=0.0)  # assuming metric in [0,1]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all three plots\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # or \"foscttm\"\n",
        "    )\n",
        "    plot_lambda_grid(df_slice, metric_name=\"accuracy\")\n",
        "\n",
        "    # 3) Bar+jitter: robustness over p (aggregate over λ and reach)\n",
        "    plot_param_bar_with_jitter(df_all, param_col=\"p\", metric_name=\"accuracy\", k_filter=5)\n",
        "\n",
        "    # 4) Bar+jitter: robustness over reach (aggregate over λ and p)\n",
        "    plot_param_bar_with_jitter(df_all, param_col=\"reach\", metric_name=\"accuracy\", k_filter=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3a4988",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\",\n",
        "                     title=None, out_file=\"lambda_grid_accuracy.pdf\"):\n",
        "    \"\"\"\n",
        "    Plot Label Transfer Accuracy (LTA) over the (lambda_topo, lambda_reg) grid.\n",
        "    \"\"\"\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values  # column name is 'accuracy'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(\"Label Transfer Accuracy (LTA)\")\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Label Transfer Accuracy (LTA) over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Violin plots for robustness over p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_violin_by_param(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    out_file=\"violin.pdf\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Violin plot of Label Transfer Accuracy (LTA):\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: LTA (stored in df[metric_name])\n",
        "      - one violin per parameter value, with mean/extrema lines.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    if len(groups) == 0:\n",
        "        raise ValueError(f\"No valid rows for param {param_col} after filtering.\")\n",
        "\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "    positions = np.arange(1, len(groups) + 1)  # positions for violins (1..N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,\n",
        "        showextrema=True,\n",
        "        showmedians=False\n",
        "    )\n",
        "\n",
        "    for body in parts['bodies']:\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    # Labeling\n",
        "    ax.set_xticks(positions)\n",
        "    xticklabels = [str(g) for g in groups]\n",
        "    ax.set_xticklabels(xticklabels, rotation=25, ha=\"right\")\n",
        "\n",
        "    ax.set_ylabel(\"Label Transfer Accuracy (LTA)\")\n",
        "    ax.set_xlabel(param_col)\n",
        "    ax.set_title(f\"Label Transfer Accuracy (LTA) across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(0.0, 1.0)  # LTA in [0,1]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all robustness plots and save as PDF\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # column name\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # or \"foscttm\"\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45cc70c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\",\n",
        "                     title=None, out_file=\"lambda_grid_accuracy.pdf\"):\n",
        "    \"\"\"\n",
        "    Plot Label Transfer Accuracy (LTA) over the (lambda_topo, lambda_reg) grid.\n",
        "    \"\"\"\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values  # column name is 'accuracy'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(\"Label Transfer Accuracy (LTA)\")\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Label Transfer Accuracy (LTA) over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Violin plots for robustness over p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_violin_by_param(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    out_file=\"violin.pdf\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Violin plot of Label Transfer Accuracy (LTA):\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: LTA (stored in df[metric_name])\n",
        "      - one violin per parameter value, with mean/extrema lines.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    if len(groups) == 0:\n",
        "        raise ValueError(f\"No valid rows for param {param_col} after filtering.\")\n",
        "\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "    positions = np.arange(1, len(groups) + 1)  # positions for violins (1..N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,\n",
        "        showextrema=True,\n",
        "        showmedians=False\n",
        "    )\n",
        "\n",
        "    for body in parts['bodies']:\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    # Labeling\n",
        "    ax.set_xticks(positions)\n",
        "    xticklabels = [str(g) for g in groups]\n",
        "    ax.set_xticklabels(xticklabels, rotation=25, ha=\"right\")\n",
        "\n",
        "    ax.set_ylabel(\"Label Transfer Accuracy (LTA)\")\n",
        "    ax.set_xlabel(param_col)\n",
        "    ax.set_title(f\"Label Transfer Accuracy (LTA) across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(0.0, 1.0)  # LTA in [0,1]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all robustness plots and save as PDF\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # column name\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "41bf85be",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load results and convert to DataFrame\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def load_grid_results(path=\"alignment_tuning_results.pkl\"):\n",
        "    \"\"\"\n",
        "    Load the dictionary produced by run_alignment_grid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : dict\n",
        "        keys: (p, k, lambda_topo, lambda_reg, reach)\n",
        "        values: result dict with key 'metrics' containing 'accuracy', 'foscttm', etc.\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "\n",
        "def results_to_df(results):\n",
        "    \"\"\"\n",
        "    Convert results dict into a tidy DataFrame with columns:\n",
        "      p, k, lambda_topo, lambda_reg, reach, accuracy, foscttm, ...\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for (p, k, lambda_topo, lambda_reg, reach), res in results.items():\n",
        "        row = {\n",
        "            \"p\": p,\n",
        "            \"k\": k,\n",
        "            \"lambda_topo\": lambda_topo,\n",
        "            \"lambda_reg\": lambda_reg,\n",
        "            \"reach\": reach,\n",
        "        }\n",
        "        metrics = res.get(\"metrics\", {})\n",
        "        for name, val in metrics.items():\n",
        "            if isinstance(val, (list, tuple, np.ndarray)):\n",
        "                row[name] = float(np.mean(val))\n",
        "            else:\n",
        "                row[name] = float(val)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) λ_topo vs λ_reg grid (2D scatter, 1eXX ticks)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_lambda_grid_df(df, p=None, k=None, reach=None, metric_name=\"accuracy\"):\n",
        "    sub = df.copy()\n",
        "    if p is not None:\n",
        "        sub = sub[sub[\"p\"] == p]\n",
        "    if k is not None:\n",
        "        sub = sub[sub[\"k\"] == k]\n",
        "    if reach is not None:\n",
        "        sub = sub[sub[\"reach\"] == reach]\n",
        "\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No matching configurations for given (p, k, reach).\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def plot_lambda_grid(df_slice, metric_name=\"accuracy\",\n",
        "                     title=None, out_file=\"lambda_grid_accuracy.pdf\"):\n",
        "    \"\"\"\n",
        "    Plot Label Transfer Accuracy (LTA) over the (lambda_topo, lambda_reg) grid.\n",
        "    \"\"\"\n",
        "    x = df_slice[\"lambda_topo\"].values\n",
        "    y = df_slice[\"lambda_reg\"].values\n",
        "    m = df_slice[metric_name].values  # column name is 'accuracy'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sc = ax.scatter(x, y, c=m, s=80, cmap=\"viridis\", edgecolors=\"k\")\n",
        "\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.set_xlabel(r\"$\\lambda_{\\mathrm{topo}}$\")\n",
        "    ax.set_ylabel(r\"$\\lambda_{\\mathrm{reg}}$\")\n",
        "\n",
        "    xticks = sorted(np.unique(x))\n",
        "    yticks = sorted(np.unique(y))\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_yticks(yticks)\n",
        "\n",
        "    def exp_notation(val, pos):\n",
        "        if val <= 0 or not np.isfinite(val):\n",
        "            return \"\"\n",
        "        exp = int(np.round(np.log10(val)))\n",
        "        return f\"1e{exp}\"\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(exp_notation))\n",
        "\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(\"Label Transfer Accuracy (LTA)\")\n",
        "\n",
        "    if title is None:\n",
        "        up = df_slice[\"p\"].unique()\n",
        "        uk = df_slice[\"k\"].unique()\n",
        "        ur = df_slice[\"reach\"].unique()\n",
        "        title = r\"Label Transfer Accuracy (LTA) over $\\lambda_{\\mathrm{topo}}$ and $\\lambda_{\\mathrm{reg}}$\"\n",
        "        if len(up) == 1 and len(uk) == 1 and len(ur) == 1:\n",
        "            title += f\" (p={up[0]}, k={uk[0]}, reach={ur[0]})\"\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Violin plots for robustness over p and reach\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def plot_violin_by_param(\n",
        "    df,\n",
        "    param_col,\n",
        "    metric_name=\"accuracy\",\n",
        "    k_filter=None,\n",
        "    out_file=\"violin.pdf\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Violin plot of Label Transfer Accuracy (LTA):\n",
        "      - x: discrete values of param_col (e.g. p or reach)\n",
        "      - y: LTA (stored in df[metric_name])\n",
        "      - one violin per parameter value, with mean/extrema lines.\n",
        "    \"\"\"\n",
        "    sub = df.copy()\n",
        "    if k_filter is not None:\n",
        "        sub = sub[sub[\"k\"] == k_filter]\n",
        "    sub = sub[np.isfinite(sub[metric_name])]\n",
        "\n",
        "    groups = sorted(sub[param_col].unique())\n",
        "    if len(groups) == 0:\n",
        "        raise ValueError(f\"No valid rows for param {param_col} after filtering.\")\n",
        "\n",
        "    data = [sub.loc[sub[param_col] == g, metric_name].values for g in groups]\n",
        "    positions = np.arange(1, len(groups) + 1)  # positions for violins (1..N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    parts = ax.violinplot(\n",
        "        data,\n",
        "        positions=positions,\n",
        "        showmeans=True,\n",
        "        showextrema=True,\n",
        "        showmedians=False\n",
        "    )\n",
        "\n",
        "    for body in parts['bodies']:\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    # Labeling\n",
        "    ax.set_xticks(positions)\n",
        "    xticklabels = [str(g) for g in groups]\n",
        "    ax.set_xticklabels(xticklabels, rotation=25, ha=\"right\")\n",
        "\n",
        "    ax.set_ylabel(\"Label Transfer Accuracy (LTA)\")\n",
        "    ax.set_xlabel(param_col)\n",
        "    ax.set_title(f\"Label Transfer Accuracy (LTA) across {param_col}\")\n",
        "\n",
        "    ax.set_ylim(0.0, 1.0)  # LTA in [0,1]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Example: generate all robustness plots and save as PDF\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # column name\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and build DataFrame\n",
        "    results = load_grid_results(\"alignment_tuning_results.pkl\")\n",
        "    df_all = results_to_df(results)\n",
        "\n",
        "    # 2) λ_topo vs λ_reg grid for a fixed (p, k, reach)\n",
        "    p_fixed = 8\n",
        "    k_fixed = 5\n",
        "    reach_fixed = 5.0\n",
        "\n",
        "    df_slice = extract_lambda_grid_df(\n",
        "        df_all,\n",
        "        p=p_fixed,\n",
        "        k=k_fixed,\n",
        "        reach=reach_fixed,\n",
        "        metric_name=\"accuracy\"   # or \"foscttm\"\n",
        "    )\n",
        "    plot_lambda_grid(\n",
        "        df_slice,\n",
        "        metric_name=\"accuracy\",\n",
        "        out_file=\"lambda_grid_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 3) Violin: robustness over p (aggregate over λ and reach)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"p\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_p_accuracy.pdf\"\n",
        "    )\n",
        "\n",
        "    # 4) Violin: robustness over reach (aggregate over λ and p)\n",
        "    plot_violin_by_param(\n",
        "        df_all,\n",
        "        param_col=\"reach\",\n",
        "        metric_name=\"accuracy\",\n",
        "        k_filter=5,\n",
        "        out_file=\"violin_reach_accuracy.pdf\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc53afd8",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python (py311-vscode)",
      "language": "python",
      "name": "py311-vscode"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
